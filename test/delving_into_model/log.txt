**************************************************
resnet18
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
       BasicBlock-11           [-1, 64, 64, 32]               0
           Conv2d-12           [-1, 64, 64, 32]          36,864
      BatchNorm2d-13           [-1, 64, 64, 32]             128
             ReLU-14           [-1, 64, 64, 32]               0
           Conv2d-15           [-1, 64, 64, 32]          36,864
      BatchNorm2d-16           [-1, 64, 64, 32]             128
             ReLU-17           [-1, 64, 64, 32]               0
       BasicBlock-18           [-1, 64, 64, 32]               0
           Conv2d-19          [-1, 128, 32, 16]          73,728
      BatchNorm2d-20          [-1, 128, 32, 16]             256
             ReLU-21          [-1, 128, 32, 16]               0
           Conv2d-22          [-1, 128, 32, 16]         147,456
      BatchNorm2d-23          [-1, 128, 32, 16]             256
           Conv2d-24          [-1, 128, 32, 16]           8,192
      BatchNorm2d-25          [-1, 128, 32, 16]             256
             ReLU-26          [-1, 128, 32, 16]               0
       BasicBlock-27          [-1, 128, 32, 16]               0
           Conv2d-28          [-1, 128, 32, 16]         147,456
      BatchNorm2d-29          [-1, 128, 32, 16]             256
             ReLU-30          [-1, 128, 32, 16]               0
           Conv2d-31          [-1, 128, 32, 16]         147,456
      BatchNorm2d-32          [-1, 128, 32, 16]             256
             ReLU-33          [-1, 128, 32, 16]               0
       BasicBlock-34          [-1, 128, 32, 16]               0
           Conv2d-35           [-1, 256, 16, 8]         294,912
      BatchNorm2d-36           [-1, 256, 16, 8]             512
             ReLU-37           [-1, 256, 16, 8]               0
           Conv2d-38           [-1, 256, 16, 8]         589,824
      BatchNorm2d-39           [-1, 256, 16, 8]             512
           Conv2d-40           [-1, 256, 16, 8]          32,768
      BatchNorm2d-41           [-1, 256, 16, 8]             512
             ReLU-42           [-1, 256, 16, 8]               0
       BasicBlock-43           [-1, 256, 16, 8]               0
           Conv2d-44           [-1, 256, 16, 8]         589,824
      BatchNorm2d-45           [-1, 256, 16, 8]             512
             ReLU-46           [-1, 256, 16, 8]               0
           Conv2d-47           [-1, 256, 16, 8]         589,824
      BatchNorm2d-48           [-1, 256, 16, 8]             512
             ReLU-49           [-1, 256, 16, 8]               0
       BasicBlock-50           [-1, 256, 16, 8]               0
           Conv2d-51           [-1, 512, 16, 8]       1,179,648
      BatchNorm2d-52           [-1, 512, 16, 8]           1,024
             ReLU-53           [-1, 512, 16, 8]               0
           Conv2d-54           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-55           [-1, 512, 16, 8]           1,024
           Conv2d-56           [-1, 512, 16, 8]         131,072
      BatchNorm2d-57           [-1, 512, 16, 8]           1,024
             ReLU-58           [-1, 512, 16, 8]               0
       BasicBlock-59           [-1, 512, 16, 8]               0
           Conv2d-60           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-61           [-1, 512, 16, 8]           1,024
             ReLU-62           [-1, 512, 16, 8]               0
           Conv2d-63           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-64           [-1, 512, 16, 8]           1,024
             ReLU-65           [-1, 512, 16, 8]               0
       BasicBlock-66           [-1, 512, 16, 8]               0
================================================================
Total params: 11,176,512
Trainable params: 11,176,512
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 47.00
Params size (MB): 42.64
Estimated Total Size (MB): 90.01
----------------------------------------------------------------
**************************************************
resnet34
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
       BasicBlock-11           [-1, 64, 64, 32]               0
           Conv2d-12           [-1, 64, 64, 32]          36,864
      BatchNorm2d-13           [-1, 64, 64, 32]             128
             ReLU-14           [-1, 64, 64, 32]               0
           Conv2d-15           [-1, 64, 64, 32]          36,864
      BatchNorm2d-16           [-1, 64, 64, 32]             128
             ReLU-17           [-1, 64, 64, 32]               0
       BasicBlock-18           [-1, 64, 64, 32]               0
           Conv2d-19           [-1, 64, 64, 32]          36,864
      BatchNorm2d-20           [-1, 64, 64, 32]             128
             ReLU-21           [-1, 64, 64, 32]               0
           Conv2d-22           [-1, 64, 64, 32]          36,864
      BatchNorm2d-23           [-1, 64, 64, 32]             128
             ReLU-24           [-1, 64, 64, 32]               0
       BasicBlock-25           [-1, 64, 64, 32]               0
           Conv2d-26          [-1, 128, 32, 16]          73,728
      BatchNorm2d-27          [-1, 128, 32, 16]             256
             ReLU-28          [-1, 128, 32, 16]               0
           Conv2d-29          [-1, 128, 32, 16]         147,456
      BatchNorm2d-30          [-1, 128, 32, 16]             256
           Conv2d-31          [-1, 128, 32, 16]           8,192
      BatchNorm2d-32          [-1, 128, 32, 16]             256
             ReLU-33          [-1, 128, 32, 16]               0
       BasicBlock-34          [-1, 128, 32, 16]               0
           Conv2d-35          [-1, 128, 32, 16]         147,456
      BatchNorm2d-36          [-1, 128, 32, 16]             256
             ReLU-37          [-1, 128, 32, 16]               0
           Conv2d-38          [-1, 128, 32, 16]         147,456
      BatchNorm2d-39          [-1, 128, 32, 16]             256
             ReLU-40          [-1, 128, 32, 16]               0
       BasicBlock-41          [-1, 128, 32, 16]               0
           Conv2d-42          [-1, 128, 32, 16]         147,456
      BatchNorm2d-43          [-1, 128, 32, 16]             256
             ReLU-44          [-1, 128, 32, 16]               0
           Conv2d-45          [-1, 128, 32, 16]         147,456
      BatchNorm2d-46          [-1, 128, 32, 16]             256
             ReLU-47          [-1, 128, 32, 16]               0
       BasicBlock-48          [-1, 128, 32, 16]               0
           Conv2d-49          [-1, 128, 32, 16]         147,456
      BatchNorm2d-50          [-1, 128, 32, 16]             256
             ReLU-51          [-1, 128, 32, 16]               0
           Conv2d-52          [-1, 128, 32, 16]         147,456
      BatchNorm2d-53          [-1, 128, 32, 16]             256
             ReLU-54          [-1, 128, 32, 16]               0
       BasicBlock-55          [-1, 128, 32, 16]               0
           Conv2d-56           [-1, 256, 16, 8]         294,912
      BatchNorm2d-57           [-1, 256, 16, 8]             512
             ReLU-58           [-1, 256, 16, 8]               0
           Conv2d-59           [-1, 256, 16, 8]         589,824
      BatchNorm2d-60           [-1, 256, 16, 8]             512
           Conv2d-61           [-1, 256, 16, 8]          32,768
      BatchNorm2d-62           [-1, 256, 16, 8]             512
             ReLU-63           [-1, 256, 16, 8]               0
       BasicBlock-64           [-1, 256, 16, 8]               0
           Conv2d-65           [-1, 256, 16, 8]         589,824
      BatchNorm2d-66           [-1, 256, 16, 8]             512
             ReLU-67           [-1, 256, 16, 8]               0
           Conv2d-68           [-1, 256, 16, 8]         589,824
      BatchNorm2d-69           [-1, 256, 16, 8]             512
             ReLU-70           [-1, 256, 16, 8]               0
       BasicBlock-71           [-1, 256, 16, 8]               0
           Conv2d-72           [-1, 256, 16, 8]         589,824
      BatchNorm2d-73           [-1, 256, 16, 8]             512
             ReLU-74           [-1, 256, 16, 8]               0
           Conv2d-75           [-1, 256, 16, 8]         589,824
      BatchNorm2d-76           [-1, 256, 16, 8]             512
             ReLU-77           [-1, 256, 16, 8]               0
       BasicBlock-78           [-1, 256, 16, 8]               0
           Conv2d-79           [-1, 256, 16, 8]         589,824
      BatchNorm2d-80           [-1, 256, 16, 8]             512
             ReLU-81           [-1, 256, 16, 8]               0
           Conv2d-82           [-1, 256, 16, 8]         589,824
      BatchNorm2d-83           [-1, 256, 16, 8]             512
             ReLU-84           [-1, 256, 16, 8]               0
       BasicBlock-85           [-1, 256, 16, 8]               0
           Conv2d-86           [-1, 256, 16, 8]         589,824
      BatchNorm2d-87           [-1, 256, 16, 8]             512
             ReLU-88           [-1, 256, 16, 8]               0
           Conv2d-89           [-1, 256, 16, 8]         589,824
      BatchNorm2d-90           [-1, 256, 16, 8]             512
             ReLU-91           [-1, 256, 16, 8]               0
       BasicBlock-92           [-1, 256, 16, 8]               0
           Conv2d-93           [-1, 256, 16, 8]         589,824
      BatchNorm2d-94           [-1, 256, 16, 8]             512
             ReLU-95           [-1, 256, 16, 8]               0
           Conv2d-96           [-1, 256, 16, 8]         589,824
      BatchNorm2d-97           [-1, 256, 16, 8]             512
             ReLU-98           [-1, 256, 16, 8]               0
       BasicBlock-99           [-1, 256, 16, 8]               0
          Conv2d-100           [-1, 512, 16, 8]       1,179,648
     BatchNorm2d-101           [-1, 512, 16, 8]           1,024
            ReLU-102           [-1, 512, 16, 8]               0
          Conv2d-103           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-104           [-1, 512, 16, 8]           1,024
          Conv2d-105           [-1, 512, 16, 8]         131,072
     BatchNorm2d-106           [-1, 512, 16, 8]           1,024
            ReLU-107           [-1, 512, 16, 8]               0
      BasicBlock-108           [-1, 512, 16, 8]               0
          Conv2d-109           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-110           [-1, 512, 16, 8]           1,024
            ReLU-111           [-1, 512, 16, 8]               0
          Conv2d-112           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-113           [-1, 512, 16, 8]           1,024
            ReLU-114           [-1, 512, 16, 8]               0
      BasicBlock-115           [-1, 512, 16, 8]               0
          Conv2d-116           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-117           [-1, 512, 16, 8]           1,024
            ReLU-118           [-1, 512, 16, 8]               0
          Conv2d-119           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-120           [-1, 512, 16, 8]           1,024
            ReLU-121           [-1, 512, 16, 8]               0
      BasicBlock-122           [-1, 512, 16, 8]               0
================================================================
Total params: 21,284,672
Trainable params: 21,284,672
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 71.50
Params size (MB): 81.19
Estimated Total Size (MB): 153.07
----------------------------------------------------------------
**************************************************
resnet50
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
             ReLU-15          [-1, 256, 64, 32]               0
       Bottleneck-16          [-1, 256, 64, 32]               0
           Conv2d-17           [-1, 64, 64, 32]          16,384
      BatchNorm2d-18           [-1, 64, 64, 32]             128
             ReLU-19           [-1, 64, 64, 32]               0
           Conv2d-20           [-1, 64, 64, 32]          36,864
      BatchNorm2d-21           [-1, 64, 64, 32]             128
             ReLU-22           [-1, 64, 64, 32]               0
           Conv2d-23          [-1, 256, 64, 32]          16,384
      BatchNorm2d-24          [-1, 256, 64, 32]             512
             ReLU-25          [-1, 256, 64, 32]               0
       Bottleneck-26          [-1, 256, 64, 32]               0
           Conv2d-27           [-1, 64, 64, 32]          16,384
      BatchNorm2d-28           [-1, 64, 64, 32]             128
             ReLU-29           [-1, 64, 64, 32]               0
           Conv2d-30           [-1, 64, 64, 32]          36,864
      BatchNorm2d-31           [-1, 64, 64, 32]             128
             ReLU-32           [-1, 64, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          16,384
      BatchNorm2d-34          [-1, 256, 64, 32]             512
             ReLU-35          [-1, 256, 64, 32]               0
       Bottleneck-36          [-1, 256, 64, 32]               0
***************************************************************************
           Conv2d-37          [-1, 128, 64, 32]          32,768
      BatchNorm2d-38          [-1, 128, 64, 32]             256
             ReLU-39          [-1, 128, 64, 32]               0
           Conv2d-40          [-1, 128, 32, 16]         147,456
      BatchNorm2d-41          [-1, 128, 32, 16]             256
             ReLU-42          [-1, 128, 32, 16]               0
           Conv2d-43          [-1, 512, 32, 16]          65,536
      BatchNorm2d-44          [-1, 512, 32, 16]           1,024
           Conv2d-45          [-1, 512, 32, 16]         131,072
      BatchNorm2d-46          [-1, 512, 32, 16]           1,024
             ReLU-47          [-1, 512, 32, 16]               0
       Bottleneck-48          [-1, 512, 32, 16]               0
           Conv2d-49          [-1, 128, 32, 16]          65,536
      BatchNorm2d-50          [-1, 128, 32, 16]             256
             ReLU-51          [-1, 128, 32, 16]               0
           Conv2d-52          [-1, 128, 32, 16]         147,456
      BatchNorm2d-53          [-1, 128, 32, 16]             256
             ReLU-54          [-1, 128, 32, 16]               0
           Conv2d-55          [-1, 512, 32, 16]          65,536
      BatchNorm2d-56          [-1, 512, 32, 16]           1,024
             ReLU-57          [-1, 512, 32, 16]               0
       Bottleneck-58          [-1, 512, 32, 16]               0
           Conv2d-59          [-1, 128, 32, 16]          65,536
      BatchNorm2d-60          [-1, 128, 32, 16]             256
             ReLU-61          [-1, 128, 32, 16]               0
           Conv2d-62          [-1, 128, 32, 16]         147,456
      BatchNorm2d-63          [-1, 128, 32, 16]             256
             ReLU-64          [-1, 128, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]          65,536
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 128, 32, 16]          65,536
      BatchNorm2d-70          [-1, 128, 32, 16]             256
             ReLU-71          [-1, 128, 32, 16]               0
           Conv2d-72          [-1, 128, 32, 16]         147,456
      BatchNorm2d-73          [-1, 128, 32, 16]             256
             ReLU-74          [-1, 128, 32, 16]               0
           Conv2d-75          [-1, 512, 32, 16]          65,536
      BatchNorm2d-76          [-1, 512, 32, 16]           1,024
             ReLU-77          [-1, 512, 32, 16]               0
       Bottleneck-78          [-1, 512, 32, 16]               0
***************************************************************************
           Conv2d-79          [-1, 256, 32, 16]         131,072
      BatchNorm2d-80          [-1, 256, 32, 16]             512
             ReLU-81          [-1, 256, 32, 16]               0
           Conv2d-82           [-1, 256, 16, 8]         589,824
      BatchNorm2d-83           [-1, 256, 16, 8]             512
             ReLU-84           [-1, 256, 16, 8]               0
           Conv2d-85          [-1, 1024, 16, 8]         262,144
      BatchNorm2d-86          [-1, 1024, 16, 8]           2,048
           Conv2d-87          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-88          [-1, 1024, 16, 8]           2,048
             ReLU-89          [-1, 1024, 16, 8]               0
       Bottleneck-90          [-1, 1024, 16, 8]               0
           Conv2d-91           [-1, 256, 16, 8]         262,144
      BatchNorm2d-92           [-1, 256, 16, 8]             512
             ReLU-93           [-1, 256, 16, 8]               0
           Conv2d-94           [-1, 256, 16, 8]         589,824
      BatchNorm2d-95           [-1, 256, 16, 8]             512
             ReLU-96           [-1, 256, 16, 8]               0
           Conv2d-97          [-1, 1024, 16, 8]         262,144
      BatchNorm2d-98          [-1, 1024, 16, 8]           2,048
             ReLU-99          [-1, 1024, 16, 8]               0
      Bottleneck-100          [-1, 1024, 16, 8]               0
          Conv2d-101           [-1, 256, 16, 8]         262,144
     BatchNorm2d-102           [-1, 256, 16, 8]             512
            ReLU-103           [-1, 256, 16, 8]               0
          Conv2d-104           [-1, 256, 16, 8]         589,824
     BatchNorm2d-105           [-1, 256, 16, 8]             512
            ReLU-106           [-1, 256, 16, 8]               0
          Conv2d-107          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-108          [-1, 1024, 16, 8]           2,048
            ReLU-109          [-1, 1024, 16, 8]               0
      Bottleneck-110          [-1, 1024, 16, 8]               0
          Conv2d-111           [-1, 256, 16, 8]         262,144
     BatchNorm2d-112           [-1, 256, 16, 8]             512
            ReLU-113           [-1, 256, 16, 8]               0
          Conv2d-114           [-1, 256, 16, 8]         589,824
     BatchNorm2d-115           [-1, 256, 16, 8]             512
            ReLU-116           [-1, 256, 16, 8]               0
          Conv2d-117          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-118          [-1, 1024, 16, 8]           2,048
            ReLU-119          [-1, 1024, 16, 8]               0
      Bottleneck-120          [-1, 1024, 16, 8]               0
          Conv2d-121           [-1, 256, 16, 8]         262,144
     BatchNorm2d-122           [-1, 256, 16, 8]             512
            ReLU-123           [-1, 256, 16, 8]               0
          Conv2d-124           [-1, 256, 16, 8]         589,824
     BatchNorm2d-125           [-1, 256, 16, 8]             512
            ReLU-126           [-1, 256, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 256, 16, 8]         262,144
     BatchNorm2d-132           [-1, 256, 16, 8]             512
            ReLU-133           [-1, 256, 16, 8]               0
          Conv2d-134           [-1, 256, 16, 8]         589,824
     BatchNorm2d-135           [-1, 256, 16, 8]             512
            ReLU-136           [-1, 256, 16, 8]               0
          Conv2d-137          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-138          [-1, 1024, 16, 8]           2,048
            ReLU-139          [-1, 1024, 16, 8]               0
      Bottleneck-140          [-1, 1024, 16, 8]               0
          Conv2d-141           [-1, 512, 16, 8]         524,288
     BatchNorm2d-142           [-1, 512, 16, 8]           1,024
            ReLU-143           [-1, 512, 16, 8]               0
          Conv2d-144           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-145           [-1, 512, 16, 8]           1,024
            ReLU-146           [-1, 512, 16, 8]               0
          Conv2d-147          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-148          [-1, 2048, 16, 8]           4,096
          Conv2d-149          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-150          [-1, 2048, 16, 8]           4,096
            ReLU-151          [-1, 2048, 16, 8]               0
      Bottleneck-152          [-1, 2048, 16, 8]               0
          Conv2d-153           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-154           [-1, 512, 16, 8]           1,024
            ReLU-155           [-1, 512, 16, 8]               0
          Conv2d-156           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-157           [-1, 512, 16, 8]           1,024
            ReLU-158           [-1, 512, 16, 8]               0
          Conv2d-159          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-160          [-1, 2048, 16, 8]           4,096
            ReLU-161          [-1, 2048, 16, 8]               0
      Bottleneck-162          [-1, 2048, 16, 8]               0
          Conv2d-163           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-164           [-1, 512, 16, 8]           1,024
            ReLU-165           [-1, 512, 16, 8]               0
          Conv2d-166           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-167           [-1, 512, 16, 8]           1,024
            ReLU-168           [-1, 512, 16, 8]               0
          Conv2d-169          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-170          [-1, 2048, 16, 8]           4,096
            ReLU-171          [-1, 2048, 16, 8]               0
      Bottleneck-172          [-1, 2048, 16, 8]               0
================================================================
Total params: 23,508,032
Trainable params: 23,508,032
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 213.75
Params size (MB): 89.68
Estimated Total Size (MB): 303.80
----------------------------------------------------------------
**************************************************
resnet101
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
             ReLU-15          [-1, 256, 64, 32]               0
       Bottleneck-16          [-1, 256, 64, 32]               0
           Conv2d-17           [-1, 64, 64, 32]          16,384
      BatchNorm2d-18           [-1, 64, 64, 32]             128
             ReLU-19           [-1, 64, 64, 32]               0
           Conv2d-20           [-1, 64, 64, 32]          36,864
      BatchNorm2d-21           [-1, 64, 64, 32]             128
             ReLU-22           [-1, 64, 64, 32]               0
           Conv2d-23          [-1, 256, 64, 32]          16,384
      BatchNorm2d-24          [-1, 256, 64, 32]             512
             ReLU-25          [-1, 256, 64, 32]               0
       Bottleneck-26          [-1, 256, 64, 32]               0
           Conv2d-27           [-1, 64, 64, 32]          16,384
      BatchNorm2d-28           [-1, 64, 64, 32]             128
             ReLU-29           [-1, 64, 64, 32]               0
           Conv2d-30           [-1, 64, 64, 32]          36,864
      BatchNorm2d-31           [-1, 64, 64, 32]             128
             ReLU-32           [-1, 64, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          16,384
      BatchNorm2d-34          [-1, 256, 64, 32]             512
             ReLU-35          [-1, 256, 64, 32]               0
       Bottleneck-36          [-1, 256, 64, 32]               0
           Conv2d-37          [-1, 128, 64, 32]          32,768
      BatchNorm2d-38          [-1, 128, 64, 32]             256
             ReLU-39          [-1, 128, 64, 32]               0
           Conv2d-40          [-1, 128, 32, 16]         147,456
      BatchNorm2d-41          [-1, 128, 32, 16]             256
             ReLU-42          [-1, 128, 32, 16]               0
           Conv2d-43          [-1, 512, 32, 16]          65,536
      BatchNorm2d-44          [-1, 512, 32, 16]           1,024
           Conv2d-45          [-1, 512, 32, 16]         131,072
      BatchNorm2d-46          [-1, 512, 32, 16]           1,024
             ReLU-47          [-1, 512, 32, 16]               0
       Bottleneck-48          [-1, 512, 32, 16]               0
           Conv2d-49          [-1, 128, 32, 16]          65,536
      BatchNorm2d-50          [-1, 128, 32, 16]             256
             ReLU-51          [-1, 128, 32, 16]               0
           Conv2d-52          [-1, 128, 32, 16]         147,456
      BatchNorm2d-53          [-1, 128, 32, 16]             256
             ReLU-54          [-1, 128, 32, 16]               0
           Conv2d-55          [-1, 512, 32, 16]          65,536
      BatchNorm2d-56          [-1, 512, 32, 16]           1,024
             ReLU-57          [-1, 512, 32, 16]               0
       Bottleneck-58          [-1, 512, 32, 16]               0
           Conv2d-59          [-1, 128, 32, 16]          65,536
      BatchNorm2d-60          [-1, 128, 32, 16]             256
             ReLU-61          [-1, 128, 32, 16]               0
           Conv2d-62          [-1, 128, 32, 16]         147,456
      BatchNorm2d-63          [-1, 128, 32, 16]             256
             ReLU-64          [-1, 128, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]          65,536
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 128, 32, 16]          65,536
      BatchNorm2d-70          [-1, 128, 32, 16]             256
             ReLU-71          [-1, 128, 32, 16]               0
           Conv2d-72          [-1, 128, 32, 16]         147,456
      BatchNorm2d-73          [-1, 128, 32, 16]             256
             ReLU-74          [-1, 128, 32, 16]               0
           Conv2d-75          [-1, 512, 32, 16]          65,536
      BatchNorm2d-76          [-1, 512, 32, 16]           1,024
             ReLU-77          [-1, 512, 32, 16]               0
       Bottleneck-78          [-1, 512, 32, 16]               0
           Conv2d-79          [-1, 256, 32, 16]         131,072
      BatchNorm2d-80          [-1, 256, 32, 16]             512
             ReLU-81          [-1, 256, 32, 16]               0
           Conv2d-82           [-1, 256, 16, 8]         589,824
      BatchNorm2d-83           [-1, 256, 16, 8]             512
             ReLU-84           [-1, 256, 16, 8]               0
           Conv2d-85          [-1, 1024, 16, 8]         262,144
      BatchNorm2d-86          [-1, 1024, 16, 8]           2,048
           Conv2d-87          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-88          [-1, 1024, 16, 8]           2,048
             ReLU-89          [-1, 1024, 16, 8]               0
       Bottleneck-90          [-1, 1024, 16, 8]               0
           Conv2d-91           [-1, 256, 16, 8]         262,144
      BatchNorm2d-92           [-1, 256, 16, 8]             512
             ReLU-93           [-1, 256, 16, 8]               0
           Conv2d-94           [-1, 256, 16, 8]         589,824
      BatchNorm2d-95           [-1, 256, 16, 8]             512
             ReLU-96           [-1, 256, 16, 8]               0
           Conv2d-97          [-1, 1024, 16, 8]         262,144
      BatchNorm2d-98          [-1, 1024, 16, 8]           2,048
             ReLU-99          [-1, 1024, 16, 8]               0
      Bottleneck-100          [-1, 1024, 16, 8]               0
          Conv2d-101           [-1, 256, 16, 8]         262,144
     BatchNorm2d-102           [-1, 256, 16, 8]             512
            ReLU-103           [-1, 256, 16, 8]               0
          Conv2d-104           [-1, 256, 16, 8]         589,824
     BatchNorm2d-105           [-1, 256, 16, 8]             512
            ReLU-106           [-1, 256, 16, 8]               0
          Conv2d-107          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-108          [-1, 1024, 16, 8]           2,048
            ReLU-109          [-1, 1024, 16, 8]               0
      Bottleneck-110          [-1, 1024, 16, 8]               0
          Conv2d-111           [-1, 256, 16, 8]         262,144
     BatchNorm2d-112           [-1, 256, 16, 8]             512
            ReLU-113           [-1, 256, 16, 8]               0
          Conv2d-114           [-1, 256, 16, 8]         589,824
     BatchNorm2d-115           [-1, 256, 16, 8]             512
            ReLU-116           [-1, 256, 16, 8]               0
          Conv2d-117          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-118          [-1, 1024, 16, 8]           2,048
            ReLU-119          [-1, 1024, 16, 8]               0
      Bottleneck-120          [-1, 1024, 16, 8]               0
          Conv2d-121           [-1, 256, 16, 8]         262,144
     BatchNorm2d-122           [-1, 256, 16, 8]             512
            ReLU-123           [-1, 256, 16, 8]               0
          Conv2d-124           [-1, 256, 16, 8]         589,824
     BatchNorm2d-125           [-1, 256, 16, 8]             512
            ReLU-126           [-1, 256, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 256, 16, 8]         262,144
     BatchNorm2d-132           [-1, 256, 16, 8]             512
            ReLU-133           [-1, 256, 16, 8]               0
          Conv2d-134           [-1, 256, 16, 8]         589,824
     BatchNorm2d-135           [-1, 256, 16, 8]             512
            ReLU-136           [-1, 256, 16, 8]               0
          Conv2d-137          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-138          [-1, 1024, 16, 8]           2,048
            ReLU-139          [-1, 1024, 16, 8]               0
      Bottleneck-140          [-1, 1024, 16, 8]               0
          Conv2d-141           [-1, 256, 16, 8]         262,144
     BatchNorm2d-142           [-1, 256, 16, 8]             512
            ReLU-143           [-1, 256, 16, 8]               0
          Conv2d-144           [-1, 256, 16, 8]         589,824
     BatchNorm2d-145           [-1, 256, 16, 8]             512
            ReLU-146           [-1, 256, 16, 8]               0
          Conv2d-147          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-148          [-1, 1024, 16, 8]           2,048
            ReLU-149          [-1, 1024, 16, 8]               0
      Bottleneck-150          [-1, 1024, 16, 8]               0
          Conv2d-151           [-1, 256, 16, 8]         262,144
     BatchNorm2d-152           [-1, 256, 16, 8]             512
            ReLU-153           [-1, 256, 16, 8]               0
          Conv2d-154           [-1, 256, 16, 8]         589,824
     BatchNorm2d-155           [-1, 256, 16, 8]             512
            ReLU-156           [-1, 256, 16, 8]               0
          Conv2d-157          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-158          [-1, 1024, 16, 8]           2,048
            ReLU-159          [-1, 1024, 16, 8]               0
      Bottleneck-160          [-1, 1024, 16, 8]               0
          Conv2d-161           [-1, 256, 16, 8]         262,144
     BatchNorm2d-162           [-1, 256, 16, 8]             512
            ReLU-163           [-1, 256, 16, 8]               0
          Conv2d-164           [-1, 256, 16, 8]         589,824
     BatchNorm2d-165           [-1, 256, 16, 8]             512
            ReLU-166           [-1, 256, 16, 8]               0
          Conv2d-167          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-168          [-1, 1024, 16, 8]           2,048
            ReLU-169          [-1, 1024, 16, 8]               0
      Bottleneck-170          [-1, 1024, 16, 8]               0
          Conv2d-171           [-1, 256, 16, 8]         262,144
     BatchNorm2d-172           [-1, 256, 16, 8]             512
            ReLU-173           [-1, 256, 16, 8]               0
          Conv2d-174           [-1, 256, 16, 8]         589,824
     BatchNorm2d-175           [-1, 256, 16, 8]             512
            ReLU-176           [-1, 256, 16, 8]               0
          Conv2d-177          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-178          [-1, 1024, 16, 8]           2,048
            ReLU-179          [-1, 1024, 16, 8]               0
      Bottleneck-180          [-1, 1024, 16, 8]               0
          Conv2d-181           [-1, 256, 16, 8]         262,144
     BatchNorm2d-182           [-1, 256, 16, 8]             512
            ReLU-183           [-1, 256, 16, 8]               0
          Conv2d-184           [-1, 256, 16, 8]         589,824
     BatchNorm2d-185           [-1, 256, 16, 8]             512
            ReLU-186           [-1, 256, 16, 8]               0
          Conv2d-187          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-188          [-1, 1024, 16, 8]           2,048
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 256, 16, 8]         262,144
     BatchNorm2d-192           [-1, 256, 16, 8]             512
            ReLU-193           [-1, 256, 16, 8]               0
          Conv2d-194           [-1, 256, 16, 8]         589,824
     BatchNorm2d-195           [-1, 256, 16, 8]             512
            ReLU-196           [-1, 256, 16, 8]               0
          Conv2d-197          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-198          [-1, 1024, 16, 8]           2,048
            ReLU-199          [-1, 1024, 16, 8]               0
      Bottleneck-200          [-1, 1024, 16, 8]               0
          Conv2d-201           [-1, 256, 16, 8]         262,144
     BatchNorm2d-202           [-1, 256, 16, 8]             512
            ReLU-203           [-1, 256, 16, 8]               0
          Conv2d-204           [-1, 256, 16, 8]         589,824
     BatchNorm2d-205           [-1, 256, 16, 8]             512
            ReLU-206           [-1, 256, 16, 8]               0
          Conv2d-207          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-208          [-1, 1024, 16, 8]           2,048
            ReLU-209          [-1, 1024, 16, 8]               0
      Bottleneck-210          [-1, 1024, 16, 8]               0
          Conv2d-211           [-1, 256, 16, 8]         262,144
     BatchNorm2d-212           [-1, 256, 16, 8]             512
            ReLU-213           [-1, 256, 16, 8]               0
          Conv2d-214           [-1, 256, 16, 8]         589,824
     BatchNorm2d-215           [-1, 256, 16, 8]             512
            ReLU-216           [-1, 256, 16, 8]               0
          Conv2d-217          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-218          [-1, 1024, 16, 8]           2,048
            ReLU-219          [-1, 1024, 16, 8]               0
      Bottleneck-220          [-1, 1024, 16, 8]               0
          Conv2d-221           [-1, 256, 16, 8]         262,144
     BatchNorm2d-222           [-1, 256, 16, 8]             512
            ReLU-223           [-1, 256, 16, 8]               0
          Conv2d-224           [-1, 256, 16, 8]         589,824
     BatchNorm2d-225           [-1, 256, 16, 8]             512
            ReLU-226           [-1, 256, 16, 8]               0
          Conv2d-227          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-228          [-1, 1024, 16, 8]           2,048
            ReLU-229          [-1, 1024, 16, 8]               0
      Bottleneck-230          [-1, 1024, 16, 8]               0
          Conv2d-231           [-1, 256, 16, 8]         262,144
     BatchNorm2d-232           [-1, 256, 16, 8]             512
            ReLU-233           [-1, 256, 16, 8]               0
          Conv2d-234           [-1, 256, 16, 8]         589,824
     BatchNorm2d-235           [-1, 256, 16, 8]             512
            ReLU-236           [-1, 256, 16, 8]               0
          Conv2d-237          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-238          [-1, 1024, 16, 8]           2,048
            ReLU-239          [-1, 1024, 16, 8]               0
      Bottleneck-240          [-1, 1024, 16, 8]               0
          Conv2d-241           [-1, 256, 16, 8]         262,144
     BatchNorm2d-242           [-1, 256, 16, 8]             512
            ReLU-243           [-1, 256, 16, 8]               0
          Conv2d-244           [-1, 256, 16, 8]         589,824
     BatchNorm2d-245           [-1, 256, 16, 8]             512
            ReLU-246           [-1, 256, 16, 8]               0
          Conv2d-247          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-248          [-1, 1024, 16, 8]           2,048
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251           [-1, 256, 16, 8]         262,144
     BatchNorm2d-252           [-1, 256, 16, 8]             512
            ReLU-253           [-1, 256, 16, 8]               0
          Conv2d-254           [-1, 256, 16, 8]         589,824
     BatchNorm2d-255           [-1, 256, 16, 8]             512
            ReLU-256           [-1, 256, 16, 8]               0
          Conv2d-257          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-258          [-1, 1024, 16, 8]           2,048
            ReLU-259          [-1, 1024, 16, 8]               0
      Bottleneck-260          [-1, 1024, 16, 8]               0
          Conv2d-261           [-1, 256, 16, 8]         262,144
     BatchNorm2d-262           [-1, 256, 16, 8]             512
            ReLU-263           [-1, 256, 16, 8]               0
          Conv2d-264           [-1, 256, 16, 8]         589,824
     BatchNorm2d-265           [-1, 256, 16, 8]             512
            ReLU-266           [-1, 256, 16, 8]               0
          Conv2d-267          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-268          [-1, 1024, 16, 8]           2,048
            ReLU-269          [-1, 1024, 16, 8]               0
      Bottleneck-270          [-1, 1024, 16, 8]               0
          Conv2d-271           [-1, 256, 16, 8]         262,144
     BatchNorm2d-272           [-1, 256, 16, 8]             512
            ReLU-273           [-1, 256, 16, 8]               0
          Conv2d-274           [-1, 256, 16, 8]         589,824
     BatchNorm2d-275           [-1, 256, 16, 8]             512
            ReLU-276           [-1, 256, 16, 8]               0
          Conv2d-277          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-278          [-1, 1024, 16, 8]           2,048
            ReLU-279          [-1, 1024, 16, 8]               0
      Bottleneck-280          [-1, 1024, 16, 8]               0
          Conv2d-281           [-1, 256, 16, 8]         262,144
     BatchNorm2d-282           [-1, 256, 16, 8]             512
            ReLU-283           [-1, 256, 16, 8]               0
          Conv2d-284           [-1, 256, 16, 8]         589,824
     BatchNorm2d-285           [-1, 256, 16, 8]             512
            ReLU-286           [-1, 256, 16, 8]               0
          Conv2d-287          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-288          [-1, 1024, 16, 8]           2,048
            ReLU-289          [-1, 1024, 16, 8]               0
      Bottleneck-290          [-1, 1024, 16, 8]               0
          Conv2d-291           [-1, 256, 16, 8]         262,144
     BatchNorm2d-292           [-1, 256, 16, 8]             512
            ReLU-293           [-1, 256, 16, 8]               0
          Conv2d-294           [-1, 256, 16, 8]         589,824
     BatchNorm2d-295           [-1, 256, 16, 8]             512
            ReLU-296           [-1, 256, 16, 8]               0
          Conv2d-297          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-298          [-1, 1024, 16, 8]           2,048
            ReLU-299          [-1, 1024, 16, 8]               0
      Bottleneck-300          [-1, 1024, 16, 8]               0
          Conv2d-301           [-1, 256, 16, 8]         262,144
     BatchNorm2d-302           [-1, 256, 16, 8]             512
            ReLU-303           [-1, 256, 16, 8]               0
          Conv2d-304           [-1, 256, 16, 8]         589,824
     BatchNorm2d-305           [-1, 256, 16, 8]             512
            ReLU-306           [-1, 256, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
            ReLU-309          [-1, 1024, 16, 8]               0
      Bottleneck-310          [-1, 1024, 16, 8]               0
          Conv2d-311           [-1, 512, 16, 8]         524,288
     BatchNorm2d-312           [-1, 512, 16, 8]           1,024
            ReLU-313           [-1, 512, 16, 8]               0
          Conv2d-314           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-315           [-1, 512, 16, 8]           1,024
            ReLU-316           [-1, 512, 16, 8]               0
          Conv2d-317          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-318          [-1, 2048, 16, 8]           4,096
          Conv2d-319          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-320          [-1, 2048, 16, 8]           4,096
            ReLU-321          [-1, 2048, 16, 8]               0
      Bottleneck-322          [-1, 2048, 16, 8]               0
          Conv2d-323           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-324           [-1, 512, 16, 8]           1,024
            ReLU-325           [-1, 512, 16, 8]               0
          Conv2d-326           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-327           [-1, 512, 16, 8]           1,024
            ReLU-328           [-1, 512, 16, 8]               0
          Conv2d-329          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-330          [-1, 2048, 16, 8]           4,096
            ReLU-331          [-1, 2048, 16, 8]               0
      Bottleneck-332          [-1, 2048, 16, 8]               0
          Conv2d-333           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-334           [-1, 512, 16, 8]           1,024
            ReLU-335           [-1, 512, 16, 8]               0
          Conv2d-336           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-337           [-1, 512, 16, 8]           1,024
            ReLU-338           [-1, 512, 16, 8]               0
          Conv2d-339          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-340          [-1, 2048, 16, 8]           4,096
            ReLU-341          [-1, 2048, 16, 8]               0
      Bottleneck-342          [-1, 2048, 16, 8]               0
================================================================
Total params: 42,500,160
Trainable params: 42,500,160
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 307.25
Params size (MB): 162.13
Estimated Total Size (MB): 469.75
----------------------------------------------------------------
**************************************************
resnet152
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
             ReLU-15          [-1, 256, 64, 32]               0
       Bottleneck-16          [-1, 256, 64, 32]               0
           Conv2d-17           [-1, 64, 64, 32]          16,384
      BatchNorm2d-18           [-1, 64, 64, 32]             128
             ReLU-19           [-1, 64, 64, 32]               0
           Conv2d-20           [-1, 64, 64, 32]          36,864
      BatchNorm2d-21           [-1, 64, 64, 32]             128
             ReLU-22           [-1, 64, 64, 32]               0
           Conv2d-23          [-1, 256, 64, 32]          16,384
      BatchNorm2d-24          [-1, 256, 64, 32]             512
             ReLU-25          [-1, 256, 64, 32]               0
       Bottleneck-26          [-1, 256, 64, 32]               0
           Conv2d-27           [-1, 64, 64, 32]          16,384
      BatchNorm2d-28           [-1, 64, 64, 32]             128
             ReLU-29           [-1, 64, 64, 32]               0
           Conv2d-30           [-1, 64, 64, 32]          36,864
      BatchNorm2d-31           [-1, 64, 64, 32]             128
             ReLU-32           [-1, 64, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          16,384
      BatchNorm2d-34          [-1, 256, 64, 32]             512
             ReLU-35          [-1, 256, 64, 32]               0
       Bottleneck-36          [-1, 256, 64, 32]               0
           Conv2d-37          [-1, 128, 64, 32]          32,768
      BatchNorm2d-38          [-1, 128, 64, 32]             256
             ReLU-39          [-1, 128, 64, 32]               0
           Conv2d-40          [-1, 128, 32, 16]         147,456
      BatchNorm2d-41          [-1, 128, 32, 16]             256
             ReLU-42          [-1, 128, 32, 16]               0
           Conv2d-43          [-1, 512, 32, 16]          65,536
      BatchNorm2d-44          [-1, 512, 32, 16]           1,024
           Conv2d-45          [-1, 512, 32, 16]         131,072
      BatchNorm2d-46          [-1, 512, 32, 16]           1,024
             ReLU-47          [-1, 512, 32, 16]               0
       Bottleneck-48          [-1, 512, 32, 16]               0
           Conv2d-49          [-1, 128, 32, 16]          65,536
      BatchNorm2d-50          [-1, 128, 32, 16]             256
             ReLU-51          [-1, 128, 32, 16]               0
           Conv2d-52          [-1, 128, 32, 16]         147,456
      BatchNorm2d-53          [-1, 128, 32, 16]             256
             ReLU-54          [-1, 128, 32, 16]               0
           Conv2d-55          [-1, 512, 32, 16]          65,536
      BatchNorm2d-56          [-1, 512, 32, 16]           1,024
             ReLU-57          [-1, 512, 32, 16]               0
       Bottleneck-58          [-1, 512, 32, 16]               0
           Conv2d-59          [-1, 128, 32, 16]          65,536
      BatchNorm2d-60          [-1, 128, 32, 16]             256
             ReLU-61          [-1, 128, 32, 16]               0
           Conv2d-62          [-1, 128, 32, 16]         147,456
      BatchNorm2d-63          [-1, 128, 32, 16]             256
             ReLU-64          [-1, 128, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]          65,536
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 128, 32, 16]          65,536
      BatchNorm2d-70          [-1, 128, 32, 16]             256
             ReLU-71          [-1, 128, 32, 16]               0
           Conv2d-72          [-1, 128, 32, 16]         147,456
      BatchNorm2d-73          [-1, 128, 32, 16]             256
             ReLU-74          [-1, 128, 32, 16]               0
           Conv2d-75          [-1, 512, 32, 16]          65,536
      BatchNorm2d-76          [-1, 512, 32, 16]           1,024
             ReLU-77          [-1, 512, 32, 16]               0
       Bottleneck-78          [-1, 512, 32, 16]               0
           Conv2d-79          [-1, 128, 32, 16]          65,536
      BatchNorm2d-80          [-1, 128, 32, 16]             256
             ReLU-81          [-1, 128, 32, 16]               0
           Conv2d-82          [-1, 128, 32, 16]         147,456
      BatchNorm2d-83          [-1, 128, 32, 16]             256
             ReLU-84          [-1, 128, 32, 16]               0
           Conv2d-85          [-1, 512, 32, 16]          65,536
      BatchNorm2d-86          [-1, 512, 32, 16]           1,024
             ReLU-87          [-1, 512, 32, 16]               0
       Bottleneck-88          [-1, 512, 32, 16]               0
           Conv2d-89          [-1, 128, 32, 16]          65,536
      BatchNorm2d-90          [-1, 128, 32, 16]             256
             ReLU-91          [-1, 128, 32, 16]               0
           Conv2d-92          [-1, 128, 32, 16]         147,456
      BatchNorm2d-93          [-1, 128, 32, 16]             256
             ReLU-94          [-1, 128, 32, 16]               0
           Conv2d-95          [-1, 512, 32, 16]          65,536
      BatchNorm2d-96          [-1, 512, 32, 16]           1,024
             ReLU-97          [-1, 512, 32, 16]               0
       Bottleneck-98          [-1, 512, 32, 16]               0
           Conv2d-99          [-1, 128, 32, 16]          65,536
     BatchNorm2d-100          [-1, 128, 32, 16]             256
            ReLU-101          [-1, 128, 32, 16]               0
          Conv2d-102          [-1, 128, 32, 16]         147,456
     BatchNorm2d-103          [-1, 128, 32, 16]             256
            ReLU-104          [-1, 128, 32, 16]               0
          Conv2d-105          [-1, 512, 32, 16]          65,536
     BatchNorm2d-106          [-1, 512, 32, 16]           1,024
            ReLU-107          [-1, 512, 32, 16]               0
      Bottleneck-108          [-1, 512, 32, 16]               0
          Conv2d-109          [-1, 128, 32, 16]          65,536
     BatchNorm2d-110          [-1, 128, 32, 16]             256
            ReLU-111          [-1, 128, 32, 16]               0
          Conv2d-112          [-1, 128, 32, 16]         147,456
     BatchNorm2d-113          [-1, 128, 32, 16]             256
            ReLU-114          [-1, 128, 32, 16]               0
          Conv2d-115          [-1, 512, 32, 16]          65,536
     BatchNorm2d-116          [-1, 512, 32, 16]           1,024
            ReLU-117          [-1, 512, 32, 16]               0
      Bottleneck-118          [-1, 512, 32, 16]               0
          Conv2d-119          [-1, 256, 32, 16]         131,072
     BatchNorm2d-120          [-1, 256, 32, 16]             512
            ReLU-121          [-1, 256, 32, 16]               0
          Conv2d-122           [-1, 256, 16, 8]         589,824
     BatchNorm2d-123           [-1, 256, 16, 8]             512
            ReLU-124           [-1, 256, 16, 8]               0
          Conv2d-125          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-126          [-1, 1024, 16, 8]           2,048
          Conv2d-127          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 256, 16, 8]         262,144
     BatchNorm2d-132           [-1, 256, 16, 8]             512
            ReLU-133           [-1, 256, 16, 8]               0
          Conv2d-134           [-1, 256, 16, 8]         589,824
     BatchNorm2d-135           [-1, 256, 16, 8]             512
            ReLU-136           [-1, 256, 16, 8]               0
          Conv2d-137          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-138          [-1, 1024, 16, 8]           2,048
            ReLU-139          [-1, 1024, 16, 8]               0
      Bottleneck-140          [-1, 1024, 16, 8]               0
          Conv2d-141           [-1, 256, 16, 8]         262,144
     BatchNorm2d-142           [-1, 256, 16, 8]             512
            ReLU-143           [-1, 256, 16, 8]               0
          Conv2d-144           [-1, 256, 16, 8]         589,824
     BatchNorm2d-145           [-1, 256, 16, 8]             512
            ReLU-146           [-1, 256, 16, 8]               0
          Conv2d-147          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-148          [-1, 1024, 16, 8]           2,048
            ReLU-149          [-1, 1024, 16, 8]               0
      Bottleneck-150          [-1, 1024, 16, 8]               0
          Conv2d-151           [-1, 256, 16, 8]         262,144
     BatchNorm2d-152           [-1, 256, 16, 8]             512
            ReLU-153           [-1, 256, 16, 8]               0
          Conv2d-154           [-1, 256, 16, 8]         589,824
     BatchNorm2d-155           [-1, 256, 16, 8]             512
            ReLU-156           [-1, 256, 16, 8]               0
          Conv2d-157          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-158          [-1, 1024, 16, 8]           2,048
            ReLU-159          [-1, 1024, 16, 8]               0
      Bottleneck-160          [-1, 1024, 16, 8]               0
          Conv2d-161           [-1, 256, 16, 8]         262,144
     BatchNorm2d-162           [-1, 256, 16, 8]             512
            ReLU-163           [-1, 256, 16, 8]               0
          Conv2d-164           [-1, 256, 16, 8]         589,824
     BatchNorm2d-165           [-1, 256, 16, 8]             512
            ReLU-166           [-1, 256, 16, 8]               0
          Conv2d-167          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-168          [-1, 1024, 16, 8]           2,048
            ReLU-169          [-1, 1024, 16, 8]               0
      Bottleneck-170          [-1, 1024, 16, 8]               0
          Conv2d-171           [-1, 256, 16, 8]         262,144
     BatchNorm2d-172           [-1, 256, 16, 8]             512
            ReLU-173           [-1, 256, 16, 8]               0
          Conv2d-174           [-1, 256, 16, 8]         589,824
     BatchNorm2d-175           [-1, 256, 16, 8]             512
            ReLU-176           [-1, 256, 16, 8]               0
          Conv2d-177          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-178          [-1, 1024, 16, 8]           2,048
            ReLU-179          [-1, 1024, 16, 8]               0
      Bottleneck-180          [-1, 1024, 16, 8]               0
          Conv2d-181           [-1, 256, 16, 8]         262,144
     BatchNorm2d-182           [-1, 256, 16, 8]             512
            ReLU-183           [-1, 256, 16, 8]               0
          Conv2d-184           [-1, 256, 16, 8]         589,824
     BatchNorm2d-185           [-1, 256, 16, 8]             512
            ReLU-186           [-1, 256, 16, 8]               0
          Conv2d-187          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-188          [-1, 1024, 16, 8]           2,048
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 256, 16, 8]         262,144
     BatchNorm2d-192           [-1, 256, 16, 8]             512
            ReLU-193           [-1, 256, 16, 8]               0
          Conv2d-194           [-1, 256, 16, 8]         589,824
     BatchNorm2d-195           [-1, 256, 16, 8]             512
            ReLU-196           [-1, 256, 16, 8]               0
          Conv2d-197          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-198          [-1, 1024, 16, 8]           2,048
            ReLU-199          [-1, 1024, 16, 8]               0
      Bottleneck-200          [-1, 1024, 16, 8]               0
          Conv2d-201           [-1, 256, 16, 8]         262,144
     BatchNorm2d-202           [-1, 256, 16, 8]             512
            ReLU-203           [-1, 256, 16, 8]               0
          Conv2d-204           [-1, 256, 16, 8]         589,824
     BatchNorm2d-205           [-1, 256, 16, 8]             512
            ReLU-206           [-1, 256, 16, 8]               0
          Conv2d-207          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-208          [-1, 1024, 16, 8]           2,048
            ReLU-209          [-1, 1024, 16, 8]               0
      Bottleneck-210          [-1, 1024, 16, 8]               0
          Conv2d-211           [-1, 256, 16, 8]         262,144
     BatchNorm2d-212           [-1, 256, 16, 8]             512
            ReLU-213           [-1, 256, 16, 8]               0
          Conv2d-214           [-1, 256, 16, 8]         589,824
     BatchNorm2d-215           [-1, 256, 16, 8]             512
            ReLU-216           [-1, 256, 16, 8]               0
          Conv2d-217          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-218          [-1, 1024, 16, 8]           2,048
            ReLU-219          [-1, 1024, 16, 8]               0
      Bottleneck-220          [-1, 1024, 16, 8]               0
          Conv2d-221           [-1, 256, 16, 8]         262,144
     BatchNorm2d-222           [-1, 256, 16, 8]             512
            ReLU-223           [-1, 256, 16, 8]               0
          Conv2d-224           [-1, 256, 16, 8]         589,824
     BatchNorm2d-225           [-1, 256, 16, 8]             512
            ReLU-226           [-1, 256, 16, 8]               0
          Conv2d-227          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-228          [-1, 1024, 16, 8]           2,048
            ReLU-229          [-1, 1024, 16, 8]               0
      Bottleneck-230          [-1, 1024, 16, 8]               0
          Conv2d-231           [-1, 256, 16, 8]         262,144
     BatchNorm2d-232           [-1, 256, 16, 8]             512
            ReLU-233           [-1, 256, 16, 8]               0
          Conv2d-234           [-1, 256, 16, 8]         589,824
     BatchNorm2d-235           [-1, 256, 16, 8]             512
            ReLU-236           [-1, 256, 16, 8]               0
          Conv2d-237          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-238          [-1, 1024, 16, 8]           2,048
            ReLU-239          [-1, 1024, 16, 8]               0
      Bottleneck-240          [-1, 1024, 16, 8]               0
          Conv2d-241           [-1, 256, 16, 8]         262,144
     BatchNorm2d-242           [-1, 256, 16, 8]             512
            ReLU-243           [-1, 256, 16, 8]               0
          Conv2d-244           [-1, 256, 16, 8]         589,824
     BatchNorm2d-245           [-1, 256, 16, 8]             512
            ReLU-246           [-1, 256, 16, 8]               0
          Conv2d-247          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-248          [-1, 1024, 16, 8]           2,048
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251           [-1, 256, 16, 8]         262,144
     BatchNorm2d-252           [-1, 256, 16, 8]             512
            ReLU-253           [-1, 256, 16, 8]               0
          Conv2d-254           [-1, 256, 16, 8]         589,824
     BatchNorm2d-255           [-1, 256, 16, 8]             512
            ReLU-256           [-1, 256, 16, 8]               0
          Conv2d-257          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-258          [-1, 1024, 16, 8]           2,048
            ReLU-259          [-1, 1024, 16, 8]               0
      Bottleneck-260          [-1, 1024, 16, 8]               0
          Conv2d-261           [-1, 256, 16, 8]         262,144
     BatchNorm2d-262           [-1, 256, 16, 8]             512
            ReLU-263           [-1, 256, 16, 8]               0
          Conv2d-264           [-1, 256, 16, 8]         589,824
     BatchNorm2d-265           [-1, 256, 16, 8]             512
            ReLU-266           [-1, 256, 16, 8]               0
          Conv2d-267          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-268          [-1, 1024, 16, 8]           2,048
            ReLU-269          [-1, 1024, 16, 8]               0
      Bottleneck-270          [-1, 1024, 16, 8]               0
          Conv2d-271           [-1, 256, 16, 8]         262,144
     BatchNorm2d-272           [-1, 256, 16, 8]             512
            ReLU-273           [-1, 256, 16, 8]               0
          Conv2d-274           [-1, 256, 16, 8]         589,824
     BatchNorm2d-275           [-1, 256, 16, 8]             512
            ReLU-276           [-1, 256, 16, 8]               0
          Conv2d-277          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-278          [-1, 1024, 16, 8]           2,048
            ReLU-279          [-1, 1024, 16, 8]               0
      Bottleneck-280          [-1, 1024, 16, 8]               0
          Conv2d-281           [-1, 256, 16, 8]         262,144
     BatchNorm2d-282           [-1, 256, 16, 8]             512
            ReLU-283           [-1, 256, 16, 8]               0
          Conv2d-284           [-1, 256, 16, 8]         589,824
     BatchNorm2d-285           [-1, 256, 16, 8]             512
            ReLU-286           [-1, 256, 16, 8]               0
          Conv2d-287          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-288          [-1, 1024, 16, 8]           2,048
            ReLU-289          [-1, 1024, 16, 8]               0
      Bottleneck-290          [-1, 1024, 16, 8]               0
          Conv2d-291           [-1, 256, 16, 8]         262,144
     BatchNorm2d-292           [-1, 256, 16, 8]             512
            ReLU-293           [-1, 256, 16, 8]               0
          Conv2d-294           [-1, 256, 16, 8]         589,824
     BatchNorm2d-295           [-1, 256, 16, 8]             512
            ReLU-296           [-1, 256, 16, 8]               0
          Conv2d-297          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-298          [-1, 1024, 16, 8]           2,048
            ReLU-299          [-1, 1024, 16, 8]               0
      Bottleneck-300          [-1, 1024, 16, 8]               0
          Conv2d-301           [-1, 256, 16, 8]         262,144
     BatchNorm2d-302           [-1, 256, 16, 8]             512
            ReLU-303           [-1, 256, 16, 8]               0
          Conv2d-304           [-1, 256, 16, 8]         589,824
     BatchNorm2d-305           [-1, 256, 16, 8]             512
            ReLU-306           [-1, 256, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
            ReLU-309          [-1, 1024, 16, 8]               0
      Bottleneck-310          [-1, 1024, 16, 8]               0
          Conv2d-311           [-1, 256, 16, 8]         262,144
     BatchNorm2d-312           [-1, 256, 16, 8]             512
            ReLU-313           [-1, 256, 16, 8]               0
          Conv2d-314           [-1, 256, 16, 8]         589,824
     BatchNorm2d-315           [-1, 256, 16, 8]             512
            ReLU-316           [-1, 256, 16, 8]               0
          Conv2d-317          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-318          [-1, 1024, 16, 8]           2,048
            ReLU-319          [-1, 1024, 16, 8]               0
      Bottleneck-320          [-1, 1024, 16, 8]               0
          Conv2d-321           [-1, 256, 16, 8]         262,144
     BatchNorm2d-322           [-1, 256, 16, 8]             512
            ReLU-323           [-1, 256, 16, 8]               0
          Conv2d-324           [-1, 256, 16, 8]         589,824
     BatchNorm2d-325           [-1, 256, 16, 8]             512
            ReLU-326           [-1, 256, 16, 8]               0
          Conv2d-327          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-328          [-1, 1024, 16, 8]           2,048
            ReLU-329          [-1, 1024, 16, 8]               0
      Bottleneck-330          [-1, 1024, 16, 8]               0
          Conv2d-331           [-1, 256, 16, 8]         262,144
     BatchNorm2d-332           [-1, 256, 16, 8]             512
            ReLU-333           [-1, 256, 16, 8]               0
          Conv2d-334           [-1, 256, 16, 8]         589,824
     BatchNorm2d-335           [-1, 256, 16, 8]             512
            ReLU-336           [-1, 256, 16, 8]               0
          Conv2d-337          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-338          [-1, 1024, 16, 8]           2,048
            ReLU-339          [-1, 1024, 16, 8]               0
      Bottleneck-340          [-1, 1024, 16, 8]               0
          Conv2d-341           [-1, 256, 16, 8]         262,144
     BatchNorm2d-342           [-1, 256, 16, 8]             512
            ReLU-343           [-1, 256, 16, 8]               0
          Conv2d-344           [-1, 256, 16, 8]         589,824
     BatchNorm2d-345           [-1, 256, 16, 8]             512
            ReLU-346           [-1, 256, 16, 8]               0
          Conv2d-347          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-348          [-1, 1024, 16, 8]           2,048
            ReLU-349          [-1, 1024, 16, 8]               0
      Bottleneck-350          [-1, 1024, 16, 8]               0
          Conv2d-351           [-1, 256, 16, 8]         262,144
     BatchNorm2d-352           [-1, 256, 16, 8]             512
            ReLU-353           [-1, 256, 16, 8]               0
          Conv2d-354           [-1, 256, 16, 8]         589,824
     BatchNorm2d-355           [-1, 256, 16, 8]             512
            ReLU-356           [-1, 256, 16, 8]               0
          Conv2d-357          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-358          [-1, 1024, 16, 8]           2,048
            ReLU-359          [-1, 1024, 16, 8]               0
      Bottleneck-360          [-1, 1024, 16, 8]               0
          Conv2d-361           [-1, 256, 16, 8]         262,144
     BatchNorm2d-362           [-1, 256, 16, 8]             512
            ReLU-363           [-1, 256, 16, 8]               0
          Conv2d-364           [-1, 256, 16, 8]         589,824
     BatchNorm2d-365           [-1, 256, 16, 8]             512
            ReLU-366           [-1, 256, 16, 8]               0
          Conv2d-367          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-368          [-1, 1024, 16, 8]           2,048
            ReLU-369          [-1, 1024, 16, 8]               0
      Bottleneck-370          [-1, 1024, 16, 8]               0
          Conv2d-371           [-1, 256, 16, 8]         262,144
     BatchNorm2d-372           [-1, 256, 16, 8]             512
            ReLU-373           [-1, 256, 16, 8]               0
          Conv2d-374           [-1, 256, 16, 8]         589,824
     BatchNorm2d-375           [-1, 256, 16, 8]             512
            ReLU-376           [-1, 256, 16, 8]               0
          Conv2d-377          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-378          [-1, 1024, 16, 8]           2,048
            ReLU-379          [-1, 1024, 16, 8]               0
      Bottleneck-380          [-1, 1024, 16, 8]               0
          Conv2d-381           [-1, 256, 16, 8]         262,144
     BatchNorm2d-382           [-1, 256, 16, 8]             512
            ReLU-383           [-1, 256, 16, 8]               0
          Conv2d-384           [-1, 256, 16, 8]         589,824
     BatchNorm2d-385           [-1, 256, 16, 8]             512
            ReLU-386           [-1, 256, 16, 8]               0
          Conv2d-387          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-388          [-1, 1024, 16, 8]           2,048
            ReLU-389          [-1, 1024, 16, 8]               0
      Bottleneck-390          [-1, 1024, 16, 8]               0
          Conv2d-391           [-1, 256, 16, 8]         262,144
     BatchNorm2d-392           [-1, 256, 16, 8]             512
            ReLU-393           [-1, 256, 16, 8]               0
          Conv2d-394           [-1, 256, 16, 8]         589,824
     BatchNorm2d-395           [-1, 256, 16, 8]             512
            ReLU-396           [-1, 256, 16, 8]               0
          Conv2d-397          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-398          [-1, 1024, 16, 8]           2,048
            ReLU-399          [-1, 1024, 16, 8]               0
      Bottleneck-400          [-1, 1024, 16, 8]               0
          Conv2d-401           [-1, 256, 16, 8]         262,144
     BatchNorm2d-402           [-1, 256, 16, 8]             512
            ReLU-403           [-1, 256, 16, 8]               0
          Conv2d-404           [-1, 256, 16, 8]         589,824
     BatchNorm2d-405           [-1, 256, 16, 8]             512
            ReLU-406           [-1, 256, 16, 8]               0
          Conv2d-407          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-408          [-1, 1024, 16, 8]           2,048
            ReLU-409          [-1, 1024, 16, 8]               0
      Bottleneck-410          [-1, 1024, 16, 8]               0
          Conv2d-411           [-1, 256, 16, 8]         262,144
     BatchNorm2d-412           [-1, 256, 16, 8]             512
            ReLU-413           [-1, 256, 16, 8]               0
          Conv2d-414           [-1, 256, 16, 8]         589,824
     BatchNorm2d-415           [-1, 256, 16, 8]             512
            ReLU-416           [-1, 256, 16, 8]               0
          Conv2d-417          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-418          [-1, 1024, 16, 8]           2,048
            ReLU-419          [-1, 1024, 16, 8]               0
      Bottleneck-420          [-1, 1024, 16, 8]               0
          Conv2d-421           [-1, 256, 16, 8]         262,144
     BatchNorm2d-422           [-1, 256, 16, 8]             512
            ReLU-423           [-1, 256, 16, 8]               0
          Conv2d-424           [-1, 256, 16, 8]         589,824
     BatchNorm2d-425           [-1, 256, 16, 8]             512
            ReLU-426           [-1, 256, 16, 8]               0
          Conv2d-427          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-428          [-1, 1024, 16, 8]           2,048
            ReLU-429          [-1, 1024, 16, 8]               0
      Bottleneck-430          [-1, 1024, 16, 8]               0
          Conv2d-431           [-1, 256, 16, 8]         262,144
     BatchNorm2d-432           [-1, 256, 16, 8]             512
            ReLU-433           [-1, 256, 16, 8]               0
          Conv2d-434           [-1, 256, 16, 8]         589,824
     BatchNorm2d-435           [-1, 256, 16, 8]             512
            ReLU-436           [-1, 256, 16, 8]               0
          Conv2d-437          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-438          [-1, 1024, 16, 8]           2,048
            ReLU-439          [-1, 1024, 16, 8]               0
      Bottleneck-440          [-1, 1024, 16, 8]               0
          Conv2d-441           [-1, 256, 16, 8]         262,144
     BatchNorm2d-442           [-1, 256, 16, 8]             512
            ReLU-443           [-1, 256, 16, 8]               0
          Conv2d-444           [-1, 256, 16, 8]         589,824
     BatchNorm2d-445           [-1, 256, 16, 8]             512
            ReLU-446           [-1, 256, 16, 8]               0
          Conv2d-447          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-448          [-1, 1024, 16, 8]           2,048
            ReLU-449          [-1, 1024, 16, 8]               0
      Bottleneck-450          [-1, 1024, 16, 8]               0
          Conv2d-451           [-1, 256, 16, 8]         262,144
     BatchNorm2d-452           [-1, 256, 16, 8]             512
            ReLU-453           [-1, 256, 16, 8]               0
          Conv2d-454           [-1, 256, 16, 8]         589,824
     BatchNorm2d-455           [-1, 256, 16, 8]             512
            ReLU-456           [-1, 256, 16, 8]               0
          Conv2d-457          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-458          [-1, 1024, 16, 8]           2,048
            ReLU-459          [-1, 1024, 16, 8]               0
      Bottleneck-460          [-1, 1024, 16, 8]               0
          Conv2d-461           [-1, 256, 16, 8]         262,144
     BatchNorm2d-462           [-1, 256, 16, 8]             512
            ReLU-463           [-1, 256, 16, 8]               0
          Conv2d-464           [-1, 256, 16, 8]         589,824
     BatchNorm2d-465           [-1, 256, 16, 8]             512
            ReLU-466           [-1, 256, 16, 8]               0
          Conv2d-467          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-468          [-1, 1024, 16, 8]           2,048
            ReLU-469          [-1, 1024, 16, 8]               0
      Bottleneck-470          [-1, 1024, 16, 8]               0
          Conv2d-471           [-1, 256, 16, 8]         262,144
     BatchNorm2d-472           [-1, 256, 16, 8]             512
            ReLU-473           [-1, 256, 16, 8]               0
          Conv2d-474           [-1, 256, 16, 8]         589,824
     BatchNorm2d-475           [-1, 256, 16, 8]             512
            ReLU-476           [-1, 256, 16, 8]               0
          Conv2d-477          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-478          [-1, 1024, 16, 8]           2,048
            ReLU-479          [-1, 1024, 16, 8]               0
      Bottleneck-480          [-1, 1024, 16, 8]               0
          Conv2d-481           [-1, 512, 16, 8]         524,288
     BatchNorm2d-482           [-1, 512, 16, 8]           1,024
            ReLU-483           [-1, 512, 16, 8]               0
          Conv2d-484           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-485           [-1, 512, 16, 8]           1,024
            ReLU-486           [-1, 512, 16, 8]               0
          Conv2d-487          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-488          [-1, 2048, 16, 8]           4,096
          Conv2d-489          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-490          [-1, 2048, 16, 8]           4,096
            ReLU-491          [-1, 2048, 16, 8]               0
      Bottleneck-492          [-1, 2048, 16, 8]               0
          Conv2d-493           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-494           [-1, 512, 16, 8]           1,024
            ReLU-495           [-1, 512, 16, 8]               0
          Conv2d-496           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-497           [-1, 512, 16, 8]           1,024
            ReLU-498           [-1, 512, 16, 8]               0
          Conv2d-499          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-500          [-1, 2048, 16, 8]           4,096
            ReLU-501          [-1, 2048, 16, 8]               0
      Bottleneck-502          [-1, 2048, 16, 8]               0
          Conv2d-503           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-504           [-1, 512, 16, 8]           1,024
            ReLU-505           [-1, 512, 16, 8]               0
          Conv2d-506           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-507           [-1, 512, 16, 8]           1,024
            ReLU-508           [-1, 512, 16, 8]               0
          Conv2d-509          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-510          [-1, 2048, 16, 8]           4,096
            ReLU-511          [-1, 2048, 16, 8]               0
      Bottleneck-512          [-1, 2048, 16, 8]               0
================================================================
Total params: 58,143,808
Trainable params: 58,143,808
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 422.75
Params size (MB): 221.80
Estimated Total Size (MB): 644.93
----------------------------------------------------------------
**************************************************
resnext50_32x4d
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]           4,608
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
             ReLU-15          [-1, 256, 64, 32]               0
       Bottleneck-16          [-1, 256, 64, 32]               0
           Conv2d-17          [-1, 128, 64, 32]          32,768
      BatchNorm2d-18          [-1, 128, 64, 32]             256
             ReLU-19          [-1, 128, 64, 32]               0
           Conv2d-20          [-1, 128, 64, 32]           4,608
      BatchNorm2d-21          [-1, 128, 64, 32]             256
             ReLU-22          [-1, 128, 64, 32]               0
           Conv2d-23          [-1, 256, 64, 32]          32,768
      BatchNorm2d-24          [-1, 256, 64, 32]             512
             ReLU-25          [-1, 256, 64, 32]               0
       Bottleneck-26          [-1, 256, 64, 32]               0
           Conv2d-27          [-1, 128, 64, 32]          32,768
      BatchNorm2d-28          [-1, 128, 64, 32]             256
             ReLU-29          [-1, 128, 64, 32]               0
           Conv2d-30          [-1, 128, 64, 32]           4,608
      BatchNorm2d-31          [-1, 128, 64, 32]             256
             ReLU-32          [-1, 128, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          32,768
      BatchNorm2d-34          [-1, 256, 64, 32]             512
             ReLU-35          [-1, 256, 64, 32]               0
       Bottleneck-36          [-1, 256, 64, 32]               0
           Conv2d-37          [-1, 256, 64, 32]          65,536
      BatchNorm2d-38          [-1, 256, 64, 32]             512
             ReLU-39          [-1, 256, 64, 32]               0
           Conv2d-40          [-1, 256, 32, 16]          18,432
      BatchNorm2d-41          [-1, 256, 32, 16]             512
             ReLU-42          [-1, 256, 32, 16]               0
           Conv2d-43          [-1, 512, 32, 16]         131,072
      BatchNorm2d-44          [-1, 512, 32, 16]           1,024
           Conv2d-45          [-1, 512, 32, 16]         131,072
      BatchNorm2d-46          [-1, 512, 32, 16]           1,024
             ReLU-47          [-1, 512, 32, 16]               0
       Bottleneck-48          [-1, 512, 32, 16]               0
           Conv2d-49          [-1, 256, 32, 16]         131,072
      BatchNorm2d-50          [-1, 256, 32, 16]             512
             ReLU-51          [-1, 256, 32, 16]               0
           Conv2d-52          [-1, 256, 32, 16]          18,432
      BatchNorm2d-53          [-1, 256, 32, 16]             512
             ReLU-54          [-1, 256, 32, 16]               0
           Conv2d-55          [-1, 512, 32, 16]         131,072
      BatchNorm2d-56          [-1, 512, 32, 16]           1,024
             ReLU-57          [-1, 512, 32, 16]               0
       Bottleneck-58          [-1, 512, 32, 16]               0
           Conv2d-59          [-1, 256, 32, 16]         131,072
      BatchNorm2d-60          [-1, 256, 32, 16]             512
             ReLU-61          [-1, 256, 32, 16]               0
           Conv2d-62          [-1, 256, 32, 16]          18,432
      BatchNorm2d-63          [-1, 256, 32, 16]             512
             ReLU-64          [-1, 256, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]         131,072
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 256, 32, 16]         131,072
      BatchNorm2d-70          [-1, 256, 32, 16]             512
             ReLU-71          [-1, 256, 32, 16]               0
           Conv2d-72          [-1, 256, 32, 16]          18,432
      BatchNorm2d-73          [-1, 256, 32, 16]             512
             ReLU-74          [-1, 256, 32, 16]               0
           Conv2d-75          [-1, 512, 32, 16]         131,072
      BatchNorm2d-76          [-1, 512, 32, 16]           1,024
             ReLU-77          [-1, 512, 32, 16]               0
       Bottleneck-78          [-1, 512, 32, 16]               0
           Conv2d-79          [-1, 512, 32, 16]         262,144
      BatchNorm2d-80          [-1, 512, 32, 16]           1,024
             ReLU-81          [-1, 512, 32, 16]               0
           Conv2d-82           [-1, 512, 16, 8]          73,728
      BatchNorm2d-83           [-1, 512, 16, 8]           1,024
             ReLU-84           [-1, 512, 16, 8]               0
           Conv2d-85          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-86          [-1, 1024, 16, 8]           2,048
           Conv2d-87          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-88          [-1, 1024, 16, 8]           2,048
             ReLU-89          [-1, 1024, 16, 8]               0
       Bottleneck-90          [-1, 1024, 16, 8]               0
           Conv2d-91           [-1, 512, 16, 8]         524,288
      BatchNorm2d-92           [-1, 512, 16, 8]           1,024
             ReLU-93           [-1, 512, 16, 8]               0
           Conv2d-94           [-1, 512, 16, 8]          73,728
      BatchNorm2d-95           [-1, 512, 16, 8]           1,024
             ReLU-96           [-1, 512, 16, 8]               0
           Conv2d-97          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-98          [-1, 1024, 16, 8]           2,048
             ReLU-99          [-1, 1024, 16, 8]               0
      Bottleneck-100          [-1, 1024, 16, 8]               0
          Conv2d-101           [-1, 512, 16, 8]         524,288
     BatchNorm2d-102           [-1, 512, 16, 8]           1,024
            ReLU-103           [-1, 512, 16, 8]               0
          Conv2d-104           [-1, 512, 16, 8]          73,728
     BatchNorm2d-105           [-1, 512, 16, 8]           1,024
            ReLU-106           [-1, 512, 16, 8]               0
          Conv2d-107          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-108          [-1, 1024, 16, 8]           2,048
            ReLU-109          [-1, 1024, 16, 8]               0
      Bottleneck-110          [-1, 1024, 16, 8]               0
          Conv2d-111           [-1, 512, 16, 8]         524,288
     BatchNorm2d-112           [-1, 512, 16, 8]           1,024
            ReLU-113           [-1, 512, 16, 8]               0
          Conv2d-114           [-1, 512, 16, 8]          73,728
     BatchNorm2d-115           [-1, 512, 16, 8]           1,024
            ReLU-116           [-1, 512, 16, 8]               0
          Conv2d-117          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-118          [-1, 1024, 16, 8]           2,048
            ReLU-119          [-1, 1024, 16, 8]               0
      Bottleneck-120          [-1, 1024, 16, 8]               0
          Conv2d-121           [-1, 512, 16, 8]         524,288
     BatchNorm2d-122           [-1, 512, 16, 8]           1,024
            ReLU-123           [-1, 512, 16, 8]               0
          Conv2d-124           [-1, 512, 16, 8]          73,728
     BatchNorm2d-125           [-1, 512, 16, 8]           1,024
            ReLU-126           [-1, 512, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 512, 16, 8]         524,288
     BatchNorm2d-132           [-1, 512, 16, 8]           1,024
            ReLU-133           [-1, 512, 16, 8]               0
          Conv2d-134           [-1, 512, 16, 8]          73,728
     BatchNorm2d-135           [-1, 512, 16, 8]           1,024
            ReLU-136           [-1, 512, 16, 8]               0
          Conv2d-137          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-138          [-1, 1024, 16, 8]           2,048
            ReLU-139          [-1, 1024, 16, 8]               0
      Bottleneck-140          [-1, 1024, 16, 8]               0
          Conv2d-141          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-142          [-1, 1024, 16, 8]           2,048
            ReLU-143          [-1, 1024, 16, 8]               0
          Conv2d-144          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-145          [-1, 1024, 16, 8]           2,048
            ReLU-146          [-1, 1024, 16, 8]               0
          Conv2d-147          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-148          [-1, 2048, 16, 8]           4,096
          Conv2d-149          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-150          [-1, 2048, 16, 8]           4,096
            ReLU-151          [-1, 2048, 16, 8]               0
      Bottleneck-152          [-1, 2048, 16, 8]               0
          Conv2d-153          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-154          [-1, 1024, 16, 8]           2,048
            ReLU-155          [-1, 1024, 16, 8]               0
          Conv2d-156          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-157          [-1, 1024, 16, 8]           2,048
            ReLU-158          [-1, 1024, 16, 8]               0
          Conv2d-159          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-160          [-1, 2048, 16, 8]           4,096
            ReLU-161          [-1, 2048, 16, 8]               0
      Bottleneck-162          [-1, 2048, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
          Conv2d-166          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-167          [-1, 1024, 16, 8]           2,048
            ReLU-168          [-1, 1024, 16, 8]               0
          Conv2d-169          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-170          [-1, 2048, 16, 8]           4,096
            ReLU-171          [-1, 2048, 16, 8]               0
      Bottleneck-172          [-1, 2048, 16, 8]               0
================================================================
Total params: 22,979,904
Trainable params: 22,979,904
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 268.50
Params size (MB): 87.66
Estimated Total Size (MB): 356.54
----------------------------------------------------------------
**************************************************
resnext101_32x8d
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 256, 64, 32]          16,384
       BatchNorm2d-6          [-1, 256, 64, 32]             512
              ReLU-7          [-1, 256, 64, 32]               0
            Conv2d-8          [-1, 256, 64, 32]          18,432
       BatchNorm2d-9          [-1, 256, 64, 32]             512
             ReLU-10          [-1, 256, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          65,536
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
             ReLU-15          [-1, 256, 64, 32]               0
       Bottleneck-16          [-1, 256, 64, 32]               0
           Conv2d-17          [-1, 256, 64, 32]          65,536
      BatchNorm2d-18          [-1, 256, 64, 32]             512
             ReLU-19          [-1, 256, 64, 32]               0
           Conv2d-20          [-1, 256, 64, 32]          18,432
      BatchNorm2d-21          [-1, 256, 64, 32]             512
             ReLU-22          [-1, 256, 64, 32]               0
           Conv2d-23          [-1, 256, 64, 32]          65,536
      BatchNorm2d-24          [-1, 256, 64, 32]             512
             ReLU-25          [-1, 256, 64, 32]               0
       Bottleneck-26          [-1, 256, 64, 32]               0
           Conv2d-27          [-1, 256, 64, 32]          65,536
      BatchNorm2d-28          [-1, 256, 64, 32]             512
             ReLU-29          [-1, 256, 64, 32]               0
           Conv2d-30          [-1, 256, 64, 32]          18,432
      BatchNorm2d-31          [-1, 256, 64, 32]             512
             ReLU-32          [-1, 256, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          65,536
      BatchNorm2d-34          [-1, 256, 64, 32]             512
             ReLU-35          [-1, 256, 64, 32]               0
       Bottleneck-36          [-1, 256, 64, 32]               0
           Conv2d-37          [-1, 512, 64, 32]         131,072
      BatchNorm2d-38          [-1, 512, 64, 32]           1,024
             ReLU-39          [-1, 512, 64, 32]               0
           Conv2d-40          [-1, 512, 32, 16]          73,728
      BatchNorm2d-41          [-1, 512, 32, 16]           1,024
             ReLU-42          [-1, 512, 32, 16]               0
           Conv2d-43          [-1, 512, 32, 16]         262,144
      BatchNorm2d-44          [-1, 512, 32, 16]           1,024
           Conv2d-45          [-1, 512, 32, 16]         131,072
      BatchNorm2d-46          [-1, 512, 32, 16]           1,024
             ReLU-47          [-1, 512, 32, 16]               0
       Bottleneck-48          [-1, 512, 32, 16]               0
           Conv2d-49          [-1, 512, 32, 16]         262,144
      BatchNorm2d-50          [-1, 512, 32, 16]           1,024
             ReLU-51          [-1, 512, 32, 16]               0
           Conv2d-52          [-1, 512, 32, 16]          73,728
      BatchNorm2d-53          [-1, 512, 32, 16]           1,024
             ReLU-54          [-1, 512, 32, 16]               0
           Conv2d-55          [-1, 512, 32, 16]         262,144
      BatchNorm2d-56          [-1, 512, 32, 16]           1,024
             ReLU-57          [-1, 512, 32, 16]               0
       Bottleneck-58          [-1, 512, 32, 16]               0
           Conv2d-59          [-1, 512, 32, 16]         262,144
      BatchNorm2d-60          [-1, 512, 32, 16]           1,024
             ReLU-61          [-1, 512, 32, 16]               0
           Conv2d-62          [-1, 512, 32, 16]          73,728
      BatchNorm2d-63          [-1, 512, 32, 16]           1,024
             ReLU-64          [-1, 512, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]         262,144
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         262,144
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
             ReLU-71          [-1, 512, 32, 16]               0
           Conv2d-72          [-1, 512, 32, 16]          73,728
      BatchNorm2d-73          [-1, 512, 32, 16]           1,024
             ReLU-74          [-1, 512, 32, 16]               0
           Conv2d-75          [-1, 512, 32, 16]         262,144
      BatchNorm2d-76          [-1, 512, 32, 16]           1,024
             ReLU-77          [-1, 512, 32, 16]               0
       Bottleneck-78          [-1, 512, 32, 16]               0
           Conv2d-79         [-1, 1024, 32, 16]         524,288
      BatchNorm2d-80         [-1, 1024, 32, 16]           2,048
             ReLU-81         [-1, 1024, 32, 16]               0
           Conv2d-82          [-1, 1024, 16, 8]         294,912
      BatchNorm2d-83          [-1, 1024, 16, 8]           2,048
             ReLU-84          [-1, 1024, 16, 8]               0
           Conv2d-85          [-1, 1024, 16, 8]       1,048,576
      BatchNorm2d-86          [-1, 1024, 16, 8]           2,048
           Conv2d-87          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-88          [-1, 1024, 16, 8]           2,048
             ReLU-89          [-1, 1024, 16, 8]               0
       Bottleneck-90          [-1, 1024, 16, 8]               0
           Conv2d-91          [-1, 1024, 16, 8]       1,048,576
      BatchNorm2d-92          [-1, 1024, 16, 8]           2,048
             ReLU-93          [-1, 1024, 16, 8]               0
           Conv2d-94          [-1, 1024, 16, 8]         294,912
      BatchNorm2d-95          [-1, 1024, 16, 8]           2,048
             ReLU-96          [-1, 1024, 16, 8]               0
           Conv2d-97          [-1, 1024, 16, 8]       1,048,576
      BatchNorm2d-98          [-1, 1024, 16, 8]           2,048
             ReLU-99          [-1, 1024, 16, 8]               0
      Bottleneck-100          [-1, 1024, 16, 8]               0
          Conv2d-101          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-102          [-1, 1024, 16, 8]           2,048
            ReLU-103          [-1, 1024, 16, 8]               0
          Conv2d-104          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-105          [-1, 1024, 16, 8]           2,048
            ReLU-106          [-1, 1024, 16, 8]               0
          Conv2d-107          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-108          [-1, 1024, 16, 8]           2,048
            ReLU-109          [-1, 1024, 16, 8]               0
      Bottleneck-110          [-1, 1024, 16, 8]               0
          Conv2d-111          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-112          [-1, 1024, 16, 8]           2,048
            ReLU-113          [-1, 1024, 16, 8]               0
          Conv2d-114          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-115          [-1, 1024, 16, 8]           2,048
            ReLU-116          [-1, 1024, 16, 8]               0
          Conv2d-117          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-118          [-1, 1024, 16, 8]           2,048
            ReLU-119          [-1, 1024, 16, 8]               0
      Bottleneck-120          [-1, 1024, 16, 8]               0
          Conv2d-121          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-122          [-1, 1024, 16, 8]           2,048
            ReLU-123          [-1, 1024, 16, 8]               0
          Conv2d-124          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-125          [-1, 1024, 16, 8]           2,048
            ReLU-126          [-1, 1024, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-132          [-1, 1024, 16, 8]           2,048
            ReLU-133          [-1, 1024, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
            ReLU-136          [-1, 1024, 16, 8]               0
          Conv2d-137          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-138          [-1, 1024, 16, 8]           2,048
            ReLU-139          [-1, 1024, 16, 8]               0
      Bottleneck-140          [-1, 1024, 16, 8]               0
          Conv2d-141          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-142          [-1, 1024, 16, 8]           2,048
            ReLU-143          [-1, 1024, 16, 8]               0
          Conv2d-144          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-145          [-1, 1024, 16, 8]           2,048
            ReLU-146          [-1, 1024, 16, 8]               0
          Conv2d-147          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-148          [-1, 1024, 16, 8]           2,048
            ReLU-149          [-1, 1024, 16, 8]               0
      Bottleneck-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
          Conv2d-154          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-155          [-1, 1024, 16, 8]           2,048
            ReLU-156          [-1, 1024, 16, 8]               0
          Conv2d-157          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-158          [-1, 1024, 16, 8]           2,048
            ReLU-159          [-1, 1024, 16, 8]               0
      Bottleneck-160          [-1, 1024, 16, 8]               0
          Conv2d-161          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-162          [-1, 1024, 16, 8]           2,048
            ReLU-163          [-1, 1024, 16, 8]               0
          Conv2d-164          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-165          [-1, 1024, 16, 8]           2,048
            ReLU-166          [-1, 1024, 16, 8]               0
          Conv2d-167          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-168          [-1, 1024, 16, 8]           2,048
            ReLU-169          [-1, 1024, 16, 8]               0
      Bottleneck-170          [-1, 1024, 16, 8]               0
          Conv2d-171          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-172          [-1, 1024, 16, 8]           2,048
            ReLU-173          [-1, 1024, 16, 8]               0
          Conv2d-174          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-175          [-1, 1024, 16, 8]           2,048
            ReLU-176          [-1, 1024, 16, 8]               0
          Conv2d-177          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-178          [-1, 1024, 16, 8]           2,048
            ReLU-179          [-1, 1024, 16, 8]               0
      Bottleneck-180          [-1, 1024, 16, 8]               0
          Conv2d-181          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-182          [-1, 1024, 16, 8]           2,048
            ReLU-183          [-1, 1024, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
            ReLU-186          [-1, 1024, 16, 8]               0
          Conv2d-187          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-188          [-1, 1024, 16, 8]           2,048
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-192          [-1, 1024, 16, 8]           2,048
            ReLU-193          [-1, 1024, 16, 8]               0
          Conv2d-194          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-195          [-1, 1024, 16, 8]           2,048
            ReLU-196          [-1, 1024, 16, 8]               0
          Conv2d-197          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-198          [-1, 1024, 16, 8]           2,048
            ReLU-199          [-1, 1024, 16, 8]               0
      Bottleneck-200          [-1, 1024, 16, 8]               0
          Conv2d-201          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-202          [-1, 1024, 16, 8]           2,048
            ReLU-203          [-1, 1024, 16, 8]               0
          Conv2d-204          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-205          [-1, 1024, 16, 8]           2,048
            ReLU-206          [-1, 1024, 16, 8]               0
          Conv2d-207          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-208          [-1, 1024, 16, 8]           2,048
            ReLU-209          [-1, 1024, 16, 8]               0
      Bottleneck-210          [-1, 1024, 16, 8]               0
          Conv2d-211          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-212          [-1, 1024, 16, 8]           2,048
            ReLU-213          [-1, 1024, 16, 8]               0
          Conv2d-214          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-215          [-1, 1024, 16, 8]           2,048
            ReLU-216          [-1, 1024, 16, 8]               0
          Conv2d-217          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-218          [-1, 1024, 16, 8]           2,048
            ReLU-219          [-1, 1024, 16, 8]               0
      Bottleneck-220          [-1, 1024, 16, 8]               0
          Conv2d-221          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-222          [-1, 1024, 16, 8]           2,048
            ReLU-223          [-1, 1024, 16, 8]               0
          Conv2d-224          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-225          [-1, 1024, 16, 8]           2,048
            ReLU-226          [-1, 1024, 16, 8]               0
          Conv2d-227          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-228          [-1, 1024, 16, 8]           2,048
            ReLU-229          [-1, 1024, 16, 8]               0
      Bottleneck-230          [-1, 1024, 16, 8]               0
          Conv2d-231          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-232          [-1, 1024, 16, 8]           2,048
            ReLU-233          [-1, 1024, 16, 8]               0
          Conv2d-234          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-235          [-1, 1024, 16, 8]           2,048
            ReLU-236          [-1, 1024, 16, 8]               0
          Conv2d-237          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-238          [-1, 1024, 16, 8]           2,048
            ReLU-239          [-1, 1024, 16, 8]               0
      Bottleneck-240          [-1, 1024, 16, 8]               0
          Conv2d-241          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-242          [-1, 1024, 16, 8]           2,048
            ReLU-243          [-1, 1024, 16, 8]               0
          Conv2d-244          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-245          [-1, 1024, 16, 8]           2,048
            ReLU-246          [-1, 1024, 16, 8]               0
          Conv2d-247          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-248          [-1, 1024, 16, 8]           2,048
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-252          [-1, 1024, 16, 8]           2,048
            ReLU-253          [-1, 1024, 16, 8]               0
          Conv2d-254          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-255          [-1, 1024, 16, 8]           2,048
            ReLU-256          [-1, 1024, 16, 8]               0
          Conv2d-257          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-258          [-1, 1024, 16, 8]           2,048
            ReLU-259          [-1, 1024, 16, 8]               0
      Bottleneck-260          [-1, 1024, 16, 8]               0
          Conv2d-261          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-262          [-1, 1024, 16, 8]           2,048
            ReLU-263          [-1, 1024, 16, 8]               0
          Conv2d-264          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-265          [-1, 1024, 16, 8]           2,048
            ReLU-266          [-1, 1024, 16, 8]               0
          Conv2d-267          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-268          [-1, 1024, 16, 8]           2,048
            ReLU-269          [-1, 1024, 16, 8]               0
      Bottleneck-270          [-1, 1024, 16, 8]               0
          Conv2d-271          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-272          [-1, 1024, 16, 8]           2,048
            ReLU-273          [-1, 1024, 16, 8]               0
          Conv2d-274          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-275          [-1, 1024, 16, 8]           2,048
            ReLU-276          [-1, 1024, 16, 8]               0
          Conv2d-277          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-278          [-1, 1024, 16, 8]           2,048
            ReLU-279          [-1, 1024, 16, 8]               0
      Bottleneck-280          [-1, 1024, 16, 8]               0
          Conv2d-281          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-282          [-1, 1024, 16, 8]           2,048
            ReLU-283          [-1, 1024, 16, 8]               0
          Conv2d-284          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-285          [-1, 1024, 16, 8]           2,048
            ReLU-286          [-1, 1024, 16, 8]               0
          Conv2d-287          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-288          [-1, 1024, 16, 8]           2,048
            ReLU-289          [-1, 1024, 16, 8]               0
      Bottleneck-290          [-1, 1024, 16, 8]               0
          Conv2d-291          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-292          [-1, 1024, 16, 8]           2,048
            ReLU-293          [-1, 1024, 16, 8]               0
          Conv2d-294          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-295          [-1, 1024, 16, 8]           2,048
            ReLU-296          [-1, 1024, 16, 8]               0
          Conv2d-297          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-298          [-1, 1024, 16, 8]           2,048
            ReLU-299          [-1, 1024, 16, 8]               0
      Bottleneck-300          [-1, 1024, 16, 8]               0
          Conv2d-301          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-302          [-1, 1024, 16, 8]           2,048
            ReLU-303          [-1, 1024, 16, 8]               0
          Conv2d-304          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-305          [-1, 1024, 16, 8]           2,048
            ReLU-306          [-1, 1024, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
            ReLU-309          [-1, 1024, 16, 8]               0
      Bottleneck-310          [-1, 1024, 16, 8]               0
          Conv2d-311          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-312          [-1, 2048, 16, 8]           4,096
            ReLU-313          [-1, 2048, 16, 8]               0
          Conv2d-314          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-315          [-1, 2048, 16, 8]           4,096
            ReLU-316          [-1, 2048, 16, 8]               0
          Conv2d-317          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-318          [-1, 2048, 16, 8]           4,096
          Conv2d-319          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-320          [-1, 2048, 16, 8]           4,096
            ReLU-321          [-1, 2048, 16, 8]               0
      Bottleneck-322          [-1, 2048, 16, 8]               0
          Conv2d-323          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-324          [-1, 2048, 16, 8]           4,096
            ReLU-325          [-1, 2048, 16, 8]               0
          Conv2d-326          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-327          [-1, 2048, 16, 8]           4,096
            ReLU-328          [-1, 2048, 16, 8]               0
          Conv2d-329          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-330          [-1, 2048, 16, 8]           4,096
            ReLU-331          [-1, 2048, 16, 8]               0
      Bottleneck-332          [-1, 2048, 16, 8]               0
          Conv2d-333          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-334          [-1, 2048, 16, 8]           4,096
            ReLU-335          [-1, 2048, 16, 8]               0
          Conv2d-336          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-337          [-1, 2048, 16, 8]           4,096
            ReLU-338          [-1, 2048, 16, 8]               0
          Conv2d-339          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-340          [-1, 2048, 16, 8]           4,096
            ReLU-341          [-1, 2048, 16, 8]               0
      Bottleneck-342          [-1, 2048, 16, 8]               0
================================================================
Total params: 86,742,336
Trainable params: 86,742,336
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 548.00
Params size (MB): 330.90
Estimated Total Size (MB): 879.27
----------------------------------------------------------------
**************************************************
wide_resnet50_2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]         147,456
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
             ReLU-15          [-1, 256, 64, 32]               0
       Bottleneck-16          [-1, 256, 64, 32]               0
           Conv2d-17          [-1, 128, 64, 32]          32,768
      BatchNorm2d-18          [-1, 128, 64, 32]             256
             ReLU-19          [-1, 128, 64, 32]               0
           Conv2d-20          [-1, 128, 64, 32]         147,456
      BatchNorm2d-21          [-1, 128, 64, 32]             256
             ReLU-22          [-1, 128, 64, 32]               0
           Conv2d-23          [-1, 256, 64, 32]          32,768
      BatchNorm2d-24          [-1, 256, 64, 32]             512
             ReLU-25          [-1, 256, 64, 32]               0
       Bottleneck-26          [-1, 256, 64, 32]               0
           Conv2d-27          [-1, 128, 64, 32]          32,768
      BatchNorm2d-28          [-1, 128, 64, 32]             256
             ReLU-29          [-1, 128, 64, 32]               0
           Conv2d-30          [-1, 128, 64, 32]         147,456
      BatchNorm2d-31          [-1, 128, 64, 32]             256
             ReLU-32          [-1, 128, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          32,768
      BatchNorm2d-34          [-1, 256, 64, 32]             512
             ReLU-35          [-1, 256, 64, 32]               0
       Bottleneck-36          [-1, 256, 64, 32]               0
           Conv2d-37          [-1, 256, 64, 32]          65,536
      BatchNorm2d-38          [-1, 256, 64, 32]             512
             ReLU-39          [-1, 256, 64, 32]               0
           Conv2d-40          [-1, 256, 32, 16]         589,824
      BatchNorm2d-41          [-1, 256, 32, 16]             512
             ReLU-42          [-1, 256, 32, 16]               0
           Conv2d-43          [-1, 512, 32, 16]         131,072
      BatchNorm2d-44          [-1, 512, 32, 16]           1,024
           Conv2d-45          [-1, 512, 32, 16]         131,072
      BatchNorm2d-46          [-1, 512, 32, 16]           1,024
             ReLU-47          [-1, 512, 32, 16]               0
       Bottleneck-48          [-1, 512, 32, 16]               0
           Conv2d-49          [-1, 256, 32, 16]         131,072
      BatchNorm2d-50          [-1, 256, 32, 16]             512
             ReLU-51          [-1, 256, 32, 16]               0
           Conv2d-52          [-1, 256, 32, 16]         589,824
      BatchNorm2d-53          [-1, 256, 32, 16]             512
             ReLU-54          [-1, 256, 32, 16]               0
           Conv2d-55          [-1, 512, 32, 16]         131,072
      BatchNorm2d-56          [-1, 512, 32, 16]           1,024
             ReLU-57          [-1, 512, 32, 16]               0
       Bottleneck-58          [-1, 512, 32, 16]               0
           Conv2d-59          [-1, 256, 32, 16]         131,072
      BatchNorm2d-60          [-1, 256, 32, 16]             512
             ReLU-61          [-1, 256, 32, 16]               0
           Conv2d-62          [-1, 256, 32, 16]         589,824
      BatchNorm2d-63          [-1, 256, 32, 16]             512
             ReLU-64          [-1, 256, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]         131,072
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 256, 32, 16]         131,072
      BatchNorm2d-70          [-1, 256, 32, 16]             512
             ReLU-71          [-1, 256, 32, 16]               0
           Conv2d-72          [-1, 256, 32, 16]         589,824
      BatchNorm2d-73          [-1, 256, 32, 16]             512
             ReLU-74          [-1, 256, 32, 16]               0
           Conv2d-75          [-1, 512, 32, 16]         131,072
      BatchNorm2d-76          [-1, 512, 32, 16]           1,024
             ReLU-77          [-1, 512, 32, 16]               0
       Bottleneck-78          [-1, 512, 32, 16]               0
           Conv2d-79          [-1, 512, 32, 16]         262,144
      BatchNorm2d-80          [-1, 512, 32, 16]           1,024
             ReLU-81          [-1, 512, 32, 16]               0
           Conv2d-82           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-83           [-1, 512, 16, 8]           1,024
             ReLU-84           [-1, 512, 16, 8]               0
           Conv2d-85          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-86          [-1, 1024, 16, 8]           2,048
           Conv2d-87          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-88          [-1, 1024, 16, 8]           2,048
             ReLU-89          [-1, 1024, 16, 8]               0
       Bottleneck-90          [-1, 1024, 16, 8]               0
           Conv2d-91           [-1, 512, 16, 8]         524,288
      BatchNorm2d-92           [-1, 512, 16, 8]           1,024
             ReLU-93           [-1, 512, 16, 8]               0
           Conv2d-94           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-95           [-1, 512, 16, 8]           1,024
             ReLU-96           [-1, 512, 16, 8]               0
           Conv2d-97          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-98          [-1, 1024, 16, 8]           2,048
             ReLU-99          [-1, 1024, 16, 8]               0
      Bottleneck-100          [-1, 1024, 16, 8]               0
          Conv2d-101           [-1, 512, 16, 8]         524,288
     BatchNorm2d-102           [-1, 512, 16, 8]           1,024
            ReLU-103           [-1, 512, 16, 8]               0
          Conv2d-104           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-105           [-1, 512, 16, 8]           1,024
            ReLU-106           [-1, 512, 16, 8]               0
          Conv2d-107          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-108          [-1, 1024, 16, 8]           2,048
            ReLU-109          [-1, 1024, 16, 8]               0
      Bottleneck-110          [-1, 1024, 16, 8]               0
          Conv2d-111           [-1, 512, 16, 8]         524,288
     BatchNorm2d-112           [-1, 512, 16, 8]           1,024
            ReLU-113           [-1, 512, 16, 8]               0
          Conv2d-114           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-115           [-1, 512, 16, 8]           1,024
            ReLU-116           [-1, 512, 16, 8]               0
          Conv2d-117          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-118          [-1, 1024, 16, 8]           2,048
            ReLU-119          [-1, 1024, 16, 8]               0
      Bottleneck-120          [-1, 1024, 16, 8]               0
          Conv2d-121           [-1, 512, 16, 8]         524,288
     BatchNorm2d-122           [-1, 512, 16, 8]           1,024
            ReLU-123           [-1, 512, 16, 8]               0
          Conv2d-124           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-125           [-1, 512, 16, 8]           1,024
            ReLU-126           [-1, 512, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 512, 16, 8]         524,288
     BatchNorm2d-132           [-1, 512, 16, 8]           1,024
            ReLU-133           [-1, 512, 16, 8]               0
          Conv2d-134           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-135           [-1, 512, 16, 8]           1,024
            ReLU-136           [-1, 512, 16, 8]               0
          Conv2d-137          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-138          [-1, 1024, 16, 8]           2,048
            ReLU-139          [-1, 1024, 16, 8]               0
      Bottleneck-140          [-1, 1024, 16, 8]               0
          Conv2d-141          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-142          [-1, 1024, 16, 8]           2,048
            ReLU-143          [-1, 1024, 16, 8]               0
          Conv2d-144          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-145          [-1, 1024, 16, 8]           2,048
            ReLU-146          [-1, 1024, 16, 8]               0
          Conv2d-147          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-148          [-1, 2048, 16, 8]           4,096
          Conv2d-149          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-150          [-1, 2048, 16, 8]           4,096
            ReLU-151          [-1, 2048, 16, 8]               0
      Bottleneck-152          [-1, 2048, 16, 8]               0
          Conv2d-153          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-154          [-1, 1024, 16, 8]           2,048
            ReLU-155          [-1, 1024, 16, 8]               0
          Conv2d-156          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-157          [-1, 1024, 16, 8]           2,048
            ReLU-158          [-1, 1024, 16, 8]               0
          Conv2d-159          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-160          [-1, 2048, 16, 8]           4,096
            ReLU-161          [-1, 2048, 16, 8]               0
      Bottleneck-162          [-1, 2048, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
          Conv2d-166          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-167          [-1, 1024, 16, 8]           2,048
            ReLU-168          [-1, 1024, 16, 8]               0
          Conv2d-169          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-170          [-1, 2048, 16, 8]           4,096
            ReLU-171          [-1, 2048, 16, 8]               0
      Bottleneck-172          [-1, 2048, 16, 8]               0
================================================================
Total params: 66,834,240
Trainable params: 66,834,240
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 268.50
Params size (MB): 254.95
Estimated Total Size (MB): 523.83
----------------------------------------------------------------
**************************************************
wide_resnet101_2
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]         147,456
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
             ReLU-15          [-1, 256, 64, 32]               0
       Bottleneck-16          [-1, 256, 64, 32]               0
           Conv2d-17          [-1, 128, 64, 32]          32,768
      BatchNorm2d-18          [-1, 128, 64, 32]             256
             ReLU-19          [-1, 128, 64, 32]               0
           Conv2d-20          [-1, 128, 64, 32]         147,456
      BatchNorm2d-21          [-1, 128, 64, 32]             256
             ReLU-22          [-1, 128, 64, 32]               0
           Conv2d-23          [-1, 256, 64, 32]          32,768
      BatchNorm2d-24          [-1, 256, 64, 32]             512
             ReLU-25          [-1, 256, 64, 32]               0
       Bottleneck-26          [-1, 256, 64, 32]               0
           Conv2d-27          [-1, 128, 64, 32]          32,768
      BatchNorm2d-28          [-1, 128, 64, 32]             256
             ReLU-29          [-1, 128, 64, 32]               0
           Conv2d-30          [-1, 128, 64, 32]         147,456
      BatchNorm2d-31          [-1, 128, 64, 32]             256
             ReLU-32          [-1, 128, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          32,768
      BatchNorm2d-34          [-1, 256, 64, 32]             512
             ReLU-35          [-1, 256, 64, 32]               0
       Bottleneck-36          [-1, 256, 64, 32]               0
           Conv2d-37          [-1, 256, 64, 32]          65,536
      BatchNorm2d-38          [-1, 256, 64, 32]             512
             ReLU-39          [-1, 256, 64, 32]               0
           Conv2d-40          [-1, 256, 32, 16]         589,824
      BatchNorm2d-41          [-1, 256, 32, 16]             512
             ReLU-42          [-1, 256, 32, 16]               0
           Conv2d-43          [-1, 512, 32, 16]         131,072
      BatchNorm2d-44          [-1, 512, 32, 16]           1,024
           Conv2d-45          [-1, 512, 32, 16]         131,072
      BatchNorm2d-46          [-1, 512, 32, 16]           1,024
             ReLU-47          [-1, 512, 32, 16]               0
       Bottleneck-48          [-1, 512, 32, 16]               0
           Conv2d-49          [-1, 256, 32, 16]         131,072
      BatchNorm2d-50          [-1, 256, 32, 16]             512
             ReLU-51          [-1, 256, 32, 16]               0
           Conv2d-52          [-1, 256, 32, 16]         589,824
      BatchNorm2d-53          [-1, 256, 32, 16]             512
             ReLU-54          [-1, 256, 32, 16]               0
           Conv2d-55          [-1, 512, 32, 16]         131,072
      BatchNorm2d-56          [-1, 512, 32, 16]           1,024
             ReLU-57          [-1, 512, 32, 16]               0
       Bottleneck-58          [-1, 512, 32, 16]               0
           Conv2d-59          [-1, 256, 32, 16]         131,072
      BatchNorm2d-60          [-1, 256, 32, 16]             512
             ReLU-61          [-1, 256, 32, 16]               0
           Conv2d-62          [-1, 256, 32, 16]         589,824
      BatchNorm2d-63          [-1, 256, 32, 16]             512
             ReLU-64          [-1, 256, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]         131,072
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 256, 32, 16]         131,072
      BatchNorm2d-70          [-1, 256, 32, 16]             512
             ReLU-71          [-1, 256, 32, 16]               0
           Conv2d-72          [-1, 256, 32, 16]         589,824
      BatchNorm2d-73          [-1, 256, 32, 16]             512
             ReLU-74          [-1, 256, 32, 16]               0
           Conv2d-75          [-1, 512, 32, 16]         131,072
      BatchNorm2d-76          [-1, 512, 32, 16]           1,024
             ReLU-77          [-1, 512, 32, 16]               0
       Bottleneck-78          [-1, 512, 32, 16]               0
           Conv2d-79          [-1, 512, 32, 16]         262,144
      BatchNorm2d-80          [-1, 512, 32, 16]           1,024
             ReLU-81          [-1, 512, 32, 16]               0
           Conv2d-82           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-83           [-1, 512, 16, 8]           1,024
             ReLU-84           [-1, 512, 16, 8]               0
           Conv2d-85          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-86          [-1, 1024, 16, 8]           2,048
           Conv2d-87          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-88          [-1, 1024, 16, 8]           2,048
             ReLU-89          [-1, 1024, 16, 8]               0
       Bottleneck-90          [-1, 1024, 16, 8]               0
           Conv2d-91           [-1, 512, 16, 8]         524,288
      BatchNorm2d-92           [-1, 512, 16, 8]           1,024
             ReLU-93           [-1, 512, 16, 8]               0
           Conv2d-94           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-95           [-1, 512, 16, 8]           1,024
             ReLU-96           [-1, 512, 16, 8]               0
           Conv2d-97          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-98          [-1, 1024, 16, 8]           2,048
             ReLU-99          [-1, 1024, 16, 8]               0
      Bottleneck-100          [-1, 1024, 16, 8]               0
          Conv2d-101           [-1, 512, 16, 8]         524,288
     BatchNorm2d-102           [-1, 512, 16, 8]           1,024
            ReLU-103           [-1, 512, 16, 8]               0
          Conv2d-104           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-105           [-1, 512, 16, 8]           1,024
            ReLU-106           [-1, 512, 16, 8]               0
          Conv2d-107          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-108          [-1, 1024, 16, 8]           2,048
            ReLU-109          [-1, 1024, 16, 8]               0
      Bottleneck-110          [-1, 1024, 16, 8]               0
          Conv2d-111           [-1, 512, 16, 8]         524,288
     BatchNorm2d-112           [-1, 512, 16, 8]           1,024
            ReLU-113           [-1, 512, 16, 8]               0
          Conv2d-114           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-115           [-1, 512, 16, 8]           1,024
            ReLU-116           [-1, 512, 16, 8]               0
          Conv2d-117          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-118          [-1, 1024, 16, 8]           2,048
            ReLU-119          [-1, 1024, 16, 8]               0
      Bottleneck-120          [-1, 1024, 16, 8]               0
          Conv2d-121           [-1, 512, 16, 8]         524,288
     BatchNorm2d-122           [-1, 512, 16, 8]           1,024
            ReLU-123           [-1, 512, 16, 8]               0
          Conv2d-124           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-125           [-1, 512, 16, 8]           1,024
            ReLU-126           [-1, 512, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 512, 16, 8]         524,288
     BatchNorm2d-132           [-1, 512, 16, 8]           1,024
            ReLU-133           [-1, 512, 16, 8]               0
          Conv2d-134           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-135           [-1, 512, 16, 8]           1,024
            ReLU-136           [-1, 512, 16, 8]               0
          Conv2d-137          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-138          [-1, 1024, 16, 8]           2,048
            ReLU-139          [-1, 1024, 16, 8]               0
      Bottleneck-140          [-1, 1024, 16, 8]               0
          Conv2d-141           [-1, 512, 16, 8]         524,288
     BatchNorm2d-142           [-1, 512, 16, 8]           1,024
            ReLU-143           [-1, 512, 16, 8]               0
          Conv2d-144           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-145           [-1, 512, 16, 8]           1,024
            ReLU-146           [-1, 512, 16, 8]               0
          Conv2d-147          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-148          [-1, 1024, 16, 8]           2,048
            ReLU-149          [-1, 1024, 16, 8]               0
      Bottleneck-150          [-1, 1024, 16, 8]               0
          Conv2d-151           [-1, 512, 16, 8]         524,288
     BatchNorm2d-152           [-1, 512, 16, 8]           1,024
            ReLU-153           [-1, 512, 16, 8]               0
          Conv2d-154           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-155           [-1, 512, 16, 8]           1,024
            ReLU-156           [-1, 512, 16, 8]               0
          Conv2d-157          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-158          [-1, 1024, 16, 8]           2,048
            ReLU-159          [-1, 1024, 16, 8]               0
      Bottleneck-160          [-1, 1024, 16, 8]               0
          Conv2d-161           [-1, 512, 16, 8]         524,288
     BatchNorm2d-162           [-1, 512, 16, 8]           1,024
            ReLU-163           [-1, 512, 16, 8]               0
          Conv2d-164           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-165           [-1, 512, 16, 8]           1,024
            ReLU-166           [-1, 512, 16, 8]               0
          Conv2d-167          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-168          [-1, 1024, 16, 8]           2,048
            ReLU-169          [-1, 1024, 16, 8]               0
      Bottleneck-170          [-1, 1024, 16, 8]               0
          Conv2d-171           [-1, 512, 16, 8]         524,288
     BatchNorm2d-172           [-1, 512, 16, 8]           1,024
            ReLU-173           [-1, 512, 16, 8]               0
          Conv2d-174           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-175           [-1, 512, 16, 8]           1,024
            ReLU-176           [-1, 512, 16, 8]               0
          Conv2d-177          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-178          [-1, 1024, 16, 8]           2,048
            ReLU-179          [-1, 1024, 16, 8]               0
      Bottleneck-180          [-1, 1024, 16, 8]               0
          Conv2d-181           [-1, 512, 16, 8]         524,288
     BatchNorm2d-182           [-1, 512, 16, 8]           1,024
            ReLU-183           [-1, 512, 16, 8]               0
          Conv2d-184           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-185           [-1, 512, 16, 8]           1,024
            ReLU-186           [-1, 512, 16, 8]               0
          Conv2d-187          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-188          [-1, 1024, 16, 8]           2,048
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 512, 16, 8]         524,288
     BatchNorm2d-192           [-1, 512, 16, 8]           1,024
            ReLU-193           [-1, 512, 16, 8]               0
          Conv2d-194           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-195           [-1, 512, 16, 8]           1,024
            ReLU-196           [-1, 512, 16, 8]               0
          Conv2d-197          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-198          [-1, 1024, 16, 8]           2,048
            ReLU-199          [-1, 1024, 16, 8]               0
      Bottleneck-200          [-1, 1024, 16, 8]               0
          Conv2d-201           [-1, 512, 16, 8]         524,288
     BatchNorm2d-202           [-1, 512, 16, 8]           1,024
            ReLU-203           [-1, 512, 16, 8]               0
          Conv2d-204           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-205           [-1, 512, 16, 8]           1,024
            ReLU-206           [-1, 512, 16, 8]               0
          Conv2d-207          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-208          [-1, 1024, 16, 8]           2,048
            ReLU-209          [-1, 1024, 16, 8]               0
      Bottleneck-210          [-1, 1024, 16, 8]               0
          Conv2d-211           [-1, 512, 16, 8]         524,288
     BatchNorm2d-212           [-1, 512, 16, 8]           1,024
            ReLU-213           [-1, 512, 16, 8]               0
          Conv2d-214           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-215           [-1, 512, 16, 8]           1,024
            ReLU-216           [-1, 512, 16, 8]               0
          Conv2d-217          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-218          [-1, 1024, 16, 8]           2,048
            ReLU-219          [-1, 1024, 16, 8]               0
      Bottleneck-220          [-1, 1024, 16, 8]               0
          Conv2d-221           [-1, 512, 16, 8]         524,288
     BatchNorm2d-222           [-1, 512, 16, 8]           1,024
            ReLU-223           [-1, 512, 16, 8]               0
          Conv2d-224           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-225           [-1, 512, 16, 8]           1,024
            ReLU-226           [-1, 512, 16, 8]               0
          Conv2d-227          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-228          [-1, 1024, 16, 8]           2,048
            ReLU-229          [-1, 1024, 16, 8]               0
      Bottleneck-230          [-1, 1024, 16, 8]               0
          Conv2d-231           [-1, 512, 16, 8]         524,288
     BatchNorm2d-232           [-1, 512, 16, 8]           1,024
            ReLU-233           [-1, 512, 16, 8]               0
          Conv2d-234           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-235           [-1, 512, 16, 8]           1,024
            ReLU-236           [-1, 512, 16, 8]               0
          Conv2d-237          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-238          [-1, 1024, 16, 8]           2,048
            ReLU-239          [-1, 1024, 16, 8]               0
      Bottleneck-240          [-1, 1024, 16, 8]               0
          Conv2d-241           [-1, 512, 16, 8]         524,288
     BatchNorm2d-242           [-1, 512, 16, 8]           1,024
            ReLU-243           [-1, 512, 16, 8]               0
          Conv2d-244           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-245           [-1, 512, 16, 8]           1,024
            ReLU-246           [-1, 512, 16, 8]               0
          Conv2d-247          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-248          [-1, 1024, 16, 8]           2,048
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251           [-1, 512, 16, 8]         524,288
     BatchNorm2d-252           [-1, 512, 16, 8]           1,024
            ReLU-253           [-1, 512, 16, 8]               0
          Conv2d-254           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-255           [-1, 512, 16, 8]           1,024
            ReLU-256           [-1, 512, 16, 8]               0
          Conv2d-257          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-258          [-1, 1024, 16, 8]           2,048
            ReLU-259          [-1, 1024, 16, 8]               0
      Bottleneck-260          [-1, 1024, 16, 8]               0
          Conv2d-261           [-1, 512, 16, 8]         524,288
     BatchNorm2d-262           [-1, 512, 16, 8]           1,024
            ReLU-263           [-1, 512, 16, 8]               0
          Conv2d-264           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-265           [-1, 512, 16, 8]           1,024
            ReLU-266           [-1, 512, 16, 8]               0
          Conv2d-267          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-268          [-1, 1024, 16, 8]           2,048
            ReLU-269          [-1, 1024, 16, 8]               0
      Bottleneck-270          [-1, 1024, 16, 8]               0
          Conv2d-271           [-1, 512, 16, 8]         524,288
     BatchNorm2d-272           [-1, 512, 16, 8]           1,024
            ReLU-273           [-1, 512, 16, 8]               0
          Conv2d-274           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-275           [-1, 512, 16, 8]           1,024
            ReLU-276           [-1, 512, 16, 8]               0
          Conv2d-277          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-278          [-1, 1024, 16, 8]           2,048
            ReLU-279          [-1, 1024, 16, 8]               0
      Bottleneck-280          [-1, 1024, 16, 8]               0
          Conv2d-281           [-1, 512, 16, 8]         524,288
     BatchNorm2d-282           [-1, 512, 16, 8]           1,024
            ReLU-283           [-1, 512, 16, 8]               0
          Conv2d-284           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-285           [-1, 512, 16, 8]           1,024
            ReLU-286           [-1, 512, 16, 8]               0
          Conv2d-287          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-288          [-1, 1024, 16, 8]           2,048
            ReLU-289          [-1, 1024, 16, 8]               0
      Bottleneck-290          [-1, 1024, 16, 8]               0
          Conv2d-291           [-1, 512, 16, 8]         524,288
     BatchNorm2d-292           [-1, 512, 16, 8]           1,024
            ReLU-293           [-1, 512, 16, 8]               0
          Conv2d-294           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-295           [-1, 512, 16, 8]           1,024
            ReLU-296           [-1, 512, 16, 8]               0
          Conv2d-297          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-298          [-1, 1024, 16, 8]           2,048
            ReLU-299          [-1, 1024, 16, 8]               0
      Bottleneck-300          [-1, 1024, 16, 8]               0
          Conv2d-301           [-1, 512, 16, 8]         524,288
     BatchNorm2d-302           [-1, 512, 16, 8]           1,024
            ReLU-303           [-1, 512, 16, 8]               0
          Conv2d-304           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-305           [-1, 512, 16, 8]           1,024
            ReLU-306           [-1, 512, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
            ReLU-309          [-1, 1024, 16, 8]               0
      Bottleneck-310          [-1, 1024, 16, 8]               0
          Conv2d-311          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-312          [-1, 1024, 16, 8]           2,048
            ReLU-313          [-1, 1024, 16, 8]               0
          Conv2d-314          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-315          [-1, 1024, 16, 8]           2,048
            ReLU-316          [-1, 1024, 16, 8]               0
          Conv2d-317          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-318          [-1, 2048, 16, 8]           4,096
          Conv2d-319          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-320          [-1, 2048, 16, 8]           4,096
            ReLU-321          [-1, 2048, 16, 8]               0
      Bottleneck-322          [-1, 2048, 16, 8]               0
          Conv2d-323          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-324          [-1, 1024, 16, 8]           2,048
            ReLU-325          [-1, 1024, 16, 8]               0
          Conv2d-326          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-327          [-1, 1024, 16, 8]           2,048
            ReLU-328          [-1, 1024, 16, 8]               0
          Conv2d-329          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-330          [-1, 2048, 16, 8]           4,096
            ReLU-331          [-1, 2048, 16, 8]               0
      Bottleneck-332          [-1, 2048, 16, 8]               0
          Conv2d-333          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-334          [-1, 1024, 16, 8]           2,048
            ReLU-335          [-1, 1024, 16, 8]               0
          Conv2d-336          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-337          [-1, 1024, 16, 8]           2,048
            ReLU-338          [-1, 1024, 16, 8]               0
          Conv2d-339          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-340          [-1, 2048, 16, 8]           4,096
            ReLU-341          [-1, 2048, 16, 8]               0
      Bottleneck-342          [-1, 2048, 16, 8]               0
================================================================
Total params: 124,837,696
Trainable params: 124,837,696
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 387.50
Params size (MB): 476.22
Estimated Total Size (MB): 864.09
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet18_se
Traceback (most recent call last):
  File "/Users/arron/Projects/PycharmProjects/reid-baseline/test/model_test.py", line 53, in <module>
    test_backbone(name, se=b[0], ibn_a=b[1], ibn_b=b[2])
  File "/Users/arron/Projects/PycharmProjects/reid-baseline/test/model_test.py", line 22, in test_backbone
    base = model_map[model_name](last_stride=1, pretrained=False, se=se, ibn_a=ibn_a, ibn_b=ibn_b)
KeyError: 'resnet18_se'
**********************************************************************
**********************************************************************
resnet18_se
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-10             [-1, 64, 1, 1]               0
           Linear-11                    [-1, 4]             256
             ReLU-12                    [-1, 4]               0
           Linear-13                   [-1, 64]             256
          Sigmoid-14                   [-1, 64]               0
          SELayer-15           [-1, 64, 64, 32]               0
             ReLU-16           [-1, 64, 64, 32]               0
       BasicBlock-17           [-1, 64, 64, 32]               0
           Conv2d-18           [-1, 64, 64, 32]          36,864
      BatchNorm2d-19           [-1, 64, 64, 32]             128
             ReLU-20           [-1, 64, 64, 32]               0
           Conv2d-21           [-1, 64, 64, 32]          36,864
      BatchNorm2d-22           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-23             [-1, 64, 1, 1]               0
           Linear-24                    [-1, 4]             256
             ReLU-25                    [-1, 4]               0
           Linear-26                   [-1, 64]             256
          Sigmoid-27                   [-1, 64]               0
          SELayer-28           [-1, 64, 64, 32]               0
             ReLU-29           [-1, 64, 64, 32]               0
       BasicBlock-30           [-1, 64, 64, 32]               0
           Conv2d-31          [-1, 128, 32, 16]          73,728
      BatchNorm2d-32          [-1, 128, 32, 16]             256
             ReLU-33          [-1, 128, 32, 16]               0
           Conv2d-34          [-1, 128, 32, 16]         147,456
      BatchNorm2d-35          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-36            [-1, 128, 1, 1]               0
           Linear-37                    [-1, 8]           1,024
             ReLU-38                    [-1, 8]               0
           Linear-39                  [-1, 128]           1,024
          Sigmoid-40                  [-1, 128]               0
          SELayer-41          [-1, 128, 32, 16]               0
           Conv2d-42          [-1, 128, 32, 16]           8,192
      BatchNorm2d-43          [-1, 128, 32, 16]             256
             ReLU-44          [-1, 128, 32, 16]               0
       BasicBlock-45          [-1, 128, 32, 16]               0
           Conv2d-46          [-1, 128, 32, 16]         147,456
      BatchNorm2d-47          [-1, 128, 32, 16]             256
             ReLU-48          [-1, 128, 32, 16]               0
           Conv2d-49          [-1, 128, 32, 16]         147,456
      BatchNorm2d-50          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-51            [-1, 128, 1, 1]               0
           Linear-52                    [-1, 8]           1,024
             ReLU-53                    [-1, 8]               0
           Linear-54                  [-1, 128]           1,024
          Sigmoid-55                  [-1, 128]               0
          SELayer-56          [-1, 128, 32, 16]               0
             ReLU-57          [-1, 128, 32, 16]               0
       BasicBlock-58          [-1, 128, 32, 16]               0
           Conv2d-59           [-1, 256, 16, 8]         294,912
      BatchNorm2d-60           [-1, 256, 16, 8]             512
             ReLU-61           [-1, 256, 16, 8]               0
           Conv2d-62           [-1, 256, 16, 8]         589,824
      BatchNorm2d-63           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-64            [-1, 256, 1, 1]               0
           Linear-65                   [-1, 16]           4,096
             ReLU-66                   [-1, 16]               0
           Linear-67                  [-1, 256]           4,096
          Sigmoid-68                  [-1, 256]               0
          SELayer-69           [-1, 256, 16, 8]               0
           Conv2d-70           [-1, 256, 16, 8]          32,768
      BatchNorm2d-71           [-1, 256, 16, 8]             512
             ReLU-72           [-1, 256, 16, 8]               0
       BasicBlock-73           [-1, 256, 16, 8]               0
           Conv2d-74           [-1, 256, 16, 8]         589,824
      BatchNorm2d-75           [-1, 256, 16, 8]             512
             ReLU-76           [-1, 256, 16, 8]               0
           Conv2d-77           [-1, 256, 16, 8]         589,824
      BatchNorm2d-78           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-79            [-1, 256, 1, 1]               0
           Linear-80                   [-1, 16]           4,096
             ReLU-81                   [-1, 16]               0
           Linear-82                  [-1, 256]           4,096
          Sigmoid-83                  [-1, 256]               0
          SELayer-84           [-1, 256, 16, 8]               0
             ReLU-85           [-1, 256, 16, 8]               0
       BasicBlock-86           [-1, 256, 16, 8]               0
           Conv2d-87           [-1, 512, 16, 8]       1,179,648
      BatchNorm2d-88           [-1, 512, 16, 8]           1,024
             ReLU-89           [-1, 512, 16, 8]               0
           Conv2d-90           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-91           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-92            [-1, 512, 1, 1]               0
           Linear-93                   [-1, 32]          16,384
             ReLU-94                   [-1, 32]               0
           Linear-95                  [-1, 512]          16,384
          Sigmoid-96                  [-1, 512]               0
          SELayer-97           [-1, 512, 16, 8]               0
           Conv2d-98           [-1, 512, 16, 8]         131,072
      BatchNorm2d-99           [-1, 512, 16, 8]           1,024
            ReLU-100           [-1, 512, 16, 8]               0
      BasicBlock-101           [-1, 512, 16, 8]               0
          Conv2d-102           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-103           [-1, 512, 16, 8]           1,024
            ReLU-104           [-1, 512, 16, 8]               0
          Conv2d-105           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-106           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-107            [-1, 512, 1, 1]               0
          Linear-108                   [-1, 32]          16,384
            ReLU-109                   [-1, 32]               0
          Linear-110                  [-1, 512]          16,384
         Sigmoid-111                  [-1, 512]               0
         SELayer-112           [-1, 512, 16, 8]               0
            ReLU-113           [-1, 512, 16, 8]               0
      BasicBlock-114           [-1, 512, 16, 8]               0
================================================================
Total params: 11,263,552
Trainable params: 11,263,552
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 51.55
Params size (MB): 42.97
Estimated Total Size (MB): 94.89
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet18_se_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
    InstanceNorm2d-6           [-1, 32, 64, 32]              64
       BatchNorm2d-7           [-1, 32, 64, 32]              64
               IBN-8           [-1, 64, 64, 32]               0
              ReLU-9           [-1, 64, 64, 32]               0
           Conv2d-10           [-1, 64, 64, 32]          36,864
      BatchNorm2d-11           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-12             [-1, 64, 1, 1]               0
           Linear-13                    [-1, 4]             256
             ReLU-14                    [-1, 4]               0
           Linear-15                   [-1, 64]             256
          Sigmoid-16                   [-1, 64]               0
          SELayer-17           [-1, 64, 64, 32]               0
             ReLU-18           [-1, 64, 64, 32]               0
       BasicBlock-19           [-1, 64, 64, 32]               0
           Conv2d-20           [-1, 64, 64, 32]          36,864
   InstanceNorm2d-21           [-1, 32, 64, 32]              64
      BatchNorm2d-22           [-1, 32, 64, 32]              64
              IBN-23           [-1, 64, 64, 32]               0
             ReLU-24           [-1, 64, 64, 32]               0
           Conv2d-25           [-1, 64, 64, 32]          36,864
      BatchNorm2d-26           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-27             [-1, 64, 1, 1]               0
           Linear-28                    [-1, 4]             256
             ReLU-29                    [-1, 4]               0
           Linear-30                   [-1, 64]             256
          Sigmoid-31                   [-1, 64]               0
          SELayer-32           [-1, 64, 64, 32]               0
             ReLU-33           [-1, 64, 64, 32]               0
       BasicBlock-34           [-1, 64, 64, 32]               0
           Conv2d-35          [-1, 128, 32, 16]          73,728
   InstanceNorm2d-36           [-1, 64, 32, 16]             128
      BatchNorm2d-37           [-1, 64, 32, 16]             128
              IBN-38          [-1, 128, 32, 16]               0
             ReLU-39          [-1, 128, 32, 16]               0
           Conv2d-40          [-1, 128, 32, 16]         147,456
      BatchNorm2d-41          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-42            [-1, 128, 1, 1]               0
           Linear-43                    [-1, 8]           1,024
             ReLU-44                    [-1, 8]               0
           Linear-45                  [-1, 128]           1,024
          Sigmoid-46                  [-1, 128]               0
          SELayer-47          [-1, 128, 32, 16]               0
           Conv2d-48          [-1, 128, 32, 16]           8,192
      BatchNorm2d-49          [-1, 128, 32, 16]             256
             ReLU-50          [-1, 128, 32, 16]               0
       BasicBlock-51          [-1, 128, 32, 16]               0
           Conv2d-52          [-1, 128, 32, 16]         147,456
   InstanceNorm2d-53           [-1, 64, 32, 16]             128
      BatchNorm2d-54           [-1, 64, 32, 16]             128
              IBN-55          [-1, 128, 32, 16]               0
             ReLU-56          [-1, 128, 32, 16]               0
           Conv2d-57          [-1, 128, 32, 16]         147,456
      BatchNorm2d-58          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-59            [-1, 128, 1, 1]               0
           Linear-60                    [-1, 8]           1,024
             ReLU-61                    [-1, 8]               0
           Linear-62                  [-1, 128]           1,024
          Sigmoid-63                  [-1, 128]               0
          SELayer-64          [-1, 128, 32, 16]               0
             ReLU-65          [-1, 128, 32, 16]               0
       BasicBlock-66          [-1, 128, 32, 16]               0
           Conv2d-67           [-1, 256, 16, 8]         294,912
   InstanceNorm2d-68           [-1, 128, 16, 8]             256
      BatchNorm2d-69           [-1, 128, 16, 8]             256
              IBN-70           [-1, 256, 16, 8]               0
             ReLU-71           [-1, 256, 16, 8]               0
           Conv2d-72           [-1, 256, 16, 8]         589,824
      BatchNorm2d-73           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-74            [-1, 256, 1, 1]               0
           Linear-75                   [-1, 16]           4,096
             ReLU-76                   [-1, 16]               0
           Linear-77                  [-1, 256]           4,096
          Sigmoid-78                  [-1, 256]               0
          SELayer-79           [-1, 256, 16, 8]               0
           Conv2d-80           [-1, 256, 16, 8]          32,768
      BatchNorm2d-81           [-1, 256, 16, 8]             512
             ReLU-82           [-1, 256, 16, 8]               0
       BasicBlock-83           [-1, 256, 16, 8]               0
           Conv2d-84           [-1, 256, 16, 8]         589,824
   InstanceNorm2d-85           [-1, 128, 16, 8]             256
      BatchNorm2d-86           [-1, 128, 16, 8]             256
              IBN-87           [-1, 256, 16, 8]               0
             ReLU-88           [-1, 256, 16, 8]               0
           Conv2d-89           [-1, 256, 16, 8]         589,824
      BatchNorm2d-90           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-91            [-1, 256, 1, 1]               0
           Linear-92                   [-1, 16]           4,096
             ReLU-93                   [-1, 16]               0
           Linear-94                  [-1, 256]           4,096
          Sigmoid-95                  [-1, 256]               0
          SELayer-96           [-1, 256, 16, 8]               0
             ReLU-97           [-1, 256, 16, 8]               0
       BasicBlock-98           [-1, 256, 16, 8]               0
           Conv2d-99           [-1, 512, 16, 8]       1,179,648
     BatchNorm2d-100           [-1, 512, 16, 8]           1,024
            ReLU-101           [-1, 512, 16, 8]               0
          Conv2d-102           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-103           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-104            [-1, 512, 1, 1]               0
          Linear-105                   [-1, 32]          16,384
            ReLU-106                   [-1, 32]               0
          Linear-107                  [-1, 512]          16,384
         Sigmoid-108                  [-1, 512]               0
         SELayer-109           [-1, 512, 16, 8]               0
          Conv2d-110           [-1, 512, 16, 8]         131,072
     BatchNorm2d-111           [-1, 512, 16, 8]           1,024
            ReLU-112           [-1, 512, 16, 8]               0
      BasicBlock-113           [-1, 512, 16, 8]               0
          Conv2d-114           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-115           [-1, 512, 16, 8]           1,024
            ReLU-116           [-1, 512, 16, 8]               0
          Conv2d-117           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-118           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-119            [-1, 512, 1, 1]               0
          Linear-120                   [-1, 32]          16,384
            ReLU-121                   [-1, 32]               0
          Linear-122                  [-1, 512]          16,384
         Sigmoid-123                  [-1, 512]               0
         SELayer-124           [-1, 512, 16, 8]               0
            ReLU-125           [-1, 512, 16, 8]               0
      BasicBlock-126           [-1, 512, 16, 8]               0
================================================================
Total params: 11,263,552
Trainable params: 11,263,552
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 55.05
Params size (MB): 42.97
Estimated Total Size (MB): 98.39
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet18_se_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-10             [-1, 64, 1, 1]               0
           Linear-11                    [-1, 4]             256
             ReLU-12                    [-1, 4]               0
           Linear-13                   [-1, 64]             256
          Sigmoid-14                   [-1, 64]               0
          SELayer-15           [-1, 64, 64, 32]               0
   InstanceNorm2d-16           [-1, 64, 64, 32]             128
             ReLU-17           [-1, 64, 64, 32]               0
       BasicBlock-18           [-1, 64, 64, 32]               0
           Conv2d-19           [-1, 64, 64, 32]          36,864
      BatchNorm2d-20           [-1, 64, 64, 32]             128
             ReLU-21           [-1, 64, 64, 32]               0
           Conv2d-22           [-1, 64, 64, 32]          36,864
      BatchNorm2d-23           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-24             [-1, 64, 1, 1]               0
           Linear-25                    [-1, 4]             256
             ReLU-26                    [-1, 4]               0
           Linear-27                   [-1, 64]             256
          Sigmoid-28                   [-1, 64]               0
          SELayer-29           [-1, 64, 64, 32]               0
   InstanceNorm2d-30           [-1, 64, 64, 32]             128
             ReLU-31           [-1, 64, 64, 32]               0
       BasicBlock-32           [-1, 64, 64, 32]               0
           Conv2d-33          [-1, 128, 32, 16]          73,728
      BatchNorm2d-34          [-1, 128, 32, 16]             256
             ReLU-35          [-1, 128, 32, 16]               0
           Conv2d-36          [-1, 128, 32, 16]         147,456
      BatchNorm2d-37          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-38            [-1, 128, 1, 1]               0
           Linear-39                    [-1, 8]           1,024
             ReLU-40                    [-1, 8]               0
           Linear-41                  [-1, 128]           1,024
          Sigmoid-42                  [-1, 128]               0
          SELayer-43          [-1, 128, 32, 16]               0
           Conv2d-44          [-1, 128, 32, 16]           8,192
      BatchNorm2d-45          [-1, 128, 32, 16]             256
   InstanceNorm2d-46          [-1, 128, 32, 16]             256
             ReLU-47          [-1, 128, 32, 16]               0
       BasicBlock-48          [-1, 128, 32, 16]               0
           Conv2d-49          [-1, 128, 32, 16]         147,456
      BatchNorm2d-50          [-1, 128, 32, 16]             256
             ReLU-51          [-1, 128, 32, 16]               0
           Conv2d-52          [-1, 128, 32, 16]         147,456
      BatchNorm2d-53          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-54            [-1, 128, 1, 1]               0
           Linear-55                    [-1, 8]           1,024
             ReLU-56                    [-1, 8]               0
           Linear-57                  [-1, 128]           1,024
          Sigmoid-58                  [-1, 128]               0
          SELayer-59          [-1, 128, 32, 16]               0
   InstanceNorm2d-60          [-1, 128, 32, 16]             256
             ReLU-61          [-1, 128, 32, 16]               0
       BasicBlock-62          [-1, 128, 32, 16]               0
           Conv2d-63           [-1, 256, 16, 8]         294,912
      BatchNorm2d-64           [-1, 256, 16, 8]             512
             ReLU-65           [-1, 256, 16, 8]               0
           Conv2d-66           [-1, 256, 16, 8]         589,824
      BatchNorm2d-67           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-68            [-1, 256, 1, 1]               0
           Linear-69                   [-1, 16]           4,096
             ReLU-70                   [-1, 16]               0
           Linear-71                  [-1, 256]           4,096
          Sigmoid-72                  [-1, 256]               0
          SELayer-73           [-1, 256, 16, 8]               0
           Conv2d-74           [-1, 256, 16, 8]          32,768
      BatchNorm2d-75           [-1, 256, 16, 8]             512
             ReLU-76           [-1, 256, 16, 8]               0
       BasicBlock-77           [-1, 256, 16, 8]               0
           Conv2d-78           [-1, 256, 16, 8]         589,824
      BatchNorm2d-79           [-1, 256, 16, 8]             512
             ReLU-80           [-1, 256, 16, 8]               0
           Conv2d-81           [-1, 256, 16, 8]         589,824
      BatchNorm2d-82           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-83            [-1, 256, 1, 1]               0
           Linear-84                   [-1, 16]           4,096
             ReLU-85                   [-1, 16]               0
           Linear-86                  [-1, 256]           4,096
          Sigmoid-87                  [-1, 256]               0
          SELayer-88           [-1, 256, 16, 8]               0
             ReLU-89           [-1, 256, 16, 8]               0
       BasicBlock-90           [-1, 256, 16, 8]               0
           Conv2d-91           [-1, 512, 16, 8]       1,179,648
      BatchNorm2d-92           [-1, 512, 16, 8]           1,024
             ReLU-93           [-1, 512, 16, 8]               0
           Conv2d-94           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-95           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-96            [-1, 512, 1, 1]               0
           Linear-97                   [-1, 32]          16,384
             ReLU-98                   [-1, 32]               0
           Linear-99                  [-1, 512]          16,384
         Sigmoid-100                  [-1, 512]               0
         SELayer-101           [-1, 512, 16, 8]               0
          Conv2d-102           [-1, 512, 16, 8]         131,072
     BatchNorm2d-103           [-1, 512, 16, 8]           1,024
            ReLU-104           [-1, 512, 16, 8]               0
      BasicBlock-105           [-1, 512, 16, 8]               0
          Conv2d-106           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-107           [-1, 512, 16, 8]           1,024
            ReLU-108           [-1, 512, 16, 8]               0
          Conv2d-109           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-110           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-111            [-1, 512, 1, 1]               0
          Linear-112                   [-1, 32]          16,384
            ReLU-113                   [-1, 32]               0
          Linear-114                  [-1, 512]          16,384
         Sigmoid-115                  [-1, 512]               0
         SELayer-116           [-1, 512, 16, 8]               0
            ReLU-117           [-1, 512, 16, 8]               0
      BasicBlock-118           [-1, 512, 16, 8]               0
================================================================
Total params: 11,264,320
Trainable params: 11,264,320
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 54.55
Params size (MB): 42.97
Estimated Total Size (MB): 97.89
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet18_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
    InstanceNorm2d-6           [-1, 32, 64, 32]              64
       BatchNorm2d-7           [-1, 32, 64, 32]              64
               IBN-8           [-1, 64, 64, 32]               0
              ReLU-9           [-1, 64, 64, 32]               0
           Conv2d-10           [-1, 64, 64, 32]          36,864
      BatchNorm2d-11           [-1, 64, 64, 32]             128
             ReLU-12           [-1, 64, 64, 32]               0
       BasicBlock-13           [-1, 64, 64, 32]               0
           Conv2d-14           [-1, 64, 64, 32]          36,864
   InstanceNorm2d-15           [-1, 32, 64, 32]              64
      BatchNorm2d-16           [-1, 32, 64, 32]              64
              IBN-17           [-1, 64, 64, 32]               0
             ReLU-18           [-1, 64, 64, 32]               0
           Conv2d-19           [-1, 64, 64, 32]          36,864
      BatchNorm2d-20           [-1, 64, 64, 32]             128
             ReLU-21           [-1, 64, 64, 32]               0
       BasicBlock-22           [-1, 64, 64, 32]               0
           Conv2d-23          [-1, 128, 32, 16]          73,728
   InstanceNorm2d-24           [-1, 64, 32, 16]             128
      BatchNorm2d-25           [-1, 64, 32, 16]             128
              IBN-26          [-1, 128, 32, 16]               0
             ReLU-27          [-1, 128, 32, 16]               0
           Conv2d-28          [-1, 128, 32, 16]         147,456
      BatchNorm2d-29          [-1, 128, 32, 16]             256
           Conv2d-30          [-1, 128, 32, 16]           8,192
      BatchNorm2d-31          [-1, 128, 32, 16]             256
             ReLU-32          [-1, 128, 32, 16]               0
       BasicBlock-33          [-1, 128, 32, 16]               0
           Conv2d-34          [-1, 128, 32, 16]         147,456
   InstanceNorm2d-35           [-1, 64, 32, 16]             128
      BatchNorm2d-36           [-1, 64, 32, 16]             128
              IBN-37          [-1, 128, 32, 16]               0
             ReLU-38          [-1, 128, 32, 16]               0
           Conv2d-39          [-1, 128, 32, 16]         147,456
      BatchNorm2d-40          [-1, 128, 32, 16]             256
             ReLU-41          [-1, 128, 32, 16]               0
       BasicBlock-42          [-1, 128, 32, 16]               0
           Conv2d-43           [-1, 256, 16, 8]         294,912
   InstanceNorm2d-44           [-1, 128, 16, 8]             256
      BatchNorm2d-45           [-1, 128, 16, 8]             256
              IBN-46           [-1, 256, 16, 8]               0
             ReLU-47           [-1, 256, 16, 8]               0
           Conv2d-48           [-1, 256, 16, 8]         589,824
      BatchNorm2d-49           [-1, 256, 16, 8]             512
           Conv2d-50           [-1, 256, 16, 8]          32,768
      BatchNorm2d-51           [-1, 256, 16, 8]             512
             ReLU-52           [-1, 256, 16, 8]               0
       BasicBlock-53           [-1, 256, 16, 8]               0
           Conv2d-54           [-1, 256, 16, 8]         589,824
   InstanceNorm2d-55           [-1, 128, 16, 8]             256
      BatchNorm2d-56           [-1, 128, 16, 8]             256
              IBN-57           [-1, 256, 16, 8]               0
             ReLU-58           [-1, 256, 16, 8]               0
           Conv2d-59           [-1, 256, 16, 8]         589,824
      BatchNorm2d-60           [-1, 256, 16, 8]             512
             ReLU-61           [-1, 256, 16, 8]               0
       BasicBlock-62           [-1, 256, 16, 8]               0
           Conv2d-63           [-1, 512, 16, 8]       1,179,648
      BatchNorm2d-64           [-1, 512, 16, 8]           1,024
             ReLU-65           [-1, 512, 16, 8]               0
           Conv2d-66           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-67           [-1, 512, 16, 8]           1,024
           Conv2d-68           [-1, 512, 16, 8]         131,072
      BatchNorm2d-69           [-1, 512, 16, 8]           1,024
             ReLU-70           [-1, 512, 16, 8]               0
       BasicBlock-71           [-1, 512, 16, 8]               0
           Conv2d-72           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-73           [-1, 512, 16, 8]           1,024
             ReLU-74           [-1, 512, 16, 8]               0
           Conv2d-75           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-76           [-1, 512, 16, 8]           1,024
             ReLU-77           [-1, 512, 16, 8]               0
       BasicBlock-78           [-1, 512, 16, 8]               0
================================================================
Total params: 11,176,512
Trainable params: 11,176,512
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 50.50
Params size (MB): 42.64
Estimated Total Size (MB): 93.51
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet18_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
   InstanceNorm2d-10           [-1, 64, 64, 32]             128
             ReLU-11           [-1, 64, 64, 32]               0
       BasicBlock-12           [-1, 64, 64, 32]               0
           Conv2d-13           [-1, 64, 64, 32]          36,864
      BatchNorm2d-14           [-1, 64, 64, 32]             128
             ReLU-15           [-1, 64, 64, 32]               0
           Conv2d-16           [-1, 64, 64, 32]          36,864
      BatchNorm2d-17           [-1, 64, 64, 32]             128
   InstanceNorm2d-18           [-1, 64, 64, 32]             128
             ReLU-19           [-1, 64, 64, 32]               0
       BasicBlock-20           [-1, 64, 64, 32]               0
           Conv2d-21          [-1, 128, 32, 16]          73,728
      BatchNorm2d-22          [-1, 128, 32, 16]             256
             ReLU-23          [-1, 128, 32, 16]               0
           Conv2d-24          [-1, 128, 32, 16]         147,456
      BatchNorm2d-25          [-1, 128, 32, 16]             256
           Conv2d-26          [-1, 128, 32, 16]           8,192
      BatchNorm2d-27          [-1, 128, 32, 16]             256
   InstanceNorm2d-28          [-1, 128, 32, 16]             256
             ReLU-29          [-1, 128, 32, 16]               0
       BasicBlock-30          [-1, 128, 32, 16]               0
           Conv2d-31          [-1, 128, 32, 16]         147,456
      BatchNorm2d-32          [-1, 128, 32, 16]             256
             ReLU-33          [-1, 128, 32, 16]               0
           Conv2d-34          [-1, 128, 32, 16]         147,456
      BatchNorm2d-35          [-1, 128, 32, 16]             256
   InstanceNorm2d-36          [-1, 128, 32, 16]             256
             ReLU-37          [-1, 128, 32, 16]               0
       BasicBlock-38          [-1, 128, 32, 16]               0
           Conv2d-39           [-1, 256, 16, 8]         294,912
      BatchNorm2d-40           [-1, 256, 16, 8]             512
             ReLU-41           [-1, 256, 16, 8]               0
           Conv2d-42           [-1, 256, 16, 8]         589,824
      BatchNorm2d-43           [-1, 256, 16, 8]             512
           Conv2d-44           [-1, 256, 16, 8]          32,768
      BatchNorm2d-45           [-1, 256, 16, 8]             512
             ReLU-46           [-1, 256, 16, 8]               0
       BasicBlock-47           [-1, 256, 16, 8]               0
           Conv2d-48           [-1, 256, 16, 8]         589,824
      BatchNorm2d-49           [-1, 256, 16, 8]             512
             ReLU-50           [-1, 256, 16, 8]               0
           Conv2d-51           [-1, 256, 16, 8]         589,824
      BatchNorm2d-52           [-1, 256, 16, 8]             512
             ReLU-53           [-1, 256, 16, 8]               0
       BasicBlock-54           [-1, 256, 16, 8]               0
           Conv2d-55           [-1, 512, 16, 8]       1,179,648
      BatchNorm2d-56           [-1, 512, 16, 8]           1,024
             ReLU-57           [-1, 512, 16, 8]               0
           Conv2d-58           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-59           [-1, 512, 16, 8]           1,024
           Conv2d-60           [-1, 512, 16, 8]         131,072
      BatchNorm2d-61           [-1, 512, 16, 8]           1,024
             ReLU-62           [-1, 512, 16, 8]               0
       BasicBlock-63           [-1, 512, 16, 8]               0
           Conv2d-64           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-65           [-1, 512, 16, 8]           1,024
             ReLU-66           [-1, 512, 16, 8]               0
           Conv2d-67           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-68           [-1, 512, 16, 8]           1,024
             ReLU-69           [-1, 512, 16, 8]               0
       BasicBlock-70           [-1, 512, 16, 8]               0
================================================================
Total params: 11,177,280
Trainable params: 11,177,280
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 50.00
Params size (MB): 42.64
Estimated Total Size (MB): 93.01
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet34_se
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-10             [-1, 64, 1, 1]               0
           Linear-11                    [-1, 4]             256
             ReLU-12                    [-1, 4]               0
           Linear-13                   [-1, 64]             256
          Sigmoid-14                   [-1, 64]               0
          SELayer-15           [-1, 64, 64, 32]               0
             ReLU-16           [-1, 64, 64, 32]               0
       BasicBlock-17           [-1, 64, 64, 32]               0
           Conv2d-18           [-1, 64, 64, 32]          36,864
      BatchNorm2d-19           [-1, 64, 64, 32]             128
             ReLU-20           [-1, 64, 64, 32]               0
           Conv2d-21           [-1, 64, 64, 32]          36,864
      BatchNorm2d-22           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-23             [-1, 64, 1, 1]               0
           Linear-24                    [-1, 4]             256
             ReLU-25                    [-1, 4]               0
           Linear-26                   [-1, 64]             256
          Sigmoid-27                   [-1, 64]               0
          SELayer-28           [-1, 64, 64, 32]               0
             ReLU-29           [-1, 64, 64, 32]               0
       BasicBlock-30           [-1, 64, 64, 32]               0
           Conv2d-31           [-1, 64, 64, 32]          36,864
      BatchNorm2d-32           [-1, 64, 64, 32]             128
             ReLU-33           [-1, 64, 64, 32]               0
           Conv2d-34           [-1, 64, 64, 32]          36,864
      BatchNorm2d-35           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-36             [-1, 64, 1, 1]               0
           Linear-37                    [-1, 4]             256
             ReLU-38                    [-1, 4]               0
           Linear-39                   [-1, 64]             256
          Sigmoid-40                   [-1, 64]               0
          SELayer-41           [-1, 64, 64, 32]               0
             ReLU-42           [-1, 64, 64, 32]               0
       BasicBlock-43           [-1, 64, 64, 32]               0
           Conv2d-44          [-1, 128, 32, 16]          73,728
      BatchNorm2d-45          [-1, 128, 32, 16]             256
             ReLU-46          [-1, 128, 32, 16]               0
           Conv2d-47          [-1, 128, 32, 16]         147,456
      BatchNorm2d-48          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-49            [-1, 128, 1, 1]               0
           Linear-50                    [-1, 8]           1,024
             ReLU-51                    [-1, 8]               0
           Linear-52                  [-1, 128]           1,024
          Sigmoid-53                  [-1, 128]               0
          SELayer-54          [-1, 128, 32, 16]               0
           Conv2d-55          [-1, 128, 32, 16]           8,192
      BatchNorm2d-56          [-1, 128, 32, 16]             256
             ReLU-57          [-1, 128, 32, 16]               0
       BasicBlock-58          [-1, 128, 32, 16]               0
           Conv2d-59          [-1, 128, 32, 16]         147,456
      BatchNorm2d-60          [-1, 128, 32, 16]             256
             ReLU-61          [-1, 128, 32, 16]               0
           Conv2d-62          [-1, 128, 32, 16]         147,456
      BatchNorm2d-63          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-64            [-1, 128, 1, 1]               0
           Linear-65                    [-1, 8]           1,024
             ReLU-66                    [-1, 8]               0
           Linear-67                  [-1, 128]           1,024
          Sigmoid-68                  [-1, 128]               0
          SELayer-69          [-1, 128, 32, 16]               0
             ReLU-70          [-1, 128, 32, 16]               0
       BasicBlock-71          [-1, 128, 32, 16]               0
           Conv2d-72          [-1, 128, 32, 16]         147,456
      BatchNorm2d-73          [-1, 128, 32, 16]             256
             ReLU-74          [-1, 128, 32, 16]               0
           Conv2d-75          [-1, 128, 32, 16]         147,456
      BatchNorm2d-76          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-77            [-1, 128, 1, 1]               0
           Linear-78                    [-1, 8]           1,024
             ReLU-79                    [-1, 8]               0
           Linear-80                  [-1, 128]           1,024
          Sigmoid-81                  [-1, 128]               0
          SELayer-82          [-1, 128, 32, 16]               0
             ReLU-83          [-1, 128, 32, 16]               0
       BasicBlock-84          [-1, 128, 32, 16]               0
           Conv2d-85          [-1, 128, 32, 16]         147,456
      BatchNorm2d-86          [-1, 128, 32, 16]             256
             ReLU-87          [-1, 128, 32, 16]               0
           Conv2d-88          [-1, 128, 32, 16]         147,456
      BatchNorm2d-89          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-90            [-1, 128, 1, 1]               0
           Linear-91                    [-1, 8]           1,024
             ReLU-92                    [-1, 8]               0
           Linear-93                  [-1, 128]           1,024
          Sigmoid-94                  [-1, 128]               0
          SELayer-95          [-1, 128, 32, 16]               0
             ReLU-96          [-1, 128, 32, 16]               0
       BasicBlock-97          [-1, 128, 32, 16]               0
           Conv2d-98           [-1, 256, 16, 8]         294,912
      BatchNorm2d-99           [-1, 256, 16, 8]             512
            ReLU-100           [-1, 256, 16, 8]               0
          Conv2d-101           [-1, 256, 16, 8]         589,824
     BatchNorm2d-102           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-103            [-1, 256, 1, 1]               0
          Linear-104                   [-1, 16]           4,096
            ReLU-105                   [-1, 16]               0
          Linear-106                  [-1, 256]           4,096
         Sigmoid-107                  [-1, 256]               0
         SELayer-108           [-1, 256, 16, 8]               0
          Conv2d-109           [-1, 256, 16, 8]          32,768
     BatchNorm2d-110           [-1, 256, 16, 8]             512
            ReLU-111           [-1, 256, 16, 8]               0
      BasicBlock-112           [-1, 256, 16, 8]               0
          Conv2d-113           [-1, 256, 16, 8]         589,824
     BatchNorm2d-114           [-1, 256, 16, 8]             512
            ReLU-115           [-1, 256, 16, 8]               0
          Conv2d-116           [-1, 256, 16, 8]         589,824
     BatchNorm2d-117           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-118            [-1, 256, 1, 1]               0
          Linear-119                   [-1, 16]           4,096
            ReLU-120                   [-1, 16]               0
          Linear-121                  [-1, 256]           4,096
         Sigmoid-122                  [-1, 256]               0
         SELayer-123           [-1, 256, 16, 8]               0
            ReLU-124           [-1, 256, 16, 8]               0
      BasicBlock-125           [-1, 256, 16, 8]               0
          Conv2d-126           [-1, 256, 16, 8]         589,824
     BatchNorm2d-127           [-1, 256, 16, 8]             512
            ReLU-128           [-1, 256, 16, 8]               0
          Conv2d-129           [-1, 256, 16, 8]         589,824
     BatchNorm2d-130           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-131            [-1, 256, 1, 1]               0
          Linear-132                   [-1, 16]           4,096
            ReLU-133                   [-1, 16]               0
          Linear-134                  [-1, 256]           4,096
         Sigmoid-135                  [-1, 256]               0
         SELayer-136           [-1, 256, 16, 8]               0
            ReLU-137           [-1, 256, 16, 8]               0
      BasicBlock-138           [-1, 256, 16, 8]               0
          Conv2d-139           [-1, 256, 16, 8]         589,824
     BatchNorm2d-140           [-1, 256, 16, 8]             512
            ReLU-141           [-1, 256, 16, 8]               0
          Conv2d-142           [-1, 256, 16, 8]         589,824
     BatchNorm2d-143           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-144            [-1, 256, 1, 1]               0
          Linear-145                   [-1, 16]           4,096
            ReLU-146                   [-1, 16]               0
          Linear-147                  [-1, 256]           4,096
         Sigmoid-148                  [-1, 256]               0
         SELayer-149           [-1, 256, 16, 8]               0
            ReLU-150           [-1, 256, 16, 8]               0
      BasicBlock-151           [-1, 256, 16, 8]               0
          Conv2d-152           [-1, 256, 16, 8]         589,824
     BatchNorm2d-153           [-1, 256, 16, 8]             512
            ReLU-154           [-1, 256, 16, 8]               0
          Conv2d-155           [-1, 256, 16, 8]         589,824
     BatchNorm2d-156           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-157            [-1, 256, 1, 1]               0
          Linear-158                   [-1, 16]           4,096
            ReLU-159                   [-1, 16]               0
          Linear-160                  [-1, 256]           4,096
         Sigmoid-161                  [-1, 256]               0
         SELayer-162           [-1, 256, 16, 8]               0
            ReLU-163           [-1, 256, 16, 8]               0
      BasicBlock-164           [-1, 256, 16, 8]               0
          Conv2d-165           [-1, 256, 16, 8]         589,824
     BatchNorm2d-166           [-1, 256, 16, 8]             512
            ReLU-167           [-1, 256, 16, 8]               0
          Conv2d-168           [-1, 256, 16, 8]         589,824
     BatchNorm2d-169           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-170            [-1, 256, 1, 1]               0
          Linear-171                   [-1, 16]           4,096
            ReLU-172                   [-1, 16]               0
          Linear-173                  [-1, 256]           4,096
         Sigmoid-174                  [-1, 256]               0
         SELayer-175           [-1, 256, 16, 8]               0
            ReLU-176           [-1, 256, 16, 8]               0
      BasicBlock-177           [-1, 256, 16, 8]               0
          Conv2d-178           [-1, 512, 16, 8]       1,179,648
     BatchNorm2d-179           [-1, 512, 16, 8]           1,024
            ReLU-180           [-1, 512, 16, 8]               0
          Conv2d-181           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-182           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-183            [-1, 512, 1, 1]               0
          Linear-184                   [-1, 32]          16,384
            ReLU-185                   [-1, 32]               0
          Linear-186                  [-1, 512]          16,384
         Sigmoid-187                  [-1, 512]               0
         SELayer-188           [-1, 512, 16, 8]               0
          Conv2d-189           [-1, 512, 16, 8]         131,072
     BatchNorm2d-190           [-1, 512, 16, 8]           1,024
            ReLU-191           [-1, 512, 16, 8]               0
      BasicBlock-192           [-1, 512, 16, 8]               0
          Conv2d-193           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-194           [-1, 512, 16, 8]           1,024
            ReLU-195           [-1, 512, 16, 8]               0
          Conv2d-196           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-197           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-198            [-1, 512, 1, 1]               0
          Linear-199                   [-1, 32]          16,384
            ReLU-200                   [-1, 32]               0
          Linear-201                  [-1, 512]          16,384
         Sigmoid-202                  [-1, 512]               0
         SELayer-203           [-1, 512, 16, 8]               0
            ReLU-204           [-1, 512, 16, 8]               0
      BasicBlock-205           [-1, 512, 16, 8]               0
          Conv2d-206           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-207           [-1, 512, 16, 8]           1,024
            ReLU-208           [-1, 512, 16, 8]               0
          Conv2d-209           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-210           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-211            [-1, 512, 1, 1]               0
          Linear-212                   [-1, 32]          16,384
            ReLU-213                   [-1, 32]               0
          Linear-214                  [-1, 512]          16,384
         Sigmoid-215                  [-1, 512]               0
         SELayer-216           [-1, 512, 16, 8]               0
            ReLU-217           [-1, 512, 16, 8]               0
      BasicBlock-218           [-1, 512, 16, 8]               0
================================================================
Total params: 21,441,856
Trainable params: 21,441,856
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 79.59
Params size (MB): 81.79
Estimated Total Size (MB): 161.76
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet34_se_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
    InstanceNorm2d-6           [-1, 32, 64, 32]              64
       BatchNorm2d-7           [-1, 32, 64, 32]              64
               IBN-8           [-1, 64, 64, 32]               0
              ReLU-9           [-1, 64, 64, 32]               0
           Conv2d-10           [-1, 64, 64, 32]          36,864
      BatchNorm2d-11           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-12             [-1, 64, 1, 1]               0
           Linear-13                    [-1, 4]             256
             ReLU-14                    [-1, 4]               0
           Linear-15                   [-1, 64]             256
          Sigmoid-16                   [-1, 64]               0
          SELayer-17           [-1, 64, 64, 32]               0
             ReLU-18           [-1, 64, 64, 32]               0
       BasicBlock-19           [-1, 64, 64, 32]               0
           Conv2d-20           [-1, 64, 64, 32]          36,864
   InstanceNorm2d-21           [-1, 32, 64, 32]              64
      BatchNorm2d-22           [-1, 32, 64, 32]              64
              IBN-23           [-1, 64, 64, 32]               0
             ReLU-24           [-1, 64, 64, 32]               0
           Conv2d-25           [-1, 64, 64, 32]          36,864
      BatchNorm2d-26           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-27             [-1, 64, 1, 1]               0
           Linear-28                    [-1, 4]             256
             ReLU-29                    [-1, 4]               0
           Linear-30                   [-1, 64]             256
          Sigmoid-31                   [-1, 64]               0
          SELayer-32           [-1, 64, 64, 32]               0
             ReLU-33           [-1, 64, 64, 32]               0
       BasicBlock-34           [-1, 64, 64, 32]               0
           Conv2d-35           [-1, 64, 64, 32]          36,864
   InstanceNorm2d-36           [-1, 32, 64, 32]              64
      BatchNorm2d-37           [-1, 32, 64, 32]              64
              IBN-38           [-1, 64, 64, 32]               0
             ReLU-39           [-1, 64, 64, 32]               0
           Conv2d-40           [-1, 64, 64, 32]          36,864
      BatchNorm2d-41           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-42             [-1, 64, 1, 1]               0
           Linear-43                    [-1, 4]             256
             ReLU-44                    [-1, 4]               0
           Linear-45                   [-1, 64]             256
          Sigmoid-46                   [-1, 64]               0
          SELayer-47           [-1, 64, 64, 32]               0
             ReLU-48           [-1, 64, 64, 32]               0
       BasicBlock-49           [-1, 64, 64, 32]               0
           Conv2d-50          [-1, 128, 32, 16]          73,728
   InstanceNorm2d-51           [-1, 64, 32, 16]             128
      BatchNorm2d-52           [-1, 64, 32, 16]             128
              IBN-53          [-1, 128, 32, 16]               0
             ReLU-54          [-1, 128, 32, 16]               0
           Conv2d-55          [-1, 128, 32, 16]         147,456
      BatchNorm2d-56          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-57            [-1, 128, 1, 1]               0
           Linear-58                    [-1, 8]           1,024
             ReLU-59                    [-1, 8]               0
           Linear-60                  [-1, 128]           1,024
          Sigmoid-61                  [-1, 128]               0
          SELayer-62          [-1, 128, 32, 16]               0
           Conv2d-63          [-1, 128, 32, 16]           8,192
      BatchNorm2d-64          [-1, 128, 32, 16]             256
             ReLU-65          [-1, 128, 32, 16]               0
       BasicBlock-66          [-1, 128, 32, 16]               0
           Conv2d-67          [-1, 128, 32, 16]         147,456
   InstanceNorm2d-68           [-1, 64, 32, 16]             128
      BatchNorm2d-69           [-1, 64, 32, 16]             128
              IBN-70          [-1, 128, 32, 16]               0
             ReLU-71          [-1, 128, 32, 16]               0
           Conv2d-72          [-1, 128, 32, 16]         147,456
      BatchNorm2d-73          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-74            [-1, 128, 1, 1]               0
           Linear-75                    [-1, 8]           1,024
             ReLU-76                    [-1, 8]               0
           Linear-77                  [-1, 128]           1,024
          Sigmoid-78                  [-1, 128]               0
          SELayer-79          [-1, 128, 32, 16]               0
             ReLU-80          [-1, 128, 32, 16]               0
       BasicBlock-81          [-1, 128, 32, 16]               0
           Conv2d-82          [-1, 128, 32, 16]         147,456
   InstanceNorm2d-83           [-1, 64, 32, 16]             128
      BatchNorm2d-84           [-1, 64, 32, 16]             128
              IBN-85          [-1, 128, 32, 16]               0
             ReLU-86          [-1, 128, 32, 16]               0
           Conv2d-87          [-1, 128, 32, 16]         147,456
      BatchNorm2d-88          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-89            [-1, 128, 1, 1]               0
           Linear-90                    [-1, 8]           1,024
             ReLU-91                    [-1, 8]               0
           Linear-92                  [-1, 128]           1,024
          Sigmoid-93                  [-1, 128]               0
          SELayer-94          [-1, 128, 32, 16]               0
             ReLU-95          [-1, 128, 32, 16]               0
       BasicBlock-96          [-1, 128, 32, 16]               0
           Conv2d-97          [-1, 128, 32, 16]         147,456
   InstanceNorm2d-98           [-1, 64, 32, 16]             128
      BatchNorm2d-99           [-1, 64, 32, 16]             128
             IBN-100          [-1, 128, 32, 16]               0
            ReLU-101          [-1, 128, 32, 16]               0
          Conv2d-102          [-1, 128, 32, 16]         147,456
     BatchNorm2d-103          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-104            [-1, 128, 1, 1]               0
          Linear-105                    [-1, 8]           1,024
            ReLU-106                    [-1, 8]               0
          Linear-107                  [-1, 128]           1,024
         Sigmoid-108                  [-1, 128]               0
         SELayer-109          [-1, 128, 32, 16]               0
            ReLU-110          [-1, 128, 32, 16]               0
      BasicBlock-111          [-1, 128, 32, 16]               0
          Conv2d-112           [-1, 256, 16, 8]         294,912
  InstanceNorm2d-113           [-1, 128, 16, 8]             256
     BatchNorm2d-114           [-1, 128, 16, 8]             256
             IBN-115           [-1, 256, 16, 8]               0
            ReLU-116           [-1, 256, 16, 8]               0
          Conv2d-117           [-1, 256, 16, 8]         589,824
     BatchNorm2d-118           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-119            [-1, 256, 1, 1]               0
          Linear-120                   [-1, 16]           4,096
            ReLU-121                   [-1, 16]               0
          Linear-122                  [-1, 256]           4,096
         Sigmoid-123                  [-1, 256]               0
         SELayer-124           [-1, 256, 16, 8]               0
          Conv2d-125           [-1, 256, 16, 8]          32,768
     BatchNorm2d-126           [-1, 256, 16, 8]             512
            ReLU-127           [-1, 256, 16, 8]               0
      BasicBlock-128           [-1, 256, 16, 8]               0
          Conv2d-129           [-1, 256, 16, 8]         589,824
  InstanceNorm2d-130           [-1, 128, 16, 8]             256
     BatchNorm2d-131           [-1, 128, 16, 8]             256
             IBN-132           [-1, 256, 16, 8]               0
            ReLU-133           [-1, 256, 16, 8]               0
          Conv2d-134           [-1, 256, 16, 8]         589,824
     BatchNorm2d-135           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-136            [-1, 256, 1, 1]               0
          Linear-137                   [-1, 16]           4,096
            ReLU-138                   [-1, 16]               0
          Linear-139                  [-1, 256]           4,096
         Sigmoid-140                  [-1, 256]               0
         SELayer-141           [-1, 256, 16, 8]               0
            ReLU-142           [-1, 256, 16, 8]               0
      BasicBlock-143           [-1, 256, 16, 8]               0
          Conv2d-144           [-1, 256, 16, 8]         589,824
  InstanceNorm2d-145           [-1, 128, 16, 8]             256
     BatchNorm2d-146           [-1, 128, 16, 8]             256
             IBN-147           [-1, 256, 16, 8]               0
            ReLU-148           [-1, 256, 16, 8]               0
          Conv2d-149           [-1, 256, 16, 8]         589,824
     BatchNorm2d-150           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-151            [-1, 256, 1, 1]               0
          Linear-152                   [-1, 16]           4,096
            ReLU-153                   [-1, 16]               0
          Linear-154                  [-1, 256]           4,096
         Sigmoid-155                  [-1, 256]               0
         SELayer-156           [-1, 256, 16, 8]               0
            ReLU-157           [-1, 256, 16, 8]               0
      BasicBlock-158           [-1, 256, 16, 8]               0
          Conv2d-159           [-1, 256, 16, 8]         589,824
  InstanceNorm2d-160           [-1, 128, 16, 8]             256
     BatchNorm2d-161           [-1, 128, 16, 8]             256
             IBN-162           [-1, 256, 16, 8]               0
            ReLU-163           [-1, 256, 16, 8]               0
          Conv2d-164           [-1, 256, 16, 8]         589,824
     BatchNorm2d-165           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-166            [-1, 256, 1, 1]               0
          Linear-167                   [-1, 16]           4,096
            ReLU-168                   [-1, 16]               0
          Linear-169                  [-1, 256]           4,096
         Sigmoid-170                  [-1, 256]               0
         SELayer-171           [-1, 256, 16, 8]               0
            ReLU-172           [-1, 256, 16, 8]               0
      BasicBlock-173           [-1, 256, 16, 8]               0
          Conv2d-174           [-1, 256, 16, 8]         589,824
  InstanceNorm2d-175           [-1, 128, 16, 8]             256
     BatchNorm2d-176           [-1, 128, 16, 8]             256
             IBN-177           [-1, 256, 16, 8]               0
            ReLU-178           [-1, 256, 16, 8]               0
          Conv2d-179           [-1, 256, 16, 8]         589,824
     BatchNorm2d-180           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-181            [-1, 256, 1, 1]               0
          Linear-182                   [-1, 16]           4,096
            ReLU-183                   [-1, 16]               0
          Linear-184                  [-1, 256]           4,096
         Sigmoid-185                  [-1, 256]               0
         SELayer-186           [-1, 256, 16, 8]               0
            ReLU-187           [-1, 256, 16, 8]               0
      BasicBlock-188           [-1, 256, 16, 8]               0
          Conv2d-189           [-1, 256, 16, 8]         589,824
  InstanceNorm2d-190           [-1, 128, 16, 8]             256
     BatchNorm2d-191           [-1, 128, 16, 8]             256
             IBN-192           [-1, 256, 16, 8]               0
            ReLU-193           [-1, 256, 16, 8]               0
          Conv2d-194           [-1, 256, 16, 8]         589,824
     BatchNorm2d-195           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-196            [-1, 256, 1, 1]               0
          Linear-197                   [-1, 16]           4,096
            ReLU-198                   [-1, 16]               0
          Linear-199                  [-1, 256]           4,096
         Sigmoid-200                  [-1, 256]               0
         SELayer-201           [-1, 256, 16, 8]               0
            ReLU-202           [-1, 256, 16, 8]               0
      BasicBlock-203           [-1, 256, 16, 8]               0
          Conv2d-204           [-1, 512, 16, 8]       1,179,648
     BatchNorm2d-205           [-1, 512, 16, 8]           1,024
            ReLU-206           [-1, 512, 16, 8]               0
          Conv2d-207           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-208           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-209            [-1, 512, 1, 1]               0
          Linear-210                   [-1, 32]          16,384
            ReLU-211                   [-1, 32]               0
          Linear-212                  [-1, 512]          16,384
         Sigmoid-213                  [-1, 512]               0
         SELayer-214           [-1, 512, 16, 8]               0
          Conv2d-215           [-1, 512, 16, 8]         131,072
     BatchNorm2d-216           [-1, 512, 16, 8]           1,024
            ReLU-217           [-1, 512, 16, 8]               0
      BasicBlock-218           [-1, 512, 16, 8]               0
          Conv2d-219           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-220           [-1, 512, 16, 8]           1,024
            ReLU-221           [-1, 512, 16, 8]               0
          Conv2d-222           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-223           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-224            [-1, 512, 1, 1]               0
          Linear-225                   [-1, 32]          16,384
            ReLU-226                   [-1, 32]               0
          Linear-227                  [-1, 512]          16,384
         Sigmoid-228                  [-1, 512]               0
         SELayer-229           [-1, 512, 16, 8]               0
            ReLU-230           [-1, 512, 16, 8]               0
      BasicBlock-231           [-1, 512, 16, 8]               0
          Conv2d-232           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-233           [-1, 512, 16, 8]           1,024
            ReLU-234           [-1, 512, 16, 8]               0
          Conv2d-235           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-236           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-237            [-1, 512, 1, 1]               0
          Linear-238                   [-1, 32]          16,384
            ReLU-239                   [-1, 32]               0
          Linear-240                  [-1, 512]          16,384
         Sigmoid-241                  [-1, 512]               0
         SELayer-242           [-1, 512, 16, 8]               0
            ReLU-243           [-1, 512, 16, 8]               0
      BasicBlock-244           [-1, 512, 16, 8]               0
================================================================
Total params: 21,441,856
Trainable params: 21,441,856
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 86.09
Params size (MB): 81.79
Estimated Total Size (MB): 168.26
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet34_se_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-10             [-1, 64, 1, 1]               0
           Linear-11                    [-1, 4]             256
             ReLU-12                    [-1, 4]               0
           Linear-13                   [-1, 64]             256
          Sigmoid-14                   [-1, 64]               0
          SELayer-15           [-1, 64, 64, 32]               0
   InstanceNorm2d-16           [-1, 64, 64, 32]             128
             ReLU-17           [-1, 64, 64, 32]               0
       BasicBlock-18           [-1, 64, 64, 32]               0
           Conv2d-19           [-1, 64, 64, 32]          36,864
      BatchNorm2d-20           [-1, 64, 64, 32]             128
             ReLU-21           [-1, 64, 64, 32]               0
           Conv2d-22           [-1, 64, 64, 32]          36,864
      BatchNorm2d-23           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-24             [-1, 64, 1, 1]               0
           Linear-25                    [-1, 4]             256
             ReLU-26                    [-1, 4]               0
           Linear-27                   [-1, 64]             256
          Sigmoid-28                   [-1, 64]               0
          SELayer-29           [-1, 64, 64, 32]               0
   InstanceNorm2d-30           [-1, 64, 64, 32]             128
             ReLU-31           [-1, 64, 64, 32]               0
       BasicBlock-32           [-1, 64, 64, 32]               0
           Conv2d-33           [-1, 64, 64, 32]          36,864
      BatchNorm2d-34           [-1, 64, 64, 32]             128
             ReLU-35           [-1, 64, 64, 32]               0
           Conv2d-36           [-1, 64, 64, 32]          36,864
      BatchNorm2d-37           [-1, 64, 64, 32]             128
AdaptiveAvgPool2d-38             [-1, 64, 1, 1]               0
           Linear-39                    [-1, 4]             256
             ReLU-40                    [-1, 4]               0
           Linear-41                   [-1, 64]             256
          Sigmoid-42                   [-1, 64]               0
          SELayer-43           [-1, 64, 64, 32]               0
   InstanceNorm2d-44           [-1, 64, 64, 32]             128
             ReLU-45           [-1, 64, 64, 32]               0
       BasicBlock-46           [-1, 64, 64, 32]               0
           Conv2d-47          [-1, 128, 32, 16]          73,728
      BatchNorm2d-48          [-1, 128, 32, 16]             256
             ReLU-49          [-1, 128, 32, 16]               0
           Conv2d-50          [-1, 128, 32, 16]         147,456
      BatchNorm2d-51          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-52            [-1, 128, 1, 1]               0
           Linear-53                    [-1, 8]           1,024
             ReLU-54                    [-1, 8]               0
           Linear-55                  [-1, 128]           1,024
          Sigmoid-56                  [-1, 128]               0
          SELayer-57          [-1, 128, 32, 16]               0
           Conv2d-58          [-1, 128, 32, 16]           8,192
      BatchNorm2d-59          [-1, 128, 32, 16]             256
   InstanceNorm2d-60          [-1, 128, 32, 16]             256
             ReLU-61          [-1, 128, 32, 16]               0
       BasicBlock-62          [-1, 128, 32, 16]               0
           Conv2d-63          [-1, 128, 32, 16]         147,456
      BatchNorm2d-64          [-1, 128, 32, 16]             256
             ReLU-65          [-1, 128, 32, 16]               0
           Conv2d-66          [-1, 128, 32, 16]         147,456
      BatchNorm2d-67          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-68            [-1, 128, 1, 1]               0
           Linear-69                    [-1, 8]           1,024
             ReLU-70                    [-1, 8]               0
           Linear-71                  [-1, 128]           1,024
          Sigmoid-72                  [-1, 128]               0
          SELayer-73          [-1, 128, 32, 16]               0
   InstanceNorm2d-74          [-1, 128, 32, 16]             256
             ReLU-75          [-1, 128, 32, 16]               0
       BasicBlock-76          [-1, 128, 32, 16]               0
           Conv2d-77          [-1, 128, 32, 16]         147,456
      BatchNorm2d-78          [-1, 128, 32, 16]             256
             ReLU-79          [-1, 128, 32, 16]               0
           Conv2d-80          [-1, 128, 32, 16]         147,456
      BatchNorm2d-81          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-82            [-1, 128, 1, 1]               0
           Linear-83                    [-1, 8]           1,024
             ReLU-84                    [-1, 8]               0
           Linear-85                  [-1, 128]           1,024
          Sigmoid-86                  [-1, 128]               0
          SELayer-87          [-1, 128, 32, 16]               0
   InstanceNorm2d-88          [-1, 128, 32, 16]             256
             ReLU-89          [-1, 128, 32, 16]               0
       BasicBlock-90          [-1, 128, 32, 16]               0
           Conv2d-91          [-1, 128, 32, 16]         147,456
      BatchNorm2d-92          [-1, 128, 32, 16]             256
             ReLU-93          [-1, 128, 32, 16]               0
           Conv2d-94          [-1, 128, 32, 16]         147,456
      BatchNorm2d-95          [-1, 128, 32, 16]             256
AdaptiveAvgPool2d-96            [-1, 128, 1, 1]               0
           Linear-97                    [-1, 8]           1,024
             ReLU-98                    [-1, 8]               0
           Linear-99                  [-1, 128]           1,024
         Sigmoid-100                  [-1, 128]               0
         SELayer-101          [-1, 128, 32, 16]               0
  InstanceNorm2d-102          [-1, 128, 32, 16]             256
            ReLU-103          [-1, 128, 32, 16]               0
      BasicBlock-104          [-1, 128, 32, 16]               0
          Conv2d-105           [-1, 256, 16, 8]         294,912
     BatchNorm2d-106           [-1, 256, 16, 8]             512
            ReLU-107           [-1, 256, 16, 8]               0
          Conv2d-108           [-1, 256, 16, 8]         589,824
     BatchNorm2d-109           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-110            [-1, 256, 1, 1]               0
          Linear-111                   [-1, 16]           4,096
            ReLU-112                   [-1, 16]               0
          Linear-113                  [-1, 256]           4,096
         Sigmoid-114                  [-1, 256]               0
         SELayer-115           [-1, 256, 16, 8]               0
          Conv2d-116           [-1, 256, 16, 8]          32,768
     BatchNorm2d-117           [-1, 256, 16, 8]             512
            ReLU-118           [-1, 256, 16, 8]               0
      BasicBlock-119           [-1, 256, 16, 8]               0
          Conv2d-120           [-1, 256, 16, 8]         589,824
     BatchNorm2d-121           [-1, 256, 16, 8]             512
            ReLU-122           [-1, 256, 16, 8]               0
          Conv2d-123           [-1, 256, 16, 8]         589,824
     BatchNorm2d-124           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-125            [-1, 256, 1, 1]               0
          Linear-126                   [-1, 16]           4,096
            ReLU-127                   [-1, 16]               0
          Linear-128                  [-1, 256]           4,096
         Sigmoid-129                  [-1, 256]               0
         SELayer-130           [-1, 256, 16, 8]               0
            ReLU-131           [-1, 256, 16, 8]               0
      BasicBlock-132           [-1, 256, 16, 8]               0
          Conv2d-133           [-1, 256, 16, 8]         589,824
     BatchNorm2d-134           [-1, 256, 16, 8]             512
            ReLU-135           [-1, 256, 16, 8]               0
          Conv2d-136           [-1, 256, 16, 8]         589,824
     BatchNorm2d-137           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-138            [-1, 256, 1, 1]               0
          Linear-139                   [-1, 16]           4,096
            ReLU-140                   [-1, 16]               0
          Linear-141                  [-1, 256]           4,096
         Sigmoid-142                  [-1, 256]               0
         SELayer-143           [-1, 256, 16, 8]               0
            ReLU-144           [-1, 256, 16, 8]               0
      BasicBlock-145           [-1, 256, 16, 8]               0
          Conv2d-146           [-1, 256, 16, 8]         589,824
     BatchNorm2d-147           [-1, 256, 16, 8]             512
            ReLU-148           [-1, 256, 16, 8]               0
          Conv2d-149           [-1, 256, 16, 8]         589,824
     BatchNorm2d-150           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-151            [-1, 256, 1, 1]               0
          Linear-152                   [-1, 16]           4,096
            ReLU-153                   [-1, 16]               0
          Linear-154                  [-1, 256]           4,096
         Sigmoid-155                  [-1, 256]               0
         SELayer-156           [-1, 256, 16, 8]               0
            ReLU-157           [-1, 256, 16, 8]               0
      BasicBlock-158           [-1, 256, 16, 8]               0
          Conv2d-159           [-1, 256, 16, 8]         589,824
     BatchNorm2d-160           [-1, 256, 16, 8]             512
            ReLU-161           [-1, 256, 16, 8]               0
          Conv2d-162           [-1, 256, 16, 8]         589,824
     BatchNorm2d-163           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-164            [-1, 256, 1, 1]               0
          Linear-165                   [-1, 16]           4,096
            ReLU-166                   [-1, 16]               0
          Linear-167                  [-1, 256]           4,096
         Sigmoid-168                  [-1, 256]               0
         SELayer-169           [-1, 256, 16, 8]               0
            ReLU-170           [-1, 256, 16, 8]               0
      BasicBlock-171           [-1, 256, 16, 8]               0
          Conv2d-172           [-1, 256, 16, 8]         589,824
     BatchNorm2d-173           [-1, 256, 16, 8]             512
            ReLU-174           [-1, 256, 16, 8]               0
          Conv2d-175           [-1, 256, 16, 8]         589,824
     BatchNorm2d-176           [-1, 256, 16, 8]             512
AdaptiveAvgPool2d-177            [-1, 256, 1, 1]               0
          Linear-178                   [-1, 16]           4,096
            ReLU-179                   [-1, 16]               0
          Linear-180                  [-1, 256]           4,096
         Sigmoid-181                  [-1, 256]               0
         SELayer-182           [-1, 256, 16, 8]               0
            ReLU-183           [-1, 256, 16, 8]               0
      BasicBlock-184           [-1, 256, 16, 8]               0
          Conv2d-185           [-1, 512, 16, 8]       1,179,648
     BatchNorm2d-186           [-1, 512, 16, 8]           1,024
            ReLU-187           [-1, 512, 16, 8]               0
          Conv2d-188           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-189           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-190            [-1, 512, 1, 1]               0
          Linear-191                   [-1, 32]          16,384
            ReLU-192                   [-1, 32]               0
          Linear-193                  [-1, 512]          16,384
         Sigmoid-194                  [-1, 512]               0
         SELayer-195           [-1, 512, 16, 8]               0
          Conv2d-196           [-1, 512, 16, 8]         131,072
     BatchNorm2d-197           [-1, 512, 16, 8]           1,024
            ReLU-198           [-1, 512, 16, 8]               0
      BasicBlock-199           [-1, 512, 16, 8]               0
          Conv2d-200           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-201           [-1, 512, 16, 8]           1,024
            ReLU-202           [-1, 512, 16, 8]               0
          Conv2d-203           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-204           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-205            [-1, 512, 1, 1]               0
          Linear-206                   [-1, 32]          16,384
            ReLU-207                   [-1, 32]               0
          Linear-208                  [-1, 512]          16,384
         Sigmoid-209                  [-1, 512]               0
         SELayer-210           [-1, 512, 16, 8]               0
            ReLU-211           [-1, 512, 16, 8]               0
      BasicBlock-212           [-1, 512, 16, 8]               0
          Conv2d-213           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-214           [-1, 512, 16, 8]           1,024
            ReLU-215           [-1, 512, 16, 8]               0
          Conv2d-216           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-217           [-1, 512, 16, 8]           1,024
AdaptiveAvgPool2d-218            [-1, 512, 1, 1]               0
          Linear-219                   [-1, 32]          16,384
            ReLU-220                   [-1, 32]               0
          Linear-221                  [-1, 512]          16,384
         Sigmoid-222                  [-1, 512]               0
         SELayer-223           [-1, 512, 16, 8]               0
            ReLU-224           [-1, 512, 16, 8]               0
      BasicBlock-225           [-1, 512, 16, 8]               0
================================================================
Total params: 21,443,264
Trainable params: 21,443,264
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 84.59
Params size (MB): 81.80
Estimated Total Size (MB): 166.76
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet34_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
    InstanceNorm2d-6           [-1, 32, 64, 32]              64
       BatchNorm2d-7           [-1, 32, 64, 32]              64
               IBN-8           [-1, 64, 64, 32]               0
              ReLU-9           [-1, 64, 64, 32]               0
           Conv2d-10           [-1, 64, 64, 32]          36,864
      BatchNorm2d-11           [-1, 64, 64, 32]             128
             ReLU-12           [-1, 64, 64, 32]               0
       BasicBlock-13           [-1, 64, 64, 32]               0
           Conv2d-14           [-1, 64, 64, 32]          36,864
   InstanceNorm2d-15           [-1, 32, 64, 32]              64
      BatchNorm2d-16           [-1, 32, 64, 32]              64
              IBN-17           [-1, 64, 64, 32]               0
             ReLU-18           [-1, 64, 64, 32]               0
           Conv2d-19           [-1, 64, 64, 32]          36,864
      BatchNorm2d-20           [-1, 64, 64, 32]             128
             ReLU-21           [-1, 64, 64, 32]               0
       BasicBlock-22           [-1, 64, 64, 32]               0
           Conv2d-23           [-1, 64, 64, 32]          36,864
   InstanceNorm2d-24           [-1, 32, 64, 32]              64
      BatchNorm2d-25           [-1, 32, 64, 32]              64
              IBN-26           [-1, 64, 64, 32]               0
             ReLU-27           [-1, 64, 64, 32]               0
           Conv2d-28           [-1, 64, 64, 32]          36,864
      BatchNorm2d-29           [-1, 64, 64, 32]             128
             ReLU-30           [-1, 64, 64, 32]               0
       BasicBlock-31           [-1, 64, 64, 32]               0
           Conv2d-32          [-1, 128, 32, 16]          73,728
   InstanceNorm2d-33           [-1, 64, 32, 16]             128
      BatchNorm2d-34           [-1, 64, 32, 16]             128
              IBN-35          [-1, 128, 32, 16]               0
             ReLU-36          [-1, 128, 32, 16]               0
           Conv2d-37          [-1, 128, 32, 16]         147,456
      BatchNorm2d-38          [-1, 128, 32, 16]             256
           Conv2d-39          [-1, 128, 32, 16]           8,192
      BatchNorm2d-40          [-1, 128, 32, 16]             256
             ReLU-41          [-1, 128, 32, 16]               0
       BasicBlock-42          [-1, 128, 32, 16]               0
           Conv2d-43          [-1, 128, 32, 16]         147,456
   InstanceNorm2d-44           [-1, 64, 32, 16]             128
      BatchNorm2d-45           [-1, 64, 32, 16]             128
              IBN-46          [-1, 128, 32, 16]               0
             ReLU-47          [-1, 128, 32, 16]               0
           Conv2d-48          [-1, 128, 32, 16]         147,456
      BatchNorm2d-49          [-1, 128, 32, 16]             256
             ReLU-50          [-1, 128, 32, 16]               0
       BasicBlock-51          [-1, 128, 32, 16]               0
           Conv2d-52          [-1, 128, 32, 16]         147,456
   InstanceNorm2d-53           [-1, 64, 32, 16]             128
      BatchNorm2d-54           [-1, 64, 32, 16]             128
              IBN-55          [-1, 128, 32, 16]               0
             ReLU-56          [-1, 128, 32, 16]               0
           Conv2d-57          [-1, 128, 32, 16]         147,456
      BatchNorm2d-58          [-1, 128, 32, 16]             256
             ReLU-59          [-1, 128, 32, 16]               0
       BasicBlock-60          [-1, 128, 32, 16]               0
           Conv2d-61          [-1, 128, 32, 16]         147,456
   InstanceNorm2d-62           [-1, 64, 32, 16]             128
      BatchNorm2d-63           [-1, 64, 32, 16]             128
              IBN-64          [-1, 128, 32, 16]               0
             ReLU-65          [-1, 128, 32, 16]               0
           Conv2d-66          [-1, 128, 32, 16]         147,456
      BatchNorm2d-67          [-1, 128, 32, 16]             256
             ReLU-68          [-1, 128, 32, 16]               0
       BasicBlock-69          [-1, 128, 32, 16]               0
           Conv2d-70           [-1, 256, 16, 8]         294,912
   InstanceNorm2d-71           [-1, 128, 16, 8]             256
      BatchNorm2d-72           [-1, 128, 16, 8]             256
              IBN-73           [-1, 256, 16, 8]               0
             ReLU-74           [-1, 256, 16, 8]               0
           Conv2d-75           [-1, 256, 16, 8]         589,824
      BatchNorm2d-76           [-1, 256, 16, 8]             512
           Conv2d-77           [-1, 256, 16, 8]          32,768
      BatchNorm2d-78           [-1, 256, 16, 8]             512
             ReLU-79           [-1, 256, 16, 8]               0
       BasicBlock-80           [-1, 256, 16, 8]               0
           Conv2d-81           [-1, 256, 16, 8]         589,824
   InstanceNorm2d-82           [-1, 128, 16, 8]             256
      BatchNorm2d-83           [-1, 128, 16, 8]             256
              IBN-84           [-1, 256, 16, 8]               0
             ReLU-85           [-1, 256, 16, 8]               0
           Conv2d-86           [-1, 256, 16, 8]         589,824
      BatchNorm2d-87           [-1, 256, 16, 8]             512
             ReLU-88           [-1, 256, 16, 8]               0
       BasicBlock-89           [-1, 256, 16, 8]               0
           Conv2d-90           [-1, 256, 16, 8]         589,824
   InstanceNorm2d-91           [-1, 128, 16, 8]             256
      BatchNorm2d-92           [-1, 128, 16, 8]             256
              IBN-93           [-1, 256, 16, 8]               0
             ReLU-94           [-1, 256, 16, 8]               0
           Conv2d-95           [-1, 256, 16, 8]         589,824
      BatchNorm2d-96           [-1, 256, 16, 8]             512
             ReLU-97           [-1, 256, 16, 8]               0
       BasicBlock-98           [-1, 256, 16, 8]               0
           Conv2d-99           [-1, 256, 16, 8]         589,824
  InstanceNorm2d-100           [-1, 128, 16, 8]             256
     BatchNorm2d-101           [-1, 128, 16, 8]             256
             IBN-102           [-1, 256, 16, 8]               0
            ReLU-103           [-1, 256, 16, 8]               0
          Conv2d-104           [-1, 256, 16, 8]         589,824
     BatchNorm2d-105           [-1, 256, 16, 8]             512
            ReLU-106           [-1, 256, 16, 8]               0
      BasicBlock-107           [-1, 256, 16, 8]               0
          Conv2d-108           [-1, 256, 16, 8]         589,824
  InstanceNorm2d-109           [-1, 128, 16, 8]             256
     BatchNorm2d-110           [-1, 128, 16, 8]             256
             IBN-111           [-1, 256, 16, 8]               0
            ReLU-112           [-1, 256, 16, 8]               0
          Conv2d-113           [-1, 256, 16, 8]         589,824
     BatchNorm2d-114           [-1, 256, 16, 8]             512
            ReLU-115           [-1, 256, 16, 8]               0
      BasicBlock-116           [-1, 256, 16, 8]               0
          Conv2d-117           [-1, 256, 16, 8]         589,824
  InstanceNorm2d-118           [-1, 128, 16, 8]             256
     BatchNorm2d-119           [-1, 128, 16, 8]             256
             IBN-120           [-1, 256, 16, 8]               0
            ReLU-121           [-1, 256, 16, 8]               0
          Conv2d-122           [-1, 256, 16, 8]         589,824
     BatchNorm2d-123           [-1, 256, 16, 8]             512
            ReLU-124           [-1, 256, 16, 8]               0
      BasicBlock-125           [-1, 256, 16, 8]               0
          Conv2d-126           [-1, 512, 16, 8]       1,179,648
     BatchNorm2d-127           [-1, 512, 16, 8]           1,024
            ReLU-128           [-1, 512, 16, 8]               0
          Conv2d-129           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-130           [-1, 512, 16, 8]           1,024
          Conv2d-131           [-1, 512, 16, 8]         131,072
     BatchNorm2d-132           [-1, 512, 16, 8]           1,024
            ReLU-133           [-1, 512, 16, 8]               0
      BasicBlock-134           [-1, 512, 16, 8]               0
          Conv2d-135           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-136           [-1, 512, 16, 8]           1,024
            ReLU-137           [-1, 512, 16, 8]               0
          Conv2d-138           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-139           [-1, 512, 16, 8]           1,024
            ReLU-140           [-1, 512, 16, 8]               0
      BasicBlock-141           [-1, 512, 16, 8]               0
          Conv2d-142           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-143           [-1, 512, 16, 8]           1,024
            ReLU-144           [-1, 512, 16, 8]               0
          Conv2d-145           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-146           [-1, 512, 16, 8]           1,024
            ReLU-147           [-1, 512, 16, 8]               0
      BasicBlock-148           [-1, 512, 16, 8]               0
================================================================
Total params: 21,284,672
Trainable params: 21,284,672
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 78.00
Params size (MB): 81.19
Estimated Total Size (MB): 159.57
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet34_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]          36,864
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
   InstanceNorm2d-10           [-1, 64, 64, 32]             128
             ReLU-11           [-1, 64, 64, 32]               0
       BasicBlock-12           [-1, 64, 64, 32]               0
           Conv2d-13           [-1, 64, 64, 32]          36,864
      BatchNorm2d-14           [-1, 64, 64, 32]             128
             ReLU-15           [-1, 64, 64, 32]               0
           Conv2d-16           [-1, 64, 64, 32]          36,864
      BatchNorm2d-17           [-1, 64, 64, 32]             128
   InstanceNorm2d-18           [-1, 64, 64, 32]             128
             ReLU-19           [-1, 64, 64, 32]               0
       BasicBlock-20           [-1, 64, 64, 32]               0
           Conv2d-21           [-1, 64, 64, 32]          36,864
      BatchNorm2d-22           [-1, 64, 64, 32]             128
             ReLU-23           [-1, 64, 64, 32]               0
           Conv2d-24           [-1, 64, 64, 32]          36,864
      BatchNorm2d-25           [-1, 64, 64, 32]             128
   InstanceNorm2d-26           [-1, 64, 64, 32]             128
             ReLU-27           [-1, 64, 64, 32]               0
       BasicBlock-28           [-1, 64, 64, 32]               0
           Conv2d-29          [-1, 128, 32, 16]          73,728
      BatchNorm2d-30          [-1, 128, 32, 16]             256
             ReLU-31          [-1, 128, 32, 16]               0
           Conv2d-32          [-1, 128, 32, 16]         147,456
      BatchNorm2d-33          [-1, 128, 32, 16]             256
           Conv2d-34          [-1, 128, 32, 16]           8,192
      BatchNorm2d-35          [-1, 128, 32, 16]             256
   InstanceNorm2d-36          [-1, 128, 32, 16]             256
             ReLU-37          [-1, 128, 32, 16]               0
       BasicBlock-38          [-1, 128, 32, 16]               0
           Conv2d-39          [-1, 128, 32, 16]         147,456
      BatchNorm2d-40          [-1, 128, 32, 16]             256
             ReLU-41          [-1, 128, 32, 16]               0
           Conv2d-42          [-1, 128, 32, 16]         147,456
      BatchNorm2d-43          [-1, 128, 32, 16]             256
   InstanceNorm2d-44          [-1, 128, 32, 16]             256
             ReLU-45          [-1, 128, 32, 16]               0
       BasicBlock-46          [-1, 128, 32, 16]               0
           Conv2d-47          [-1, 128, 32, 16]         147,456
      BatchNorm2d-48          [-1, 128, 32, 16]             256
             ReLU-49          [-1, 128, 32, 16]               0
           Conv2d-50          [-1, 128, 32, 16]         147,456
      BatchNorm2d-51          [-1, 128, 32, 16]             256
   InstanceNorm2d-52          [-1, 128, 32, 16]             256
             ReLU-53          [-1, 128, 32, 16]               0
       BasicBlock-54          [-1, 128, 32, 16]               0
           Conv2d-55          [-1, 128, 32, 16]         147,456
      BatchNorm2d-56          [-1, 128, 32, 16]             256
             ReLU-57          [-1, 128, 32, 16]               0
           Conv2d-58          [-1, 128, 32, 16]         147,456
      BatchNorm2d-59          [-1, 128, 32, 16]             256
   InstanceNorm2d-60          [-1, 128, 32, 16]             256
             ReLU-61          [-1, 128, 32, 16]               0
       BasicBlock-62          [-1, 128, 32, 16]               0
           Conv2d-63           [-1, 256, 16, 8]         294,912
      BatchNorm2d-64           [-1, 256, 16, 8]             512
             ReLU-65           [-1, 256, 16, 8]               0
           Conv2d-66           [-1, 256, 16, 8]         589,824
      BatchNorm2d-67           [-1, 256, 16, 8]             512
           Conv2d-68           [-1, 256, 16, 8]          32,768
      BatchNorm2d-69           [-1, 256, 16, 8]             512
             ReLU-70           [-1, 256, 16, 8]               0
       BasicBlock-71           [-1, 256, 16, 8]               0
           Conv2d-72           [-1, 256, 16, 8]         589,824
      BatchNorm2d-73           [-1, 256, 16, 8]             512
             ReLU-74           [-1, 256, 16, 8]               0
           Conv2d-75           [-1, 256, 16, 8]         589,824
      BatchNorm2d-76           [-1, 256, 16, 8]             512
             ReLU-77           [-1, 256, 16, 8]               0
       BasicBlock-78           [-1, 256, 16, 8]               0
           Conv2d-79           [-1, 256, 16, 8]         589,824
      BatchNorm2d-80           [-1, 256, 16, 8]             512
             ReLU-81           [-1, 256, 16, 8]               0
           Conv2d-82           [-1, 256, 16, 8]         589,824
      BatchNorm2d-83           [-1, 256, 16, 8]             512
             ReLU-84           [-1, 256, 16, 8]               0
       BasicBlock-85           [-1, 256, 16, 8]               0
           Conv2d-86           [-1, 256, 16, 8]         589,824
      BatchNorm2d-87           [-1, 256, 16, 8]             512
             ReLU-88           [-1, 256, 16, 8]               0
           Conv2d-89           [-1, 256, 16, 8]         589,824
      BatchNorm2d-90           [-1, 256, 16, 8]             512
             ReLU-91           [-1, 256, 16, 8]               0
       BasicBlock-92           [-1, 256, 16, 8]               0
           Conv2d-93           [-1, 256, 16, 8]         589,824
      BatchNorm2d-94           [-1, 256, 16, 8]             512
             ReLU-95           [-1, 256, 16, 8]               0
           Conv2d-96           [-1, 256, 16, 8]         589,824
      BatchNorm2d-97           [-1, 256, 16, 8]             512
             ReLU-98           [-1, 256, 16, 8]               0
       BasicBlock-99           [-1, 256, 16, 8]               0
          Conv2d-100           [-1, 256, 16, 8]         589,824
     BatchNorm2d-101           [-1, 256, 16, 8]             512
            ReLU-102           [-1, 256, 16, 8]               0
          Conv2d-103           [-1, 256, 16, 8]         589,824
     BatchNorm2d-104           [-1, 256, 16, 8]             512
            ReLU-105           [-1, 256, 16, 8]               0
      BasicBlock-106           [-1, 256, 16, 8]               0
          Conv2d-107           [-1, 512, 16, 8]       1,179,648
     BatchNorm2d-108           [-1, 512, 16, 8]           1,024
            ReLU-109           [-1, 512, 16, 8]               0
          Conv2d-110           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-111           [-1, 512, 16, 8]           1,024
          Conv2d-112           [-1, 512, 16, 8]         131,072
     BatchNorm2d-113           [-1, 512, 16, 8]           1,024
            ReLU-114           [-1, 512, 16, 8]               0
      BasicBlock-115           [-1, 512, 16, 8]               0
          Conv2d-116           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-117           [-1, 512, 16, 8]           1,024
            ReLU-118           [-1, 512, 16, 8]               0
          Conv2d-119           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-120           [-1, 512, 16, 8]           1,024
            ReLU-121           [-1, 512, 16, 8]               0
      BasicBlock-122           [-1, 512, 16, 8]               0
          Conv2d-123           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-124           [-1, 512, 16, 8]           1,024
            ReLU-125           [-1, 512, 16, 8]               0
          Conv2d-126           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-127           [-1, 512, 16, 8]           1,024
            ReLU-128           [-1, 512, 16, 8]               0
      BasicBlock-129           [-1, 512, 16, 8]               0
================================================================
Total params: 21,286,080
Trainable params: 21,286,080
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 76.50
Params size (MB): 81.20
Estimated Total Size (MB): 158.07
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet50_se
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
             ReLU-21          [-1, 256, 64, 32]               0
       Bottleneck-22          [-1, 256, 64, 32]               0
           Conv2d-23           [-1, 64, 64, 32]          16,384
      BatchNorm2d-24           [-1, 64, 64, 32]             128
             ReLU-25           [-1, 64, 64, 32]               0
           Conv2d-26           [-1, 64, 64, 32]          36,864
      BatchNorm2d-27           [-1, 64, 64, 32]             128
             ReLU-28           [-1, 64, 64, 32]               0
           Conv2d-29          [-1, 256, 64, 32]          16,384
      BatchNorm2d-30          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0
           Linear-32                   [-1, 16]           4,096
             ReLU-33                   [-1, 16]               0
           Linear-34                  [-1, 256]           4,096
          Sigmoid-35                  [-1, 256]               0
          SELayer-36          [-1, 256, 64, 32]               0
             ReLU-37          [-1, 256, 64, 32]               0
       Bottleneck-38          [-1, 256, 64, 32]               0
           Conv2d-39           [-1, 64, 64, 32]          16,384
      BatchNorm2d-40           [-1, 64, 64, 32]             128
             ReLU-41           [-1, 64, 64, 32]               0
           Conv2d-42           [-1, 64, 64, 32]          36,864
      BatchNorm2d-43           [-1, 64, 64, 32]             128
             ReLU-44           [-1, 64, 64, 32]               0
           Conv2d-45          [-1, 256, 64, 32]          16,384
      BatchNorm2d-46          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-47            [-1, 256, 1, 1]               0
           Linear-48                   [-1, 16]           4,096
             ReLU-49                   [-1, 16]               0
           Linear-50                  [-1, 256]           4,096
          Sigmoid-51                  [-1, 256]               0
          SELayer-52          [-1, 256, 64, 32]               0
             ReLU-53          [-1, 256, 64, 32]               0
       Bottleneck-54          [-1, 256, 64, 32]               0
           Conv2d-55          [-1, 128, 64, 32]          32,768
      BatchNorm2d-56          [-1, 128, 64, 32]             256
             ReLU-57          [-1, 128, 64, 32]               0
           Conv2d-58          [-1, 128, 32, 16]         147,456
      BatchNorm2d-59          [-1, 128, 32, 16]             256
             ReLU-60          [-1, 128, 32, 16]               0
           Conv2d-61          [-1, 512, 32, 16]          65,536
      BatchNorm2d-62          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-63            [-1, 512, 1, 1]               0
           Linear-64                   [-1, 32]          16,384
             ReLU-65                   [-1, 32]               0
           Linear-66                  [-1, 512]          16,384
          Sigmoid-67                  [-1, 512]               0
          SELayer-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         131,072
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
             ReLU-71          [-1, 512, 32, 16]               0
       Bottleneck-72          [-1, 512, 32, 16]               0
           Conv2d-73          [-1, 128, 32, 16]          65,536
      BatchNorm2d-74          [-1, 128, 32, 16]             256
             ReLU-75          [-1, 128, 32, 16]               0
           Conv2d-76          [-1, 128, 32, 16]         147,456
      BatchNorm2d-77          [-1, 128, 32, 16]             256
             ReLU-78          [-1, 128, 32, 16]               0
           Conv2d-79          [-1, 512, 32, 16]          65,536
      BatchNorm2d-80          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-81            [-1, 512, 1, 1]               0
           Linear-82                   [-1, 32]          16,384
             ReLU-83                   [-1, 32]               0
           Linear-84                  [-1, 512]          16,384
          Sigmoid-85                  [-1, 512]               0
          SELayer-86          [-1, 512, 32, 16]               0
             ReLU-87          [-1, 512, 32, 16]               0
       Bottleneck-88          [-1, 512, 32, 16]               0
           Conv2d-89          [-1, 128, 32, 16]          65,536
      BatchNorm2d-90          [-1, 128, 32, 16]             256
             ReLU-91          [-1, 128, 32, 16]               0
           Conv2d-92          [-1, 128, 32, 16]         147,456
      BatchNorm2d-93          [-1, 128, 32, 16]             256
             ReLU-94          [-1, 128, 32, 16]               0
           Conv2d-95          [-1, 512, 32, 16]          65,536
      BatchNorm2d-96          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-97            [-1, 512, 1, 1]               0
           Linear-98                   [-1, 32]          16,384
             ReLU-99                   [-1, 32]               0
          Linear-100                  [-1, 512]          16,384
         Sigmoid-101                  [-1, 512]               0
         SELayer-102          [-1, 512, 32, 16]               0
            ReLU-103          [-1, 512, 32, 16]               0
      Bottleneck-104          [-1, 512, 32, 16]               0
          Conv2d-105          [-1, 128, 32, 16]          65,536
     BatchNorm2d-106          [-1, 128, 32, 16]             256
            ReLU-107          [-1, 128, 32, 16]               0
          Conv2d-108          [-1, 128, 32, 16]         147,456
     BatchNorm2d-109          [-1, 128, 32, 16]             256
            ReLU-110          [-1, 128, 32, 16]               0
          Conv2d-111          [-1, 512, 32, 16]          65,536
     BatchNorm2d-112          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-113            [-1, 512, 1, 1]               0
          Linear-114                   [-1, 32]          16,384
            ReLU-115                   [-1, 32]               0
          Linear-116                  [-1, 512]          16,384
         Sigmoid-117                  [-1, 512]               0
         SELayer-118          [-1, 512, 32, 16]               0
            ReLU-119          [-1, 512, 32, 16]               0
      Bottleneck-120          [-1, 512, 32, 16]               0
          Conv2d-121          [-1, 256, 32, 16]         131,072
     BatchNorm2d-122          [-1, 256, 32, 16]             512
            ReLU-123          [-1, 256, 32, 16]               0
          Conv2d-124           [-1, 256, 16, 8]         589,824
     BatchNorm2d-125           [-1, 256, 16, 8]             512
            ReLU-126           [-1, 256, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-129           [-1, 1024, 1, 1]               0
          Linear-130                   [-1, 64]          65,536
            ReLU-131                   [-1, 64]               0
          Linear-132                 [-1, 1024]          65,536
         Sigmoid-133                 [-1, 1024]               0
         SELayer-134          [-1, 1024, 16, 8]               0
          Conv2d-135          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-136          [-1, 1024, 16, 8]           2,048
            ReLU-137          [-1, 1024, 16, 8]               0
      Bottleneck-138          [-1, 1024, 16, 8]               0
          Conv2d-139           [-1, 256, 16, 8]         262,144
     BatchNorm2d-140           [-1, 256, 16, 8]             512
            ReLU-141           [-1, 256, 16, 8]               0
          Conv2d-142           [-1, 256, 16, 8]         589,824
     BatchNorm2d-143           [-1, 256, 16, 8]             512
            ReLU-144           [-1, 256, 16, 8]               0
          Conv2d-145          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-146          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-147           [-1, 1024, 1, 1]               0
          Linear-148                   [-1, 64]          65,536
            ReLU-149                   [-1, 64]               0
          Linear-150                 [-1, 1024]          65,536
         Sigmoid-151                 [-1, 1024]               0
         SELayer-152          [-1, 1024, 16, 8]               0
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 256, 16, 8]         262,144
     BatchNorm2d-156           [-1, 256, 16, 8]             512
            ReLU-157           [-1, 256, 16, 8]               0
          Conv2d-158           [-1, 256, 16, 8]         589,824
     BatchNorm2d-159           [-1, 256, 16, 8]             512
            ReLU-160           [-1, 256, 16, 8]               0
          Conv2d-161          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-162          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-163           [-1, 1024, 1, 1]               0
          Linear-164                   [-1, 64]          65,536
            ReLU-165                   [-1, 64]               0
          Linear-166                 [-1, 1024]          65,536
         Sigmoid-167                 [-1, 1024]               0
         SELayer-168          [-1, 1024, 16, 8]               0
            ReLU-169          [-1, 1024, 16, 8]               0
      Bottleneck-170          [-1, 1024, 16, 8]               0
          Conv2d-171           [-1, 256, 16, 8]         262,144
     BatchNorm2d-172           [-1, 256, 16, 8]             512
            ReLU-173           [-1, 256, 16, 8]               0
          Conv2d-174           [-1, 256, 16, 8]         589,824
     BatchNorm2d-175           [-1, 256, 16, 8]             512
            ReLU-176           [-1, 256, 16, 8]               0
          Conv2d-177          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-178          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-179           [-1, 1024, 1, 1]               0
          Linear-180                   [-1, 64]          65,536
            ReLU-181                   [-1, 64]               0
          Linear-182                 [-1, 1024]          65,536
         Sigmoid-183                 [-1, 1024]               0
         SELayer-184          [-1, 1024, 16, 8]               0
            ReLU-185          [-1, 1024, 16, 8]               0
      Bottleneck-186          [-1, 1024, 16, 8]               0
          Conv2d-187           [-1, 256, 16, 8]         262,144
     BatchNorm2d-188           [-1, 256, 16, 8]             512
            ReLU-189           [-1, 256, 16, 8]               0
          Conv2d-190           [-1, 256, 16, 8]         589,824
     BatchNorm2d-191           [-1, 256, 16, 8]             512
            ReLU-192           [-1, 256, 16, 8]               0
          Conv2d-193          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-194          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-195           [-1, 1024, 1, 1]               0
          Linear-196                   [-1, 64]          65,536
            ReLU-197                   [-1, 64]               0
          Linear-198                 [-1, 1024]          65,536
         Sigmoid-199                 [-1, 1024]               0
         SELayer-200          [-1, 1024, 16, 8]               0
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203           [-1, 256, 16, 8]         262,144
     BatchNorm2d-204           [-1, 256, 16, 8]             512
            ReLU-205           [-1, 256, 16, 8]               0
          Conv2d-206           [-1, 256, 16, 8]         589,824
     BatchNorm2d-207           [-1, 256, 16, 8]             512
            ReLU-208           [-1, 256, 16, 8]               0
          Conv2d-209          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-210          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-211           [-1, 1024, 1, 1]               0
          Linear-212                   [-1, 64]          65,536
            ReLU-213                   [-1, 64]               0
          Linear-214                 [-1, 1024]          65,536
         Sigmoid-215                 [-1, 1024]               0
         SELayer-216          [-1, 1024, 16, 8]               0
            ReLU-217          [-1, 1024, 16, 8]               0
      Bottleneck-218          [-1, 1024, 16, 8]               0
          Conv2d-219           [-1, 512, 16, 8]         524,288
     BatchNorm2d-220           [-1, 512, 16, 8]           1,024
            ReLU-221           [-1, 512, 16, 8]               0
          Conv2d-222           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-223           [-1, 512, 16, 8]           1,024
            ReLU-224           [-1, 512, 16, 8]               0
          Conv2d-225          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-226          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-227           [-1, 2048, 1, 1]               0
          Linear-228                  [-1, 128]         262,144
            ReLU-229                  [-1, 128]               0
          Linear-230                 [-1, 2048]         262,144
         Sigmoid-231                 [-1, 2048]               0
         SELayer-232          [-1, 2048, 16, 8]               0
          Conv2d-233          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-234          [-1, 2048, 16, 8]           4,096
            ReLU-235          [-1, 2048, 16, 8]               0
      Bottleneck-236          [-1, 2048, 16, 8]               0
          Conv2d-237           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-238           [-1, 512, 16, 8]           1,024
            ReLU-239           [-1, 512, 16, 8]               0
          Conv2d-240           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-241           [-1, 512, 16, 8]           1,024
            ReLU-242           [-1, 512, 16, 8]               0
          Conv2d-243          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-244          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-245           [-1, 2048, 1, 1]               0
          Linear-246                  [-1, 128]         262,144
            ReLU-247                  [-1, 128]               0
          Linear-248                 [-1, 2048]         262,144
         Sigmoid-249                 [-1, 2048]               0
         SELayer-250          [-1, 2048, 16, 8]               0
            ReLU-251          [-1, 2048, 16, 8]               0
      Bottleneck-252          [-1, 2048, 16, 8]               0
          Conv2d-253           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-254           [-1, 512, 16, 8]           1,024
            ReLU-255           [-1, 512, 16, 8]               0
          Conv2d-256           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-257           [-1, 512, 16, 8]           1,024
            ReLU-258           [-1, 512, 16, 8]               0
          Conv2d-259          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-260          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-261           [-1, 2048, 1, 1]               0
          Linear-262                  [-1, 128]         262,144
            ReLU-263                  [-1, 128]               0
          Linear-264                 [-1, 2048]         262,144
         Sigmoid-265                 [-1, 2048]               0
         SELayer-266          [-1, 2048, 16, 8]               0
            ReLU-267          [-1, 2048, 16, 8]               0
      Bottleneck-268          [-1, 2048, 16, 8]               0
================================================================
Total params: 26,022,976
Trainable params: 26,022,976
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 246.11
Params size (MB): 99.27
Estimated Total Size (MB): 345.75
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet50_se_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
    InstanceNorm2d-6           [-1, 32, 64, 32]              64
       BatchNorm2d-7           [-1, 32, 64, 32]              64
               IBN-8           [-1, 64, 64, 32]               0
              ReLU-9           [-1, 64, 64, 32]               0
           Conv2d-10           [-1, 64, 64, 32]          36,864
      BatchNorm2d-11           [-1, 64, 64, 32]             128
             ReLU-12           [-1, 64, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-15            [-1, 256, 1, 1]               0
           Linear-16                   [-1, 16]           4,096
             ReLU-17                   [-1, 16]               0
           Linear-18                  [-1, 256]           4,096
          Sigmoid-19                  [-1, 256]               0
          SELayer-20          [-1, 256, 64, 32]               0
           Conv2d-21          [-1, 256, 64, 32]          16,384
      BatchNorm2d-22          [-1, 256, 64, 32]             512
             ReLU-23          [-1, 256, 64, 32]               0
       Bottleneck-24          [-1, 256, 64, 32]               0
           Conv2d-25           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-26           [-1, 32, 64, 32]              64
      BatchNorm2d-27           [-1, 32, 64, 32]              64
              IBN-28           [-1, 64, 64, 32]               0
             ReLU-29           [-1, 64, 64, 32]               0
           Conv2d-30           [-1, 64, 64, 32]          36,864
      BatchNorm2d-31           [-1, 64, 64, 32]             128
             ReLU-32           [-1, 64, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          16,384
      BatchNorm2d-34          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-35            [-1, 256, 1, 1]               0
           Linear-36                   [-1, 16]           4,096
             ReLU-37                   [-1, 16]               0
           Linear-38                  [-1, 256]           4,096
          Sigmoid-39                  [-1, 256]               0
          SELayer-40          [-1, 256, 64, 32]               0
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-44           [-1, 32, 64, 32]              64
      BatchNorm2d-45           [-1, 32, 64, 32]              64
              IBN-46           [-1, 64, 64, 32]               0
             ReLU-47           [-1, 64, 64, 32]               0
           Conv2d-48           [-1, 64, 64, 32]          36,864
      BatchNorm2d-49           [-1, 64, 64, 32]             128
             ReLU-50           [-1, 64, 64, 32]               0
           Conv2d-51          [-1, 256, 64, 32]          16,384
      BatchNorm2d-52          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-53            [-1, 256, 1, 1]               0
           Linear-54                   [-1, 16]           4,096
             ReLU-55                   [-1, 16]               0
           Linear-56                  [-1, 256]           4,096
          Sigmoid-57                  [-1, 256]               0
          SELayer-58          [-1, 256, 64, 32]               0
             ReLU-59          [-1, 256, 64, 32]               0
       Bottleneck-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-62           [-1, 64, 64, 32]             128
      BatchNorm2d-63           [-1, 64, 64, 32]             128
              IBN-64          [-1, 128, 64, 32]               0
             ReLU-65          [-1, 128, 64, 32]               0
           Conv2d-66          [-1, 128, 32, 16]         147,456
      BatchNorm2d-67          [-1, 128, 32, 16]             256
             ReLU-68          [-1, 128, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]          65,536
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-71            [-1, 512, 1, 1]               0
           Linear-72                   [-1, 32]          16,384
             ReLU-73                   [-1, 32]               0
           Linear-74                  [-1, 512]          16,384
          Sigmoid-75                  [-1, 512]               0
          SELayer-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         131,072
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-82           [-1, 64, 32, 16]             128
      BatchNorm2d-83           [-1, 64, 32, 16]             128
              IBN-84          [-1, 128, 32, 16]               0
             ReLU-85          [-1, 128, 32, 16]               0
           Conv2d-86          [-1, 128, 32, 16]         147,456
      BatchNorm2d-87          [-1, 128, 32, 16]             256
             ReLU-88          [-1, 128, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]          65,536
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-91            [-1, 512, 1, 1]               0
           Linear-92                   [-1, 32]          16,384
             ReLU-93                   [-1, 32]               0
           Linear-94                  [-1, 512]          16,384
          Sigmoid-95                  [-1, 512]               0
          SELayer-96          [-1, 512, 32, 16]               0
             ReLU-97          [-1, 512, 32, 16]               0
       Bottleneck-98          [-1, 512, 32, 16]               0
           Conv2d-99          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-100           [-1, 64, 32, 16]             128
     BatchNorm2d-101           [-1, 64, 32, 16]             128
             IBN-102          [-1, 128, 32, 16]               0
            ReLU-103          [-1, 128, 32, 16]               0
          Conv2d-104          [-1, 128, 32, 16]         147,456
     BatchNorm2d-105          [-1, 128, 32, 16]             256
            ReLU-106          [-1, 128, 32, 16]               0
          Conv2d-107          [-1, 512, 32, 16]          65,536
     BatchNorm2d-108          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-109            [-1, 512, 1, 1]               0
          Linear-110                   [-1, 32]          16,384
            ReLU-111                   [-1, 32]               0
          Linear-112                  [-1, 512]          16,384
         Sigmoid-113                  [-1, 512]               0
         SELayer-114          [-1, 512, 32, 16]               0
            ReLU-115          [-1, 512, 32, 16]               0
      Bottleneck-116          [-1, 512, 32, 16]               0
          Conv2d-117          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-118           [-1, 64, 32, 16]             128
     BatchNorm2d-119           [-1, 64, 32, 16]             128
             IBN-120          [-1, 128, 32, 16]               0
            ReLU-121          [-1, 128, 32, 16]               0
          Conv2d-122          [-1, 128, 32, 16]         147,456
     BatchNorm2d-123          [-1, 128, 32, 16]             256
            ReLU-124          [-1, 128, 32, 16]               0
          Conv2d-125          [-1, 512, 32, 16]          65,536
     BatchNorm2d-126          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-127            [-1, 512, 1, 1]               0
          Linear-128                   [-1, 32]          16,384
            ReLU-129                   [-1, 32]               0
          Linear-130                  [-1, 512]          16,384
         Sigmoid-131                  [-1, 512]               0
         SELayer-132          [-1, 512, 32, 16]               0
            ReLU-133          [-1, 512, 32, 16]               0
      Bottleneck-134          [-1, 512, 32, 16]               0
          Conv2d-135          [-1, 256, 32, 16]         131,072
  InstanceNorm2d-136          [-1, 128, 32, 16]             256
     BatchNorm2d-137          [-1, 128, 32, 16]             256
             IBN-138          [-1, 256, 32, 16]               0
            ReLU-139          [-1, 256, 32, 16]               0
          Conv2d-140           [-1, 256, 16, 8]         589,824
     BatchNorm2d-141           [-1, 256, 16, 8]             512
            ReLU-142           [-1, 256, 16, 8]               0
          Conv2d-143          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-144          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-145           [-1, 1024, 1, 1]               0
          Linear-146                   [-1, 64]          65,536
            ReLU-147                   [-1, 64]               0
          Linear-148                 [-1, 1024]          65,536
         Sigmoid-149                 [-1, 1024]               0
         SELayer-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-156           [-1, 128, 16, 8]             256
     BatchNorm2d-157           [-1, 128, 16, 8]             256
             IBN-158           [-1, 256, 16, 8]               0
            ReLU-159           [-1, 256, 16, 8]               0
          Conv2d-160           [-1, 256, 16, 8]         589,824
     BatchNorm2d-161           [-1, 256, 16, 8]             512
            ReLU-162           [-1, 256, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-165           [-1, 1024, 1, 1]               0
          Linear-166                   [-1, 64]          65,536
            ReLU-167                   [-1, 64]               0
          Linear-168                 [-1, 1024]          65,536
         Sigmoid-169                 [-1, 1024]               0
         SELayer-170          [-1, 1024, 16, 8]               0
            ReLU-171          [-1, 1024, 16, 8]               0
      Bottleneck-172          [-1, 1024, 16, 8]               0
          Conv2d-173           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-174           [-1, 128, 16, 8]             256
     BatchNorm2d-175           [-1, 128, 16, 8]             256
             IBN-176           [-1, 256, 16, 8]               0
            ReLU-177           [-1, 256, 16, 8]               0
          Conv2d-178           [-1, 256, 16, 8]         589,824
     BatchNorm2d-179           [-1, 256, 16, 8]             512
            ReLU-180           [-1, 256, 16, 8]               0
          Conv2d-181          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-182          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-183           [-1, 1024, 1, 1]               0
          Linear-184                   [-1, 64]          65,536
            ReLU-185                   [-1, 64]               0
          Linear-186                 [-1, 1024]          65,536
         Sigmoid-187                 [-1, 1024]               0
         SELayer-188          [-1, 1024, 16, 8]               0
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-192           [-1, 128, 16, 8]             256
     BatchNorm2d-193           [-1, 128, 16, 8]             256
             IBN-194           [-1, 256, 16, 8]               0
            ReLU-195           [-1, 256, 16, 8]               0
          Conv2d-196           [-1, 256, 16, 8]         589,824
     BatchNorm2d-197           [-1, 256, 16, 8]             512
            ReLU-198           [-1, 256, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-201           [-1, 1024, 1, 1]               0
          Linear-202                   [-1, 64]          65,536
            ReLU-203                   [-1, 64]               0
          Linear-204                 [-1, 1024]          65,536
         Sigmoid-205                 [-1, 1024]               0
         SELayer-206          [-1, 1024, 16, 8]               0
            ReLU-207          [-1, 1024, 16, 8]               0
      Bottleneck-208          [-1, 1024, 16, 8]               0
          Conv2d-209           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-210           [-1, 128, 16, 8]             256
     BatchNorm2d-211           [-1, 128, 16, 8]             256
             IBN-212           [-1, 256, 16, 8]               0
            ReLU-213           [-1, 256, 16, 8]               0
          Conv2d-214           [-1, 256, 16, 8]         589,824
     BatchNorm2d-215           [-1, 256, 16, 8]             512
            ReLU-216           [-1, 256, 16, 8]               0
          Conv2d-217          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-218          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-219           [-1, 1024, 1, 1]               0
          Linear-220                   [-1, 64]          65,536
            ReLU-221                   [-1, 64]               0
          Linear-222                 [-1, 1024]          65,536
         Sigmoid-223                 [-1, 1024]               0
         SELayer-224          [-1, 1024, 16, 8]               0
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-228           [-1, 128, 16, 8]             256
     BatchNorm2d-229           [-1, 128, 16, 8]             256
             IBN-230           [-1, 256, 16, 8]               0
            ReLU-231           [-1, 256, 16, 8]               0
          Conv2d-232           [-1, 256, 16, 8]         589,824
     BatchNorm2d-233           [-1, 256, 16, 8]             512
            ReLU-234           [-1, 256, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-237           [-1, 1024, 1, 1]               0
          Linear-238                   [-1, 64]          65,536
            ReLU-239                   [-1, 64]               0
          Linear-240                 [-1, 1024]          65,536
         Sigmoid-241                 [-1, 1024]               0
         SELayer-242          [-1, 1024, 16, 8]               0
            ReLU-243          [-1, 1024, 16, 8]               0
      Bottleneck-244          [-1, 1024, 16, 8]               0
          Conv2d-245           [-1, 512, 16, 8]         524,288
     BatchNorm2d-246           [-1, 512, 16, 8]           1,024
            ReLU-247           [-1, 512, 16, 8]               0
          Conv2d-248           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-249           [-1, 512, 16, 8]           1,024
            ReLU-250           [-1, 512, 16, 8]               0
          Conv2d-251          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-252          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-253           [-1, 2048, 1, 1]               0
          Linear-254                  [-1, 128]         262,144
            ReLU-255                  [-1, 128]               0
          Linear-256                 [-1, 2048]         262,144
         Sigmoid-257                 [-1, 2048]               0
         SELayer-258          [-1, 2048, 16, 8]               0
          Conv2d-259          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-260          [-1, 2048, 16, 8]           4,096
            ReLU-261          [-1, 2048, 16, 8]               0
      Bottleneck-262          [-1, 2048, 16, 8]               0
          Conv2d-263           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-264           [-1, 512, 16, 8]           1,024
            ReLU-265           [-1, 512, 16, 8]               0
          Conv2d-266           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-267           [-1, 512, 16, 8]           1,024
            ReLU-268           [-1, 512, 16, 8]               0
          Conv2d-269          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-270          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-271           [-1, 2048, 1, 1]               0
          Linear-272                  [-1, 128]         262,144
            ReLU-273                  [-1, 128]               0
          Linear-274                 [-1, 2048]         262,144
         Sigmoid-275                 [-1, 2048]               0
         SELayer-276          [-1, 2048, 16, 8]               0
            ReLU-277          [-1, 2048, 16, 8]               0
      Bottleneck-278          [-1, 2048, 16, 8]               0
          Conv2d-279           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-280           [-1, 512, 16, 8]           1,024
            ReLU-281           [-1, 512, 16, 8]               0
          Conv2d-282           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-283           [-1, 512, 16, 8]           1,024
            ReLU-284           [-1, 512, 16, 8]               0
          Conv2d-285          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-286          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-287           [-1, 2048, 1, 1]               0
          Linear-288                  [-1, 128]         262,144
            ReLU-289                  [-1, 128]               0
          Linear-290                 [-1, 2048]         262,144
         Sigmoid-291                 [-1, 2048]               0
         SELayer-292          [-1, 2048, 16, 8]               0
            ReLU-293          [-1, 2048, 16, 8]               0
      Bottleneck-294          [-1, 2048, 16, 8]               0
================================================================
Total params: 26,022,976
Trainable params: 26,022,976
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 254.86
Params size (MB): 99.27
Estimated Total Size (MB): 354.50
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet50_se_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
   InstanceNorm2d-21          [-1, 256, 64, 32]             512
             ReLU-22          [-1, 256, 64, 32]               0
       Bottleneck-23          [-1, 256, 64, 32]               0
           Conv2d-24           [-1, 64, 64, 32]          16,384
      BatchNorm2d-25           [-1, 64, 64, 32]             128
             ReLU-26           [-1, 64, 64, 32]               0
           Conv2d-27           [-1, 64, 64, 32]          36,864
      BatchNorm2d-28           [-1, 64, 64, 32]             128
             ReLU-29           [-1, 64, 64, 32]               0
           Conv2d-30          [-1, 256, 64, 32]          16,384
      BatchNorm2d-31          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-32            [-1, 256, 1, 1]               0
           Linear-33                   [-1, 16]           4,096
             ReLU-34                   [-1, 16]               0
           Linear-35                  [-1, 256]           4,096
          Sigmoid-36                  [-1, 256]               0
          SELayer-37          [-1, 256, 64, 32]               0
   InstanceNorm2d-38          [-1, 256, 64, 32]             512
             ReLU-39          [-1, 256, 64, 32]               0
       Bottleneck-40          [-1, 256, 64, 32]               0
           Conv2d-41           [-1, 64, 64, 32]          16,384
      BatchNorm2d-42           [-1, 64, 64, 32]             128
             ReLU-43           [-1, 64, 64, 32]               0
           Conv2d-44           [-1, 64, 64, 32]          36,864
      BatchNorm2d-45           [-1, 64, 64, 32]             128
             ReLU-46           [-1, 64, 64, 32]               0
           Conv2d-47          [-1, 256, 64, 32]          16,384
      BatchNorm2d-48          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-49            [-1, 256, 1, 1]               0
           Linear-50                   [-1, 16]           4,096
             ReLU-51                   [-1, 16]               0
           Linear-52                  [-1, 256]           4,096
          Sigmoid-53                  [-1, 256]               0
          SELayer-54          [-1, 256, 64, 32]               0
   InstanceNorm2d-55          [-1, 256, 64, 32]             512
             ReLU-56          [-1, 256, 64, 32]               0
       Bottleneck-57          [-1, 256, 64, 32]               0
           Conv2d-58          [-1, 128, 64, 32]          32,768
      BatchNorm2d-59          [-1, 128, 64, 32]             256
             ReLU-60          [-1, 128, 64, 32]               0
           Conv2d-61          [-1, 128, 32, 16]         147,456
      BatchNorm2d-62          [-1, 128, 32, 16]             256
             ReLU-63          [-1, 128, 32, 16]               0
           Conv2d-64          [-1, 512, 32, 16]          65,536
      BatchNorm2d-65          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-66            [-1, 512, 1, 1]               0
           Linear-67                   [-1, 32]          16,384
             ReLU-68                   [-1, 32]               0
           Linear-69                  [-1, 512]          16,384
          Sigmoid-70                  [-1, 512]               0
          SELayer-71          [-1, 512, 32, 16]               0
           Conv2d-72          [-1, 512, 32, 16]         131,072
      BatchNorm2d-73          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-74          [-1, 512, 32, 16]           1,024
             ReLU-75          [-1, 512, 32, 16]               0
       Bottleneck-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 128, 32, 16]          65,536
      BatchNorm2d-78          [-1, 128, 32, 16]             256
             ReLU-79          [-1, 128, 32, 16]               0
           Conv2d-80          [-1, 128, 32, 16]         147,456
      BatchNorm2d-81          [-1, 128, 32, 16]             256
             ReLU-82          [-1, 128, 32, 16]               0
           Conv2d-83          [-1, 512, 32, 16]          65,536
      BatchNorm2d-84          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-85            [-1, 512, 1, 1]               0
           Linear-86                   [-1, 32]          16,384
             ReLU-87                   [-1, 32]               0
           Linear-88                  [-1, 512]          16,384
          Sigmoid-89                  [-1, 512]               0
          SELayer-90          [-1, 512, 32, 16]               0
   InstanceNorm2d-91          [-1, 512, 32, 16]           1,024
             ReLU-92          [-1, 512, 32, 16]               0
       Bottleneck-93          [-1, 512, 32, 16]               0
           Conv2d-94          [-1, 128, 32, 16]          65,536
      BatchNorm2d-95          [-1, 128, 32, 16]             256
             ReLU-96          [-1, 128, 32, 16]               0
           Conv2d-97          [-1, 128, 32, 16]         147,456
      BatchNorm2d-98          [-1, 128, 32, 16]             256
             ReLU-99          [-1, 128, 32, 16]               0
          Conv2d-100          [-1, 512, 32, 16]          65,536
     BatchNorm2d-101          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-102            [-1, 512, 1, 1]               0
          Linear-103                   [-1, 32]          16,384
            ReLU-104                   [-1, 32]               0
          Linear-105                  [-1, 512]          16,384
         Sigmoid-106                  [-1, 512]               0
         SELayer-107          [-1, 512, 32, 16]               0
  InstanceNorm2d-108          [-1, 512, 32, 16]           1,024
            ReLU-109          [-1, 512, 32, 16]               0
      Bottleneck-110          [-1, 512, 32, 16]               0
          Conv2d-111          [-1, 128, 32, 16]          65,536
     BatchNorm2d-112          [-1, 128, 32, 16]             256
            ReLU-113          [-1, 128, 32, 16]               0
          Conv2d-114          [-1, 128, 32, 16]         147,456
     BatchNorm2d-115          [-1, 128, 32, 16]             256
            ReLU-116          [-1, 128, 32, 16]               0
          Conv2d-117          [-1, 512, 32, 16]          65,536
     BatchNorm2d-118          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-119            [-1, 512, 1, 1]               0
          Linear-120                   [-1, 32]          16,384
            ReLU-121                   [-1, 32]               0
          Linear-122                  [-1, 512]          16,384
         Sigmoid-123                  [-1, 512]               0
         SELayer-124          [-1, 512, 32, 16]               0
  InstanceNorm2d-125          [-1, 512, 32, 16]           1,024
            ReLU-126          [-1, 512, 32, 16]               0
      Bottleneck-127          [-1, 512, 32, 16]               0
          Conv2d-128          [-1, 256, 32, 16]         131,072
     BatchNorm2d-129          [-1, 256, 32, 16]             512
            ReLU-130          [-1, 256, 32, 16]               0
          Conv2d-131           [-1, 256, 16, 8]         589,824
     BatchNorm2d-132           [-1, 256, 16, 8]             512
            ReLU-133           [-1, 256, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-136           [-1, 1024, 1, 1]               0
          Linear-137                   [-1, 64]          65,536
            ReLU-138                   [-1, 64]               0
          Linear-139                 [-1, 1024]          65,536
         Sigmoid-140                 [-1, 1024]               0
         SELayer-141          [-1, 1024, 16, 8]               0
          Conv2d-142          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-143          [-1, 1024, 16, 8]           2,048
            ReLU-144          [-1, 1024, 16, 8]               0
      Bottleneck-145          [-1, 1024, 16, 8]               0
          Conv2d-146           [-1, 256, 16, 8]         262,144
     BatchNorm2d-147           [-1, 256, 16, 8]             512
            ReLU-148           [-1, 256, 16, 8]               0
          Conv2d-149           [-1, 256, 16, 8]         589,824
     BatchNorm2d-150           [-1, 256, 16, 8]             512
            ReLU-151           [-1, 256, 16, 8]               0
          Conv2d-152          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-153          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-154           [-1, 1024, 1, 1]               0
          Linear-155                   [-1, 64]          65,536
            ReLU-156                   [-1, 64]               0
          Linear-157                 [-1, 1024]          65,536
         Sigmoid-158                 [-1, 1024]               0
         SELayer-159          [-1, 1024, 16, 8]               0
            ReLU-160          [-1, 1024, 16, 8]               0
      Bottleneck-161          [-1, 1024, 16, 8]               0
          Conv2d-162           [-1, 256, 16, 8]         262,144
     BatchNorm2d-163           [-1, 256, 16, 8]             512
            ReLU-164           [-1, 256, 16, 8]               0
          Conv2d-165           [-1, 256, 16, 8]         589,824
     BatchNorm2d-166           [-1, 256, 16, 8]             512
            ReLU-167           [-1, 256, 16, 8]               0
          Conv2d-168          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-169          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-170           [-1, 1024, 1, 1]               0
          Linear-171                   [-1, 64]          65,536
            ReLU-172                   [-1, 64]               0
          Linear-173                 [-1, 1024]          65,536
         Sigmoid-174                 [-1, 1024]               0
         SELayer-175          [-1, 1024, 16, 8]               0
            ReLU-176          [-1, 1024, 16, 8]               0
      Bottleneck-177          [-1, 1024, 16, 8]               0
          Conv2d-178           [-1, 256, 16, 8]         262,144
     BatchNorm2d-179           [-1, 256, 16, 8]             512
            ReLU-180           [-1, 256, 16, 8]               0
          Conv2d-181           [-1, 256, 16, 8]         589,824
     BatchNorm2d-182           [-1, 256, 16, 8]             512
            ReLU-183           [-1, 256, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-186           [-1, 1024, 1, 1]               0
          Linear-187                   [-1, 64]          65,536
            ReLU-188                   [-1, 64]               0
          Linear-189                 [-1, 1024]          65,536
         Sigmoid-190                 [-1, 1024]               0
         SELayer-191          [-1, 1024, 16, 8]               0
            ReLU-192          [-1, 1024, 16, 8]               0
      Bottleneck-193          [-1, 1024, 16, 8]               0
          Conv2d-194           [-1, 256, 16, 8]         262,144
     BatchNorm2d-195           [-1, 256, 16, 8]             512
            ReLU-196           [-1, 256, 16, 8]               0
          Conv2d-197           [-1, 256, 16, 8]         589,824
     BatchNorm2d-198           [-1, 256, 16, 8]             512
            ReLU-199           [-1, 256, 16, 8]               0
          Conv2d-200          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-201          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-202           [-1, 1024, 1, 1]               0
          Linear-203                   [-1, 64]          65,536
            ReLU-204                   [-1, 64]               0
          Linear-205                 [-1, 1024]          65,536
         Sigmoid-206                 [-1, 1024]               0
         SELayer-207          [-1, 1024, 16, 8]               0
            ReLU-208          [-1, 1024, 16, 8]               0
      Bottleneck-209          [-1, 1024, 16, 8]               0
          Conv2d-210           [-1, 256, 16, 8]         262,144
     BatchNorm2d-211           [-1, 256, 16, 8]             512
            ReLU-212           [-1, 256, 16, 8]               0
          Conv2d-213           [-1, 256, 16, 8]         589,824
     BatchNorm2d-214           [-1, 256, 16, 8]             512
            ReLU-215           [-1, 256, 16, 8]               0
          Conv2d-216          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-217          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-218           [-1, 1024, 1, 1]               0
          Linear-219                   [-1, 64]          65,536
            ReLU-220                   [-1, 64]               0
          Linear-221                 [-1, 1024]          65,536
         Sigmoid-222                 [-1, 1024]               0
         SELayer-223          [-1, 1024, 16, 8]               0
            ReLU-224          [-1, 1024, 16, 8]               0
      Bottleneck-225          [-1, 1024, 16, 8]               0
          Conv2d-226           [-1, 512, 16, 8]         524,288
     BatchNorm2d-227           [-1, 512, 16, 8]           1,024
            ReLU-228           [-1, 512, 16, 8]               0
          Conv2d-229           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-230           [-1, 512, 16, 8]           1,024
            ReLU-231           [-1, 512, 16, 8]               0
          Conv2d-232          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-233          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-234           [-1, 2048, 1, 1]               0
          Linear-235                  [-1, 128]         262,144
            ReLU-236                  [-1, 128]               0
          Linear-237                 [-1, 2048]         262,144
         Sigmoid-238                 [-1, 2048]               0
         SELayer-239          [-1, 2048, 16, 8]               0
          Conv2d-240          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-241          [-1, 2048, 16, 8]           4,096
            ReLU-242          [-1, 2048, 16, 8]               0
      Bottleneck-243          [-1, 2048, 16, 8]               0
          Conv2d-244           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-245           [-1, 512, 16, 8]           1,024
            ReLU-246           [-1, 512, 16, 8]               0
          Conv2d-247           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-248           [-1, 512, 16, 8]           1,024
            ReLU-249           [-1, 512, 16, 8]               0
          Conv2d-250          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-251          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-252           [-1, 2048, 1, 1]               0
          Linear-253                  [-1, 128]         262,144
            ReLU-254                  [-1, 128]               0
          Linear-255                 [-1, 2048]         262,144
         Sigmoid-256                 [-1, 2048]               0
         SELayer-257          [-1, 2048, 16, 8]               0
            ReLU-258          [-1, 2048, 16, 8]               0
      Bottleneck-259          [-1, 2048, 16, 8]               0
          Conv2d-260           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-261           [-1, 512, 16, 8]           1,024
            ReLU-262           [-1, 512, 16, 8]               0
          Conv2d-263           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-264           [-1, 512, 16, 8]           1,024
            ReLU-265           [-1, 512, 16, 8]               0
          Conv2d-266          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-267          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-268           [-1, 2048, 1, 1]               0
          Linear-269                  [-1, 128]         262,144
            ReLU-270                  [-1, 128]               0
          Linear-271                 [-1, 2048]         262,144
         Sigmoid-272                 [-1, 2048]               0
         SELayer-273          [-1, 2048, 16, 8]               0
            ReLU-274          [-1, 2048, 16, 8]               0
      Bottleneck-275          [-1, 2048, 16, 8]               0
================================================================
Total params: 26,028,608
Trainable params: 26,028,608
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 266.11
Params size (MB): 99.29
Estimated Total Size (MB): 365.78
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet50_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
    InstanceNorm2d-6           [-1, 32, 64, 32]              64
       BatchNorm2d-7           [-1, 32, 64, 32]              64
               IBN-8           [-1, 64, 64, 32]               0
              ReLU-9           [-1, 64, 64, 32]               0
           Conv2d-10           [-1, 64, 64, 32]          36,864
      BatchNorm2d-11           [-1, 64, 64, 32]             128
             ReLU-12           [-1, 64, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
           Conv2d-15          [-1, 256, 64, 32]          16,384
      BatchNorm2d-16          [-1, 256, 64, 32]             512
             ReLU-17          [-1, 256, 64, 32]               0
       Bottleneck-18          [-1, 256, 64, 32]               0
           Conv2d-19           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-20           [-1, 32, 64, 32]              64
      BatchNorm2d-21           [-1, 32, 64, 32]              64
              IBN-22           [-1, 64, 64, 32]               0
             ReLU-23           [-1, 64, 64, 32]               0
           Conv2d-24           [-1, 64, 64, 32]          36,864
      BatchNorm2d-25           [-1, 64, 64, 32]             128
             ReLU-26           [-1, 64, 64, 32]               0
           Conv2d-27          [-1, 256, 64, 32]          16,384
      BatchNorm2d-28          [-1, 256, 64, 32]             512
             ReLU-29          [-1, 256, 64, 32]               0
       Bottleneck-30          [-1, 256, 64, 32]               0
           Conv2d-31           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-32           [-1, 32, 64, 32]              64
      BatchNorm2d-33           [-1, 32, 64, 32]              64
              IBN-34           [-1, 64, 64, 32]               0
             ReLU-35           [-1, 64, 64, 32]               0
           Conv2d-36           [-1, 64, 64, 32]          36,864
      BatchNorm2d-37           [-1, 64, 64, 32]             128
             ReLU-38           [-1, 64, 64, 32]               0
           Conv2d-39          [-1, 256, 64, 32]          16,384
      BatchNorm2d-40          [-1, 256, 64, 32]             512
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-44           [-1, 64, 64, 32]             128
      BatchNorm2d-45           [-1, 64, 64, 32]             128
              IBN-46          [-1, 128, 64, 32]               0
             ReLU-47          [-1, 128, 64, 32]               0
           Conv2d-48          [-1, 128, 32, 16]         147,456
      BatchNorm2d-49          [-1, 128, 32, 16]             256
             ReLU-50          [-1, 128, 32, 16]               0
           Conv2d-51          [-1, 512, 32, 16]          65,536
      BatchNorm2d-52          [-1, 512, 32, 16]           1,024
           Conv2d-53          [-1, 512, 32, 16]         131,072
      BatchNorm2d-54          [-1, 512, 32, 16]           1,024
             ReLU-55          [-1, 512, 32, 16]               0
       Bottleneck-56          [-1, 512, 32, 16]               0
           Conv2d-57          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-58           [-1, 64, 32, 16]             128
      BatchNorm2d-59           [-1, 64, 32, 16]             128
              IBN-60          [-1, 128, 32, 16]               0
             ReLU-61          [-1, 128, 32, 16]               0
           Conv2d-62          [-1, 128, 32, 16]         147,456
      BatchNorm2d-63          [-1, 128, 32, 16]             256
             ReLU-64          [-1, 128, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]          65,536
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-70           [-1, 64, 32, 16]             128
      BatchNorm2d-71           [-1, 64, 32, 16]             128
              IBN-72          [-1, 128, 32, 16]               0
             ReLU-73          [-1, 128, 32, 16]               0
           Conv2d-74          [-1, 128, 32, 16]         147,456
      BatchNorm2d-75          [-1, 128, 32, 16]             256
             ReLU-76          [-1, 128, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]          65,536
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-82           [-1, 64, 32, 16]             128
      BatchNorm2d-83           [-1, 64, 32, 16]             128
              IBN-84          [-1, 128, 32, 16]               0
             ReLU-85          [-1, 128, 32, 16]               0
           Conv2d-86          [-1, 128, 32, 16]         147,456
      BatchNorm2d-87          [-1, 128, 32, 16]             256
             ReLU-88          [-1, 128, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]          65,536
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
             ReLU-91          [-1, 512, 32, 16]               0
       Bottleneck-92          [-1, 512, 32, 16]               0
           Conv2d-93          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-94          [-1, 128, 32, 16]             256
      BatchNorm2d-95          [-1, 128, 32, 16]             256
              IBN-96          [-1, 256, 32, 16]               0
             ReLU-97          [-1, 256, 32, 16]               0
           Conv2d-98           [-1, 256, 16, 8]         589,824
      BatchNorm2d-99           [-1, 256, 16, 8]             512
            ReLU-100           [-1, 256, 16, 8]               0
          Conv2d-101          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-102          [-1, 1024, 16, 8]           2,048
          Conv2d-103          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-104          [-1, 1024, 16, 8]           2,048
            ReLU-105          [-1, 1024, 16, 8]               0
      Bottleneck-106          [-1, 1024, 16, 8]               0
          Conv2d-107           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-108           [-1, 128, 16, 8]             256
     BatchNorm2d-109           [-1, 128, 16, 8]             256
             IBN-110           [-1, 256, 16, 8]               0
            ReLU-111           [-1, 256, 16, 8]               0
          Conv2d-112           [-1, 256, 16, 8]         589,824
     BatchNorm2d-113           [-1, 256, 16, 8]             512
            ReLU-114           [-1, 256, 16, 8]               0
          Conv2d-115          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-116          [-1, 1024, 16, 8]           2,048
            ReLU-117          [-1, 1024, 16, 8]               0
      Bottleneck-118          [-1, 1024, 16, 8]               0
          Conv2d-119           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-120           [-1, 128, 16, 8]             256
     BatchNorm2d-121           [-1, 128, 16, 8]             256
             IBN-122           [-1, 256, 16, 8]               0
            ReLU-123           [-1, 256, 16, 8]               0
          Conv2d-124           [-1, 256, 16, 8]         589,824
     BatchNorm2d-125           [-1, 256, 16, 8]             512
            ReLU-126           [-1, 256, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-132           [-1, 128, 16, 8]             256
     BatchNorm2d-133           [-1, 128, 16, 8]             256
             IBN-134           [-1, 256, 16, 8]               0
            ReLU-135           [-1, 256, 16, 8]               0
          Conv2d-136           [-1, 256, 16, 8]         589,824
     BatchNorm2d-137           [-1, 256, 16, 8]             512
            ReLU-138           [-1, 256, 16, 8]               0
          Conv2d-139          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-140          [-1, 1024, 16, 8]           2,048
            ReLU-141          [-1, 1024, 16, 8]               0
      Bottleneck-142          [-1, 1024, 16, 8]               0
          Conv2d-143           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-144           [-1, 128, 16, 8]             256
     BatchNorm2d-145           [-1, 128, 16, 8]             256
             IBN-146           [-1, 256, 16, 8]               0
            ReLU-147           [-1, 256, 16, 8]               0
          Conv2d-148           [-1, 256, 16, 8]         589,824
     BatchNorm2d-149           [-1, 256, 16, 8]             512
            ReLU-150           [-1, 256, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-156           [-1, 128, 16, 8]             256
     BatchNorm2d-157           [-1, 128, 16, 8]             256
             IBN-158           [-1, 256, 16, 8]               0
            ReLU-159           [-1, 256, 16, 8]               0
          Conv2d-160           [-1, 256, 16, 8]         589,824
     BatchNorm2d-161           [-1, 256, 16, 8]             512
            ReLU-162           [-1, 256, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
      Bottleneck-166          [-1, 1024, 16, 8]               0
          Conv2d-167           [-1, 512, 16, 8]         524,288
     BatchNorm2d-168           [-1, 512, 16, 8]           1,024
            ReLU-169           [-1, 512, 16, 8]               0
          Conv2d-170           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-171           [-1, 512, 16, 8]           1,024
            ReLU-172           [-1, 512, 16, 8]               0
          Conv2d-173          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-174          [-1, 2048, 16, 8]           4,096
          Conv2d-175          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-176          [-1, 2048, 16, 8]           4,096
            ReLU-177          [-1, 2048, 16, 8]               0
      Bottleneck-178          [-1, 2048, 16, 8]               0
          Conv2d-179           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-180           [-1, 512, 16, 8]           1,024
            ReLU-181           [-1, 512, 16, 8]               0
          Conv2d-182           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-183           [-1, 512, 16, 8]           1,024
            ReLU-184           [-1, 512, 16, 8]               0
          Conv2d-185          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-186          [-1, 2048, 16, 8]           4,096
            ReLU-187          [-1, 2048, 16, 8]               0
      Bottleneck-188          [-1, 2048, 16, 8]               0
          Conv2d-189           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-190           [-1, 512, 16, 8]           1,024
            ReLU-191           [-1, 512, 16, 8]               0
          Conv2d-192           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-193           [-1, 512, 16, 8]           1,024
            ReLU-194           [-1, 512, 16, 8]               0
          Conv2d-195          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-196          [-1, 2048, 16, 8]           4,096
            ReLU-197          [-1, 2048, 16, 8]               0
      Bottleneck-198          [-1, 2048, 16, 8]               0
================================================================
Total params: 23,508,032
Trainable params: 23,508,032
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 222.50
Params size (MB): 89.68
Estimated Total Size (MB): 312.55
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet50_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
   InstanceNorm2d-15          [-1, 256, 64, 32]             512
             ReLU-16          [-1, 256, 64, 32]               0
       Bottleneck-17          [-1, 256, 64, 32]               0
           Conv2d-18           [-1, 64, 64, 32]          16,384
      BatchNorm2d-19           [-1, 64, 64, 32]             128
             ReLU-20           [-1, 64, 64, 32]               0
           Conv2d-21           [-1, 64, 64, 32]          36,864
      BatchNorm2d-22           [-1, 64, 64, 32]             128
             ReLU-23           [-1, 64, 64, 32]               0
           Conv2d-24          [-1, 256, 64, 32]          16,384
      BatchNorm2d-25          [-1, 256, 64, 32]             512
   InstanceNorm2d-26          [-1, 256, 64, 32]             512
             ReLU-27          [-1, 256, 64, 32]               0
       Bottleneck-28          [-1, 256, 64, 32]               0
           Conv2d-29           [-1, 64, 64, 32]          16,384
      BatchNorm2d-30           [-1, 64, 64, 32]             128
             ReLU-31           [-1, 64, 64, 32]               0
           Conv2d-32           [-1, 64, 64, 32]          36,864
      BatchNorm2d-33           [-1, 64, 64, 32]             128
             ReLU-34           [-1, 64, 64, 32]               0
           Conv2d-35          [-1, 256, 64, 32]          16,384
      BatchNorm2d-36          [-1, 256, 64, 32]             512
   InstanceNorm2d-37          [-1, 256, 64, 32]             512
             ReLU-38          [-1, 256, 64, 32]               0
       Bottleneck-39          [-1, 256, 64, 32]               0
           Conv2d-40          [-1, 128, 64, 32]          32,768
      BatchNorm2d-41          [-1, 128, 64, 32]             256
             ReLU-42          [-1, 128, 64, 32]               0
           Conv2d-43          [-1, 128, 32, 16]         147,456
      BatchNorm2d-44          [-1, 128, 32, 16]             256
             ReLU-45          [-1, 128, 32, 16]               0
           Conv2d-46          [-1, 512, 32, 16]          65,536
      BatchNorm2d-47          [-1, 512, 32, 16]           1,024
           Conv2d-48          [-1, 512, 32, 16]         131,072
      BatchNorm2d-49          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-50          [-1, 512, 32, 16]           1,024
             ReLU-51          [-1, 512, 32, 16]               0
       Bottleneck-52          [-1, 512, 32, 16]               0
           Conv2d-53          [-1, 128, 32, 16]          65,536
      BatchNorm2d-54          [-1, 128, 32, 16]             256
             ReLU-55          [-1, 128, 32, 16]               0
           Conv2d-56          [-1, 128, 32, 16]         147,456
      BatchNorm2d-57          [-1, 128, 32, 16]             256
             ReLU-58          [-1, 128, 32, 16]               0
           Conv2d-59          [-1, 512, 32, 16]          65,536
      BatchNorm2d-60          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-61          [-1, 512, 32, 16]           1,024
             ReLU-62          [-1, 512, 32, 16]               0
       Bottleneck-63          [-1, 512, 32, 16]               0
           Conv2d-64          [-1, 128, 32, 16]          65,536
      BatchNorm2d-65          [-1, 128, 32, 16]             256
             ReLU-66          [-1, 128, 32, 16]               0
           Conv2d-67          [-1, 128, 32, 16]         147,456
      BatchNorm2d-68          [-1, 128, 32, 16]             256
             ReLU-69          [-1, 128, 32, 16]               0
           Conv2d-70          [-1, 512, 32, 16]          65,536
      BatchNorm2d-71          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-72          [-1, 512, 32, 16]           1,024
             ReLU-73          [-1, 512, 32, 16]               0
       Bottleneck-74          [-1, 512, 32, 16]               0
           Conv2d-75          [-1, 128, 32, 16]          65,536
      BatchNorm2d-76          [-1, 128, 32, 16]             256
             ReLU-77          [-1, 128, 32, 16]               0
           Conv2d-78          [-1, 128, 32, 16]         147,456
      BatchNorm2d-79          [-1, 128, 32, 16]             256
             ReLU-80          [-1, 128, 32, 16]               0
           Conv2d-81          [-1, 512, 32, 16]          65,536
      BatchNorm2d-82          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-83          [-1, 512, 32, 16]           1,024
             ReLU-84          [-1, 512, 32, 16]               0
       Bottleneck-85          [-1, 512, 32, 16]               0
           Conv2d-86          [-1, 256, 32, 16]         131,072
      BatchNorm2d-87          [-1, 256, 32, 16]             512
             ReLU-88          [-1, 256, 32, 16]               0
           Conv2d-89           [-1, 256, 16, 8]         589,824
      BatchNorm2d-90           [-1, 256, 16, 8]             512
             ReLU-91           [-1, 256, 16, 8]               0
           Conv2d-92          [-1, 1024, 16, 8]         262,144
      BatchNorm2d-93          [-1, 1024, 16, 8]           2,048
           Conv2d-94          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-95          [-1, 1024, 16, 8]           2,048
             ReLU-96          [-1, 1024, 16, 8]               0
       Bottleneck-97          [-1, 1024, 16, 8]               0
           Conv2d-98           [-1, 256, 16, 8]         262,144
      BatchNorm2d-99           [-1, 256, 16, 8]             512
            ReLU-100           [-1, 256, 16, 8]               0
          Conv2d-101           [-1, 256, 16, 8]         589,824
     BatchNorm2d-102           [-1, 256, 16, 8]             512
            ReLU-103           [-1, 256, 16, 8]               0
          Conv2d-104          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-105          [-1, 1024, 16, 8]           2,048
            ReLU-106          [-1, 1024, 16, 8]               0
      Bottleneck-107          [-1, 1024, 16, 8]               0
          Conv2d-108           [-1, 256, 16, 8]         262,144
     BatchNorm2d-109           [-1, 256, 16, 8]             512
            ReLU-110           [-1, 256, 16, 8]               0
          Conv2d-111           [-1, 256, 16, 8]         589,824
     BatchNorm2d-112           [-1, 256, 16, 8]             512
            ReLU-113           [-1, 256, 16, 8]               0
          Conv2d-114          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-115          [-1, 1024, 16, 8]           2,048
            ReLU-116          [-1, 1024, 16, 8]               0
      Bottleneck-117          [-1, 1024, 16, 8]               0
          Conv2d-118           [-1, 256, 16, 8]         262,144
     BatchNorm2d-119           [-1, 256, 16, 8]             512
            ReLU-120           [-1, 256, 16, 8]               0
          Conv2d-121           [-1, 256, 16, 8]         589,824
     BatchNorm2d-122           [-1, 256, 16, 8]             512
            ReLU-123           [-1, 256, 16, 8]               0
          Conv2d-124          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-125          [-1, 1024, 16, 8]           2,048
            ReLU-126          [-1, 1024, 16, 8]               0
      Bottleneck-127          [-1, 1024, 16, 8]               0
          Conv2d-128           [-1, 256, 16, 8]         262,144
     BatchNorm2d-129           [-1, 256, 16, 8]             512
            ReLU-130           [-1, 256, 16, 8]               0
          Conv2d-131           [-1, 256, 16, 8]         589,824
     BatchNorm2d-132           [-1, 256, 16, 8]             512
            ReLU-133           [-1, 256, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
            ReLU-136          [-1, 1024, 16, 8]               0
      Bottleneck-137          [-1, 1024, 16, 8]               0
          Conv2d-138           [-1, 256, 16, 8]         262,144
     BatchNorm2d-139           [-1, 256, 16, 8]             512
            ReLU-140           [-1, 256, 16, 8]               0
          Conv2d-141           [-1, 256, 16, 8]         589,824
     BatchNorm2d-142           [-1, 256, 16, 8]             512
            ReLU-143           [-1, 256, 16, 8]               0
          Conv2d-144          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-145          [-1, 1024, 16, 8]           2,048
            ReLU-146          [-1, 1024, 16, 8]               0
      Bottleneck-147          [-1, 1024, 16, 8]               0
          Conv2d-148           [-1, 512, 16, 8]         524,288
     BatchNorm2d-149           [-1, 512, 16, 8]           1,024
            ReLU-150           [-1, 512, 16, 8]               0
          Conv2d-151           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-152           [-1, 512, 16, 8]           1,024
            ReLU-153           [-1, 512, 16, 8]               0
          Conv2d-154          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-155          [-1, 2048, 16, 8]           4,096
          Conv2d-156          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-157          [-1, 2048, 16, 8]           4,096
            ReLU-158          [-1, 2048, 16, 8]               0
      Bottleneck-159          [-1, 2048, 16, 8]               0
          Conv2d-160           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-161           [-1, 512, 16, 8]           1,024
            ReLU-162           [-1, 512, 16, 8]               0
          Conv2d-163           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-164           [-1, 512, 16, 8]           1,024
            ReLU-165           [-1, 512, 16, 8]               0
          Conv2d-166          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-167          [-1, 2048, 16, 8]           4,096
            ReLU-168          [-1, 2048, 16, 8]               0
      Bottleneck-169          [-1, 2048, 16, 8]               0
          Conv2d-170           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-171           [-1, 512, 16, 8]           1,024
            ReLU-172           [-1, 512, 16, 8]               0
          Conv2d-173           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-174           [-1, 512, 16, 8]           1,024
            ReLU-175           [-1, 512, 16, 8]               0
          Conv2d-176          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-177          [-1, 2048, 16, 8]           4,096
            ReLU-178          [-1, 2048, 16, 8]               0
      Bottleneck-179          [-1, 2048, 16, 8]               0
================================================================
Total params: 23,513,664
Trainable params: 23,513,664
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 233.75
Params size (MB): 89.70
Estimated Total Size (MB): 323.82
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet101_se
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
             ReLU-21          [-1, 256, 64, 32]               0
       Bottleneck-22          [-1, 256, 64, 32]               0
           Conv2d-23           [-1, 64, 64, 32]          16,384
      BatchNorm2d-24           [-1, 64, 64, 32]             128
             ReLU-25           [-1, 64, 64, 32]               0
           Conv2d-26           [-1, 64, 64, 32]          36,864
      BatchNorm2d-27           [-1, 64, 64, 32]             128
             ReLU-28           [-1, 64, 64, 32]               0
           Conv2d-29          [-1, 256, 64, 32]          16,384
      BatchNorm2d-30          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0
           Linear-32                   [-1, 16]           4,096
             ReLU-33                   [-1, 16]               0
           Linear-34                  [-1, 256]           4,096
          Sigmoid-35                  [-1, 256]               0
          SELayer-36          [-1, 256, 64, 32]               0
             ReLU-37          [-1, 256, 64, 32]               0
       Bottleneck-38          [-1, 256, 64, 32]               0
           Conv2d-39           [-1, 64, 64, 32]          16,384
      BatchNorm2d-40           [-1, 64, 64, 32]             128
             ReLU-41           [-1, 64, 64, 32]               0
           Conv2d-42           [-1, 64, 64, 32]          36,864
      BatchNorm2d-43           [-1, 64, 64, 32]             128
             ReLU-44           [-1, 64, 64, 32]               0
           Conv2d-45          [-1, 256, 64, 32]          16,384
      BatchNorm2d-46          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-47            [-1, 256, 1, 1]               0
           Linear-48                   [-1, 16]           4,096
             ReLU-49                   [-1, 16]               0
           Linear-50                  [-1, 256]           4,096
          Sigmoid-51                  [-1, 256]               0
          SELayer-52          [-1, 256, 64, 32]               0
             ReLU-53          [-1, 256, 64, 32]               0
       Bottleneck-54          [-1, 256, 64, 32]               0
           Conv2d-55          [-1, 128, 64, 32]          32,768
      BatchNorm2d-56          [-1, 128, 64, 32]             256
             ReLU-57          [-1, 128, 64, 32]               0
           Conv2d-58          [-1, 128, 32, 16]         147,456
      BatchNorm2d-59          [-1, 128, 32, 16]             256
             ReLU-60          [-1, 128, 32, 16]               0
           Conv2d-61          [-1, 512, 32, 16]          65,536
      BatchNorm2d-62          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-63            [-1, 512, 1, 1]               0
           Linear-64                   [-1, 32]          16,384
             ReLU-65                   [-1, 32]               0
           Linear-66                  [-1, 512]          16,384
          Sigmoid-67                  [-1, 512]               0
          SELayer-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         131,072
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
             ReLU-71          [-1, 512, 32, 16]               0
       Bottleneck-72          [-1, 512, 32, 16]               0
           Conv2d-73          [-1, 128, 32, 16]          65,536
      BatchNorm2d-74          [-1, 128, 32, 16]             256
             ReLU-75          [-1, 128, 32, 16]               0
           Conv2d-76          [-1, 128, 32, 16]         147,456
      BatchNorm2d-77          [-1, 128, 32, 16]             256
             ReLU-78          [-1, 128, 32, 16]               0
           Conv2d-79          [-1, 512, 32, 16]          65,536
      BatchNorm2d-80          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-81            [-1, 512, 1, 1]               0
           Linear-82                   [-1, 32]          16,384
             ReLU-83                   [-1, 32]               0
           Linear-84                  [-1, 512]          16,384
          Sigmoid-85                  [-1, 512]               0
          SELayer-86          [-1, 512, 32, 16]               0
             ReLU-87          [-1, 512, 32, 16]               0
       Bottleneck-88          [-1, 512, 32, 16]               0
           Conv2d-89          [-1, 128, 32, 16]          65,536
      BatchNorm2d-90          [-1, 128, 32, 16]             256
             ReLU-91          [-1, 128, 32, 16]               0
           Conv2d-92          [-1, 128, 32, 16]         147,456
      BatchNorm2d-93          [-1, 128, 32, 16]             256
             ReLU-94          [-1, 128, 32, 16]               0
           Conv2d-95          [-1, 512, 32, 16]          65,536
      BatchNorm2d-96          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-97            [-1, 512, 1, 1]               0
           Linear-98                   [-1, 32]          16,384
             ReLU-99                   [-1, 32]               0
          Linear-100                  [-1, 512]          16,384
         Sigmoid-101                  [-1, 512]               0
         SELayer-102          [-1, 512, 32, 16]               0
            ReLU-103          [-1, 512, 32, 16]               0
      Bottleneck-104          [-1, 512, 32, 16]               0
          Conv2d-105          [-1, 128, 32, 16]          65,536
     BatchNorm2d-106          [-1, 128, 32, 16]             256
            ReLU-107          [-1, 128, 32, 16]               0
          Conv2d-108          [-1, 128, 32, 16]         147,456
     BatchNorm2d-109          [-1, 128, 32, 16]             256
            ReLU-110          [-1, 128, 32, 16]               0
          Conv2d-111          [-1, 512, 32, 16]          65,536
     BatchNorm2d-112          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-113            [-1, 512, 1, 1]               0
          Linear-114                   [-1, 32]          16,384
            ReLU-115                   [-1, 32]               0
          Linear-116                  [-1, 512]          16,384
         Sigmoid-117                  [-1, 512]               0
         SELayer-118          [-1, 512, 32, 16]               0
            ReLU-119          [-1, 512, 32, 16]               0
      Bottleneck-120          [-1, 512, 32, 16]               0
          Conv2d-121          [-1, 256, 32, 16]         131,072
     BatchNorm2d-122          [-1, 256, 32, 16]             512
            ReLU-123          [-1, 256, 32, 16]               0
          Conv2d-124           [-1, 256, 16, 8]         589,824
     BatchNorm2d-125           [-1, 256, 16, 8]             512
            ReLU-126           [-1, 256, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-129           [-1, 1024, 1, 1]               0
          Linear-130                   [-1, 64]          65,536
            ReLU-131                   [-1, 64]               0
          Linear-132                 [-1, 1024]          65,536
         Sigmoid-133                 [-1, 1024]               0
         SELayer-134          [-1, 1024, 16, 8]               0
          Conv2d-135          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-136          [-1, 1024, 16, 8]           2,048
            ReLU-137          [-1, 1024, 16, 8]               0
      Bottleneck-138          [-1, 1024, 16, 8]               0
          Conv2d-139           [-1, 256, 16, 8]         262,144
     BatchNorm2d-140           [-1, 256, 16, 8]             512
            ReLU-141           [-1, 256, 16, 8]               0
          Conv2d-142           [-1, 256, 16, 8]         589,824
     BatchNorm2d-143           [-1, 256, 16, 8]             512
            ReLU-144           [-1, 256, 16, 8]               0
          Conv2d-145          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-146          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-147           [-1, 1024, 1, 1]               0
          Linear-148                   [-1, 64]          65,536
            ReLU-149                   [-1, 64]               0
          Linear-150                 [-1, 1024]          65,536
         Sigmoid-151                 [-1, 1024]               0
         SELayer-152          [-1, 1024, 16, 8]               0
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 256, 16, 8]         262,144
     BatchNorm2d-156           [-1, 256, 16, 8]             512
            ReLU-157           [-1, 256, 16, 8]               0
          Conv2d-158           [-1, 256, 16, 8]         589,824
     BatchNorm2d-159           [-1, 256, 16, 8]             512
            ReLU-160           [-1, 256, 16, 8]               0
          Conv2d-161          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-162          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-163           [-1, 1024, 1, 1]               0
          Linear-164                   [-1, 64]          65,536
            ReLU-165                   [-1, 64]               0
          Linear-166                 [-1, 1024]          65,536
         Sigmoid-167                 [-1, 1024]               0
         SELayer-168          [-1, 1024, 16, 8]               0
            ReLU-169          [-1, 1024, 16, 8]               0
      Bottleneck-170          [-1, 1024, 16, 8]               0
          Conv2d-171           [-1, 256, 16, 8]         262,144
     BatchNorm2d-172           [-1, 256, 16, 8]             512
            ReLU-173           [-1, 256, 16, 8]               0
          Conv2d-174           [-1, 256, 16, 8]         589,824
     BatchNorm2d-175           [-1, 256, 16, 8]             512
            ReLU-176           [-1, 256, 16, 8]               0
          Conv2d-177          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-178          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-179           [-1, 1024, 1, 1]               0
          Linear-180                   [-1, 64]          65,536
            ReLU-181                   [-1, 64]               0
          Linear-182                 [-1, 1024]          65,536
         Sigmoid-183                 [-1, 1024]               0
         SELayer-184          [-1, 1024, 16, 8]               0
            ReLU-185          [-1, 1024, 16, 8]               0
      Bottleneck-186          [-1, 1024, 16, 8]               0
          Conv2d-187           [-1, 256, 16, 8]         262,144
     BatchNorm2d-188           [-1, 256, 16, 8]             512
            ReLU-189           [-1, 256, 16, 8]               0
          Conv2d-190           [-1, 256, 16, 8]         589,824
     BatchNorm2d-191           [-1, 256, 16, 8]             512
            ReLU-192           [-1, 256, 16, 8]               0
          Conv2d-193          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-194          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-195           [-1, 1024, 1, 1]               0
          Linear-196                   [-1, 64]          65,536
            ReLU-197                   [-1, 64]               0
          Linear-198                 [-1, 1024]          65,536
         Sigmoid-199                 [-1, 1024]               0
         SELayer-200          [-1, 1024, 16, 8]               0
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203           [-1, 256, 16, 8]         262,144
     BatchNorm2d-204           [-1, 256, 16, 8]             512
            ReLU-205           [-1, 256, 16, 8]               0
          Conv2d-206           [-1, 256, 16, 8]         589,824
     BatchNorm2d-207           [-1, 256, 16, 8]             512
            ReLU-208           [-1, 256, 16, 8]               0
          Conv2d-209          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-210          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-211           [-1, 1024, 1, 1]               0
          Linear-212                   [-1, 64]          65,536
            ReLU-213                   [-1, 64]               0
          Linear-214                 [-1, 1024]          65,536
         Sigmoid-215                 [-1, 1024]               0
         SELayer-216          [-1, 1024, 16, 8]               0
            ReLU-217          [-1, 1024, 16, 8]               0
      Bottleneck-218          [-1, 1024, 16, 8]               0
          Conv2d-219           [-1, 256, 16, 8]         262,144
     BatchNorm2d-220           [-1, 256, 16, 8]             512
            ReLU-221           [-1, 256, 16, 8]               0
          Conv2d-222           [-1, 256, 16, 8]         589,824
     BatchNorm2d-223           [-1, 256, 16, 8]             512
            ReLU-224           [-1, 256, 16, 8]               0
          Conv2d-225          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-226          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-227           [-1, 1024, 1, 1]               0
          Linear-228                   [-1, 64]          65,536
            ReLU-229                   [-1, 64]               0
          Linear-230                 [-1, 1024]          65,536
         Sigmoid-231                 [-1, 1024]               0
         SELayer-232          [-1, 1024, 16, 8]               0
            ReLU-233          [-1, 1024, 16, 8]               0
      Bottleneck-234          [-1, 1024, 16, 8]               0
          Conv2d-235           [-1, 256, 16, 8]         262,144
     BatchNorm2d-236           [-1, 256, 16, 8]             512
            ReLU-237           [-1, 256, 16, 8]               0
          Conv2d-238           [-1, 256, 16, 8]         589,824
     BatchNorm2d-239           [-1, 256, 16, 8]             512
            ReLU-240           [-1, 256, 16, 8]               0
          Conv2d-241          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-242          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-243           [-1, 1024, 1, 1]               0
          Linear-244                   [-1, 64]          65,536
            ReLU-245                   [-1, 64]               0
          Linear-246                 [-1, 1024]          65,536
         Sigmoid-247                 [-1, 1024]               0
         SELayer-248          [-1, 1024, 16, 8]               0
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251           [-1, 256, 16, 8]         262,144
     BatchNorm2d-252           [-1, 256, 16, 8]             512
            ReLU-253           [-1, 256, 16, 8]               0
          Conv2d-254           [-1, 256, 16, 8]         589,824
     BatchNorm2d-255           [-1, 256, 16, 8]             512
            ReLU-256           [-1, 256, 16, 8]               0
          Conv2d-257          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-258          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-259           [-1, 1024, 1, 1]               0
          Linear-260                   [-1, 64]          65,536
            ReLU-261                   [-1, 64]               0
          Linear-262                 [-1, 1024]          65,536
         Sigmoid-263                 [-1, 1024]               0
         SELayer-264          [-1, 1024, 16, 8]               0
            ReLU-265          [-1, 1024, 16, 8]               0
      Bottleneck-266          [-1, 1024, 16, 8]               0
          Conv2d-267           [-1, 256, 16, 8]         262,144
     BatchNorm2d-268           [-1, 256, 16, 8]             512
            ReLU-269           [-1, 256, 16, 8]               0
          Conv2d-270           [-1, 256, 16, 8]         589,824
     BatchNorm2d-271           [-1, 256, 16, 8]             512
            ReLU-272           [-1, 256, 16, 8]               0
          Conv2d-273          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-274          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-275           [-1, 1024, 1, 1]               0
          Linear-276                   [-1, 64]          65,536
            ReLU-277                   [-1, 64]               0
          Linear-278                 [-1, 1024]          65,536
         Sigmoid-279                 [-1, 1024]               0
         SELayer-280          [-1, 1024, 16, 8]               0
            ReLU-281          [-1, 1024, 16, 8]               0
      Bottleneck-282          [-1, 1024, 16, 8]               0
          Conv2d-283           [-1, 256, 16, 8]         262,144
     BatchNorm2d-284           [-1, 256, 16, 8]             512
            ReLU-285           [-1, 256, 16, 8]               0
          Conv2d-286           [-1, 256, 16, 8]         589,824
     BatchNorm2d-287           [-1, 256, 16, 8]             512
            ReLU-288           [-1, 256, 16, 8]               0
          Conv2d-289          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-290          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-291           [-1, 1024, 1, 1]               0
          Linear-292                   [-1, 64]          65,536
            ReLU-293                   [-1, 64]               0
          Linear-294                 [-1, 1024]          65,536
         Sigmoid-295                 [-1, 1024]               0
         SELayer-296          [-1, 1024, 16, 8]               0
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299           [-1, 256, 16, 8]         262,144
     BatchNorm2d-300           [-1, 256, 16, 8]             512
            ReLU-301           [-1, 256, 16, 8]               0
          Conv2d-302           [-1, 256, 16, 8]         589,824
     BatchNorm2d-303           [-1, 256, 16, 8]             512
            ReLU-304           [-1, 256, 16, 8]               0
          Conv2d-305          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-306          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-307           [-1, 1024, 1, 1]               0
          Linear-308                   [-1, 64]          65,536
            ReLU-309                   [-1, 64]               0
          Linear-310                 [-1, 1024]          65,536
         Sigmoid-311                 [-1, 1024]               0
         SELayer-312          [-1, 1024, 16, 8]               0
            ReLU-313          [-1, 1024, 16, 8]               0
      Bottleneck-314          [-1, 1024, 16, 8]               0
          Conv2d-315           [-1, 256, 16, 8]         262,144
     BatchNorm2d-316           [-1, 256, 16, 8]             512
            ReLU-317           [-1, 256, 16, 8]               0
          Conv2d-318           [-1, 256, 16, 8]         589,824
     BatchNorm2d-319           [-1, 256, 16, 8]             512
            ReLU-320           [-1, 256, 16, 8]               0
          Conv2d-321          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-322          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-323           [-1, 1024, 1, 1]               0
          Linear-324                   [-1, 64]          65,536
            ReLU-325                   [-1, 64]               0
          Linear-326                 [-1, 1024]          65,536
         Sigmoid-327                 [-1, 1024]               0
         SELayer-328          [-1, 1024, 16, 8]               0
            ReLU-329          [-1, 1024, 16, 8]               0
      Bottleneck-330          [-1, 1024, 16, 8]               0
          Conv2d-331           [-1, 256, 16, 8]         262,144
     BatchNorm2d-332           [-1, 256, 16, 8]             512
            ReLU-333           [-1, 256, 16, 8]               0
          Conv2d-334           [-1, 256, 16, 8]         589,824
     BatchNorm2d-335           [-1, 256, 16, 8]             512
            ReLU-336           [-1, 256, 16, 8]               0
          Conv2d-337          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-338          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-339           [-1, 1024, 1, 1]               0
          Linear-340                   [-1, 64]          65,536
            ReLU-341                   [-1, 64]               0
          Linear-342                 [-1, 1024]          65,536
         Sigmoid-343                 [-1, 1024]               0
         SELayer-344          [-1, 1024, 16, 8]               0
            ReLU-345          [-1, 1024, 16, 8]               0
      Bottleneck-346          [-1, 1024, 16, 8]               0
          Conv2d-347           [-1, 256, 16, 8]         262,144
     BatchNorm2d-348           [-1, 256, 16, 8]             512
            ReLU-349           [-1, 256, 16, 8]               0
          Conv2d-350           [-1, 256, 16, 8]         589,824
     BatchNorm2d-351           [-1, 256, 16, 8]             512
            ReLU-352           [-1, 256, 16, 8]               0
          Conv2d-353          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-354          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-355           [-1, 1024, 1, 1]               0
          Linear-356                   [-1, 64]          65,536
            ReLU-357                   [-1, 64]               0
          Linear-358                 [-1, 1024]          65,536
         Sigmoid-359                 [-1, 1024]               0
         SELayer-360          [-1, 1024, 16, 8]               0
            ReLU-361          [-1, 1024, 16, 8]               0
      Bottleneck-362          [-1, 1024, 16, 8]               0
          Conv2d-363           [-1, 256, 16, 8]         262,144
     BatchNorm2d-364           [-1, 256, 16, 8]             512
            ReLU-365           [-1, 256, 16, 8]               0
          Conv2d-366           [-1, 256, 16, 8]         589,824
     BatchNorm2d-367           [-1, 256, 16, 8]             512
            ReLU-368           [-1, 256, 16, 8]               0
          Conv2d-369          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-370          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-371           [-1, 1024, 1, 1]               0
          Linear-372                   [-1, 64]          65,536
            ReLU-373                   [-1, 64]               0
          Linear-374                 [-1, 1024]          65,536
         Sigmoid-375                 [-1, 1024]               0
         SELayer-376          [-1, 1024, 16, 8]               0
            ReLU-377          [-1, 1024, 16, 8]               0
      Bottleneck-378          [-1, 1024, 16, 8]               0
          Conv2d-379           [-1, 256, 16, 8]         262,144
     BatchNorm2d-380           [-1, 256, 16, 8]             512
            ReLU-381           [-1, 256, 16, 8]               0
          Conv2d-382           [-1, 256, 16, 8]         589,824
     BatchNorm2d-383           [-1, 256, 16, 8]             512
            ReLU-384           [-1, 256, 16, 8]               0
          Conv2d-385          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-386          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-387           [-1, 1024, 1, 1]               0
          Linear-388                   [-1, 64]          65,536
            ReLU-389                   [-1, 64]               0
          Linear-390                 [-1, 1024]          65,536
         Sigmoid-391                 [-1, 1024]               0
         SELayer-392          [-1, 1024, 16, 8]               0
            ReLU-393          [-1, 1024, 16, 8]               0
      Bottleneck-394          [-1, 1024, 16, 8]               0
          Conv2d-395           [-1, 256, 16, 8]         262,144
     BatchNorm2d-396           [-1, 256, 16, 8]             512
            ReLU-397           [-1, 256, 16, 8]               0
          Conv2d-398           [-1, 256, 16, 8]         589,824
     BatchNorm2d-399           [-1, 256, 16, 8]             512
            ReLU-400           [-1, 256, 16, 8]               0
          Conv2d-401          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-402          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-403           [-1, 1024, 1, 1]               0
          Linear-404                   [-1, 64]          65,536
            ReLU-405                   [-1, 64]               0
          Linear-406                 [-1, 1024]          65,536
         Sigmoid-407                 [-1, 1024]               0
         SELayer-408          [-1, 1024, 16, 8]               0
            ReLU-409          [-1, 1024, 16, 8]               0
      Bottleneck-410          [-1, 1024, 16, 8]               0
          Conv2d-411           [-1, 256, 16, 8]         262,144
     BatchNorm2d-412           [-1, 256, 16, 8]             512
            ReLU-413           [-1, 256, 16, 8]               0
          Conv2d-414           [-1, 256, 16, 8]         589,824
     BatchNorm2d-415           [-1, 256, 16, 8]             512
            ReLU-416           [-1, 256, 16, 8]               0
          Conv2d-417          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-418          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-419           [-1, 1024, 1, 1]               0
          Linear-420                   [-1, 64]          65,536
            ReLU-421                   [-1, 64]               0
          Linear-422                 [-1, 1024]          65,536
         Sigmoid-423                 [-1, 1024]               0
         SELayer-424          [-1, 1024, 16, 8]               0
            ReLU-425          [-1, 1024, 16, 8]               0
      Bottleneck-426          [-1, 1024, 16, 8]               0
          Conv2d-427           [-1, 256, 16, 8]         262,144
     BatchNorm2d-428           [-1, 256, 16, 8]             512
            ReLU-429           [-1, 256, 16, 8]               0
          Conv2d-430           [-1, 256, 16, 8]         589,824
     BatchNorm2d-431           [-1, 256, 16, 8]             512
            ReLU-432           [-1, 256, 16, 8]               0
          Conv2d-433          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-434          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-435           [-1, 1024, 1, 1]               0
          Linear-436                   [-1, 64]          65,536
            ReLU-437                   [-1, 64]               0
          Linear-438                 [-1, 1024]          65,536
         Sigmoid-439                 [-1, 1024]               0
         SELayer-440          [-1, 1024, 16, 8]               0
            ReLU-441          [-1, 1024, 16, 8]               0
      Bottleneck-442          [-1, 1024, 16, 8]               0
          Conv2d-443           [-1, 256, 16, 8]         262,144
     BatchNorm2d-444           [-1, 256, 16, 8]             512
            ReLU-445           [-1, 256, 16, 8]               0
          Conv2d-446           [-1, 256, 16, 8]         589,824
     BatchNorm2d-447           [-1, 256, 16, 8]             512
            ReLU-448           [-1, 256, 16, 8]               0
          Conv2d-449          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-450          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-451           [-1, 1024, 1, 1]               0
          Linear-452                   [-1, 64]          65,536
            ReLU-453                   [-1, 64]               0
          Linear-454                 [-1, 1024]          65,536
         Sigmoid-455                 [-1, 1024]               0
         SELayer-456          [-1, 1024, 16, 8]               0
            ReLU-457          [-1, 1024, 16, 8]               0
      Bottleneck-458          [-1, 1024, 16, 8]               0
          Conv2d-459           [-1, 256, 16, 8]         262,144
     BatchNorm2d-460           [-1, 256, 16, 8]             512
            ReLU-461           [-1, 256, 16, 8]               0
          Conv2d-462           [-1, 256, 16, 8]         589,824
     BatchNorm2d-463           [-1, 256, 16, 8]             512
            ReLU-464           [-1, 256, 16, 8]               0
          Conv2d-465          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-466          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-467           [-1, 1024, 1, 1]               0
          Linear-468                   [-1, 64]          65,536
            ReLU-469                   [-1, 64]               0
          Linear-470                 [-1, 1024]          65,536
         Sigmoid-471                 [-1, 1024]               0
         SELayer-472          [-1, 1024, 16, 8]               0
            ReLU-473          [-1, 1024, 16, 8]               0
      Bottleneck-474          [-1, 1024, 16, 8]               0
          Conv2d-475           [-1, 256, 16, 8]         262,144
     BatchNorm2d-476           [-1, 256, 16, 8]             512
            ReLU-477           [-1, 256, 16, 8]               0
          Conv2d-478           [-1, 256, 16, 8]         589,824
     BatchNorm2d-479           [-1, 256, 16, 8]             512
            ReLU-480           [-1, 256, 16, 8]               0
          Conv2d-481          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-482          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-483           [-1, 1024, 1, 1]               0
          Linear-484                   [-1, 64]          65,536
            ReLU-485                   [-1, 64]               0
          Linear-486                 [-1, 1024]          65,536
         Sigmoid-487                 [-1, 1024]               0
         SELayer-488          [-1, 1024, 16, 8]               0
            ReLU-489          [-1, 1024, 16, 8]               0
      Bottleneck-490          [-1, 1024, 16, 8]               0
          Conv2d-491           [-1, 512, 16, 8]         524,288
     BatchNorm2d-492           [-1, 512, 16, 8]           1,024
            ReLU-493           [-1, 512, 16, 8]               0
          Conv2d-494           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-495           [-1, 512, 16, 8]           1,024
            ReLU-496           [-1, 512, 16, 8]               0
          Conv2d-497          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-498          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-499           [-1, 2048, 1, 1]               0
          Linear-500                  [-1, 128]         262,144
            ReLU-501                  [-1, 128]               0
          Linear-502                 [-1, 2048]         262,144
         Sigmoid-503                 [-1, 2048]               0
         SELayer-504          [-1, 2048, 16, 8]               0
          Conv2d-505          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-506          [-1, 2048, 16, 8]           4,096
            ReLU-507          [-1, 2048, 16, 8]               0
      Bottleneck-508          [-1, 2048, 16, 8]               0
          Conv2d-509           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-510           [-1, 512, 16, 8]           1,024
            ReLU-511           [-1, 512, 16, 8]               0
          Conv2d-512           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-513           [-1, 512, 16, 8]           1,024
            ReLU-514           [-1, 512, 16, 8]               0
          Conv2d-515          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-516          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-517           [-1, 2048, 1, 1]               0
          Linear-518                  [-1, 128]         262,144
            ReLU-519                  [-1, 128]               0
          Linear-520                 [-1, 2048]         262,144
         Sigmoid-521                 [-1, 2048]               0
         SELayer-522          [-1, 2048, 16, 8]               0
            ReLU-523          [-1, 2048, 16, 8]               0
      Bottleneck-524          [-1, 2048, 16, 8]               0
          Conv2d-525           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-526           [-1, 512, 16, 8]           1,024
            ReLU-527           [-1, 512, 16, 8]               0
          Conv2d-528           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-529           [-1, 512, 16, 8]           1,024
            ReLU-530           [-1, 512, 16, 8]               0
          Conv2d-531          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-532          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-533           [-1, 2048, 1, 1]               0
          Linear-534                  [-1, 128]         262,144
            ReLU-535                  [-1, 128]               0
          Linear-536                 [-1, 2048]         262,144
         Sigmoid-537                 [-1, 2048]               0
         SELayer-538          [-1, 2048, 16, 8]               0
            ReLU-539          [-1, 2048, 16, 8]               0
      Bottleneck-540          [-1, 2048, 16, 8]               0
================================================================
Total params: 47,243,328
Trainable params: 47,243,328
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 357.03
Params size (MB): 180.22
Estimated Total Size (MB): 537.62
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet101_se_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
    InstanceNorm2d-6           [-1, 32, 64, 32]              64
       BatchNorm2d-7           [-1, 32, 64, 32]              64
               IBN-8           [-1, 64, 64, 32]               0
              ReLU-9           [-1, 64, 64, 32]               0
           Conv2d-10           [-1, 64, 64, 32]          36,864
      BatchNorm2d-11           [-1, 64, 64, 32]             128
             ReLU-12           [-1, 64, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-15            [-1, 256, 1, 1]               0
           Linear-16                   [-1, 16]           4,096
             ReLU-17                   [-1, 16]               0
           Linear-18                  [-1, 256]           4,096
          Sigmoid-19                  [-1, 256]               0
          SELayer-20          [-1, 256, 64, 32]               0
           Conv2d-21          [-1, 256, 64, 32]          16,384
      BatchNorm2d-22          [-1, 256, 64, 32]             512
             ReLU-23          [-1, 256, 64, 32]               0
       Bottleneck-24          [-1, 256, 64, 32]               0
           Conv2d-25           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-26           [-1, 32, 64, 32]              64
      BatchNorm2d-27           [-1, 32, 64, 32]              64
              IBN-28           [-1, 64, 64, 32]               0
             ReLU-29           [-1, 64, 64, 32]               0
           Conv2d-30           [-1, 64, 64, 32]          36,864
      BatchNorm2d-31           [-1, 64, 64, 32]             128
             ReLU-32           [-1, 64, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          16,384
      BatchNorm2d-34          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-35            [-1, 256, 1, 1]               0
           Linear-36                   [-1, 16]           4,096
             ReLU-37                   [-1, 16]               0
           Linear-38                  [-1, 256]           4,096
          Sigmoid-39                  [-1, 256]               0
          SELayer-40          [-1, 256, 64, 32]               0
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-44           [-1, 32, 64, 32]              64
      BatchNorm2d-45           [-1, 32, 64, 32]              64
              IBN-46           [-1, 64, 64, 32]               0
             ReLU-47           [-1, 64, 64, 32]               0
           Conv2d-48           [-1, 64, 64, 32]          36,864
      BatchNorm2d-49           [-1, 64, 64, 32]             128
             ReLU-50           [-1, 64, 64, 32]               0
           Conv2d-51          [-1, 256, 64, 32]          16,384
      BatchNorm2d-52          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-53            [-1, 256, 1, 1]               0
           Linear-54                   [-1, 16]           4,096
             ReLU-55                   [-1, 16]               0
           Linear-56                  [-1, 256]           4,096
          Sigmoid-57                  [-1, 256]               0
          SELayer-58          [-1, 256, 64, 32]               0
             ReLU-59          [-1, 256, 64, 32]               0
       Bottleneck-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-62           [-1, 64, 64, 32]             128
      BatchNorm2d-63           [-1, 64, 64, 32]             128
              IBN-64          [-1, 128, 64, 32]               0
             ReLU-65          [-1, 128, 64, 32]               0
           Conv2d-66          [-1, 128, 32, 16]         147,456
      BatchNorm2d-67          [-1, 128, 32, 16]             256
             ReLU-68          [-1, 128, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]          65,536
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-71            [-1, 512, 1, 1]               0
           Linear-72                   [-1, 32]          16,384
             ReLU-73                   [-1, 32]               0
           Linear-74                  [-1, 512]          16,384
          Sigmoid-75                  [-1, 512]               0
          SELayer-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         131,072
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-82           [-1, 64, 32, 16]             128
      BatchNorm2d-83           [-1, 64, 32, 16]             128
              IBN-84          [-1, 128, 32, 16]               0
             ReLU-85          [-1, 128, 32, 16]               0
           Conv2d-86          [-1, 128, 32, 16]         147,456
      BatchNorm2d-87          [-1, 128, 32, 16]             256
             ReLU-88          [-1, 128, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]          65,536
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-91            [-1, 512, 1, 1]               0
           Linear-92                   [-1, 32]          16,384
             ReLU-93                   [-1, 32]               0
           Linear-94                  [-1, 512]          16,384
          Sigmoid-95                  [-1, 512]               0
          SELayer-96          [-1, 512, 32, 16]               0
             ReLU-97          [-1, 512, 32, 16]               0
       Bottleneck-98          [-1, 512, 32, 16]               0
           Conv2d-99          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-100           [-1, 64, 32, 16]             128
     BatchNorm2d-101           [-1, 64, 32, 16]             128
             IBN-102          [-1, 128, 32, 16]               0
            ReLU-103          [-1, 128, 32, 16]               0
          Conv2d-104          [-1, 128, 32, 16]         147,456
     BatchNorm2d-105          [-1, 128, 32, 16]             256
            ReLU-106          [-1, 128, 32, 16]               0
          Conv2d-107          [-1, 512, 32, 16]          65,536
     BatchNorm2d-108          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-109            [-1, 512, 1, 1]               0
          Linear-110                   [-1, 32]          16,384
            ReLU-111                   [-1, 32]               0
          Linear-112                  [-1, 512]          16,384
         Sigmoid-113                  [-1, 512]               0
         SELayer-114          [-1, 512, 32, 16]               0
            ReLU-115          [-1, 512, 32, 16]               0
      Bottleneck-116          [-1, 512, 32, 16]               0
          Conv2d-117          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-118           [-1, 64, 32, 16]             128
     BatchNorm2d-119           [-1, 64, 32, 16]             128
             IBN-120          [-1, 128, 32, 16]               0
            ReLU-121          [-1, 128, 32, 16]               0
          Conv2d-122          [-1, 128, 32, 16]         147,456
     BatchNorm2d-123          [-1, 128, 32, 16]             256
            ReLU-124          [-1, 128, 32, 16]               0
          Conv2d-125          [-1, 512, 32, 16]          65,536
     BatchNorm2d-126          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-127            [-1, 512, 1, 1]               0
          Linear-128                   [-1, 32]          16,384
            ReLU-129                   [-1, 32]               0
          Linear-130                  [-1, 512]          16,384
         Sigmoid-131                  [-1, 512]               0
         SELayer-132          [-1, 512, 32, 16]               0
            ReLU-133          [-1, 512, 32, 16]               0
      Bottleneck-134          [-1, 512, 32, 16]               0
          Conv2d-135          [-1, 256, 32, 16]         131,072
  InstanceNorm2d-136          [-1, 128, 32, 16]             256
     BatchNorm2d-137          [-1, 128, 32, 16]             256
             IBN-138          [-1, 256, 32, 16]               0
            ReLU-139          [-1, 256, 32, 16]               0
          Conv2d-140           [-1, 256, 16, 8]         589,824
     BatchNorm2d-141           [-1, 256, 16, 8]             512
            ReLU-142           [-1, 256, 16, 8]               0
          Conv2d-143          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-144          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-145           [-1, 1024, 1, 1]               0
          Linear-146                   [-1, 64]          65,536
            ReLU-147                   [-1, 64]               0
          Linear-148                 [-1, 1024]          65,536
         Sigmoid-149                 [-1, 1024]               0
         SELayer-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-156           [-1, 128, 16, 8]             256
     BatchNorm2d-157           [-1, 128, 16, 8]             256
             IBN-158           [-1, 256, 16, 8]               0
            ReLU-159           [-1, 256, 16, 8]               0
          Conv2d-160           [-1, 256, 16, 8]         589,824
     BatchNorm2d-161           [-1, 256, 16, 8]             512
            ReLU-162           [-1, 256, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-165           [-1, 1024, 1, 1]               0
          Linear-166                   [-1, 64]          65,536
            ReLU-167                   [-1, 64]               0
          Linear-168                 [-1, 1024]          65,536
         Sigmoid-169                 [-1, 1024]               0
         SELayer-170          [-1, 1024, 16, 8]               0
            ReLU-171          [-1, 1024, 16, 8]               0
      Bottleneck-172          [-1, 1024, 16, 8]               0
          Conv2d-173           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-174           [-1, 128, 16, 8]             256
     BatchNorm2d-175           [-1, 128, 16, 8]             256
             IBN-176           [-1, 256, 16, 8]               0
            ReLU-177           [-1, 256, 16, 8]               0
          Conv2d-178           [-1, 256, 16, 8]         589,824
     BatchNorm2d-179           [-1, 256, 16, 8]             512
            ReLU-180           [-1, 256, 16, 8]               0
          Conv2d-181          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-182          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-183           [-1, 1024, 1, 1]               0
          Linear-184                   [-1, 64]          65,536
            ReLU-185                   [-1, 64]               0
          Linear-186                 [-1, 1024]          65,536
         Sigmoid-187                 [-1, 1024]               0
         SELayer-188          [-1, 1024, 16, 8]               0
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-192           [-1, 128, 16, 8]             256
     BatchNorm2d-193           [-1, 128, 16, 8]             256
             IBN-194           [-1, 256, 16, 8]               0
            ReLU-195           [-1, 256, 16, 8]               0
          Conv2d-196           [-1, 256, 16, 8]         589,824
     BatchNorm2d-197           [-1, 256, 16, 8]             512
            ReLU-198           [-1, 256, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-201           [-1, 1024, 1, 1]               0
          Linear-202                   [-1, 64]          65,536
            ReLU-203                   [-1, 64]               0
          Linear-204                 [-1, 1024]          65,536
         Sigmoid-205                 [-1, 1024]               0
         SELayer-206          [-1, 1024, 16, 8]               0
            ReLU-207          [-1, 1024, 16, 8]               0
      Bottleneck-208          [-1, 1024, 16, 8]               0
          Conv2d-209           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-210           [-1, 128, 16, 8]             256
     BatchNorm2d-211           [-1, 128, 16, 8]             256
             IBN-212           [-1, 256, 16, 8]               0
            ReLU-213           [-1, 256, 16, 8]               0
          Conv2d-214           [-1, 256, 16, 8]         589,824
     BatchNorm2d-215           [-1, 256, 16, 8]             512
            ReLU-216           [-1, 256, 16, 8]               0
          Conv2d-217          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-218          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-219           [-1, 1024, 1, 1]               0
          Linear-220                   [-1, 64]          65,536
            ReLU-221                   [-1, 64]               0
          Linear-222                 [-1, 1024]          65,536
         Sigmoid-223                 [-1, 1024]               0
         SELayer-224          [-1, 1024, 16, 8]               0
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-228           [-1, 128, 16, 8]             256
     BatchNorm2d-229           [-1, 128, 16, 8]             256
             IBN-230           [-1, 256, 16, 8]               0
            ReLU-231           [-1, 256, 16, 8]               0
          Conv2d-232           [-1, 256, 16, 8]         589,824
     BatchNorm2d-233           [-1, 256, 16, 8]             512
            ReLU-234           [-1, 256, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-237           [-1, 1024, 1, 1]               0
          Linear-238                   [-1, 64]          65,536
            ReLU-239                   [-1, 64]               0
          Linear-240                 [-1, 1024]          65,536
         Sigmoid-241                 [-1, 1024]               0
         SELayer-242          [-1, 1024, 16, 8]               0
            ReLU-243          [-1, 1024, 16, 8]               0
      Bottleneck-244          [-1, 1024, 16, 8]               0
          Conv2d-245           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-246           [-1, 128, 16, 8]             256
     BatchNorm2d-247           [-1, 128, 16, 8]             256
             IBN-248           [-1, 256, 16, 8]               0
            ReLU-249           [-1, 256, 16, 8]               0
          Conv2d-250           [-1, 256, 16, 8]         589,824
     BatchNorm2d-251           [-1, 256, 16, 8]             512
            ReLU-252           [-1, 256, 16, 8]               0
          Conv2d-253          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-254          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-255           [-1, 1024, 1, 1]               0
          Linear-256                   [-1, 64]          65,536
            ReLU-257                   [-1, 64]               0
          Linear-258                 [-1, 1024]          65,536
         Sigmoid-259                 [-1, 1024]               0
         SELayer-260          [-1, 1024, 16, 8]               0
            ReLU-261          [-1, 1024, 16, 8]               0
      Bottleneck-262          [-1, 1024, 16, 8]               0
          Conv2d-263           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-264           [-1, 128, 16, 8]             256
     BatchNorm2d-265           [-1, 128, 16, 8]             256
             IBN-266           [-1, 256, 16, 8]               0
            ReLU-267           [-1, 256, 16, 8]               0
          Conv2d-268           [-1, 256, 16, 8]         589,824
     BatchNorm2d-269           [-1, 256, 16, 8]             512
            ReLU-270           [-1, 256, 16, 8]               0
          Conv2d-271          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-272          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-273           [-1, 1024, 1, 1]               0
          Linear-274                   [-1, 64]          65,536
            ReLU-275                   [-1, 64]               0
          Linear-276                 [-1, 1024]          65,536
         Sigmoid-277                 [-1, 1024]               0
         SELayer-278          [-1, 1024, 16, 8]               0
            ReLU-279          [-1, 1024, 16, 8]               0
      Bottleneck-280          [-1, 1024, 16, 8]               0
          Conv2d-281           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-282           [-1, 128, 16, 8]             256
     BatchNorm2d-283           [-1, 128, 16, 8]             256
             IBN-284           [-1, 256, 16, 8]               0
            ReLU-285           [-1, 256, 16, 8]               0
          Conv2d-286           [-1, 256, 16, 8]         589,824
     BatchNorm2d-287           [-1, 256, 16, 8]             512
            ReLU-288           [-1, 256, 16, 8]               0
          Conv2d-289          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-290          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-291           [-1, 1024, 1, 1]               0
          Linear-292                   [-1, 64]          65,536
            ReLU-293                   [-1, 64]               0
          Linear-294                 [-1, 1024]          65,536
         Sigmoid-295                 [-1, 1024]               0
         SELayer-296          [-1, 1024, 16, 8]               0
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-300           [-1, 128, 16, 8]             256
     BatchNorm2d-301           [-1, 128, 16, 8]             256
             IBN-302           [-1, 256, 16, 8]               0
            ReLU-303           [-1, 256, 16, 8]               0
          Conv2d-304           [-1, 256, 16, 8]         589,824
     BatchNorm2d-305           [-1, 256, 16, 8]             512
            ReLU-306           [-1, 256, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-309           [-1, 1024, 1, 1]               0
          Linear-310                   [-1, 64]          65,536
            ReLU-311                   [-1, 64]               0
          Linear-312                 [-1, 1024]          65,536
         Sigmoid-313                 [-1, 1024]               0
         SELayer-314          [-1, 1024, 16, 8]               0
            ReLU-315          [-1, 1024, 16, 8]               0
      Bottleneck-316          [-1, 1024, 16, 8]               0
          Conv2d-317           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-318           [-1, 128, 16, 8]             256
     BatchNorm2d-319           [-1, 128, 16, 8]             256
             IBN-320           [-1, 256, 16, 8]               0
            ReLU-321           [-1, 256, 16, 8]               0
          Conv2d-322           [-1, 256, 16, 8]         589,824
     BatchNorm2d-323           [-1, 256, 16, 8]             512
            ReLU-324           [-1, 256, 16, 8]               0
          Conv2d-325          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-326          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-327           [-1, 1024, 1, 1]               0
          Linear-328                   [-1, 64]          65,536
            ReLU-329                   [-1, 64]               0
          Linear-330                 [-1, 1024]          65,536
         Sigmoid-331                 [-1, 1024]               0
         SELayer-332          [-1, 1024, 16, 8]               0
            ReLU-333          [-1, 1024, 16, 8]               0
      Bottleneck-334          [-1, 1024, 16, 8]               0
          Conv2d-335           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-336           [-1, 128, 16, 8]             256
     BatchNorm2d-337           [-1, 128, 16, 8]             256
             IBN-338           [-1, 256, 16, 8]               0
            ReLU-339           [-1, 256, 16, 8]               0
          Conv2d-340           [-1, 256, 16, 8]         589,824
     BatchNorm2d-341           [-1, 256, 16, 8]             512
            ReLU-342           [-1, 256, 16, 8]               0
          Conv2d-343          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-344          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-345           [-1, 1024, 1, 1]               0
          Linear-346                   [-1, 64]          65,536
            ReLU-347                   [-1, 64]               0
          Linear-348                 [-1, 1024]          65,536
         Sigmoid-349                 [-1, 1024]               0
         SELayer-350          [-1, 1024, 16, 8]               0
            ReLU-351          [-1, 1024, 16, 8]               0
      Bottleneck-352          [-1, 1024, 16, 8]               0
          Conv2d-353           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-354           [-1, 128, 16, 8]             256
     BatchNorm2d-355           [-1, 128, 16, 8]             256
             IBN-356           [-1, 256, 16, 8]               0
            ReLU-357           [-1, 256, 16, 8]               0
          Conv2d-358           [-1, 256, 16, 8]         589,824
     BatchNorm2d-359           [-1, 256, 16, 8]             512
            ReLU-360           [-1, 256, 16, 8]               0
          Conv2d-361          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-362          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-363           [-1, 1024, 1, 1]               0
          Linear-364                   [-1, 64]          65,536
            ReLU-365                   [-1, 64]               0
          Linear-366                 [-1, 1024]          65,536
         Sigmoid-367                 [-1, 1024]               0
         SELayer-368          [-1, 1024, 16, 8]               0
            ReLU-369          [-1, 1024, 16, 8]               0
      Bottleneck-370          [-1, 1024, 16, 8]               0
          Conv2d-371           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-372           [-1, 128, 16, 8]             256
     BatchNorm2d-373           [-1, 128, 16, 8]             256
             IBN-374           [-1, 256, 16, 8]               0
            ReLU-375           [-1, 256, 16, 8]               0
          Conv2d-376           [-1, 256, 16, 8]         589,824
     BatchNorm2d-377           [-1, 256, 16, 8]             512
            ReLU-378           [-1, 256, 16, 8]               0
          Conv2d-379          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-380          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-381           [-1, 1024, 1, 1]               0
          Linear-382                   [-1, 64]          65,536
            ReLU-383                   [-1, 64]               0
          Linear-384                 [-1, 1024]          65,536
         Sigmoid-385                 [-1, 1024]               0
         SELayer-386          [-1, 1024, 16, 8]               0
            ReLU-387          [-1, 1024, 16, 8]               0
      Bottleneck-388          [-1, 1024, 16, 8]               0
          Conv2d-389           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-390           [-1, 128, 16, 8]             256
     BatchNorm2d-391           [-1, 128, 16, 8]             256
             IBN-392           [-1, 256, 16, 8]               0
            ReLU-393           [-1, 256, 16, 8]               0
          Conv2d-394           [-1, 256, 16, 8]         589,824
     BatchNorm2d-395           [-1, 256, 16, 8]             512
            ReLU-396           [-1, 256, 16, 8]               0
          Conv2d-397          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-398          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-399           [-1, 1024, 1, 1]               0
          Linear-400                   [-1, 64]          65,536
            ReLU-401                   [-1, 64]               0
          Linear-402                 [-1, 1024]          65,536
         Sigmoid-403                 [-1, 1024]               0
         SELayer-404          [-1, 1024, 16, 8]               0
            ReLU-405          [-1, 1024, 16, 8]               0
      Bottleneck-406          [-1, 1024, 16, 8]               0
          Conv2d-407           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-408           [-1, 128, 16, 8]             256
     BatchNorm2d-409           [-1, 128, 16, 8]             256
             IBN-410           [-1, 256, 16, 8]               0
            ReLU-411           [-1, 256, 16, 8]               0
          Conv2d-412           [-1, 256, 16, 8]         589,824
     BatchNorm2d-413           [-1, 256, 16, 8]             512
            ReLU-414           [-1, 256, 16, 8]               0
          Conv2d-415          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-416          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-417           [-1, 1024, 1, 1]               0
          Linear-418                   [-1, 64]          65,536
            ReLU-419                   [-1, 64]               0
          Linear-420                 [-1, 1024]          65,536
         Sigmoid-421                 [-1, 1024]               0
         SELayer-422          [-1, 1024, 16, 8]               0
            ReLU-423          [-1, 1024, 16, 8]               0
      Bottleneck-424          [-1, 1024, 16, 8]               0
          Conv2d-425           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-426           [-1, 128, 16, 8]             256
     BatchNorm2d-427           [-1, 128, 16, 8]             256
             IBN-428           [-1, 256, 16, 8]               0
            ReLU-429           [-1, 256, 16, 8]               0
          Conv2d-430           [-1, 256, 16, 8]         589,824
     BatchNorm2d-431           [-1, 256, 16, 8]             512
            ReLU-432           [-1, 256, 16, 8]               0
          Conv2d-433          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-434          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-435           [-1, 1024, 1, 1]               0
          Linear-436                   [-1, 64]          65,536
            ReLU-437                   [-1, 64]               0
          Linear-438                 [-1, 1024]          65,536
         Sigmoid-439                 [-1, 1024]               0
         SELayer-440          [-1, 1024, 16, 8]               0
            ReLU-441          [-1, 1024, 16, 8]               0
      Bottleneck-442          [-1, 1024, 16, 8]               0
          Conv2d-443           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-444           [-1, 128, 16, 8]             256
     BatchNorm2d-445           [-1, 128, 16, 8]             256
             IBN-446           [-1, 256, 16, 8]               0
            ReLU-447           [-1, 256, 16, 8]               0
          Conv2d-448           [-1, 256, 16, 8]         589,824
     BatchNorm2d-449           [-1, 256, 16, 8]             512
            ReLU-450           [-1, 256, 16, 8]               0
          Conv2d-451          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-452          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-453           [-1, 1024, 1, 1]               0
          Linear-454                   [-1, 64]          65,536
            ReLU-455                   [-1, 64]               0
          Linear-456                 [-1, 1024]          65,536
         Sigmoid-457                 [-1, 1024]               0
         SELayer-458          [-1, 1024, 16, 8]               0
            ReLU-459          [-1, 1024, 16, 8]               0
      Bottleneck-460          [-1, 1024, 16, 8]               0
          Conv2d-461           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-462           [-1, 128, 16, 8]             256
     BatchNorm2d-463           [-1, 128, 16, 8]             256
             IBN-464           [-1, 256, 16, 8]               0
            ReLU-465           [-1, 256, 16, 8]               0
          Conv2d-466           [-1, 256, 16, 8]         589,824
     BatchNorm2d-467           [-1, 256, 16, 8]             512
            ReLU-468           [-1, 256, 16, 8]               0
          Conv2d-469          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-470          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-471           [-1, 1024, 1, 1]               0
          Linear-472                   [-1, 64]          65,536
            ReLU-473                   [-1, 64]               0
          Linear-474                 [-1, 1024]          65,536
         Sigmoid-475                 [-1, 1024]               0
         SELayer-476          [-1, 1024, 16, 8]               0
            ReLU-477          [-1, 1024, 16, 8]               0
      Bottleneck-478          [-1, 1024, 16, 8]               0
          Conv2d-479           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-480           [-1, 128, 16, 8]             256
     BatchNorm2d-481           [-1, 128, 16, 8]             256
             IBN-482           [-1, 256, 16, 8]               0
            ReLU-483           [-1, 256, 16, 8]               0
          Conv2d-484           [-1, 256, 16, 8]         589,824
     BatchNorm2d-485           [-1, 256, 16, 8]             512
            ReLU-486           [-1, 256, 16, 8]               0
          Conv2d-487          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-488          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-489           [-1, 1024, 1, 1]               0
          Linear-490                   [-1, 64]          65,536
            ReLU-491                   [-1, 64]               0
          Linear-492                 [-1, 1024]          65,536
         Sigmoid-493                 [-1, 1024]               0
         SELayer-494          [-1, 1024, 16, 8]               0
            ReLU-495          [-1, 1024, 16, 8]               0
      Bottleneck-496          [-1, 1024, 16, 8]               0
          Conv2d-497           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-498           [-1, 128, 16, 8]             256
     BatchNorm2d-499           [-1, 128, 16, 8]             256
             IBN-500           [-1, 256, 16, 8]               0
            ReLU-501           [-1, 256, 16, 8]               0
          Conv2d-502           [-1, 256, 16, 8]         589,824
     BatchNorm2d-503           [-1, 256, 16, 8]             512
            ReLU-504           [-1, 256, 16, 8]               0
          Conv2d-505          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-506          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-507           [-1, 1024, 1, 1]               0
          Linear-508                   [-1, 64]          65,536
            ReLU-509                   [-1, 64]               0
          Linear-510                 [-1, 1024]          65,536
         Sigmoid-511                 [-1, 1024]               0
         SELayer-512          [-1, 1024, 16, 8]               0
            ReLU-513          [-1, 1024, 16, 8]               0
      Bottleneck-514          [-1, 1024, 16, 8]               0
          Conv2d-515           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-516           [-1, 128, 16, 8]             256
     BatchNorm2d-517           [-1, 128, 16, 8]             256
             IBN-518           [-1, 256, 16, 8]               0
            ReLU-519           [-1, 256, 16, 8]               0
          Conv2d-520           [-1, 256, 16, 8]         589,824
     BatchNorm2d-521           [-1, 256, 16, 8]             512
            ReLU-522           [-1, 256, 16, 8]               0
          Conv2d-523          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-524          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-525           [-1, 1024, 1, 1]               0
          Linear-526                   [-1, 64]          65,536
            ReLU-527                   [-1, 64]               0
          Linear-528                 [-1, 1024]          65,536
         Sigmoid-529                 [-1, 1024]               0
         SELayer-530          [-1, 1024, 16, 8]               0
            ReLU-531          [-1, 1024, 16, 8]               0
      Bottleneck-532          [-1, 1024, 16, 8]               0
          Conv2d-533           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-534           [-1, 128, 16, 8]             256
     BatchNorm2d-535           [-1, 128, 16, 8]             256
             IBN-536           [-1, 256, 16, 8]               0
            ReLU-537           [-1, 256, 16, 8]               0
          Conv2d-538           [-1, 256, 16, 8]         589,824
     BatchNorm2d-539           [-1, 256, 16, 8]             512
            ReLU-540           [-1, 256, 16, 8]               0
          Conv2d-541          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-542          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-543           [-1, 1024, 1, 1]               0
          Linear-544                   [-1, 64]          65,536
            ReLU-545                   [-1, 64]               0
          Linear-546                 [-1, 1024]          65,536
         Sigmoid-547                 [-1, 1024]               0
         SELayer-548          [-1, 1024, 16, 8]               0
            ReLU-549          [-1, 1024, 16, 8]               0
      Bottleneck-550          [-1, 1024, 16, 8]               0
          Conv2d-551           [-1, 512, 16, 8]         524,288
     BatchNorm2d-552           [-1, 512, 16, 8]           1,024
            ReLU-553           [-1, 512, 16, 8]               0
          Conv2d-554           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-555           [-1, 512, 16, 8]           1,024
            ReLU-556           [-1, 512, 16, 8]               0
          Conv2d-557          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-558          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-559           [-1, 2048, 1, 1]               0
          Linear-560                  [-1, 128]         262,144
            ReLU-561                  [-1, 128]               0
          Linear-562                 [-1, 2048]         262,144
         Sigmoid-563                 [-1, 2048]               0
         SELayer-564          [-1, 2048, 16, 8]               0
          Conv2d-565          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-566          [-1, 2048, 16, 8]           4,096
            ReLU-567          [-1, 2048, 16, 8]               0
      Bottleneck-568          [-1, 2048, 16, 8]               0
          Conv2d-569           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-570           [-1, 512, 16, 8]           1,024
            ReLU-571           [-1, 512, 16, 8]               0
          Conv2d-572           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-573           [-1, 512, 16, 8]           1,024
            ReLU-574           [-1, 512, 16, 8]               0
          Conv2d-575          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-576          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-577           [-1, 2048, 1, 1]               0
          Linear-578                  [-1, 128]         262,144
            ReLU-579                  [-1, 128]               0
          Linear-580                 [-1, 2048]         262,144
         Sigmoid-581                 [-1, 2048]               0
         SELayer-582          [-1, 2048, 16, 8]               0
            ReLU-583          [-1, 2048, 16, 8]               0
      Bottleneck-584          [-1, 2048, 16, 8]               0
          Conv2d-585           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-586           [-1, 512, 16, 8]           1,024
            ReLU-587           [-1, 512, 16, 8]               0
          Conv2d-588           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-589           [-1, 512, 16, 8]           1,024
            ReLU-590           [-1, 512, 16, 8]               0
          Conv2d-591          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-592          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-593           [-1, 2048, 1, 1]               0
          Linear-594                  [-1, 128]         262,144
            ReLU-595                  [-1, 128]               0
          Linear-596                 [-1, 2048]         262,144
         Sigmoid-597                 [-1, 2048]               0
         SELayer-598          [-1, 2048, 16, 8]               0
            ReLU-599          [-1, 2048, 16, 8]               0
      Bottleneck-600          [-1, 2048, 16, 8]               0
================================================================
Total params: 47,243,328
Trainable params: 47,243,328
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 370.03
Params size (MB): 180.22
Estimated Total Size (MB): 550.62
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet101_se_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
   InstanceNorm2d-21          [-1, 256, 64, 32]             512
             ReLU-22          [-1, 256, 64, 32]               0
       Bottleneck-23          [-1, 256, 64, 32]               0
           Conv2d-24           [-1, 64, 64, 32]          16,384
      BatchNorm2d-25           [-1, 64, 64, 32]             128
             ReLU-26           [-1, 64, 64, 32]               0
           Conv2d-27           [-1, 64, 64, 32]          36,864
      BatchNorm2d-28           [-1, 64, 64, 32]             128
             ReLU-29           [-1, 64, 64, 32]               0
           Conv2d-30          [-1, 256, 64, 32]          16,384
      BatchNorm2d-31          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-32            [-1, 256, 1, 1]               0
           Linear-33                   [-1, 16]           4,096
             ReLU-34                   [-1, 16]               0
           Linear-35                  [-1, 256]           4,096
          Sigmoid-36                  [-1, 256]               0
          SELayer-37          [-1, 256, 64, 32]               0
   InstanceNorm2d-38          [-1, 256, 64, 32]             512
             ReLU-39          [-1, 256, 64, 32]               0
       Bottleneck-40          [-1, 256, 64, 32]               0
           Conv2d-41           [-1, 64, 64, 32]          16,384
      BatchNorm2d-42           [-1, 64, 64, 32]             128
             ReLU-43           [-1, 64, 64, 32]               0
           Conv2d-44           [-1, 64, 64, 32]          36,864
      BatchNorm2d-45           [-1, 64, 64, 32]             128
             ReLU-46           [-1, 64, 64, 32]               0
           Conv2d-47          [-1, 256, 64, 32]          16,384
      BatchNorm2d-48          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-49            [-1, 256, 1, 1]               0
           Linear-50                   [-1, 16]           4,096
             ReLU-51                   [-1, 16]               0
           Linear-52                  [-1, 256]           4,096
          Sigmoid-53                  [-1, 256]               0
          SELayer-54          [-1, 256, 64, 32]               0
   InstanceNorm2d-55          [-1, 256, 64, 32]             512
             ReLU-56          [-1, 256, 64, 32]               0
       Bottleneck-57          [-1, 256, 64, 32]               0
           Conv2d-58          [-1, 128, 64, 32]          32,768
      BatchNorm2d-59          [-1, 128, 64, 32]             256
             ReLU-60          [-1, 128, 64, 32]               0
           Conv2d-61          [-1, 128, 32, 16]         147,456
      BatchNorm2d-62          [-1, 128, 32, 16]             256
             ReLU-63          [-1, 128, 32, 16]               0
           Conv2d-64          [-1, 512, 32, 16]          65,536
      BatchNorm2d-65          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-66            [-1, 512, 1, 1]               0
           Linear-67                   [-1, 32]          16,384
             ReLU-68                   [-1, 32]               0
           Linear-69                  [-1, 512]          16,384
          Sigmoid-70                  [-1, 512]               0
          SELayer-71          [-1, 512, 32, 16]               0
           Conv2d-72          [-1, 512, 32, 16]         131,072
      BatchNorm2d-73          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-74          [-1, 512, 32, 16]           1,024
             ReLU-75          [-1, 512, 32, 16]               0
       Bottleneck-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 128, 32, 16]          65,536
      BatchNorm2d-78          [-1, 128, 32, 16]             256
             ReLU-79          [-1, 128, 32, 16]               0
           Conv2d-80          [-1, 128, 32, 16]         147,456
      BatchNorm2d-81          [-1, 128, 32, 16]             256
             ReLU-82          [-1, 128, 32, 16]               0
           Conv2d-83          [-1, 512, 32, 16]          65,536
      BatchNorm2d-84          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-85            [-1, 512, 1, 1]               0
           Linear-86                   [-1, 32]          16,384
             ReLU-87                   [-1, 32]               0
           Linear-88                  [-1, 512]          16,384
          Sigmoid-89                  [-1, 512]               0
          SELayer-90          [-1, 512, 32, 16]               0
   InstanceNorm2d-91          [-1, 512, 32, 16]           1,024
             ReLU-92          [-1, 512, 32, 16]               0
       Bottleneck-93          [-1, 512, 32, 16]               0
           Conv2d-94          [-1, 128, 32, 16]          65,536
      BatchNorm2d-95          [-1, 128, 32, 16]             256
             ReLU-96          [-1, 128, 32, 16]               0
           Conv2d-97          [-1, 128, 32, 16]         147,456
      BatchNorm2d-98          [-1, 128, 32, 16]             256
             ReLU-99          [-1, 128, 32, 16]               0
          Conv2d-100          [-1, 512, 32, 16]          65,536
     BatchNorm2d-101          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-102            [-1, 512, 1, 1]               0
          Linear-103                   [-1, 32]          16,384
            ReLU-104                   [-1, 32]               0
          Linear-105                  [-1, 512]          16,384
         Sigmoid-106                  [-1, 512]               0
         SELayer-107          [-1, 512, 32, 16]               0
  InstanceNorm2d-108          [-1, 512, 32, 16]           1,024
            ReLU-109          [-1, 512, 32, 16]               0
      Bottleneck-110          [-1, 512, 32, 16]               0
          Conv2d-111          [-1, 128, 32, 16]          65,536
     BatchNorm2d-112          [-1, 128, 32, 16]             256
            ReLU-113          [-1, 128, 32, 16]               0
          Conv2d-114          [-1, 128, 32, 16]         147,456
     BatchNorm2d-115          [-1, 128, 32, 16]             256
            ReLU-116          [-1, 128, 32, 16]               0
          Conv2d-117          [-1, 512, 32, 16]          65,536
     BatchNorm2d-118          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-119            [-1, 512, 1, 1]               0
          Linear-120                   [-1, 32]          16,384
            ReLU-121                   [-1, 32]               0
          Linear-122                  [-1, 512]          16,384
         Sigmoid-123                  [-1, 512]               0
         SELayer-124          [-1, 512, 32, 16]               0
  InstanceNorm2d-125          [-1, 512, 32, 16]           1,024
            ReLU-126          [-1, 512, 32, 16]               0
      Bottleneck-127          [-1, 512, 32, 16]               0
          Conv2d-128          [-1, 256, 32, 16]         131,072
     BatchNorm2d-129          [-1, 256, 32, 16]             512
            ReLU-130          [-1, 256, 32, 16]               0
          Conv2d-131           [-1, 256, 16, 8]         589,824
     BatchNorm2d-132           [-1, 256, 16, 8]             512
            ReLU-133           [-1, 256, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-136           [-1, 1024, 1, 1]               0
          Linear-137                   [-1, 64]          65,536
            ReLU-138                   [-1, 64]               0
          Linear-139                 [-1, 1024]          65,536
         Sigmoid-140                 [-1, 1024]               0
         SELayer-141          [-1, 1024, 16, 8]               0
          Conv2d-142          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-143          [-1, 1024, 16, 8]           2,048
            ReLU-144          [-1, 1024, 16, 8]               0
      Bottleneck-145          [-1, 1024, 16, 8]               0
          Conv2d-146           [-1, 256, 16, 8]         262,144
     BatchNorm2d-147           [-1, 256, 16, 8]             512
            ReLU-148           [-1, 256, 16, 8]               0
          Conv2d-149           [-1, 256, 16, 8]         589,824
     BatchNorm2d-150           [-1, 256, 16, 8]             512
            ReLU-151           [-1, 256, 16, 8]               0
          Conv2d-152          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-153          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-154           [-1, 1024, 1, 1]               0
          Linear-155                   [-1, 64]          65,536
            ReLU-156                   [-1, 64]               0
          Linear-157                 [-1, 1024]          65,536
         Sigmoid-158                 [-1, 1024]               0
         SELayer-159          [-1, 1024, 16, 8]               0
            ReLU-160          [-1, 1024, 16, 8]               0
      Bottleneck-161          [-1, 1024, 16, 8]               0
          Conv2d-162           [-1, 256, 16, 8]         262,144
     BatchNorm2d-163           [-1, 256, 16, 8]             512
            ReLU-164           [-1, 256, 16, 8]               0
          Conv2d-165           [-1, 256, 16, 8]         589,824
     BatchNorm2d-166           [-1, 256, 16, 8]             512
            ReLU-167           [-1, 256, 16, 8]               0
          Conv2d-168          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-169          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-170           [-1, 1024, 1, 1]               0
          Linear-171                   [-1, 64]          65,536
            ReLU-172                   [-1, 64]               0
          Linear-173                 [-1, 1024]          65,536
         Sigmoid-174                 [-1, 1024]               0
         SELayer-175          [-1, 1024, 16, 8]               0
            ReLU-176          [-1, 1024, 16, 8]               0
      Bottleneck-177          [-1, 1024, 16, 8]               0
          Conv2d-178           [-1, 256, 16, 8]         262,144
     BatchNorm2d-179           [-1, 256, 16, 8]             512
            ReLU-180           [-1, 256, 16, 8]               0
          Conv2d-181           [-1, 256, 16, 8]         589,824
     BatchNorm2d-182           [-1, 256, 16, 8]             512
            ReLU-183           [-1, 256, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-186           [-1, 1024, 1, 1]               0
          Linear-187                   [-1, 64]          65,536
            ReLU-188                   [-1, 64]               0
          Linear-189                 [-1, 1024]          65,536
         Sigmoid-190                 [-1, 1024]               0
         SELayer-191          [-1, 1024, 16, 8]               0
            ReLU-192          [-1, 1024, 16, 8]               0
      Bottleneck-193          [-1, 1024, 16, 8]               0
          Conv2d-194           [-1, 256, 16, 8]         262,144
     BatchNorm2d-195           [-1, 256, 16, 8]             512
            ReLU-196           [-1, 256, 16, 8]               0
          Conv2d-197           [-1, 256, 16, 8]         589,824
     BatchNorm2d-198           [-1, 256, 16, 8]             512
            ReLU-199           [-1, 256, 16, 8]               0
          Conv2d-200          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-201          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-202           [-1, 1024, 1, 1]               0
          Linear-203                   [-1, 64]          65,536
            ReLU-204                   [-1, 64]               0
          Linear-205                 [-1, 1024]          65,536
         Sigmoid-206                 [-1, 1024]               0
         SELayer-207          [-1, 1024, 16, 8]               0
            ReLU-208          [-1, 1024, 16, 8]               0
      Bottleneck-209          [-1, 1024, 16, 8]               0
          Conv2d-210           [-1, 256, 16, 8]         262,144
     BatchNorm2d-211           [-1, 256, 16, 8]             512
            ReLU-212           [-1, 256, 16, 8]               0
          Conv2d-213           [-1, 256, 16, 8]         589,824
     BatchNorm2d-214           [-1, 256, 16, 8]             512
            ReLU-215           [-1, 256, 16, 8]               0
          Conv2d-216          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-217          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-218           [-1, 1024, 1, 1]               0
          Linear-219                   [-1, 64]          65,536
            ReLU-220                   [-1, 64]               0
          Linear-221                 [-1, 1024]          65,536
         Sigmoid-222                 [-1, 1024]               0
         SELayer-223          [-1, 1024, 16, 8]               0
            ReLU-224          [-1, 1024, 16, 8]               0
      Bottleneck-225          [-1, 1024, 16, 8]               0
          Conv2d-226           [-1, 256, 16, 8]         262,144
     BatchNorm2d-227           [-1, 256, 16, 8]             512
            ReLU-228           [-1, 256, 16, 8]               0
          Conv2d-229           [-1, 256, 16, 8]         589,824
     BatchNorm2d-230           [-1, 256, 16, 8]             512
            ReLU-231           [-1, 256, 16, 8]               0
          Conv2d-232          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-233          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-234           [-1, 1024, 1, 1]               0
          Linear-235                   [-1, 64]          65,536
            ReLU-236                   [-1, 64]               0
          Linear-237                 [-1, 1024]          65,536
         Sigmoid-238                 [-1, 1024]               0
         SELayer-239          [-1, 1024, 16, 8]               0
            ReLU-240          [-1, 1024, 16, 8]               0
      Bottleneck-241          [-1, 1024, 16, 8]               0
          Conv2d-242           [-1, 256, 16, 8]         262,144
     BatchNorm2d-243           [-1, 256, 16, 8]             512
            ReLU-244           [-1, 256, 16, 8]               0
          Conv2d-245           [-1, 256, 16, 8]         589,824
     BatchNorm2d-246           [-1, 256, 16, 8]             512
            ReLU-247           [-1, 256, 16, 8]               0
          Conv2d-248          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-249          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-250           [-1, 1024, 1, 1]               0
          Linear-251                   [-1, 64]          65,536
            ReLU-252                   [-1, 64]               0
          Linear-253                 [-1, 1024]          65,536
         Sigmoid-254                 [-1, 1024]               0
         SELayer-255          [-1, 1024, 16, 8]               0
            ReLU-256          [-1, 1024, 16, 8]               0
      Bottleneck-257          [-1, 1024, 16, 8]               0
          Conv2d-258           [-1, 256, 16, 8]         262,144
     BatchNorm2d-259           [-1, 256, 16, 8]             512
            ReLU-260           [-1, 256, 16, 8]               0
          Conv2d-261           [-1, 256, 16, 8]         589,824
     BatchNorm2d-262           [-1, 256, 16, 8]             512
            ReLU-263           [-1, 256, 16, 8]               0
          Conv2d-264          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-265          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-266           [-1, 1024, 1, 1]               0
          Linear-267                   [-1, 64]          65,536
            ReLU-268                   [-1, 64]               0
          Linear-269                 [-1, 1024]          65,536
         Sigmoid-270                 [-1, 1024]               0
         SELayer-271          [-1, 1024, 16, 8]               0
            ReLU-272          [-1, 1024, 16, 8]               0
      Bottleneck-273          [-1, 1024, 16, 8]               0
          Conv2d-274           [-1, 256, 16, 8]         262,144
     BatchNorm2d-275           [-1, 256, 16, 8]             512
            ReLU-276           [-1, 256, 16, 8]               0
          Conv2d-277           [-1, 256, 16, 8]         589,824
     BatchNorm2d-278           [-1, 256, 16, 8]             512
            ReLU-279           [-1, 256, 16, 8]               0
          Conv2d-280          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-281          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-282           [-1, 1024, 1, 1]               0
          Linear-283                   [-1, 64]          65,536
            ReLU-284                   [-1, 64]               0
          Linear-285                 [-1, 1024]          65,536
         Sigmoid-286                 [-1, 1024]               0
         SELayer-287          [-1, 1024, 16, 8]               0
            ReLU-288          [-1, 1024, 16, 8]               0
      Bottleneck-289          [-1, 1024, 16, 8]               0
          Conv2d-290           [-1, 256, 16, 8]         262,144
     BatchNorm2d-291           [-1, 256, 16, 8]             512
            ReLU-292           [-1, 256, 16, 8]               0
          Conv2d-293           [-1, 256, 16, 8]         589,824
     BatchNorm2d-294           [-1, 256, 16, 8]             512
            ReLU-295           [-1, 256, 16, 8]               0
          Conv2d-296          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-297          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-298           [-1, 1024, 1, 1]               0
          Linear-299                   [-1, 64]          65,536
            ReLU-300                   [-1, 64]               0
          Linear-301                 [-1, 1024]          65,536
         Sigmoid-302                 [-1, 1024]               0
         SELayer-303          [-1, 1024, 16, 8]               0
            ReLU-304          [-1, 1024, 16, 8]               0
      Bottleneck-305          [-1, 1024, 16, 8]               0
          Conv2d-306           [-1, 256, 16, 8]         262,144
     BatchNorm2d-307           [-1, 256, 16, 8]             512
            ReLU-308           [-1, 256, 16, 8]               0
          Conv2d-309           [-1, 256, 16, 8]         589,824
     BatchNorm2d-310           [-1, 256, 16, 8]             512
            ReLU-311           [-1, 256, 16, 8]               0
          Conv2d-312          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-313          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-314           [-1, 1024, 1, 1]               0
          Linear-315                   [-1, 64]          65,536
            ReLU-316                   [-1, 64]               0
          Linear-317                 [-1, 1024]          65,536
         Sigmoid-318                 [-1, 1024]               0
         SELayer-319          [-1, 1024, 16, 8]               0
            ReLU-320          [-1, 1024, 16, 8]               0
      Bottleneck-321          [-1, 1024, 16, 8]               0
          Conv2d-322           [-1, 256, 16, 8]         262,144
     BatchNorm2d-323           [-1, 256, 16, 8]             512
            ReLU-324           [-1, 256, 16, 8]               0
          Conv2d-325           [-1, 256, 16, 8]         589,824
     BatchNorm2d-326           [-1, 256, 16, 8]             512
            ReLU-327           [-1, 256, 16, 8]               0
          Conv2d-328          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-329          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-330           [-1, 1024, 1, 1]               0
          Linear-331                   [-1, 64]          65,536
            ReLU-332                   [-1, 64]               0
          Linear-333                 [-1, 1024]          65,536
         Sigmoid-334                 [-1, 1024]               0
         SELayer-335          [-1, 1024, 16, 8]               0
            ReLU-336          [-1, 1024, 16, 8]               0
      Bottleneck-337          [-1, 1024, 16, 8]               0
          Conv2d-338           [-1, 256, 16, 8]         262,144
     BatchNorm2d-339           [-1, 256, 16, 8]             512
            ReLU-340           [-1, 256, 16, 8]               0
          Conv2d-341           [-1, 256, 16, 8]         589,824
     BatchNorm2d-342           [-1, 256, 16, 8]             512
            ReLU-343           [-1, 256, 16, 8]               0
          Conv2d-344          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-345          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-346           [-1, 1024, 1, 1]               0
          Linear-347                   [-1, 64]          65,536
            ReLU-348                   [-1, 64]               0
          Linear-349                 [-1, 1024]          65,536
         Sigmoid-350                 [-1, 1024]               0
         SELayer-351          [-1, 1024, 16, 8]               0
            ReLU-352          [-1, 1024, 16, 8]               0
      Bottleneck-353          [-1, 1024, 16, 8]               0
          Conv2d-354           [-1, 256, 16, 8]         262,144
     BatchNorm2d-355           [-1, 256, 16, 8]             512
            ReLU-356           [-1, 256, 16, 8]               0
          Conv2d-357           [-1, 256, 16, 8]         589,824
     BatchNorm2d-358           [-1, 256, 16, 8]             512
            ReLU-359           [-1, 256, 16, 8]               0
          Conv2d-360          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-361          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-362           [-1, 1024, 1, 1]               0
          Linear-363                   [-1, 64]          65,536
            ReLU-364                   [-1, 64]               0
          Linear-365                 [-1, 1024]          65,536
         Sigmoid-366                 [-1, 1024]               0
         SELayer-367          [-1, 1024, 16, 8]               0
            ReLU-368          [-1, 1024, 16, 8]               0
      Bottleneck-369          [-1, 1024, 16, 8]               0
          Conv2d-370           [-1, 256, 16, 8]         262,144
     BatchNorm2d-371           [-1, 256, 16, 8]             512
            ReLU-372           [-1, 256, 16, 8]               0
          Conv2d-373           [-1, 256, 16, 8]         589,824
     BatchNorm2d-374           [-1, 256, 16, 8]             512
            ReLU-375           [-1, 256, 16, 8]               0
          Conv2d-376          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-377          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-378           [-1, 1024, 1, 1]               0
          Linear-379                   [-1, 64]          65,536
            ReLU-380                   [-1, 64]               0
          Linear-381                 [-1, 1024]          65,536
         Sigmoid-382                 [-1, 1024]               0
         SELayer-383          [-1, 1024, 16, 8]               0
            ReLU-384          [-1, 1024, 16, 8]               0
      Bottleneck-385          [-1, 1024, 16, 8]               0
          Conv2d-386           [-1, 256, 16, 8]         262,144
     BatchNorm2d-387           [-1, 256, 16, 8]             512
            ReLU-388           [-1, 256, 16, 8]               0
          Conv2d-389           [-1, 256, 16, 8]         589,824
     BatchNorm2d-390           [-1, 256, 16, 8]             512
            ReLU-391           [-1, 256, 16, 8]               0
          Conv2d-392          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-393          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-394           [-1, 1024, 1, 1]               0
          Linear-395                   [-1, 64]          65,536
            ReLU-396                   [-1, 64]               0
          Linear-397                 [-1, 1024]          65,536
         Sigmoid-398                 [-1, 1024]               0
         SELayer-399          [-1, 1024, 16, 8]               0
            ReLU-400          [-1, 1024, 16, 8]               0
      Bottleneck-401          [-1, 1024, 16, 8]               0
          Conv2d-402           [-1, 256, 16, 8]         262,144
     BatchNorm2d-403           [-1, 256, 16, 8]             512
            ReLU-404           [-1, 256, 16, 8]               0
          Conv2d-405           [-1, 256, 16, 8]         589,824
     BatchNorm2d-406           [-1, 256, 16, 8]             512
            ReLU-407           [-1, 256, 16, 8]               0
          Conv2d-408          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-409          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-410           [-1, 1024, 1, 1]               0
          Linear-411                   [-1, 64]          65,536
            ReLU-412                   [-1, 64]               0
          Linear-413                 [-1, 1024]          65,536
         Sigmoid-414                 [-1, 1024]               0
         SELayer-415          [-1, 1024, 16, 8]               0
            ReLU-416          [-1, 1024, 16, 8]               0
      Bottleneck-417          [-1, 1024, 16, 8]               0
          Conv2d-418           [-1, 256, 16, 8]         262,144
     BatchNorm2d-419           [-1, 256, 16, 8]             512
            ReLU-420           [-1, 256, 16, 8]               0
          Conv2d-421           [-1, 256, 16, 8]         589,824
     BatchNorm2d-422           [-1, 256, 16, 8]             512
            ReLU-423           [-1, 256, 16, 8]               0
          Conv2d-424          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-425          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-426           [-1, 1024, 1, 1]               0
          Linear-427                   [-1, 64]          65,536
            ReLU-428                   [-1, 64]               0
          Linear-429                 [-1, 1024]          65,536
         Sigmoid-430                 [-1, 1024]               0
         SELayer-431          [-1, 1024, 16, 8]               0
            ReLU-432          [-1, 1024, 16, 8]               0
      Bottleneck-433          [-1, 1024, 16, 8]               0
          Conv2d-434           [-1, 256, 16, 8]         262,144
     BatchNorm2d-435           [-1, 256, 16, 8]             512
            ReLU-436           [-1, 256, 16, 8]               0
          Conv2d-437           [-1, 256, 16, 8]         589,824
     BatchNorm2d-438           [-1, 256, 16, 8]             512
            ReLU-439           [-1, 256, 16, 8]               0
          Conv2d-440          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-441          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-442           [-1, 1024, 1, 1]               0
          Linear-443                   [-1, 64]          65,536
            ReLU-444                   [-1, 64]               0
          Linear-445                 [-1, 1024]          65,536
         Sigmoid-446                 [-1, 1024]               0
         SELayer-447          [-1, 1024, 16, 8]               0
            ReLU-448          [-1, 1024, 16, 8]               0
      Bottleneck-449          [-1, 1024, 16, 8]               0
          Conv2d-450           [-1, 256, 16, 8]         262,144
     BatchNorm2d-451           [-1, 256, 16, 8]             512
            ReLU-452           [-1, 256, 16, 8]               0
          Conv2d-453           [-1, 256, 16, 8]         589,824
     BatchNorm2d-454           [-1, 256, 16, 8]             512
            ReLU-455           [-1, 256, 16, 8]               0
          Conv2d-456          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-457          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-458           [-1, 1024, 1, 1]               0
          Linear-459                   [-1, 64]          65,536
            ReLU-460                   [-1, 64]               0
          Linear-461                 [-1, 1024]          65,536
         Sigmoid-462                 [-1, 1024]               0
         SELayer-463          [-1, 1024, 16, 8]               0
            ReLU-464          [-1, 1024, 16, 8]               0
      Bottleneck-465          [-1, 1024, 16, 8]               0
          Conv2d-466           [-1, 256, 16, 8]         262,144
     BatchNorm2d-467           [-1, 256, 16, 8]             512
            ReLU-468           [-1, 256, 16, 8]               0
          Conv2d-469           [-1, 256, 16, 8]         589,824
     BatchNorm2d-470           [-1, 256, 16, 8]             512
            ReLU-471           [-1, 256, 16, 8]               0
          Conv2d-472          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-473          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-474           [-1, 1024, 1, 1]               0
          Linear-475                   [-1, 64]          65,536
            ReLU-476                   [-1, 64]               0
          Linear-477                 [-1, 1024]          65,536
         Sigmoid-478                 [-1, 1024]               0
         SELayer-479          [-1, 1024, 16, 8]               0
            ReLU-480          [-1, 1024, 16, 8]               0
      Bottleneck-481          [-1, 1024, 16, 8]               0
          Conv2d-482           [-1, 256, 16, 8]         262,144
     BatchNorm2d-483           [-1, 256, 16, 8]             512
            ReLU-484           [-1, 256, 16, 8]               0
          Conv2d-485           [-1, 256, 16, 8]         589,824
     BatchNorm2d-486           [-1, 256, 16, 8]             512
            ReLU-487           [-1, 256, 16, 8]               0
          Conv2d-488          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-489          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-490           [-1, 1024, 1, 1]               0
          Linear-491                   [-1, 64]          65,536
            ReLU-492                   [-1, 64]               0
          Linear-493                 [-1, 1024]          65,536
         Sigmoid-494                 [-1, 1024]               0
         SELayer-495          [-1, 1024, 16, 8]               0
            ReLU-496          [-1, 1024, 16, 8]               0
      Bottleneck-497          [-1, 1024, 16, 8]               0
          Conv2d-498           [-1, 512, 16, 8]         524,288
     BatchNorm2d-499           [-1, 512, 16, 8]           1,024
            ReLU-500           [-1, 512, 16, 8]               0
          Conv2d-501           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-502           [-1, 512, 16, 8]           1,024
            ReLU-503           [-1, 512, 16, 8]               0
          Conv2d-504          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-505          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-506           [-1, 2048, 1, 1]               0
          Linear-507                  [-1, 128]         262,144
            ReLU-508                  [-1, 128]               0
          Linear-509                 [-1, 2048]         262,144
         Sigmoid-510                 [-1, 2048]               0
         SELayer-511          [-1, 2048, 16, 8]               0
          Conv2d-512          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-513          [-1, 2048, 16, 8]           4,096
            ReLU-514          [-1, 2048, 16, 8]               0
      Bottleneck-515          [-1, 2048, 16, 8]               0
          Conv2d-516           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-517           [-1, 512, 16, 8]           1,024
            ReLU-518           [-1, 512, 16, 8]               0
          Conv2d-519           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-520           [-1, 512, 16, 8]           1,024
            ReLU-521           [-1, 512, 16, 8]               0
          Conv2d-522          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-523          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-524           [-1, 2048, 1, 1]               0
          Linear-525                  [-1, 128]         262,144
            ReLU-526                  [-1, 128]               0
          Linear-527                 [-1, 2048]         262,144
         Sigmoid-528                 [-1, 2048]               0
         SELayer-529          [-1, 2048, 16, 8]               0
            ReLU-530          [-1, 2048, 16, 8]               0
      Bottleneck-531          [-1, 2048, 16, 8]               0
          Conv2d-532           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-533           [-1, 512, 16, 8]           1,024
            ReLU-534           [-1, 512, 16, 8]               0
          Conv2d-535           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-536           [-1, 512, 16, 8]           1,024
            ReLU-537           [-1, 512, 16, 8]               0
          Conv2d-538          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-539          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-540           [-1, 2048, 1, 1]               0
          Linear-541                  [-1, 128]         262,144
            ReLU-542                  [-1, 128]               0
          Linear-543                 [-1, 2048]         262,144
         Sigmoid-544                 [-1, 2048]               0
         SELayer-545          [-1, 2048, 16, 8]               0
            ReLU-546          [-1, 2048, 16, 8]               0
      Bottleneck-547          [-1, 2048, 16, 8]               0
================================================================
Total params: 47,248,960
Trainable params: 47,248,960
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 377.03
Params size (MB): 180.24
Estimated Total Size (MB): 557.64
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet101_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
    InstanceNorm2d-6           [-1, 32, 64, 32]              64
       BatchNorm2d-7           [-1, 32, 64, 32]              64
               IBN-8           [-1, 64, 64, 32]               0
              ReLU-9           [-1, 64, 64, 32]               0
           Conv2d-10           [-1, 64, 64, 32]          36,864
      BatchNorm2d-11           [-1, 64, 64, 32]             128
             ReLU-12           [-1, 64, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
           Conv2d-15          [-1, 256, 64, 32]          16,384
      BatchNorm2d-16          [-1, 256, 64, 32]             512
             ReLU-17          [-1, 256, 64, 32]               0
       Bottleneck-18          [-1, 256, 64, 32]               0
           Conv2d-19           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-20           [-1, 32, 64, 32]              64
      BatchNorm2d-21           [-1, 32, 64, 32]              64
              IBN-22           [-1, 64, 64, 32]               0
             ReLU-23           [-1, 64, 64, 32]               0
           Conv2d-24           [-1, 64, 64, 32]          36,864
      BatchNorm2d-25           [-1, 64, 64, 32]             128
             ReLU-26           [-1, 64, 64, 32]               0
           Conv2d-27          [-1, 256, 64, 32]          16,384
      BatchNorm2d-28          [-1, 256, 64, 32]             512
             ReLU-29          [-1, 256, 64, 32]               0
       Bottleneck-30          [-1, 256, 64, 32]               0
           Conv2d-31           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-32           [-1, 32, 64, 32]              64
      BatchNorm2d-33           [-1, 32, 64, 32]              64
              IBN-34           [-1, 64, 64, 32]               0
             ReLU-35           [-1, 64, 64, 32]               0
           Conv2d-36           [-1, 64, 64, 32]          36,864
      BatchNorm2d-37           [-1, 64, 64, 32]             128
             ReLU-38           [-1, 64, 64, 32]               0
           Conv2d-39          [-1, 256, 64, 32]          16,384
      BatchNorm2d-40          [-1, 256, 64, 32]             512
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-44           [-1, 64, 64, 32]             128
      BatchNorm2d-45           [-1, 64, 64, 32]             128
              IBN-46          [-1, 128, 64, 32]               0
             ReLU-47          [-1, 128, 64, 32]               0
           Conv2d-48          [-1, 128, 32, 16]         147,456
      BatchNorm2d-49          [-1, 128, 32, 16]             256
             ReLU-50          [-1, 128, 32, 16]               0
           Conv2d-51          [-1, 512, 32, 16]          65,536
      BatchNorm2d-52          [-1, 512, 32, 16]           1,024
           Conv2d-53          [-1, 512, 32, 16]         131,072
      BatchNorm2d-54          [-1, 512, 32, 16]           1,024
             ReLU-55          [-1, 512, 32, 16]               0
       Bottleneck-56          [-1, 512, 32, 16]               0
           Conv2d-57          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-58           [-1, 64, 32, 16]             128
      BatchNorm2d-59           [-1, 64, 32, 16]             128
              IBN-60          [-1, 128, 32, 16]               0
             ReLU-61          [-1, 128, 32, 16]               0
           Conv2d-62          [-1, 128, 32, 16]         147,456
      BatchNorm2d-63          [-1, 128, 32, 16]             256
             ReLU-64          [-1, 128, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]          65,536
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-70           [-1, 64, 32, 16]             128
      BatchNorm2d-71           [-1, 64, 32, 16]             128
              IBN-72          [-1, 128, 32, 16]               0
             ReLU-73          [-1, 128, 32, 16]               0
           Conv2d-74          [-1, 128, 32, 16]         147,456
      BatchNorm2d-75          [-1, 128, 32, 16]             256
             ReLU-76          [-1, 128, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]          65,536
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-82           [-1, 64, 32, 16]             128
      BatchNorm2d-83           [-1, 64, 32, 16]             128
              IBN-84          [-1, 128, 32, 16]               0
             ReLU-85          [-1, 128, 32, 16]               0
           Conv2d-86          [-1, 128, 32, 16]         147,456
      BatchNorm2d-87          [-1, 128, 32, 16]             256
             ReLU-88          [-1, 128, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]          65,536
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
             ReLU-91          [-1, 512, 32, 16]               0
       Bottleneck-92          [-1, 512, 32, 16]               0
           Conv2d-93          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-94          [-1, 128, 32, 16]             256
      BatchNorm2d-95          [-1, 128, 32, 16]             256
              IBN-96          [-1, 256, 32, 16]               0
             ReLU-97          [-1, 256, 32, 16]               0
           Conv2d-98           [-1, 256, 16, 8]         589,824
      BatchNorm2d-99           [-1, 256, 16, 8]             512
            ReLU-100           [-1, 256, 16, 8]               0
          Conv2d-101          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-102          [-1, 1024, 16, 8]           2,048
          Conv2d-103          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-104          [-1, 1024, 16, 8]           2,048
            ReLU-105          [-1, 1024, 16, 8]               0
      Bottleneck-106          [-1, 1024, 16, 8]               0
          Conv2d-107           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-108           [-1, 128, 16, 8]             256
     BatchNorm2d-109           [-1, 128, 16, 8]             256
             IBN-110           [-1, 256, 16, 8]               0
            ReLU-111           [-1, 256, 16, 8]               0
          Conv2d-112           [-1, 256, 16, 8]         589,824
     BatchNorm2d-113           [-1, 256, 16, 8]             512
            ReLU-114           [-1, 256, 16, 8]               0
          Conv2d-115          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-116          [-1, 1024, 16, 8]           2,048
            ReLU-117          [-1, 1024, 16, 8]               0
      Bottleneck-118          [-1, 1024, 16, 8]               0
          Conv2d-119           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-120           [-1, 128, 16, 8]             256
     BatchNorm2d-121           [-1, 128, 16, 8]             256
             IBN-122           [-1, 256, 16, 8]               0
            ReLU-123           [-1, 256, 16, 8]               0
          Conv2d-124           [-1, 256, 16, 8]         589,824
     BatchNorm2d-125           [-1, 256, 16, 8]             512
            ReLU-126           [-1, 256, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-132           [-1, 128, 16, 8]             256
     BatchNorm2d-133           [-1, 128, 16, 8]             256
             IBN-134           [-1, 256, 16, 8]               0
            ReLU-135           [-1, 256, 16, 8]               0
          Conv2d-136           [-1, 256, 16, 8]         589,824
     BatchNorm2d-137           [-1, 256, 16, 8]             512
            ReLU-138           [-1, 256, 16, 8]               0
          Conv2d-139          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-140          [-1, 1024, 16, 8]           2,048
            ReLU-141          [-1, 1024, 16, 8]               0
      Bottleneck-142          [-1, 1024, 16, 8]               0
          Conv2d-143           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-144           [-1, 128, 16, 8]             256
     BatchNorm2d-145           [-1, 128, 16, 8]             256
             IBN-146           [-1, 256, 16, 8]               0
            ReLU-147           [-1, 256, 16, 8]               0
          Conv2d-148           [-1, 256, 16, 8]         589,824
     BatchNorm2d-149           [-1, 256, 16, 8]             512
            ReLU-150           [-1, 256, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-156           [-1, 128, 16, 8]             256
     BatchNorm2d-157           [-1, 128, 16, 8]             256
             IBN-158           [-1, 256, 16, 8]               0
            ReLU-159           [-1, 256, 16, 8]               0
          Conv2d-160           [-1, 256, 16, 8]         589,824
     BatchNorm2d-161           [-1, 256, 16, 8]             512
            ReLU-162           [-1, 256, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
      Bottleneck-166          [-1, 1024, 16, 8]               0
          Conv2d-167           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-168           [-1, 128, 16, 8]             256
     BatchNorm2d-169           [-1, 128, 16, 8]             256
             IBN-170           [-1, 256, 16, 8]               0
            ReLU-171           [-1, 256, 16, 8]               0
          Conv2d-172           [-1, 256, 16, 8]         589,824
     BatchNorm2d-173           [-1, 256, 16, 8]             512
            ReLU-174           [-1, 256, 16, 8]               0
          Conv2d-175          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-176          [-1, 1024, 16, 8]           2,048
            ReLU-177          [-1, 1024, 16, 8]               0
      Bottleneck-178          [-1, 1024, 16, 8]               0
          Conv2d-179           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-180           [-1, 128, 16, 8]             256
     BatchNorm2d-181           [-1, 128, 16, 8]             256
             IBN-182           [-1, 256, 16, 8]               0
            ReLU-183           [-1, 256, 16, 8]               0
          Conv2d-184           [-1, 256, 16, 8]         589,824
     BatchNorm2d-185           [-1, 256, 16, 8]             512
            ReLU-186           [-1, 256, 16, 8]               0
          Conv2d-187          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-188          [-1, 1024, 16, 8]           2,048
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-192           [-1, 128, 16, 8]             256
     BatchNorm2d-193           [-1, 128, 16, 8]             256
             IBN-194           [-1, 256, 16, 8]               0
            ReLU-195           [-1, 256, 16, 8]               0
          Conv2d-196           [-1, 256, 16, 8]         589,824
     BatchNorm2d-197           [-1, 256, 16, 8]             512
            ReLU-198           [-1, 256, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-204           [-1, 128, 16, 8]             256
     BatchNorm2d-205           [-1, 128, 16, 8]             256
             IBN-206           [-1, 256, 16, 8]               0
            ReLU-207           [-1, 256, 16, 8]               0
          Conv2d-208           [-1, 256, 16, 8]         589,824
     BatchNorm2d-209           [-1, 256, 16, 8]             512
            ReLU-210           [-1, 256, 16, 8]               0
          Conv2d-211          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-212          [-1, 1024, 16, 8]           2,048
            ReLU-213          [-1, 1024, 16, 8]               0
      Bottleneck-214          [-1, 1024, 16, 8]               0
          Conv2d-215           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-216           [-1, 128, 16, 8]             256
     BatchNorm2d-217           [-1, 128, 16, 8]             256
             IBN-218           [-1, 256, 16, 8]               0
            ReLU-219           [-1, 256, 16, 8]               0
          Conv2d-220           [-1, 256, 16, 8]         589,824
     BatchNorm2d-221           [-1, 256, 16, 8]             512
            ReLU-222           [-1, 256, 16, 8]               0
          Conv2d-223          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-224          [-1, 1024, 16, 8]           2,048
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-228           [-1, 128, 16, 8]             256
     BatchNorm2d-229           [-1, 128, 16, 8]             256
             IBN-230           [-1, 256, 16, 8]               0
            ReLU-231           [-1, 256, 16, 8]               0
          Conv2d-232           [-1, 256, 16, 8]         589,824
     BatchNorm2d-233           [-1, 256, 16, 8]             512
            ReLU-234           [-1, 256, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
            ReLU-237          [-1, 1024, 16, 8]               0
      Bottleneck-238          [-1, 1024, 16, 8]               0
          Conv2d-239           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-240           [-1, 128, 16, 8]             256
     BatchNorm2d-241           [-1, 128, 16, 8]             256
             IBN-242           [-1, 256, 16, 8]               0
            ReLU-243           [-1, 256, 16, 8]               0
          Conv2d-244           [-1, 256, 16, 8]         589,824
     BatchNorm2d-245           [-1, 256, 16, 8]             512
            ReLU-246           [-1, 256, 16, 8]               0
          Conv2d-247          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-248          [-1, 1024, 16, 8]           2,048
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-252           [-1, 128, 16, 8]             256
     BatchNorm2d-253           [-1, 128, 16, 8]             256
             IBN-254           [-1, 256, 16, 8]               0
            ReLU-255           [-1, 256, 16, 8]               0
          Conv2d-256           [-1, 256, 16, 8]         589,824
     BatchNorm2d-257           [-1, 256, 16, 8]             512
            ReLU-258           [-1, 256, 16, 8]               0
          Conv2d-259          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-260          [-1, 1024, 16, 8]           2,048
            ReLU-261          [-1, 1024, 16, 8]               0
      Bottleneck-262          [-1, 1024, 16, 8]               0
          Conv2d-263           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-264           [-1, 128, 16, 8]             256
     BatchNorm2d-265           [-1, 128, 16, 8]             256
             IBN-266           [-1, 256, 16, 8]               0
            ReLU-267           [-1, 256, 16, 8]               0
          Conv2d-268           [-1, 256, 16, 8]         589,824
     BatchNorm2d-269           [-1, 256, 16, 8]             512
            ReLU-270           [-1, 256, 16, 8]               0
          Conv2d-271          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-272          [-1, 1024, 16, 8]           2,048
            ReLU-273          [-1, 1024, 16, 8]               0
      Bottleneck-274          [-1, 1024, 16, 8]               0
          Conv2d-275           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-276           [-1, 128, 16, 8]             256
     BatchNorm2d-277           [-1, 128, 16, 8]             256
             IBN-278           [-1, 256, 16, 8]               0
            ReLU-279           [-1, 256, 16, 8]               0
          Conv2d-280           [-1, 256, 16, 8]         589,824
     BatchNorm2d-281           [-1, 256, 16, 8]             512
            ReLU-282           [-1, 256, 16, 8]               0
          Conv2d-283          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-284          [-1, 1024, 16, 8]           2,048
            ReLU-285          [-1, 1024, 16, 8]               0
      Bottleneck-286          [-1, 1024, 16, 8]               0
          Conv2d-287           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-288           [-1, 128, 16, 8]             256
     BatchNorm2d-289           [-1, 128, 16, 8]             256
             IBN-290           [-1, 256, 16, 8]               0
            ReLU-291           [-1, 256, 16, 8]               0
          Conv2d-292           [-1, 256, 16, 8]         589,824
     BatchNorm2d-293           [-1, 256, 16, 8]             512
            ReLU-294           [-1, 256, 16, 8]               0
          Conv2d-295          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-296          [-1, 1024, 16, 8]           2,048
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-300           [-1, 128, 16, 8]             256
     BatchNorm2d-301           [-1, 128, 16, 8]             256
             IBN-302           [-1, 256, 16, 8]               0
            ReLU-303           [-1, 256, 16, 8]               0
          Conv2d-304           [-1, 256, 16, 8]         589,824
     BatchNorm2d-305           [-1, 256, 16, 8]             512
            ReLU-306           [-1, 256, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
            ReLU-309          [-1, 1024, 16, 8]               0
      Bottleneck-310          [-1, 1024, 16, 8]               0
          Conv2d-311           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-312           [-1, 128, 16, 8]             256
     BatchNorm2d-313           [-1, 128, 16, 8]             256
             IBN-314           [-1, 256, 16, 8]               0
            ReLU-315           [-1, 256, 16, 8]               0
          Conv2d-316           [-1, 256, 16, 8]         589,824
     BatchNorm2d-317           [-1, 256, 16, 8]             512
            ReLU-318           [-1, 256, 16, 8]               0
          Conv2d-319          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-320          [-1, 1024, 16, 8]           2,048
            ReLU-321          [-1, 1024, 16, 8]               0
      Bottleneck-322          [-1, 1024, 16, 8]               0
          Conv2d-323           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-324           [-1, 128, 16, 8]             256
     BatchNorm2d-325           [-1, 128, 16, 8]             256
             IBN-326           [-1, 256, 16, 8]               0
            ReLU-327           [-1, 256, 16, 8]               0
          Conv2d-328           [-1, 256, 16, 8]         589,824
     BatchNorm2d-329           [-1, 256, 16, 8]             512
            ReLU-330           [-1, 256, 16, 8]               0
          Conv2d-331          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-332          [-1, 1024, 16, 8]           2,048
            ReLU-333          [-1, 1024, 16, 8]               0
      Bottleneck-334          [-1, 1024, 16, 8]               0
          Conv2d-335           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-336           [-1, 128, 16, 8]             256
     BatchNorm2d-337           [-1, 128, 16, 8]             256
             IBN-338           [-1, 256, 16, 8]               0
            ReLU-339           [-1, 256, 16, 8]               0
          Conv2d-340           [-1, 256, 16, 8]         589,824
     BatchNorm2d-341           [-1, 256, 16, 8]             512
            ReLU-342           [-1, 256, 16, 8]               0
          Conv2d-343          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-344          [-1, 1024, 16, 8]           2,048
            ReLU-345          [-1, 1024, 16, 8]               0
      Bottleneck-346          [-1, 1024, 16, 8]               0
          Conv2d-347           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-348           [-1, 128, 16, 8]             256
     BatchNorm2d-349           [-1, 128, 16, 8]             256
             IBN-350           [-1, 256, 16, 8]               0
            ReLU-351           [-1, 256, 16, 8]               0
          Conv2d-352           [-1, 256, 16, 8]         589,824
     BatchNorm2d-353           [-1, 256, 16, 8]             512
            ReLU-354           [-1, 256, 16, 8]               0
          Conv2d-355          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-356          [-1, 1024, 16, 8]           2,048
            ReLU-357          [-1, 1024, 16, 8]               0
      Bottleneck-358          [-1, 1024, 16, 8]               0
          Conv2d-359           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-360           [-1, 128, 16, 8]             256
     BatchNorm2d-361           [-1, 128, 16, 8]             256
             IBN-362           [-1, 256, 16, 8]               0
            ReLU-363           [-1, 256, 16, 8]               0
          Conv2d-364           [-1, 256, 16, 8]         589,824
     BatchNorm2d-365           [-1, 256, 16, 8]             512
            ReLU-366           [-1, 256, 16, 8]               0
          Conv2d-367          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-368          [-1, 1024, 16, 8]           2,048
            ReLU-369          [-1, 1024, 16, 8]               0
      Bottleneck-370          [-1, 1024, 16, 8]               0
          Conv2d-371           [-1, 512, 16, 8]         524,288
     BatchNorm2d-372           [-1, 512, 16, 8]           1,024
            ReLU-373           [-1, 512, 16, 8]               0
          Conv2d-374           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-375           [-1, 512, 16, 8]           1,024
            ReLU-376           [-1, 512, 16, 8]               0
          Conv2d-377          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-378          [-1, 2048, 16, 8]           4,096
          Conv2d-379          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-380          [-1, 2048, 16, 8]           4,096
            ReLU-381          [-1, 2048, 16, 8]               0
      Bottleneck-382          [-1, 2048, 16, 8]               0
          Conv2d-383           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-384           [-1, 512, 16, 8]           1,024
            ReLU-385           [-1, 512, 16, 8]               0
          Conv2d-386           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-387           [-1, 512, 16, 8]           1,024
            ReLU-388           [-1, 512, 16, 8]               0
          Conv2d-389          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-390          [-1, 2048, 16, 8]           4,096
            ReLU-391          [-1, 2048, 16, 8]               0
      Bottleneck-392          [-1, 2048, 16, 8]               0
          Conv2d-393           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-394           [-1, 512, 16, 8]           1,024
            ReLU-395           [-1, 512, 16, 8]               0
          Conv2d-396           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-397           [-1, 512, 16, 8]           1,024
            ReLU-398           [-1, 512, 16, 8]               0
          Conv2d-399          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-400          [-1, 2048, 16, 8]           4,096
            ReLU-401          [-1, 2048, 16, 8]               0
      Bottleneck-402          [-1, 2048, 16, 8]               0
================================================================
Total params: 42,500,160
Trainable params: 42,500,160
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 320.25
Params size (MB): 162.13
Estimated Total Size (MB): 482.75
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet101_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
   InstanceNorm2d-15          [-1, 256, 64, 32]             512
             ReLU-16          [-1, 256, 64, 32]               0
       Bottleneck-17          [-1, 256, 64, 32]               0
           Conv2d-18           [-1, 64, 64, 32]          16,384
      BatchNorm2d-19           [-1, 64, 64, 32]             128
             ReLU-20           [-1, 64, 64, 32]               0
           Conv2d-21           [-1, 64, 64, 32]          36,864
      BatchNorm2d-22           [-1, 64, 64, 32]             128
             ReLU-23           [-1, 64, 64, 32]               0
           Conv2d-24          [-1, 256, 64, 32]          16,384
      BatchNorm2d-25          [-1, 256, 64, 32]             512
   InstanceNorm2d-26          [-1, 256, 64, 32]             512
             ReLU-27          [-1, 256, 64, 32]               0
       Bottleneck-28          [-1, 256, 64, 32]               0
           Conv2d-29           [-1, 64, 64, 32]          16,384
      BatchNorm2d-30           [-1, 64, 64, 32]             128
             ReLU-31           [-1, 64, 64, 32]               0
           Conv2d-32           [-1, 64, 64, 32]          36,864
      BatchNorm2d-33           [-1, 64, 64, 32]             128
             ReLU-34           [-1, 64, 64, 32]               0
           Conv2d-35          [-1, 256, 64, 32]          16,384
      BatchNorm2d-36          [-1, 256, 64, 32]             512
   InstanceNorm2d-37          [-1, 256, 64, 32]             512
             ReLU-38          [-1, 256, 64, 32]               0
       Bottleneck-39          [-1, 256, 64, 32]               0
           Conv2d-40          [-1, 128, 64, 32]          32,768
      BatchNorm2d-41          [-1, 128, 64, 32]             256
             ReLU-42          [-1, 128, 64, 32]               0
           Conv2d-43          [-1, 128, 32, 16]         147,456
      BatchNorm2d-44          [-1, 128, 32, 16]             256
             ReLU-45          [-1, 128, 32, 16]               0
           Conv2d-46          [-1, 512, 32, 16]          65,536
      BatchNorm2d-47          [-1, 512, 32, 16]           1,024
           Conv2d-48          [-1, 512, 32, 16]         131,072
      BatchNorm2d-49          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-50          [-1, 512, 32, 16]           1,024
             ReLU-51          [-1, 512, 32, 16]               0
       Bottleneck-52          [-1, 512, 32, 16]               0
           Conv2d-53          [-1, 128, 32, 16]          65,536
      BatchNorm2d-54          [-1, 128, 32, 16]             256
             ReLU-55          [-1, 128, 32, 16]               0
           Conv2d-56          [-1, 128, 32, 16]         147,456
      BatchNorm2d-57          [-1, 128, 32, 16]             256
             ReLU-58          [-1, 128, 32, 16]               0
           Conv2d-59          [-1, 512, 32, 16]          65,536
      BatchNorm2d-60          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-61          [-1, 512, 32, 16]           1,024
             ReLU-62          [-1, 512, 32, 16]               0
       Bottleneck-63          [-1, 512, 32, 16]               0
           Conv2d-64          [-1, 128, 32, 16]          65,536
      BatchNorm2d-65          [-1, 128, 32, 16]             256
             ReLU-66          [-1, 128, 32, 16]               0
           Conv2d-67          [-1, 128, 32, 16]         147,456
      BatchNorm2d-68          [-1, 128, 32, 16]             256
             ReLU-69          [-1, 128, 32, 16]               0
           Conv2d-70          [-1, 512, 32, 16]          65,536
      BatchNorm2d-71          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-72          [-1, 512, 32, 16]           1,024
             ReLU-73          [-1, 512, 32, 16]               0
       Bottleneck-74          [-1, 512, 32, 16]               0
           Conv2d-75          [-1, 128, 32, 16]          65,536
      BatchNorm2d-76          [-1, 128, 32, 16]             256
             ReLU-77          [-1, 128, 32, 16]               0
           Conv2d-78          [-1, 128, 32, 16]         147,456
      BatchNorm2d-79          [-1, 128, 32, 16]             256
             ReLU-80          [-1, 128, 32, 16]               0
           Conv2d-81          [-1, 512, 32, 16]          65,536
      BatchNorm2d-82          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-83          [-1, 512, 32, 16]           1,024
             ReLU-84          [-1, 512, 32, 16]               0
       Bottleneck-85          [-1, 512, 32, 16]               0
           Conv2d-86          [-1, 256, 32, 16]         131,072
      BatchNorm2d-87          [-1, 256, 32, 16]             512
             ReLU-88          [-1, 256, 32, 16]               0
           Conv2d-89           [-1, 256, 16, 8]         589,824
      BatchNorm2d-90           [-1, 256, 16, 8]             512
             ReLU-91           [-1, 256, 16, 8]               0
           Conv2d-92          [-1, 1024, 16, 8]         262,144
      BatchNorm2d-93          [-1, 1024, 16, 8]           2,048
           Conv2d-94          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-95          [-1, 1024, 16, 8]           2,048
             ReLU-96          [-1, 1024, 16, 8]               0
       Bottleneck-97          [-1, 1024, 16, 8]               0
           Conv2d-98           [-1, 256, 16, 8]         262,144
      BatchNorm2d-99           [-1, 256, 16, 8]             512
            ReLU-100           [-1, 256, 16, 8]               0
          Conv2d-101           [-1, 256, 16, 8]         589,824
     BatchNorm2d-102           [-1, 256, 16, 8]             512
            ReLU-103           [-1, 256, 16, 8]               0
          Conv2d-104          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-105          [-1, 1024, 16, 8]           2,048
            ReLU-106          [-1, 1024, 16, 8]               0
      Bottleneck-107          [-1, 1024, 16, 8]               0
          Conv2d-108           [-1, 256, 16, 8]         262,144
     BatchNorm2d-109           [-1, 256, 16, 8]             512
            ReLU-110           [-1, 256, 16, 8]               0
          Conv2d-111           [-1, 256, 16, 8]         589,824
     BatchNorm2d-112           [-1, 256, 16, 8]             512
            ReLU-113           [-1, 256, 16, 8]               0
          Conv2d-114          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-115          [-1, 1024, 16, 8]           2,048
            ReLU-116          [-1, 1024, 16, 8]               0
      Bottleneck-117          [-1, 1024, 16, 8]               0
          Conv2d-118           [-1, 256, 16, 8]         262,144
     BatchNorm2d-119           [-1, 256, 16, 8]             512
            ReLU-120           [-1, 256, 16, 8]               0
          Conv2d-121           [-1, 256, 16, 8]         589,824
     BatchNorm2d-122           [-1, 256, 16, 8]             512
            ReLU-123           [-1, 256, 16, 8]               0
          Conv2d-124          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-125          [-1, 1024, 16, 8]           2,048
            ReLU-126          [-1, 1024, 16, 8]               0
      Bottleneck-127          [-1, 1024, 16, 8]               0
          Conv2d-128           [-1, 256, 16, 8]         262,144
     BatchNorm2d-129           [-1, 256, 16, 8]             512
            ReLU-130           [-1, 256, 16, 8]               0
          Conv2d-131           [-1, 256, 16, 8]         589,824
     BatchNorm2d-132           [-1, 256, 16, 8]             512
            ReLU-133           [-1, 256, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
            ReLU-136          [-1, 1024, 16, 8]               0
      Bottleneck-137          [-1, 1024, 16, 8]               0
          Conv2d-138           [-1, 256, 16, 8]         262,144
     BatchNorm2d-139           [-1, 256, 16, 8]             512
            ReLU-140           [-1, 256, 16, 8]               0
          Conv2d-141           [-1, 256, 16, 8]         589,824
     BatchNorm2d-142           [-1, 256, 16, 8]             512
            ReLU-143           [-1, 256, 16, 8]               0
          Conv2d-144          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-145          [-1, 1024, 16, 8]           2,048
            ReLU-146          [-1, 1024, 16, 8]               0
      Bottleneck-147          [-1, 1024, 16, 8]               0
          Conv2d-148           [-1, 256, 16, 8]         262,144
     BatchNorm2d-149           [-1, 256, 16, 8]             512
            ReLU-150           [-1, 256, 16, 8]               0
          Conv2d-151           [-1, 256, 16, 8]         589,824
     BatchNorm2d-152           [-1, 256, 16, 8]             512
            ReLU-153           [-1, 256, 16, 8]               0
          Conv2d-154          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-155          [-1, 1024, 16, 8]           2,048
            ReLU-156          [-1, 1024, 16, 8]               0
      Bottleneck-157          [-1, 1024, 16, 8]               0
          Conv2d-158           [-1, 256, 16, 8]         262,144
     BatchNorm2d-159           [-1, 256, 16, 8]             512
            ReLU-160           [-1, 256, 16, 8]               0
          Conv2d-161           [-1, 256, 16, 8]         589,824
     BatchNorm2d-162           [-1, 256, 16, 8]             512
            ReLU-163           [-1, 256, 16, 8]               0
          Conv2d-164          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-165          [-1, 1024, 16, 8]           2,048
            ReLU-166          [-1, 1024, 16, 8]               0
      Bottleneck-167          [-1, 1024, 16, 8]               0
          Conv2d-168           [-1, 256, 16, 8]         262,144
     BatchNorm2d-169           [-1, 256, 16, 8]             512
            ReLU-170           [-1, 256, 16, 8]               0
          Conv2d-171           [-1, 256, 16, 8]         589,824
     BatchNorm2d-172           [-1, 256, 16, 8]             512
            ReLU-173           [-1, 256, 16, 8]               0
          Conv2d-174          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-175          [-1, 1024, 16, 8]           2,048
            ReLU-176          [-1, 1024, 16, 8]               0
      Bottleneck-177          [-1, 1024, 16, 8]               0
          Conv2d-178           [-1, 256, 16, 8]         262,144
     BatchNorm2d-179           [-1, 256, 16, 8]             512
            ReLU-180           [-1, 256, 16, 8]               0
          Conv2d-181           [-1, 256, 16, 8]         589,824
     BatchNorm2d-182           [-1, 256, 16, 8]             512
            ReLU-183           [-1, 256, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
            ReLU-186          [-1, 1024, 16, 8]               0
      Bottleneck-187          [-1, 1024, 16, 8]               0
          Conv2d-188           [-1, 256, 16, 8]         262,144
     BatchNorm2d-189           [-1, 256, 16, 8]             512
            ReLU-190           [-1, 256, 16, 8]               0
          Conv2d-191           [-1, 256, 16, 8]         589,824
     BatchNorm2d-192           [-1, 256, 16, 8]             512
            ReLU-193           [-1, 256, 16, 8]               0
          Conv2d-194          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-195          [-1, 1024, 16, 8]           2,048
            ReLU-196          [-1, 1024, 16, 8]               0
      Bottleneck-197          [-1, 1024, 16, 8]               0
          Conv2d-198           [-1, 256, 16, 8]         262,144
     BatchNorm2d-199           [-1, 256, 16, 8]             512
            ReLU-200           [-1, 256, 16, 8]               0
          Conv2d-201           [-1, 256, 16, 8]         589,824
     BatchNorm2d-202           [-1, 256, 16, 8]             512
            ReLU-203           [-1, 256, 16, 8]               0
          Conv2d-204          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-205          [-1, 1024, 16, 8]           2,048
            ReLU-206          [-1, 1024, 16, 8]               0
      Bottleneck-207          [-1, 1024, 16, 8]               0
          Conv2d-208           [-1, 256, 16, 8]         262,144
     BatchNorm2d-209           [-1, 256, 16, 8]             512
            ReLU-210           [-1, 256, 16, 8]               0
          Conv2d-211           [-1, 256, 16, 8]         589,824
     BatchNorm2d-212           [-1, 256, 16, 8]             512
            ReLU-213           [-1, 256, 16, 8]               0
          Conv2d-214          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-215          [-1, 1024, 16, 8]           2,048
            ReLU-216          [-1, 1024, 16, 8]               0
      Bottleneck-217          [-1, 1024, 16, 8]               0
          Conv2d-218           [-1, 256, 16, 8]         262,144
     BatchNorm2d-219           [-1, 256, 16, 8]             512
            ReLU-220           [-1, 256, 16, 8]               0
          Conv2d-221           [-1, 256, 16, 8]         589,824
     BatchNorm2d-222           [-1, 256, 16, 8]             512
            ReLU-223           [-1, 256, 16, 8]               0
          Conv2d-224          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-225          [-1, 1024, 16, 8]           2,048
            ReLU-226          [-1, 1024, 16, 8]               0
      Bottleneck-227          [-1, 1024, 16, 8]               0
          Conv2d-228           [-1, 256, 16, 8]         262,144
     BatchNorm2d-229           [-1, 256, 16, 8]             512
            ReLU-230           [-1, 256, 16, 8]               0
          Conv2d-231           [-1, 256, 16, 8]         589,824
     BatchNorm2d-232           [-1, 256, 16, 8]             512
            ReLU-233           [-1, 256, 16, 8]               0
          Conv2d-234          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-235          [-1, 1024, 16, 8]           2,048
            ReLU-236          [-1, 1024, 16, 8]               0
      Bottleneck-237          [-1, 1024, 16, 8]               0
          Conv2d-238           [-1, 256, 16, 8]         262,144
     BatchNorm2d-239           [-1, 256, 16, 8]             512
            ReLU-240           [-1, 256, 16, 8]               0
          Conv2d-241           [-1, 256, 16, 8]         589,824
     BatchNorm2d-242           [-1, 256, 16, 8]             512
            ReLU-243           [-1, 256, 16, 8]               0
          Conv2d-244          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-245          [-1, 1024, 16, 8]           2,048
            ReLU-246          [-1, 1024, 16, 8]               0
      Bottleneck-247          [-1, 1024, 16, 8]               0
          Conv2d-248           [-1, 256, 16, 8]         262,144
     BatchNorm2d-249           [-1, 256, 16, 8]             512
            ReLU-250           [-1, 256, 16, 8]               0
          Conv2d-251           [-1, 256, 16, 8]         589,824
     BatchNorm2d-252           [-1, 256, 16, 8]             512
            ReLU-253           [-1, 256, 16, 8]               0
          Conv2d-254          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-255          [-1, 1024, 16, 8]           2,048
            ReLU-256          [-1, 1024, 16, 8]               0
      Bottleneck-257          [-1, 1024, 16, 8]               0
          Conv2d-258           [-1, 256, 16, 8]         262,144
     BatchNorm2d-259           [-1, 256, 16, 8]             512
            ReLU-260           [-1, 256, 16, 8]               0
          Conv2d-261           [-1, 256, 16, 8]         589,824
     BatchNorm2d-262           [-1, 256, 16, 8]             512
            ReLU-263           [-1, 256, 16, 8]               0
          Conv2d-264          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-265          [-1, 1024, 16, 8]           2,048
            ReLU-266          [-1, 1024, 16, 8]               0
      Bottleneck-267          [-1, 1024, 16, 8]               0
          Conv2d-268           [-1, 256, 16, 8]         262,144
     BatchNorm2d-269           [-1, 256, 16, 8]             512
            ReLU-270           [-1, 256, 16, 8]               0
          Conv2d-271           [-1, 256, 16, 8]         589,824
     BatchNorm2d-272           [-1, 256, 16, 8]             512
            ReLU-273           [-1, 256, 16, 8]               0
          Conv2d-274          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-275          [-1, 1024, 16, 8]           2,048
            ReLU-276          [-1, 1024, 16, 8]               0
      Bottleneck-277          [-1, 1024, 16, 8]               0
          Conv2d-278           [-1, 256, 16, 8]         262,144
     BatchNorm2d-279           [-1, 256, 16, 8]             512
            ReLU-280           [-1, 256, 16, 8]               0
          Conv2d-281           [-1, 256, 16, 8]         589,824
     BatchNorm2d-282           [-1, 256, 16, 8]             512
            ReLU-283           [-1, 256, 16, 8]               0
          Conv2d-284          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-285          [-1, 1024, 16, 8]           2,048
            ReLU-286          [-1, 1024, 16, 8]               0
      Bottleneck-287          [-1, 1024, 16, 8]               0
          Conv2d-288           [-1, 256, 16, 8]         262,144
     BatchNorm2d-289           [-1, 256, 16, 8]             512
            ReLU-290           [-1, 256, 16, 8]               0
          Conv2d-291           [-1, 256, 16, 8]         589,824
     BatchNorm2d-292           [-1, 256, 16, 8]             512
            ReLU-293           [-1, 256, 16, 8]               0
          Conv2d-294          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-295          [-1, 1024, 16, 8]           2,048
            ReLU-296          [-1, 1024, 16, 8]               0
      Bottleneck-297          [-1, 1024, 16, 8]               0
          Conv2d-298           [-1, 256, 16, 8]         262,144
     BatchNorm2d-299           [-1, 256, 16, 8]             512
            ReLU-300           [-1, 256, 16, 8]               0
          Conv2d-301           [-1, 256, 16, 8]         589,824
     BatchNorm2d-302           [-1, 256, 16, 8]             512
            ReLU-303           [-1, 256, 16, 8]               0
          Conv2d-304          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-305          [-1, 1024, 16, 8]           2,048
            ReLU-306          [-1, 1024, 16, 8]               0
      Bottleneck-307          [-1, 1024, 16, 8]               0
          Conv2d-308           [-1, 256, 16, 8]         262,144
     BatchNorm2d-309           [-1, 256, 16, 8]             512
            ReLU-310           [-1, 256, 16, 8]               0
          Conv2d-311           [-1, 256, 16, 8]         589,824
     BatchNorm2d-312           [-1, 256, 16, 8]             512
            ReLU-313           [-1, 256, 16, 8]               0
          Conv2d-314          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-315          [-1, 1024, 16, 8]           2,048
            ReLU-316          [-1, 1024, 16, 8]               0
      Bottleneck-317          [-1, 1024, 16, 8]               0
          Conv2d-318           [-1, 512, 16, 8]         524,288
     BatchNorm2d-319           [-1, 512, 16, 8]           1,024
            ReLU-320           [-1, 512, 16, 8]               0
          Conv2d-321           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-322           [-1, 512, 16, 8]           1,024
            ReLU-323           [-1, 512, 16, 8]               0
          Conv2d-324          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-325          [-1, 2048, 16, 8]           4,096
          Conv2d-326          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-327          [-1, 2048, 16, 8]           4,096
            ReLU-328          [-1, 2048, 16, 8]               0
      Bottleneck-329          [-1, 2048, 16, 8]               0
          Conv2d-330           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-331           [-1, 512, 16, 8]           1,024
            ReLU-332           [-1, 512, 16, 8]               0
          Conv2d-333           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-334           [-1, 512, 16, 8]           1,024
            ReLU-335           [-1, 512, 16, 8]               0
          Conv2d-336          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-337          [-1, 2048, 16, 8]           4,096
            ReLU-338          [-1, 2048, 16, 8]               0
      Bottleneck-339          [-1, 2048, 16, 8]               0
          Conv2d-340           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-341           [-1, 512, 16, 8]           1,024
            ReLU-342           [-1, 512, 16, 8]               0
          Conv2d-343           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-344           [-1, 512, 16, 8]           1,024
            ReLU-345           [-1, 512, 16, 8]               0
          Conv2d-346          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-347          [-1, 2048, 16, 8]           4,096
            ReLU-348          [-1, 2048, 16, 8]               0
      Bottleneck-349          [-1, 2048, 16, 8]               0
================================================================
Total params: 42,505,792
Trainable params: 42,505,792
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 327.25
Params size (MB): 162.15
Estimated Total Size (MB): 489.77
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet152_se
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
             ReLU-21          [-1, 256, 64, 32]               0
       Bottleneck-22          [-1, 256, 64, 32]               0
           Conv2d-23           [-1, 64, 64, 32]          16,384
      BatchNorm2d-24           [-1, 64, 64, 32]             128
             ReLU-25           [-1, 64, 64, 32]               0
           Conv2d-26           [-1, 64, 64, 32]          36,864
      BatchNorm2d-27           [-1, 64, 64, 32]             128
             ReLU-28           [-1, 64, 64, 32]               0
           Conv2d-29          [-1, 256, 64, 32]          16,384
      BatchNorm2d-30          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0
           Linear-32                   [-1, 16]           4,096
             ReLU-33                   [-1, 16]               0
           Linear-34                  [-1, 256]           4,096
          Sigmoid-35                  [-1, 256]               0
          SELayer-36          [-1, 256, 64, 32]               0
             ReLU-37          [-1, 256, 64, 32]               0
       Bottleneck-38          [-1, 256, 64, 32]               0
           Conv2d-39           [-1, 64, 64, 32]          16,384
      BatchNorm2d-40           [-1, 64, 64, 32]             128
             ReLU-41           [-1, 64, 64, 32]               0
           Conv2d-42           [-1, 64, 64, 32]          36,864
      BatchNorm2d-43           [-1, 64, 64, 32]             128
             ReLU-44           [-1, 64, 64, 32]               0
           Conv2d-45          [-1, 256, 64, 32]          16,384
      BatchNorm2d-46          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-47            [-1, 256, 1, 1]               0
           Linear-48                   [-1, 16]           4,096
             ReLU-49                   [-1, 16]               0
           Linear-50                  [-1, 256]           4,096
          Sigmoid-51                  [-1, 256]               0
          SELayer-52          [-1, 256, 64, 32]               0
             ReLU-53          [-1, 256, 64, 32]               0
       Bottleneck-54          [-1, 256, 64, 32]               0
           Conv2d-55          [-1, 128, 64, 32]          32,768
      BatchNorm2d-56          [-1, 128, 64, 32]             256
             ReLU-57          [-1, 128, 64, 32]               0
           Conv2d-58          [-1, 128, 32, 16]         147,456
      BatchNorm2d-59          [-1, 128, 32, 16]             256
             ReLU-60          [-1, 128, 32, 16]               0
           Conv2d-61          [-1, 512, 32, 16]          65,536
      BatchNorm2d-62          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-63            [-1, 512, 1, 1]               0
           Linear-64                   [-1, 32]          16,384
             ReLU-65                   [-1, 32]               0
           Linear-66                  [-1, 512]          16,384
          Sigmoid-67                  [-1, 512]               0
          SELayer-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         131,072
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
             ReLU-71          [-1, 512, 32, 16]               0
       Bottleneck-72          [-1, 512, 32, 16]               0
           Conv2d-73          [-1, 128, 32, 16]          65,536
      BatchNorm2d-74          [-1, 128, 32, 16]             256
             ReLU-75          [-1, 128, 32, 16]               0
           Conv2d-76          [-1, 128, 32, 16]         147,456
      BatchNorm2d-77          [-1, 128, 32, 16]             256
             ReLU-78          [-1, 128, 32, 16]               0
           Conv2d-79          [-1, 512, 32, 16]          65,536
      BatchNorm2d-80          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-81            [-1, 512, 1, 1]               0
           Linear-82                   [-1, 32]          16,384
             ReLU-83                   [-1, 32]               0
           Linear-84                  [-1, 512]          16,384
          Sigmoid-85                  [-1, 512]               0
          SELayer-86          [-1, 512, 32, 16]               0
             ReLU-87          [-1, 512, 32, 16]               0
       Bottleneck-88          [-1, 512, 32, 16]               0
           Conv2d-89          [-1, 128, 32, 16]          65,536
      BatchNorm2d-90          [-1, 128, 32, 16]             256
             ReLU-91          [-1, 128, 32, 16]               0
           Conv2d-92          [-1, 128, 32, 16]         147,456
      BatchNorm2d-93          [-1, 128, 32, 16]             256
             ReLU-94          [-1, 128, 32, 16]               0
           Conv2d-95          [-1, 512, 32, 16]          65,536
      BatchNorm2d-96          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-97            [-1, 512, 1, 1]               0
           Linear-98                   [-1, 32]          16,384
             ReLU-99                   [-1, 32]               0
          Linear-100                  [-1, 512]          16,384
         Sigmoid-101                  [-1, 512]               0
         SELayer-102          [-1, 512, 32, 16]               0
            ReLU-103          [-1, 512, 32, 16]               0
      Bottleneck-104          [-1, 512, 32, 16]               0
          Conv2d-105          [-1, 128, 32, 16]          65,536
     BatchNorm2d-106          [-1, 128, 32, 16]             256
            ReLU-107          [-1, 128, 32, 16]               0
          Conv2d-108          [-1, 128, 32, 16]         147,456
     BatchNorm2d-109          [-1, 128, 32, 16]             256
            ReLU-110          [-1, 128, 32, 16]               0
          Conv2d-111          [-1, 512, 32, 16]          65,536
     BatchNorm2d-112          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-113            [-1, 512, 1, 1]               0
          Linear-114                   [-1, 32]          16,384
            ReLU-115                   [-1, 32]               0
          Linear-116                  [-1, 512]          16,384
         Sigmoid-117                  [-1, 512]               0
         SELayer-118          [-1, 512, 32, 16]               0
            ReLU-119          [-1, 512, 32, 16]               0
      Bottleneck-120          [-1, 512, 32, 16]               0
          Conv2d-121          [-1, 128, 32, 16]          65,536
     BatchNorm2d-122          [-1, 128, 32, 16]             256
            ReLU-123          [-1, 128, 32, 16]               0
          Conv2d-124          [-1, 128, 32, 16]         147,456
     BatchNorm2d-125          [-1, 128, 32, 16]             256
            ReLU-126          [-1, 128, 32, 16]               0
          Conv2d-127          [-1, 512, 32, 16]          65,536
     BatchNorm2d-128          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-129            [-1, 512, 1, 1]               0
          Linear-130                   [-1, 32]          16,384
            ReLU-131                   [-1, 32]               0
          Linear-132                  [-1, 512]          16,384
         Sigmoid-133                  [-1, 512]               0
         SELayer-134          [-1, 512, 32, 16]               0
            ReLU-135          [-1, 512, 32, 16]               0
      Bottleneck-136          [-1, 512, 32, 16]               0
          Conv2d-137          [-1, 128, 32, 16]          65,536
     BatchNorm2d-138          [-1, 128, 32, 16]             256
            ReLU-139          [-1, 128, 32, 16]               0
          Conv2d-140          [-1, 128, 32, 16]         147,456
     BatchNorm2d-141          [-1, 128, 32, 16]             256
            ReLU-142          [-1, 128, 32, 16]               0
          Conv2d-143          [-1, 512, 32, 16]          65,536
     BatchNorm2d-144          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-145            [-1, 512, 1, 1]               0
          Linear-146                   [-1, 32]          16,384
            ReLU-147                   [-1, 32]               0
          Linear-148                  [-1, 512]          16,384
         Sigmoid-149                  [-1, 512]               0
         SELayer-150          [-1, 512, 32, 16]               0
            ReLU-151          [-1, 512, 32, 16]               0
      Bottleneck-152          [-1, 512, 32, 16]               0
          Conv2d-153          [-1, 128, 32, 16]          65,536
     BatchNorm2d-154          [-1, 128, 32, 16]             256
            ReLU-155          [-1, 128, 32, 16]               0
          Conv2d-156          [-1, 128, 32, 16]         147,456
     BatchNorm2d-157          [-1, 128, 32, 16]             256
            ReLU-158          [-1, 128, 32, 16]               0
          Conv2d-159          [-1, 512, 32, 16]          65,536
     BatchNorm2d-160          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-161            [-1, 512, 1, 1]               0
          Linear-162                   [-1, 32]          16,384
            ReLU-163                   [-1, 32]               0
          Linear-164                  [-1, 512]          16,384
         Sigmoid-165                  [-1, 512]               0
         SELayer-166          [-1, 512, 32, 16]               0
            ReLU-167          [-1, 512, 32, 16]               0
      Bottleneck-168          [-1, 512, 32, 16]               0
          Conv2d-169          [-1, 128, 32, 16]          65,536
     BatchNorm2d-170          [-1, 128, 32, 16]             256
            ReLU-171          [-1, 128, 32, 16]               0
          Conv2d-172          [-1, 128, 32, 16]         147,456
     BatchNorm2d-173          [-1, 128, 32, 16]             256
            ReLU-174          [-1, 128, 32, 16]               0
          Conv2d-175          [-1, 512, 32, 16]          65,536
     BatchNorm2d-176          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-177            [-1, 512, 1, 1]               0
          Linear-178                   [-1, 32]          16,384
            ReLU-179                   [-1, 32]               0
          Linear-180                  [-1, 512]          16,384
         Sigmoid-181                  [-1, 512]               0
         SELayer-182          [-1, 512, 32, 16]               0
            ReLU-183          [-1, 512, 32, 16]               0
      Bottleneck-184          [-1, 512, 32, 16]               0
          Conv2d-185          [-1, 256, 32, 16]         131,072
     BatchNorm2d-186          [-1, 256, 32, 16]             512
            ReLU-187          [-1, 256, 32, 16]               0
          Conv2d-188           [-1, 256, 16, 8]         589,824
     BatchNorm2d-189           [-1, 256, 16, 8]             512
            ReLU-190           [-1, 256, 16, 8]               0
          Conv2d-191          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-192          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-193           [-1, 1024, 1, 1]               0
          Linear-194                   [-1, 64]          65,536
            ReLU-195                   [-1, 64]               0
          Linear-196                 [-1, 1024]          65,536
         Sigmoid-197                 [-1, 1024]               0
         SELayer-198          [-1, 1024, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203           [-1, 256, 16, 8]         262,144
     BatchNorm2d-204           [-1, 256, 16, 8]             512
            ReLU-205           [-1, 256, 16, 8]               0
          Conv2d-206           [-1, 256, 16, 8]         589,824
     BatchNorm2d-207           [-1, 256, 16, 8]             512
            ReLU-208           [-1, 256, 16, 8]               0
          Conv2d-209          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-210          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-211           [-1, 1024, 1, 1]               0
          Linear-212                   [-1, 64]          65,536
            ReLU-213                   [-1, 64]               0
          Linear-214                 [-1, 1024]          65,536
         Sigmoid-215                 [-1, 1024]               0
         SELayer-216          [-1, 1024, 16, 8]               0
            ReLU-217          [-1, 1024, 16, 8]               0
      Bottleneck-218          [-1, 1024, 16, 8]               0
          Conv2d-219           [-1, 256, 16, 8]         262,144
     BatchNorm2d-220           [-1, 256, 16, 8]             512
            ReLU-221           [-1, 256, 16, 8]               0
          Conv2d-222           [-1, 256, 16, 8]         589,824
     BatchNorm2d-223           [-1, 256, 16, 8]             512
            ReLU-224           [-1, 256, 16, 8]               0
          Conv2d-225          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-226          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-227           [-1, 1024, 1, 1]               0
          Linear-228                   [-1, 64]          65,536
            ReLU-229                   [-1, 64]               0
          Linear-230                 [-1, 1024]          65,536
         Sigmoid-231                 [-1, 1024]               0
         SELayer-232          [-1, 1024, 16, 8]               0
            ReLU-233          [-1, 1024, 16, 8]               0
      Bottleneck-234          [-1, 1024, 16, 8]               0
          Conv2d-235           [-1, 256, 16, 8]         262,144
     BatchNorm2d-236           [-1, 256, 16, 8]             512
            ReLU-237           [-1, 256, 16, 8]               0
          Conv2d-238           [-1, 256, 16, 8]         589,824
     BatchNorm2d-239           [-1, 256, 16, 8]             512
            ReLU-240           [-1, 256, 16, 8]               0
          Conv2d-241          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-242          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-243           [-1, 1024, 1, 1]               0
          Linear-244                   [-1, 64]          65,536
            ReLU-245                   [-1, 64]               0
          Linear-246                 [-1, 1024]          65,536
         Sigmoid-247                 [-1, 1024]               0
         SELayer-248          [-1, 1024, 16, 8]               0
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251           [-1, 256, 16, 8]         262,144
     BatchNorm2d-252           [-1, 256, 16, 8]             512
            ReLU-253           [-1, 256, 16, 8]               0
          Conv2d-254           [-1, 256, 16, 8]         589,824
     BatchNorm2d-255           [-1, 256, 16, 8]             512
            ReLU-256           [-1, 256, 16, 8]               0
          Conv2d-257          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-258          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-259           [-1, 1024, 1, 1]               0
          Linear-260                   [-1, 64]          65,536
            ReLU-261                   [-1, 64]               0
          Linear-262                 [-1, 1024]          65,536
         Sigmoid-263                 [-1, 1024]               0
         SELayer-264          [-1, 1024, 16, 8]               0
            ReLU-265          [-1, 1024, 16, 8]               0
      Bottleneck-266          [-1, 1024, 16, 8]               0
          Conv2d-267           [-1, 256, 16, 8]         262,144
     BatchNorm2d-268           [-1, 256, 16, 8]             512
            ReLU-269           [-1, 256, 16, 8]               0
          Conv2d-270           [-1, 256, 16, 8]         589,824
     BatchNorm2d-271           [-1, 256, 16, 8]             512
            ReLU-272           [-1, 256, 16, 8]               0
          Conv2d-273          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-274          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-275           [-1, 1024, 1, 1]               0
          Linear-276                   [-1, 64]          65,536
            ReLU-277                   [-1, 64]               0
          Linear-278                 [-1, 1024]          65,536
         Sigmoid-279                 [-1, 1024]               0
         SELayer-280          [-1, 1024, 16, 8]               0
            ReLU-281          [-1, 1024, 16, 8]               0
      Bottleneck-282          [-1, 1024, 16, 8]               0
          Conv2d-283           [-1, 256, 16, 8]         262,144
     BatchNorm2d-284           [-1, 256, 16, 8]             512
            ReLU-285           [-1, 256, 16, 8]               0
          Conv2d-286           [-1, 256, 16, 8]         589,824
     BatchNorm2d-287           [-1, 256, 16, 8]             512
            ReLU-288           [-1, 256, 16, 8]               0
          Conv2d-289          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-290          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-291           [-1, 1024, 1, 1]               0
          Linear-292                   [-1, 64]          65,536
            ReLU-293                   [-1, 64]               0
          Linear-294                 [-1, 1024]          65,536
         Sigmoid-295                 [-1, 1024]               0
         SELayer-296          [-1, 1024, 16, 8]               0
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299           [-1, 256, 16, 8]         262,144
     BatchNorm2d-300           [-1, 256, 16, 8]             512
            ReLU-301           [-1, 256, 16, 8]               0
          Conv2d-302           [-1, 256, 16, 8]         589,824
     BatchNorm2d-303           [-1, 256, 16, 8]             512
            ReLU-304           [-1, 256, 16, 8]               0
          Conv2d-305          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-306          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-307           [-1, 1024, 1, 1]               0
          Linear-308                   [-1, 64]          65,536
            ReLU-309                   [-1, 64]               0
          Linear-310                 [-1, 1024]          65,536
         Sigmoid-311                 [-1, 1024]               0
         SELayer-312          [-1, 1024, 16, 8]               0
            ReLU-313          [-1, 1024, 16, 8]               0
      Bottleneck-314          [-1, 1024, 16, 8]               0
          Conv2d-315           [-1, 256, 16, 8]         262,144
     BatchNorm2d-316           [-1, 256, 16, 8]             512
            ReLU-317           [-1, 256, 16, 8]               0
          Conv2d-318           [-1, 256, 16, 8]         589,824
     BatchNorm2d-319           [-1, 256, 16, 8]             512
            ReLU-320           [-1, 256, 16, 8]               0
          Conv2d-321          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-322          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-323           [-1, 1024, 1, 1]               0
          Linear-324                   [-1, 64]          65,536
            ReLU-325                   [-1, 64]               0
          Linear-326                 [-1, 1024]          65,536
         Sigmoid-327                 [-1, 1024]               0
         SELayer-328          [-1, 1024, 16, 8]               0
            ReLU-329          [-1, 1024, 16, 8]               0
      Bottleneck-330          [-1, 1024, 16, 8]               0
          Conv2d-331           [-1, 256, 16, 8]         262,144
     BatchNorm2d-332           [-1, 256, 16, 8]             512
            ReLU-333           [-1, 256, 16, 8]               0
          Conv2d-334           [-1, 256, 16, 8]         589,824
     BatchNorm2d-335           [-1, 256, 16, 8]             512
            ReLU-336           [-1, 256, 16, 8]               0
          Conv2d-337          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-338          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-339           [-1, 1024, 1, 1]               0
          Linear-340                   [-1, 64]          65,536
            ReLU-341                   [-1, 64]               0
          Linear-342                 [-1, 1024]          65,536
         Sigmoid-343                 [-1, 1024]               0
         SELayer-344          [-1, 1024, 16, 8]               0
            ReLU-345          [-1, 1024, 16, 8]               0
      Bottleneck-346          [-1, 1024, 16, 8]               0
          Conv2d-347           [-1, 256, 16, 8]         262,144
     BatchNorm2d-348           [-1, 256, 16, 8]             512
            ReLU-349           [-1, 256, 16, 8]               0
          Conv2d-350           [-1, 256, 16, 8]         589,824
     BatchNorm2d-351           [-1, 256, 16, 8]             512
            ReLU-352           [-1, 256, 16, 8]               0
          Conv2d-353          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-354          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-355           [-1, 1024, 1, 1]               0
          Linear-356                   [-1, 64]          65,536
            ReLU-357                   [-1, 64]               0
          Linear-358                 [-1, 1024]          65,536
         Sigmoid-359                 [-1, 1024]               0
         SELayer-360          [-1, 1024, 16, 8]               0
            ReLU-361          [-1, 1024, 16, 8]               0
      Bottleneck-362          [-1, 1024, 16, 8]               0
          Conv2d-363           [-1, 256, 16, 8]         262,144
     BatchNorm2d-364           [-1, 256, 16, 8]             512
            ReLU-365           [-1, 256, 16, 8]               0
          Conv2d-366           [-1, 256, 16, 8]         589,824
     BatchNorm2d-367           [-1, 256, 16, 8]             512
            ReLU-368           [-1, 256, 16, 8]               0
          Conv2d-369          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-370          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-371           [-1, 1024, 1, 1]               0
          Linear-372                   [-1, 64]          65,536
            ReLU-373                   [-1, 64]               0
          Linear-374                 [-1, 1024]          65,536
         Sigmoid-375                 [-1, 1024]               0
         SELayer-376          [-1, 1024, 16, 8]               0
            ReLU-377          [-1, 1024, 16, 8]               0
      Bottleneck-378          [-1, 1024, 16, 8]               0
          Conv2d-379           [-1, 256, 16, 8]         262,144
     BatchNorm2d-380           [-1, 256, 16, 8]             512
            ReLU-381           [-1, 256, 16, 8]               0
          Conv2d-382           [-1, 256, 16, 8]         589,824
     BatchNorm2d-383           [-1, 256, 16, 8]             512
            ReLU-384           [-1, 256, 16, 8]               0
          Conv2d-385          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-386          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-387           [-1, 1024, 1, 1]               0
          Linear-388                   [-1, 64]          65,536
            ReLU-389                   [-1, 64]               0
          Linear-390                 [-1, 1024]          65,536
         Sigmoid-391                 [-1, 1024]               0
         SELayer-392          [-1, 1024, 16, 8]               0
            ReLU-393          [-1, 1024, 16, 8]               0
      Bottleneck-394          [-1, 1024, 16, 8]               0
          Conv2d-395           [-1, 256, 16, 8]         262,144
     BatchNorm2d-396           [-1, 256, 16, 8]             512
            ReLU-397           [-1, 256, 16, 8]               0
          Conv2d-398           [-1, 256, 16, 8]         589,824
     BatchNorm2d-399           [-1, 256, 16, 8]             512
            ReLU-400           [-1, 256, 16, 8]               0
          Conv2d-401          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-402          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-403           [-1, 1024, 1, 1]               0
          Linear-404                   [-1, 64]          65,536
            ReLU-405                   [-1, 64]               0
          Linear-406                 [-1, 1024]          65,536
         Sigmoid-407                 [-1, 1024]               0
         SELayer-408          [-1, 1024, 16, 8]               0
            ReLU-409          [-1, 1024, 16, 8]               0
      Bottleneck-410          [-1, 1024, 16, 8]               0
          Conv2d-411           [-1, 256, 16, 8]         262,144
     BatchNorm2d-412           [-1, 256, 16, 8]             512
            ReLU-413           [-1, 256, 16, 8]               0
          Conv2d-414           [-1, 256, 16, 8]         589,824
     BatchNorm2d-415           [-1, 256, 16, 8]             512
            ReLU-416           [-1, 256, 16, 8]               0
          Conv2d-417          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-418          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-419           [-1, 1024, 1, 1]               0
          Linear-420                   [-1, 64]          65,536
            ReLU-421                   [-1, 64]               0
          Linear-422                 [-1, 1024]          65,536
         Sigmoid-423                 [-1, 1024]               0
         SELayer-424          [-1, 1024, 16, 8]               0
            ReLU-425          [-1, 1024, 16, 8]               0
      Bottleneck-426          [-1, 1024, 16, 8]               0
          Conv2d-427           [-1, 256, 16, 8]         262,144
     BatchNorm2d-428           [-1, 256, 16, 8]             512
            ReLU-429           [-1, 256, 16, 8]               0
          Conv2d-430           [-1, 256, 16, 8]         589,824
     BatchNorm2d-431           [-1, 256, 16, 8]             512
            ReLU-432           [-1, 256, 16, 8]               0
          Conv2d-433          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-434          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-435           [-1, 1024, 1, 1]               0
          Linear-436                   [-1, 64]          65,536
            ReLU-437                   [-1, 64]               0
          Linear-438                 [-1, 1024]          65,536
         Sigmoid-439                 [-1, 1024]               0
         SELayer-440          [-1, 1024, 16, 8]               0
            ReLU-441          [-1, 1024, 16, 8]               0
      Bottleneck-442          [-1, 1024, 16, 8]               0
          Conv2d-443           [-1, 256, 16, 8]         262,144
     BatchNorm2d-444           [-1, 256, 16, 8]             512
            ReLU-445           [-1, 256, 16, 8]               0
          Conv2d-446           [-1, 256, 16, 8]         589,824
     BatchNorm2d-447           [-1, 256, 16, 8]             512
            ReLU-448           [-1, 256, 16, 8]               0
          Conv2d-449          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-450          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-451           [-1, 1024, 1, 1]               0
          Linear-452                   [-1, 64]          65,536
            ReLU-453                   [-1, 64]               0
          Linear-454                 [-1, 1024]          65,536
         Sigmoid-455                 [-1, 1024]               0
         SELayer-456          [-1, 1024, 16, 8]               0
            ReLU-457          [-1, 1024, 16, 8]               0
      Bottleneck-458          [-1, 1024, 16, 8]               0
          Conv2d-459           [-1, 256, 16, 8]         262,144
     BatchNorm2d-460           [-1, 256, 16, 8]             512
            ReLU-461           [-1, 256, 16, 8]               0
          Conv2d-462           [-1, 256, 16, 8]         589,824
     BatchNorm2d-463           [-1, 256, 16, 8]             512
            ReLU-464           [-1, 256, 16, 8]               0
          Conv2d-465          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-466          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-467           [-1, 1024, 1, 1]               0
          Linear-468                   [-1, 64]          65,536
            ReLU-469                   [-1, 64]               0
          Linear-470                 [-1, 1024]          65,536
         Sigmoid-471                 [-1, 1024]               0
         SELayer-472          [-1, 1024, 16, 8]               0
            ReLU-473          [-1, 1024, 16, 8]               0
      Bottleneck-474          [-1, 1024, 16, 8]               0
          Conv2d-475           [-1, 256, 16, 8]         262,144
     BatchNorm2d-476           [-1, 256, 16, 8]             512
            ReLU-477           [-1, 256, 16, 8]               0
          Conv2d-478           [-1, 256, 16, 8]         589,824
     BatchNorm2d-479           [-1, 256, 16, 8]             512
            ReLU-480           [-1, 256, 16, 8]               0
          Conv2d-481          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-482          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-483           [-1, 1024, 1, 1]               0
          Linear-484                   [-1, 64]          65,536
            ReLU-485                   [-1, 64]               0
          Linear-486                 [-1, 1024]          65,536
         Sigmoid-487                 [-1, 1024]               0
         SELayer-488          [-1, 1024, 16, 8]               0
            ReLU-489          [-1, 1024, 16, 8]               0
      Bottleneck-490          [-1, 1024, 16, 8]               0
          Conv2d-491           [-1, 256, 16, 8]         262,144
     BatchNorm2d-492           [-1, 256, 16, 8]             512
            ReLU-493           [-1, 256, 16, 8]               0
          Conv2d-494           [-1, 256, 16, 8]         589,824
     BatchNorm2d-495           [-1, 256, 16, 8]             512
            ReLU-496           [-1, 256, 16, 8]               0
          Conv2d-497          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-498          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-499           [-1, 1024, 1, 1]               0
          Linear-500                   [-1, 64]          65,536
            ReLU-501                   [-1, 64]               0
          Linear-502                 [-1, 1024]          65,536
         Sigmoid-503                 [-1, 1024]               0
         SELayer-504          [-1, 1024, 16, 8]               0
            ReLU-505          [-1, 1024, 16, 8]               0
      Bottleneck-506          [-1, 1024, 16, 8]               0
          Conv2d-507           [-1, 256, 16, 8]         262,144
     BatchNorm2d-508           [-1, 256, 16, 8]             512
            ReLU-509           [-1, 256, 16, 8]               0
          Conv2d-510           [-1, 256, 16, 8]         589,824
     BatchNorm2d-511           [-1, 256, 16, 8]             512
            ReLU-512           [-1, 256, 16, 8]               0
          Conv2d-513          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-514          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-515           [-1, 1024, 1, 1]               0
          Linear-516                   [-1, 64]          65,536
            ReLU-517                   [-1, 64]               0
          Linear-518                 [-1, 1024]          65,536
         Sigmoid-519                 [-1, 1024]               0
         SELayer-520          [-1, 1024, 16, 8]               0
            ReLU-521          [-1, 1024, 16, 8]               0
      Bottleneck-522          [-1, 1024, 16, 8]               0
          Conv2d-523           [-1, 256, 16, 8]         262,144
     BatchNorm2d-524           [-1, 256, 16, 8]             512
            ReLU-525           [-1, 256, 16, 8]               0
          Conv2d-526           [-1, 256, 16, 8]         589,824
     BatchNorm2d-527           [-1, 256, 16, 8]             512
            ReLU-528           [-1, 256, 16, 8]               0
          Conv2d-529          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-530          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-531           [-1, 1024, 1, 1]               0
          Linear-532                   [-1, 64]          65,536
            ReLU-533                   [-1, 64]               0
          Linear-534                 [-1, 1024]          65,536
         Sigmoid-535                 [-1, 1024]               0
         SELayer-536          [-1, 1024, 16, 8]               0
            ReLU-537          [-1, 1024, 16, 8]               0
      Bottleneck-538          [-1, 1024, 16, 8]               0
          Conv2d-539           [-1, 256, 16, 8]         262,144
     BatchNorm2d-540           [-1, 256, 16, 8]             512
            ReLU-541           [-1, 256, 16, 8]               0
          Conv2d-542           [-1, 256, 16, 8]         589,824
     BatchNorm2d-543           [-1, 256, 16, 8]             512
            ReLU-544           [-1, 256, 16, 8]               0
          Conv2d-545          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-546          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-547           [-1, 1024, 1, 1]               0
          Linear-548                   [-1, 64]          65,536
            ReLU-549                   [-1, 64]               0
          Linear-550                 [-1, 1024]          65,536
         Sigmoid-551                 [-1, 1024]               0
         SELayer-552          [-1, 1024, 16, 8]               0
            ReLU-553          [-1, 1024, 16, 8]               0
      Bottleneck-554          [-1, 1024, 16, 8]               0
          Conv2d-555           [-1, 256, 16, 8]         262,144
     BatchNorm2d-556           [-1, 256, 16, 8]             512
            ReLU-557           [-1, 256, 16, 8]               0
          Conv2d-558           [-1, 256, 16, 8]         589,824
     BatchNorm2d-559           [-1, 256, 16, 8]             512
            ReLU-560           [-1, 256, 16, 8]               0
          Conv2d-561          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-562          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-563           [-1, 1024, 1, 1]               0
          Linear-564                   [-1, 64]          65,536
            ReLU-565                   [-1, 64]               0
          Linear-566                 [-1, 1024]          65,536
         Sigmoid-567                 [-1, 1024]               0
         SELayer-568          [-1, 1024, 16, 8]               0
            ReLU-569          [-1, 1024, 16, 8]               0
      Bottleneck-570          [-1, 1024, 16, 8]               0
          Conv2d-571           [-1, 256, 16, 8]         262,144
     BatchNorm2d-572           [-1, 256, 16, 8]             512
            ReLU-573           [-1, 256, 16, 8]               0
          Conv2d-574           [-1, 256, 16, 8]         589,824
     BatchNorm2d-575           [-1, 256, 16, 8]             512
            ReLU-576           [-1, 256, 16, 8]               0
          Conv2d-577          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-578          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-579           [-1, 1024, 1, 1]               0
          Linear-580                   [-1, 64]          65,536
            ReLU-581                   [-1, 64]               0
          Linear-582                 [-1, 1024]          65,536
         Sigmoid-583                 [-1, 1024]               0
         SELayer-584          [-1, 1024, 16, 8]               0
            ReLU-585          [-1, 1024, 16, 8]               0
      Bottleneck-586          [-1, 1024, 16, 8]               0
          Conv2d-587           [-1, 256, 16, 8]         262,144
     BatchNorm2d-588           [-1, 256, 16, 8]             512
            ReLU-589           [-1, 256, 16, 8]               0
          Conv2d-590           [-1, 256, 16, 8]         589,824
     BatchNorm2d-591           [-1, 256, 16, 8]             512
            ReLU-592           [-1, 256, 16, 8]               0
          Conv2d-593          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-594          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-595           [-1, 1024, 1, 1]               0
          Linear-596                   [-1, 64]          65,536
            ReLU-597                   [-1, 64]               0
          Linear-598                 [-1, 1024]          65,536
         Sigmoid-599                 [-1, 1024]               0
         SELayer-600          [-1, 1024, 16, 8]               0
            ReLU-601          [-1, 1024, 16, 8]               0
      Bottleneck-602          [-1, 1024, 16, 8]               0
          Conv2d-603           [-1, 256, 16, 8]         262,144
     BatchNorm2d-604           [-1, 256, 16, 8]             512
            ReLU-605           [-1, 256, 16, 8]               0
          Conv2d-606           [-1, 256, 16, 8]         589,824
     BatchNorm2d-607           [-1, 256, 16, 8]             512
            ReLU-608           [-1, 256, 16, 8]               0
          Conv2d-609          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-610          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-611           [-1, 1024, 1, 1]               0
          Linear-612                   [-1, 64]          65,536
            ReLU-613                   [-1, 64]               0
          Linear-614                 [-1, 1024]          65,536
         Sigmoid-615                 [-1, 1024]               0
         SELayer-616          [-1, 1024, 16, 8]               0
            ReLU-617          [-1, 1024, 16, 8]               0
      Bottleneck-618          [-1, 1024, 16, 8]               0
          Conv2d-619           [-1, 256, 16, 8]         262,144
     BatchNorm2d-620           [-1, 256, 16, 8]             512
            ReLU-621           [-1, 256, 16, 8]               0
          Conv2d-622           [-1, 256, 16, 8]         589,824
     BatchNorm2d-623           [-1, 256, 16, 8]             512
            ReLU-624           [-1, 256, 16, 8]               0
          Conv2d-625          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-626          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-627           [-1, 1024, 1, 1]               0
          Linear-628                   [-1, 64]          65,536
            ReLU-629                   [-1, 64]               0
          Linear-630                 [-1, 1024]          65,536
         Sigmoid-631                 [-1, 1024]               0
         SELayer-632          [-1, 1024, 16, 8]               0
            ReLU-633          [-1, 1024, 16, 8]               0
      Bottleneck-634          [-1, 1024, 16, 8]               0
          Conv2d-635           [-1, 256, 16, 8]         262,144
     BatchNorm2d-636           [-1, 256, 16, 8]             512
            ReLU-637           [-1, 256, 16, 8]               0
          Conv2d-638           [-1, 256, 16, 8]         589,824
     BatchNorm2d-639           [-1, 256, 16, 8]             512
            ReLU-640           [-1, 256, 16, 8]               0
          Conv2d-641          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-642          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-643           [-1, 1024, 1, 1]               0
          Linear-644                   [-1, 64]          65,536
            ReLU-645                   [-1, 64]               0
          Linear-646                 [-1, 1024]          65,536
         Sigmoid-647                 [-1, 1024]               0
         SELayer-648          [-1, 1024, 16, 8]               0
            ReLU-649          [-1, 1024, 16, 8]               0
      Bottleneck-650          [-1, 1024, 16, 8]               0
          Conv2d-651           [-1, 256, 16, 8]         262,144
     BatchNorm2d-652           [-1, 256, 16, 8]             512
            ReLU-653           [-1, 256, 16, 8]               0
          Conv2d-654           [-1, 256, 16, 8]         589,824
     BatchNorm2d-655           [-1, 256, 16, 8]             512
            ReLU-656           [-1, 256, 16, 8]               0
          Conv2d-657          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-658          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-659           [-1, 1024, 1, 1]               0
          Linear-660                   [-1, 64]          65,536
            ReLU-661                   [-1, 64]               0
          Linear-662                 [-1, 1024]          65,536
         Sigmoid-663                 [-1, 1024]               0
         SELayer-664          [-1, 1024, 16, 8]               0
            ReLU-665          [-1, 1024, 16, 8]               0
      Bottleneck-666          [-1, 1024, 16, 8]               0
          Conv2d-667           [-1, 256, 16, 8]         262,144
     BatchNorm2d-668           [-1, 256, 16, 8]             512
            ReLU-669           [-1, 256, 16, 8]               0
          Conv2d-670           [-1, 256, 16, 8]         589,824
     BatchNorm2d-671           [-1, 256, 16, 8]             512
            ReLU-672           [-1, 256, 16, 8]               0
          Conv2d-673          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-674          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-675           [-1, 1024, 1, 1]               0
          Linear-676                   [-1, 64]          65,536
            ReLU-677                   [-1, 64]               0
          Linear-678                 [-1, 1024]          65,536
         Sigmoid-679                 [-1, 1024]               0
         SELayer-680          [-1, 1024, 16, 8]               0
            ReLU-681          [-1, 1024, 16, 8]               0
      Bottleneck-682          [-1, 1024, 16, 8]               0
          Conv2d-683           [-1, 256, 16, 8]         262,144
     BatchNorm2d-684           [-1, 256, 16, 8]             512
            ReLU-685           [-1, 256, 16, 8]               0
          Conv2d-686           [-1, 256, 16, 8]         589,824
     BatchNorm2d-687           [-1, 256, 16, 8]             512
            ReLU-688           [-1, 256, 16, 8]               0
          Conv2d-689          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-690          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-691           [-1, 1024, 1, 1]               0
          Linear-692                   [-1, 64]          65,536
            ReLU-693                   [-1, 64]               0
          Linear-694                 [-1, 1024]          65,536
         Sigmoid-695                 [-1, 1024]               0
         SELayer-696          [-1, 1024, 16, 8]               0
            ReLU-697          [-1, 1024, 16, 8]               0
      Bottleneck-698          [-1, 1024, 16, 8]               0
          Conv2d-699           [-1, 256, 16, 8]         262,144
     BatchNorm2d-700           [-1, 256, 16, 8]             512
            ReLU-701           [-1, 256, 16, 8]               0
          Conv2d-702           [-1, 256, 16, 8]         589,824
     BatchNorm2d-703           [-1, 256, 16, 8]             512
            ReLU-704           [-1, 256, 16, 8]               0
          Conv2d-705          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-706          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-707           [-1, 1024, 1, 1]               0
          Linear-708                   [-1, 64]          65,536
            ReLU-709                   [-1, 64]               0
          Linear-710                 [-1, 1024]          65,536
         Sigmoid-711                 [-1, 1024]               0
         SELayer-712          [-1, 1024, 16, 8]               0
            ReLU-713          [-1, 1024, 16, 8]               0
      Bottleneck-714          [-1, 1024, 16, 8]               0
          Conv2d-715           [-1, 256, 16, 8]         262,144
     BatchNorm2d-716           [-1, 256, 16, 8]             512
            ReLU-717           [-1, 256, 16, 8]               0
          Conv2d-718           [-1, 256, 16, 8]         589,824
     BatchNorm2d-719           [-1, 256, 16, 8]             512
            ReLU-720           [-1, 256, 16, 8]               0
          Conv2d-721          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-722          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-723           [-1, 1024, 1, 1]               0
          Linear-724                   [-1, 64]          65,536
            ReLU-725                   [-1, 64]               0
          Linear-726                 [-1, 1024]          65,536
         Sigmoid-727                 [-1, 1024]               0
         SELayer-728          [-1, 1024, 16, 8]               0
            ReLU-729          [-1, 1024, 16, 8]               0
      Bottleneck-730          [-1, 1024, 16, 8]               0
          Conv2d-731           [-1, 256, 16, 8]         262,144
     BatchNorm2d-732           [-1, 256, 16, 8]             512
            ReLU-733           [-1, 256, 16, 8]               0
          Conv2d-734           [-1, 256, 16, 8]         589,824
     BatchNorm2d-735           [-1, 256, 16, 8]             512
            ReLU-736           [-1, 256, 16, 8]               0
          Conv2d-737          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-738          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-739           [-1, 1024, 1, 1]               0
          Linear-740                   [-1, 64]          65,536
            ReLU-741                   [-1, 64]               0
          Linear-742                 [-1, 1024]          65,536
         Sigmoid-743                 [-1, 1024]               0
         SELayer-744          [-1, 1024, 16, 8]               0
            ReLU-745          [-1, 1024, 16, 8]               0
      Bottleneck-746          [-1, 1024, 16, 8]               0
          Conv2d-747           [-1, 256, 16, 8]         262,144
     BatchNorm2d-748           [-1, 256, 16, 8]             512
            ReLU-749           [-1, 256, 16, 8]               0
          Conv2d-750           [-1, 256, 16, 8]         589,824
     BatchNorm2d-751           [-1, 256, 16, 8]             512
            ReLU-752           [-1, 256, 16, 8]               0
          Conv2d-753          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-754          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-755           [-1, 1024, 1, 1]               0
          Linear-756                   [-1, 64]          65,536
            ReLU-757                   [-1, 64]               0
          Linear-758                 [-1, 1024]          65,536
         Sigmoid-759                 [-1, 1024]               0
         SELayer-760          [-1, 1024, 16, 8]               0
            ReLU-761          [-1, 1024, 16, 8]               0
      Bottleneck-762          [-1, 1024, 16, 8]               0
          Conv2d-763           [-1, 512, 16, 8]         524,288
     BatchNorm2d-764           [-1, 512, 16, 8]           1,024
            ReLU-765           [-1, 512, 16, 8]               0
          Conv2d-766           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-767           [-1, 512, 16, 8]           1,024
            ReLU-768           [-1, 512, 16, 8]               0
          Conv2d-769          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-770          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-771           [-1, 2048, 1, 1]               0
          Linear-772                  [-1, 128]         262,144
            ReLU-773                  [-1, 128]               0
          Linear-774                 [-1, 2048]         262,144
         Sigmoid-775                 [-1, 2048]               0
         SELayer-776          [-1, 2048, 16, 8]               0
          Conv2d-777          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-778          [-1, 2048, 16, 8]           4,096
            ReLU-779          [-1, 2048, 16, 8]               0
      Bottleneck-780          [-1, 2048, 16, 8]               0
          Conv2d-781           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-782           [-1, 512, 16, 8]           1,024
            ReLU-783           [-1, 512, 16, 8]               0
          Conv2d-784           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-785           [-1, 512, 16, 8]           1,024
            ReLU-786           [-1, 512, 16, 8]               0
          Conv2d-787          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-788          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-789           [-1, 2048, 1, 1]               0
          Linear-790                  [-1, 128]         262,144
            ReLU-791                  [-1, 128]               0
          Linear-792                 [-1, 2048]         262,144
         Sigmoid-793                 [-1, 2048]               0
         SELayer-794          [-1, 2048, 16, 8]               0
            ReLU-795          [-1, 2048, 16, 8]               0
      Bottleneck-796          [-1, 2048, 16, 8]               0
          Conv2d-797           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-798           [-1, 512, 16, 8]           1,024
            ReLU-799           [-1, 512, 16, 8]               0
          Conv2d-800           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-801           [-1, 512, 16, 8]           1,024
            ReLU-802           [-1, 512, 16, 8]               0
          Conv2d-803          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-804          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-805           [-1, 2048, 1, 1]               0
          Linear-806                  [-1, 128]         262,144
            ReLU-807                  [-1, 128]               0
          Linear-808                 [-1, 2048]         262,144
         Sigmoid-809                 [-1, 2048]               0
         SELayer-810          [-1, 2048, 16, 8]               0
            ReLU-811          [-1, 2048, 16, 8]               0
      Bottleneck-812          [-1, 2048, 16, 8]               0
================================================================
Total params: 64,721,984
Trainable params: 64,721,984
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 493.89
Params size (MB): 246.89
Estimated Total Size (MB): 741.16
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet152_se_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
    InstanceNorm2d-6           [-1, 32, 64, 32]              64
       BatchNorm2d-7           [-1, 32, 64, 32]              64
               IBN-8           [-1, 64, 64, 32]               0
              ReLU-9           [-1, 64, 64, 32]               0
           Conv2d-10           [-1, 64, 64, 32]          36,864
      BatchNorm2d-11           [-1, 64, 64, 32]             128
             ReLU-12           [-1, 64, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-15            [-1, 256, 1, 1]               0
           Linear-16                   [-1, 16]           4,096
             ReLU-17                   [-1, 16]               0
           Linear-18                  [-1, 256]           4,096
          Sigmoid-19                  [-1, 256]               0
          SELayer-20          [-1, 256, 64, 32]               0
           Conv2d-21          [-1, 256, 64, 32]          16,384
      BatchNorm2d-22          [-1, 256, 64, 32]             512
             ReLU-23          [-1, 256, 64, 32]               0
       Bottleneck-24          [-1, 256, 64, 32]               0
           Conv2d-25           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-26           [-1, 32, 64, 32]              64
      BatchNorm2d-27           [-1, 32, 64, 32]              64
              IBN-28           [-1, 64, 64, 32]               0
             ReLU-29           [-1, 64, 64, 32]               0
           Conv2d-30           [-1, 64, 64, 32]          36,864
      BatchNorm2d-31           [-1, 64, 64, 32]             128
             ReLU-32           [-1, 64, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          16,384
      BatchNorm2d-34          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-35            [-1, 256, 1, 1]               0
           Linear-36                   [-1, 16]           4,096
             ReLU-37                   [-1, 16]               0
           Linear-38                  [-1, 256]           4,096
          Sigmoid-39                  [-1, 256]               0
          SELayer-40          [-1, 256, 64, 32]               0
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-44           [-1, 32, 64, 32]              64
      BatchNorm2d-45           [-1, 32, 64, 32]              64
              IBN-46           [-1, 64, 64, 32]               0
             ReLU-47           [-1, 64, 64, 32]               0
           Conv2d-48           [-1, 64, 64, 32]          36,864
      BatchNorm2d-49           [-1, 64, 64, 32]             128
             ReLU-50           [-1, 64, 64, 32]               0
           Conv2d-51          [-1, 256, 64, 32]          16,384
      BatchNorm2d-52          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-53            [-1, 256, 1, 1]               0
           Linear-54                   [-1, 16]           4,096
             ReLU-55                   [-1, 16]               0
           Linear-56                  [-1, 256]           4,096
          Sigmoid-57                  [-1, 256]               0
          SELayer-58          [-1, 256, 64, 32]               0
             ReLU-59          [-1, 256, 64, 32]               0
       Bottleneck-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-62           [-1, 64, 64, 32]             128
      BatchNorm2d-63           [-1, 64, 64, 32]             128
              IBN-64          [-1, 128, 64, 32]               0
             ReLU-65          [-1, 128, 64, 32]               0
           Conv2d-66          [-1, 128, 32, 16]         147,456
      BatchNorm2d-67          [-1, 128, 32, 16]             256
             ReLU-68          [-1, 128, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]          65,536
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-71            [-1, 512, 1, 1]               0
           Linear-72                   [-1, 32]          16,384
             ReLU-73                   [-1, 32]               0
           Linear-74                  [-1, 512]          16,384
          Sigmoid-75                  [-1, 512]               0
          SELayer-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         131,072
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-82           [-1, 64, 32, 16]             128
      BatchNorm2d-83           [-1, 64, 32, 16]             128
              IBN-84          [-1, 128, 32, 16]               0
             ReLU-85          [-1, 128, 32, 16]               0
           Conv2d-86          [-1, 128, 32, 16]         147,456
      BatchNorm2d-87          [-1, 128, 32, 16]             256
             ReLU-88          [-1, 128, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]          65,536
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-91            [-1, 512, 1, 1]               0
           Linear-92                   [-1, 32]          16,384
             ReLU-93                   [-1, 32]               0
           Linear-94                  [-1, 512]          16,384
          Sigmoid-95                  [-1, 512]               0
          SELayer-96          [-1, 512, 32, 16]               0
             ReLU-97          [-1, 512, 32, 16]               0
       Bottleneck-98          [-1, 512, 32, 16]               0
           Conv2d-99          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-100           [-1, 64, 32, 16]             128
     BatchNorm2d-101           [-1, 64, 32, 16]             128
             IBN-102          [-1, 128, 32, 16]               0
            ReLU-103          [-1, 128, 32, 16]               0
          Conv2d-104          [-1, 128, 32, 16]         147,456
     BatchNorm2d-105          [-1, 128, 32, 16]             256
            ReLU-106          [-1, 128, 32, 16]               0
          Conv2d-107          [-1, 512, 32, 16]          65,536
     BatchNorm2d-108          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-109            [-1, 512, 1, 1]               0
          Linear-110                   [-1, 32]          16,384
            ReLU-111                   [-1, 32]               0
          Linear-112                  [-1, 512]          16,384
         Sigmoid-113                  [-1, 512]               0
         SELayer-114          [-1, 512, 32, 16]               0
            ReLU-115          [-1, 512, 32, 16]               0
      Bottleneck-116          [-1, 512, 32, 16]               0
          Conv2d-117          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-118           [-1, 64, 32, 16]             128
     BatchNorm2d-119           [-1, 64, 32, 16]             128
             IBN-120          [-1, 128, 32, 16]               0
            ReLU-121          [-1, 128, 32, 16]               0
          Conv2d-122          [-1, 128, 32, 16]         147,456
     BatchNorm2d-123          [-1, 128, 32, 16]             256
            ReLU-124          [-1, 128, 32, 16]               0
          Conv2d-125          [-1, 512, 32, 16]          65,536
     BatchNorm2d-126          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-127            [-1, 512, 1, 1]               0
          Linear-128                   [-1, 32]          16,384
            ReLU-129                   [-1, 32]               0
          Linear-130                  [-1, 512]          16,384
         Sigmoid-131                  [-1, 512]               0
         SELayer-132          [-1, 512, 32, 16]               0
            ReLU-133          [-1, 512, 32, 16]               0
      Bottleneck-134          [-1, 512, 32, 16]               0
          Conv2d-135          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-136           [-1, 64, 32, 16]             128
     BatchNorm2d-137           [-1, 64, 32, 16]             128
             IBN-138          [-1, 128, 32, 16]               0
            ReLU-139          [-1, 128, 32, 16]               0
          Conv2d-140          [-1, 128, 32, 16]         147,456
     BatchNorm2d-141          [-1, 128, 32, 16]             256
            ReLU-142          [-1, 128, 32, 16]               0
          Conv2d-143          [-1, 512, 32, 16]          65,536
     BatchNorm2d-144          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-145            [-1, 512, 1, 1]               0
          Linear-146                   [-1, 32]          16,384
            ReLU-147                   [-1, 32]               0
          Linear-148                  [-1, 512]          16,384
         Sigmoid-149                  [-1, 512]               0
         SELayer-150          [-1, 512, 32, 16]               0
            ReLU-151          [-1, 512, 32, 16]               0
      Bottleneck-152          [-1, 512, 32, 16]               0
          Conv2d-153          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-154           [-1, 64, 32, 16]             128
     BatchNorm2d-155           [-1, 64, 32, 16]             128
             IBN-156          [-1, 128, 32, 16]               0
            ReLU-157          [-1, 128, 32, 16]               0
          Conv2d-158          [-1, 128, 32, 16]         147,456
     BatchNorm2d-159          [-1, 128, 32, 16]             256
            ReLU-160          [-1, 128, 32, 16]               0
          Conv2d-161          [-1, 512, 32, 16]          65,536
     BatchNorm2d-162          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-163            [-1, 512, 1, 1]               0
          Linear-164                   [-1, 32]          16,384
            ReLU-165                   [-1, 32]               0
          Linear-166                  [-1, 512]          16,384
         Sigmoid-167                  [-1, 512]               0
         SELayer-168          [-1, 512, 32, 16]               0
            ReLU-169          [-1, 512, 32, 16]               0
      Bottleneck-170          [-1, 512, 32, 16]               0
          Conv2d-171          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-172           [-1, 64, 32, 16]             128
     BatchNorm2d-173           [-1, 64, 32, 16]             128
             IBN-174          [-1, 128, 32, 16]               0
            ReLU-175          [-1, 128, 32, 16]               0
          Conv2d-176          [-1, 128, 32, 16]         147,456
     BatchNorm2d-177          [-1, 128, 32, 16]             256
            ReLU-178          [-1, 128, 32, 16]               0
          Conv2d-179          [-1, 512, 32, 16]          65,536
     BatchNorm2d-180          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-181            [-1, 512, 1, 1]               0
          Linear-182                   [-1, 32]          16,384
            ReLU-183                   [-1, 32]               0
          Linear-184                  [-1, 512]          16,384
         Sigmoid-185                  [-1, 512]               0
         SELayer-186          [-1, 512, 32, 16]               0
            ReLU-187          [-1, 512, 32, 16]               0
      Bottleneck-188          [-1, 512, 32, 16]               0
          Conv2d-189          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-190           [-1, 64, 32, 16]             128
     BatchNorm2d-191           [-1, 64, 32, 16]             128
             IBN-192          [-1, 128, 32, 16]               0
            ReLU-193          [-1, 128, 32, 16]               0
          Conv2d-194          [-1, 128, 32, 16]         147,456
     BatchNorm2d-195          [-1, 128, 32, 16]             256
            ReLU-196          [-1, 128, 32, 16]               0
          Conv2d-197          [-1, 512, 32, 16]          65,536
     BatchNorm2d-198          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-199            [-1, 512, 1, 1]               0
          Linear-200                   [-1, 32]          16,384
            ReLU-201                   [-1, 32]               0
          Linear-202                  [-1, 512]          16,384
         Sigmoid-203                  [-1, 512]               0
         SELayer-204          [-1, 512, 32, 16]               0
            ReLU-205          [-1, 512, 32, 16]               0
      Bottleneck-206          [-1, 512, 32, 16]               0
          Conv2d-207          [-1, 256, 32, 16]         131,072
  InstanceNorm2d-208          [-1, 128, 32, 16]             256
     BatchNorm2d-209          [-1, 128, 32, 16]             256
             IBN-210          [-1, 256, 32, 16]               0
            ReLU-211          [-1, 256, 32, 16]               0
          Conv2d-212           [-1, 256, 16, 8]         589,824
     BatchNorm2d-213           [-1, 256, 16, 8]             512
            ReLU-214           [-1, 256, 16, 8]               0
          Conv2d-215          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-216          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-217           [-1, 1024, 1, 1]               0
          Linear-218                   [-1, 64]          65,536
            ReLU-219                   [-1, 64]               0
          Linear-220                 [-1, 1024]          65,536
         Sigmoid-221                 [-1, 1024]               0
         SELayer-222          [-1, 1024, 16, 8]               0
          Conv2d-223          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-224          [-1, 1024, 16, 8]           2,048
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-228           [-1, 128, 16, 8]             256
     BatchNorm2d-229           [-1, 128, 16, 8]             256
             IBN-230           [-1, 256, 16, 8]               0
            ReLU-231           [-1, 256, 16, 8]               0
          Conv2d-232           [-1, 256, 16, 8]         589,824
     BatchNorm2d-233           [-1, 256, 16, 8]             512
            ReLU-234           [-1, 256, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-237           [-1, 1024, 1, 1]               0
          Linear-238                   [-1, 64]          65,536
            ReLU-239                   [-1, 64]               0
          Linear-240                 [-1, 1024]          65,536
         Sigmoid-241                 [-1, 1024]               0
         SELayer-242          [-1, 1024, 16, 8]               0
            ReLU-243          [-1, 1024, 16, 8]               0
      Bottleneck-244          [-1, 1024, 16, 8]               0
          Conv2d-245           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-246           [-1, 128, 16, 8]             256
     BatchNorm2d-247           [-1, 128, 16, 8]             256
             IBN-248           [-1, 256, 16, 8]               0
            ReLU-249           [-1, 256, 16, 8]               0
          Conv2d-250           [-1, 256, 16, 8]         589,824
     BatchNorm2d-251           [-1, 256, 16, 8]             512
            ReLU-252           [-1, 256, 16, 8]               0
          Conv2d-253          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-254          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-255           [-1, 1024, 1, 1]               0
          Linear-256                   [-1, 64]          65,536
            ReLU-257                   [-1, 64]               0
          Linear-258                 [-1, 1024]          65,536
         Sigmoid-259                 [-1, 1024]               0
         SELayer-260          [-1, 1024, 16, 8]               0
            ReLU-261          [-1, 1024, 16, 8]               0
      Bottleneck-262          [-1, 1024, 16, 8]               0
          Conv2d-263           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-264           [-1, 128, 16, 8]             256
     BatchNorm2d-265           [-1, 128, 16, 8]             256
             IBN-266           [-1, 256, 16, 8]               0
            ReLU-267           [-1, 256, 16, 8]               0
          Conv2d-268           [-1, 256, 16, 8]         589,824
     BatchNorm2d-269           [-1, 256, 16, 8]             512
            ReLU-270           [-1, 256, 16, 8]               0
          Conv2d-271          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-272          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-273           [-1, 1024, 1, 1]               0
          Linear-274                   [-1, 64]          65,536
            ReLU-275                   [-1, 64]               0
          Linear-276                 [-1, 1024]          65,536
         Sigmoid-277                 [-1, 1024]               0
         SELayer-278          [-1, 1024, 16, 8]               0
            ReLU-279          [-1, 1024, 16, 8]               0
      Bottleneck-280          [-1, 1024, 16, 8]               0
          Conv2d-281           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-282           [-1, 128, 16, 8]             256
     BatchNorm2d-283           [-1, 128, 16, 8]             256
             IBN-284           [-1, 256, 16, 8]               0
            ReLU-285           [-1, 256, 16, 8]               0
          Conv2d-286           [-1, 256, 16, 8]         589,824
     BatchNorm2d-287           [-1, 256, 16, 8]             512
            ReLU-288           [-1, 256, 16, 8]               0
          Conv2d-289          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-290          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-291           [-1, 1024, 1, 1]               0
          Linear-292                   [-1, 64]          65,536
            ReLU-293                   [-1, 64]               0
          Linear-294                 [-1, 1024]          65,536
         Sigmoid-295                 [-1, 1024]               0
         SELayer-296          [-1, 1024, 16, 8]               0
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-300           [-1, 128, 16, 8]             256
     BatchNorm2d-301           [-1, 128, 16, 8]             256
             IBN-302           [-1, 256, 16, 8]               0
            ReLU-303           [-1, 256, 16, 8]               0
          Conv2d-304           [-1, 256, 16, 8]         589,824
     BatchNorm2d-305           [-1, 256, 16, 8]             512
            ReLU-306           [-1, 256, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-309           [-1, 1024, 1, 1]               0
          Linear-310                   [-1, 64]          65,536
            ReLU-311                   [-1, 64]               0
          Linear-312                 [-1, 1024]          65,536
         Sigmoid-313                 [-1, 1024]               0
         SELayer-314          [-1, 1024, 16, 8]               0
            ReLU-315          [-1, 1024, 16, 8]               0
      Bottleneck-316          [-1, 1024, 16, 8]               0
          Conv2d-317           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-318           [-1, 128, 16, 8]             256
     BatchNorm2d-319           [-1, 128, 16, 8]             256
             IBN-320           [-1, 256, 16, 8]               0
            ReLU-321           [-1, 256, 16, 8]               0
          Conv2d-322           [-1, 256, 16, 8]         589,824
     BatchNorm2d-323           [-1, 256, 16, 8]             512
            ReLU-324           [-1, 256, 16, 8]               0
          Conv2d-325          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-326          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-327           [-1, 1024, 1, 1]               0
          Linear-328                   [-1, 64]          65,536
            ReLU-329                   [-1, 64]               0
          Linear-330                 [-1, 1024]          65,536
         Sigmoid-331                 [-1, 1024]               0
         SELayer-332          [-1, 1024, 16, 8]               0
            ReLU-333          [-1, 1024, 16, 8]               0
      Bottleneck-334          [-1, 1024, 16, 8]               0
          Conv2d-335           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-336           [-1, 128, 16, 8]             256
     BatchNorm2d-337           [-1, 128, 16, 8]             256
             IBN-338           [-1, 256, 16, 8]               0
            ReLU-339           [-1, 256, 16, 8]               0
          Conv2d-340           [-1, 256, 16, 8]         589,824
     BatchNorm2d-341           [-1, 256, 16, 8]             512
            ReLU-342           [-1, 256, 16, 8]               0
          Conv2d-343          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-344          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-345           [-1, 1024, 1, 1]               0
          Linear-346                   [-1, 64]          65,536
            ReLU-347                   [-1, 64]               0
          Linear-348                 [-1, 1024]          65,536
         Sigmoid-349                 [-1, 1024]               0
         SELayer-350          [-1, 1024, 16, 8]               0
            ReLU-351          [-1, 1024, 16, 8]               0
      Bottleneck-352          [-1, 1024, 16, 8]               0
          Conv2d-353           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-354           [-1, 128, 16, 8]             256
     BatchNorm2d-355           [-1, 128, 16, 8]             256
             IBN-356           [-1, 256, 16, 8]               0
            ReLU-357           [-1, 256, 16, 8]               0
          Conv2d-358           [-1, 256, 16, 8]         589,824
     BatchNorm2d-359           [-1, 256, 16, 8]             512
            ReLU-360           [-1, 256, 16, 8]               0
          Conv2d-361          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-362          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-363           [-1, 1024, 1, 1]               0
          Linear-364                   [-1, 64]          65,536
            ReLU-365                   [-1, 64]               0
          Linear-366                 [-1, 1024]          65,536
         Sigmoid-367                 [-1, 1024]               0
         SELayer-368          [-1, 1024, 16, 8]               0
            ReLU-369          [-1, 1024, 16, 8]               0
      Bottleneck-370          [-1, 1024, 16, 8]               0
          Conv2d-371           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-372           [-1, 128, 16, 8]             256
     BatchNorm2d-373           [-1, 128, 16, 8]             256
             IBN-374           [-1, 256, 16, 8]               0
            ReLU-375           [-1, 256, 16, 8]               0
          Conv2d-376           [-1, 256, 16, 8]         589,824
     BatchNorm2d-377           [-1, 256, 16, 8]             512
            ReLU-378           [-1, 256, 16, 8]               0
          Conv2d-379          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-380          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-381           [-1, 1024, 1, 1]               0
          Linear-382                   [-1, 64]          65,536
            ReLU-383                   [-1, 64]               0
          Linear-384                 [-1, 1024]          65,536
         Sigmoid-385                 [-1, 1024]               0
         SELayer-386          [-1, 1024, 16, 8]               0
            ReLU-387          [-1, 1024, 16, 8]               0
      Bottleneck-388          [-1, 1024, 16, 8]               0
          Conv2d-389           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-390           [-1, 128, 16, 8]             256
     BatchNorm2d-391           [-1, 128, 16, 8]             256
             IBN-392           [-1, 256, 16, 8]               0
            ReLU-393           [-1, 256, 16, 8]               0
          Conv2d-394           [-1, 256, 16, 8]         589,824
     BatchNorm2d-395           [-1, 256, 16, 8]             512
            ReLU-396           [-1, 256, 16, 8]               0
          Conv2d-397          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-398          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-399           [-1, 1024, 1, 1]               0
          Linear-400                   [-1, 64]          65,536
            ReLU-401                   [-1, 64]               0
          Linear-402                 [-1, 1024]          65,536
         Sigmoid-403                 [-1, 1024]               0
         SELayer-404          [-1, 1024, 16, 8]               0
            ReLU-405          [-1, 1024, 16, 8]               0
      Bottleneck-406          [-1, 1024, 16, 8]               0
          Conv2d-407           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-408           [-1, 128, 16, 8]             256
     BatchNorm2d-409           [-1, 128, 16, 8]             256
             IBN-410           [-1, 256, 16, 8]               0
            ReLU-411           [-1, 256, 16, 8]               0
          Conv2d-412           [-1, 256, 16, 8]         589,824
     BatchNorm2d-413           [-1, 256, 16, 8]             512
            ReLU-414           [-1, 256, 16, 8]               0
          Conv2d-415          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-416          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-417           [-1, 1024, 1, 1]               0
          Linear-418                   [-1, 64]          65,536
            ReLU-419                   [-1, 64]               0
          Linear-420                 [-1, 1024]          65,536
         Sigmoid-421                 [-1, 1024]               0
         SELayer-422          [-1, 1024, 16, 8]               0
            ReLU-423          [-1, 1024, 16, 8]               0
      Bottleneck-424          [-1, 1024, 16, 8]               0
          Conv2d-425           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-426           [-1, 128, 16, 8]             256
     BatchNorm2d-427           [-1, 128, 16, 8]             256
             IBN-428           [-1, 256, 16, 8]               0
            ReLU-429           [-1, 256, 16, 8]               0
          Conv2d-430           [-1, 256, 16, 8]         589,824
     BatchNorm2d-431           [-1, 256, 16, 8]             512
            ReLU-432           [-1, 256, 16, 8]               0
          Conv2d-433          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-434          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-435           [-1, 1024, 1, 1]               0
          Linear-436                   [-1, 64]          65,536
            ReLU-437                   [-1, 64]               0
          Linear-438                 [-1, 1024]          65,536
         Sigmoid-439                 [-1, 1024]               0
         SELayer-440          [-1, 1024, 16, 8]               0
            ReLU-441          [-1, 1024, 16, 8]               0
      Bottleneck-442          [-1, 1024, 16, 8]               0
          Conv2d-443           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-444           [-1, 128, 16, 8]             256
     BatchNorm2d-445           [-1, 128, 16, 8]             256
             IBN-446           [-1, 256, 16, 8]               0
            ReLU-447           [-1, 256, 16, 8]               0
          Conv2d-448           [-1, 256, 16, 8]         589,824
     BatchNorm2d-449           [-1, 256, 16, 8]             512
            ReLU-450           [-1, 256, 16, 8]               0
          Conv2d-451          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-452          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-453           [-1, 1024, 1, 1]               0
          Linear-454                   [-1, 64]          65,536
            ReLU-455                   [-1, 64]               0
          Linear-456                 [-1, 1024]          65,536
         Sigmoid-457                 [-1, 1024]               0
         SELayer-458          [-1, 1024, 16, 8]               0
            ReLU-459          [-1, 1024, 16, 8]               0
      Bottleneck-460          [-1, 1024, 16, 8]               0
          Conv2d-461           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-462           [-1, 128, 16, 8]             256
     BatchNorm2d-463           [-1, 128, 16, 8]             256
             IBN-464           [-1, 256, 16, 8]               0
            ReLU-465           [-1, 256, 16, 8]               0
          Conv2d-466           [-1, 256, 16, 8]         589,824
     BatchNorm2d-467           [-1, 256, 16, 8]             512
            ReLU-468           [-1, 256, 16, 8]               0
          Conv2d-469          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-470          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-471           [-1, 1024, 1, 1]               0
          Linear-472                   [-1, 64]          65,536
            ReLU-473                   [-1, 64]               0
          Linear-474                 [-1, 1024]          65,536
         Sigmoid-475                 [-1, 1024]               0
         SELayer-476          [-1, 1024, 16, 8]               0
            ReLU-477          [-1, 1024, 16, 8]               0
      Bottleneck-478          [-1, 1024, 16, 8]               0
          Conv2d-479           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-480           [-1, 128, 16, 8]             256
     BatchNorm2d-481           [-1, 128, 16, 8]             256
             IBN-482           [-1, 256, 16, 8]               0
            ReLU-483           [-1, 256, 16, 8]               0
          Conv2d-484           [-1, 256, 16, 8]         589,824
     BatchNorm2d-485           [-1, 256, 16, 8]             512
            ReLU-486           [-1, 256, 16, 8]               0
          Conv2d-487          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-488          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-489           [-1, 1024, 1, 1]               0
          Linear-490                   [-1, 64]          65,536
            ReLU-491                   [-1, 64]               0
          Linear-492                 [-1, 1024]          65,536
         Sigmoid-493                 [-1, 1024]               0
         SELayer-494          [-1, 1024, 16, 8]               0
            ReLU-495          [-1, 1024, 16, 8]               0
      Bottleneck-496          [-1, 1024, 16, 8]               0
          Conv2d-497           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-498           [-1, 128, 16, 8]             256
     BatchNorm2d-499           [-1, 128, 16, 8]             256
             IBN-500           [-1, 256, 16, 8]               0
            ReLU-501           [-1, 256, 16, 8]               0
          Conv2d-502           [-1, 256, 16, 8]         589,824
     BatchNorm2d-503           [-1, 256, 16, 8]             512
            ReLU-504           [-1, 256, 16, 8]               0
          Conv2d-505          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-506          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-507           [-1, 1024, 1, 1]               0
          Linear-508                   [-1, 64]          65,536
            ReLU-509                   [-1, 64]               0
          Linear-510                 [-1, 1024]          65,536
         Sigmoid-511                 [-1, 1024]               0
         SELayer-512          [-1, 1024, 16, 8]               0
            ReLU-513          [-1, 1024, 16, 8]               0
      Bottleneck-514          [-1, 1024, 16, 8]               0
          Conv2d-515           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-516           [-1, 128, 16, 8]             256
     BatchNorm2d-517           [-1, 128, 16, 8]             256
             IBN-518           [-1, 256, 16, 8]               0
            ReLU-519           [-1, 256, 16, 8]               0
          Conv2d-520           [-1, 256, 16, 8]         589,824
     BatchNorm2d-521           [-1, 256, 16, 8]             512
            ReLU-522           [-1, 256, 16, 8]               0
          Conv2d-523          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-524          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-525           [-1, 1024, 1, 1]               0
          Linear-526                   [-1, 64]          65,536
            ReLU-527                   [-1, 64]               0
          Linear-528                 [-1, 1024]          65,536
         Sigmoid-529                 [-1, 1024]               0
         SELayer-530          [-1, 1024, 16, 8]               0
            ReLU-531          [-1, 1024, 16, 8]               0
      Bottleneck-532          [-1, 1024, 16, 8]               0
          Conv2d-533           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-534           [-1, 128, 16, 8]             256
     BatchNorm2d-535           [-1, 128, 16, 8]             256
             IBN-536           [-1, 256, 16, 8]               0
            ReLU-537           [-1, 256, 16, 8]               0
          Conv2d-538           [-1, 256, 16, 8]         589,824
     BatchNorm2d-539           [-1, 256, 16, 8]             512
            ReLU-540           [-1, 256, 16, 8]               0
          Conv2d-541          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-542          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-543           [-1, 1024, 1, 1]               0
          Linear-544                   [-1, 64]          65,536
            ReLU-545                   [-1, 64]               0
          Linear-546                 [-1, 1024]          65,536
         Sigmoid-547                 [-1, 1024]               0
         SELayer-548          [-1, 1024, 16, 8]               0
            ReLU-549          [-1, 1024, 16, 8]               0
      Bottleneck-550          [-1, 1024, 16, 8]               0
          Conv2d-551           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-552           [-1, 128, 16, 8]             256
     BatchNorm2d-553           [-1, 128, 16, 8]             256
             IBN-554           [-1, 256, 16, 8]               0
            ReLU-555           [-1, 256, 16, 8]               0
          Conv2d-556           [-1, 256, 16, 8]         589,824
     BatchNorm2d-557           [-1, 256, 16, 8]             512
            ReLU-558           [-1, 256, 16, 8]               0
          Conv2d-559          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-560          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-561           [-1, 1024, 1, 1]               0
          Linear-562                   [-1, 64]          65,536
            ReLU-563                   [-1, 64]               0
          Linear-564                 [-1, 1024]          65,536
         Sigmoid-565                 [-1, 1024]               0
         SELayer-566          [-1, 1024, 16, 8]               0
            ReLU-567          [-1, 1024, 16, 8]               0
      Bottleneck-568          [-1, 1024, 16, 8]               0
          Conv2d-569           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-570           [-1, 128, 16, 8]             256
     BatchNorm2d-571           [-1, 128, 16, 8]             256
             IBN-572           [-1, 256, 16, 8]               0
            ReLU-573           [-1, 256, 16, 8]               0
          Conv2d-574           [-1, 256, 16, 8]         589,824
     BatchNorm2d-575           [-1, 256, 16, 8]             512
            ReLU-576           [-1, 256, 16, 8]               0
          Conv2d-577          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-578          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-579           [-1, 1024, 1, 1]               0
          Linear-580                   [-1, 64]          65,536
            ReLU-581                   [-1, 64]               0
          Linear-582                 [-1, 1024]          65,536
         Sigmoid-583                 [-1, 1024]               0
         SELayer-584          [-1, 1024, 16, 8]               0
            ReLU-585          [-1, 1024, 16, 8]               0
      Bottleneck-586          [-1, 1024, 16, 8]               0
          Conv2d-587           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-588           [-1, 128, 16, 8]             256
     BatchNorm2d-589           [-1, 128, 16, 8]             256
             IBN-590           [-1, 256, 16, 8]               0
            ReLU-591           [-1, 256, 16, 8]               0
          Conv2d-592           [-1, 256, 16, 8]         589,824
     BatchNorm2d-593           [-1, 256, 16, 8]             512
            ReLU-594           [-1, 256, 16, 8]               0
          Conv2d-595          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-596          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-597           [-1, 1024, 1, 1]               0
          Linear-598                   [-1, 64]          65,536
            ReLU-599                   [-1, 64]               0
          Linear-600                 [-1, 1024]          65,536
         Sigmoid-601                 [-1, 1024]               0
         SELayer-602          [-1, 1024, 16, 8]               0
            ReLU-603          [-1, 1024, 16, 8]               0
      Bottleneck-604          [-1, 1024, 16, 8]               0
          Conv2d-605           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-606           [-1, 128, 16, 8]             256
     BatchNorm2d-607           [-1, 128, 16, 8]             256
             IBN-608           [-1, 256, 16, 8]               0
            ReLU-609           [-1, 256, 16, 8]               0
          Conv2d-610           [-1, 256, 16, 8]         589,824
     BatchNorm2d-611           [-1, 256, 16, 8]             512
            ReLU-612           [-1, 256, 16, 8]               0
          Conv2d-613          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-614          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-615           [-1, 1024, 1, 1]               0
          Linear-616                   [-1, 64]          65,536
            ReLU-617                   [-1, 64]               0
          Linear-618                 [-1, 1024]          65,536
         Sigmoid-619                 [-1, 1024]               0
         SELayer-620          [-1, 1024, 16, 8]               0
            ReLU-621          [-1, 1024, 16, 8]               0
      Bottleneck-622          [-1, 1024, 16, 8]               0
          Conv2d-623           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-624           [-1, 128, 16, 8]             256
     BatchNorm2d-625           [-1, 128, 16, 8]             256
             IBN-626           [-1, 256, 16, 8]               0
            ReLU-627           [-1, 256, 16, 8]               0
          Conv2d-628           [-1, 256, 16, 8]         589,824
     BatchNorm2d-629           [-1, 256, 16, 8]             512
            ReLU-630           [-1, 256, 16, 8]               0
          Conv2d-631          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-632          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-633           [-1, 1024, 1, 1]               0
          Linear-634                   [-1, 64]          65,536
            ReLU-635                   [-1, 64]               0
          Linear-636                 [-1, 1024]          65,536
         Sigmoid-637                 [-1, 1024]               0
         SELayer-638          [-1, 1024, 16, 8]               0
            ReLU-639          [-1, 1024, 16, 8]               0
      Bottleneck-640          [-1, 1024, 16, 8]               0
          Conv2d-641           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-642           [-1, 128, 16, 8]             256
     BatchNorm2d-643           [-1, 128, 16, 8]             256
             IBN-644           [-1, 256, 16, 8]               0
            ReLU-645           [-1, 256, 16, 8]               0
          Conv2d-646           [-1, 256, 16, 8]         589,824
     BatchNorm2d-647           [-1, 256, 16, 8]             512
            ReLU-648           [-1, 256, 16, 8]               0
          Conv2d-649          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-650          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-651           [-1, 1024, 1, 1]               0
          Linear-652                   [-1, 64]          65,536
            ReLU-653                   [-1, 64]               0
          Linear-654                 [-1, 1024]          65,536
         Sigmoid-655                 [-1, 1024]               0
         SELayer-656          [-1, 1024, 16, 8]               0
            ReLU-657          [-1, 1024, 16, 8]               0
      Bottleneck-658          [-1, 1024, 16, 8]               0
          Conv2d-659           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-660           [-1, 128, 16, 8]             256
     BatchNorm2d-661           [-1, 128, 16, 8]             256
             IBN-662           [-1, 256, 16, 8]               0
            ReLU-663           [-1, 256, 16, 8]               0
          Conv2d-664           [-1, 256, 16, 8]         589,824
     BatchNorm2d-665           [-1, 256, 16, 8]             512
            ReLU-666           [-1, 256, 16, 8]               0
          Conv2d-667          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-668          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-669           [-1, 1024, 1, 1]               0
          Linear-670                   [-1, 64]          65,536
            ReLU-671                   [-1, 64]               0
          Linear-672                 [-1, 1024]          65,536
         Sigmoid-673                 [-1, 1024]               0
         SELayer-674          [-1, 1024, 16, 8]               0
            ReLU-675          [-1, 1024, 16, 8]               0
      Bottleneck-676          [-1, 1024, 16, 8]               0
          Conv2d-677           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-678           [-1, 128, 16, 8]             256
     BatchNorm2d-679           [-1, 128, 16, 8]             256
             IBN-680           [-1, 256, 16, 8]               0
            ReLU-681           [-1, 256, 16, 8]               0
          Conv2d-682           [-1, 256, 16, 8]         589,824
     BatchNorm2d-683           [-1, 256, 16, 8]             512
            ReLU-684           [-1, 256, 16, 8]               0
          Conv2d-685          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-686          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-687           [-1, 1024, 1, 1]               0
          Linear-688                   [-1, 64]          65,536
            ReLU-689                   [-1, 64]               0
          Linear-690                 [-1, 1024]          65,536
         Sigmoid-691                 [-1, 1024]               0
         SELayer-692          [-1, 1024, 16, 8]               0
            ReLU-693          [-1, 1024, 16, 8]               0
      Bottleneck-694          [-1, 1024, 16, 8]               0
          Conv2d-695           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-696           [-1, 128, 16, 8]             256
     BatchNorm2d-697           [-1, 128, 16, 8]             256
             IBN-698           [-1, 256, 16, 8]               0
            ReLU-699           [-1, 256, 16, 8]               0
          Conv2d-700           [-1, 256, 16, 8]         589,824
     BatchNorm2d-701           [-1, 256, 16, 8]             512
            ReLU-702           [-1, 256, 16, 8]               0
          Conv2d-703          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-704          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-705           [-1, 1024, 1, 1]               0
          Linear-706                   [-1, 64]          65,536
            ReLU-707                   [-1, 64]               0
          Linear-708                 [-1, 1024]          65,536
         Sigmoid-709                 [-1, 1024]               0
         SELayer-710          [-1, 1024, 16, 8]               0
            ReLU-711          [-1, 1024, 16, 8]               0
      Bottleneck-712          [-1, 1024, 16, 8]               0
          Conv2d-713           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-714           [-1, 128, 16, 8]             256
     BatchNorm2d-715           [-1, 128, 16, 8]             256
             IBN-716           [-1, 256, 16, 8]               0
            ReLU-717           [-1, 256, 16, 8]               0
          Conv2d-718           [-1, 256, 16, 8]         589,824
     BatchNorm2d-719           [-1, 256, 16, 8]             512
            ReLU-720           [-1, 256, 16, 8]               0
          Conv2d-721          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-722          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-723           [-1, 1024, 1, 1]               0
          Linear-724                   [-1, 64]          65,536
            ReLU-725                   [-1, 64]               0
          Linear-726                 [-1, 1024]          65,536
         Sigmoid-727                 [-1, 1024]               0
         SELayer-728          [-1, 1024, 16, 8]               0
            ReLU-729          [-1, 1024, 16, 8]               0
      Bottleneck-730          [-1, 1024, 16, 8]               0
          Conv2d-731           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-732           [-1, 128, 16, 8]             256
     BatchNorm2d-733           [-1, 128, 16, 8]             256
             IBN-734           [-1, 256, 16, 8]               0
            ReLU-735           [-1, 256, 16, 8]               0
          Conv2d-736           [-1, 256, 16, 8]         589,824
     BatchNorm2d-737           [-1, 256, 16, 8]             512
            ReLU-738           [-1, 256, 16, 8]               0
          Conv2d-739          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-740          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-741           [-1, 1024, 1, 1]               0
          Linear-742                   [-1, 64]          65,536
            ReLU-743                   [-1, 64]               0
          Linear-744                 [-1, 1024]          65,536
         Sigmoid-745                 [-1, 1024]               0
         SELayer-746          [-1, 1024, 16, 8]               0
            ReLU-747          [-1, 1024, 16, 8]               0
      Bottleneck-748          [-1, 1024, 16, 8]               0
          Conv2d-749           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-750           [-1, 128, 16, 8]             256
     BatchNorm2d-751           [-1, 128, 16, 8]             256
             IBN-752           [-1, 256, 16, 8]               0
            ReLU-753           [-1, 256, 16, 8]               0
          Conv2d-754           [-1, 256, 16, 8]         589,824
     BatchNorm2d-755           [-1, 256, 16, 8]             512
            ReLU-756           [-1, 256, 16, 8]               0
          Conv2d-757          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-758          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-759           [-1, 1024, 1, 1]               0
          Linear-760                   [-1, 64]          65,536
            ReLU-761                   [-1, 64]               0
          Linear-762                 [-1, 1024]          65,536
         Sigmoid-763                 [-1, 1024]               0
         SELayer-764          [-1, 1024, 16, 8]               0
            ReLU-765          [-1, 1024, 16, 8]               0
      Bottleneck-766          [-1, 1024, 16, 8]               0
          Conv2d-767           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-768           [-1, 128, 16, 8]             256
     BatchNorm2d-769           [-1, 128, 16, 8]             256
             IBN-770           [-1, 256, 16, 8]               0
            ReLU-771           [-1, 256, 16, 8]               0
          Conv2d-772           [-1, 256, 16, 8]         589,824
     BatchNorm2d-773           [-1, 256, 16, 8]             512
            ReLU-774           [-1, 256, 16, 8]               0
          Conv2d-775          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-776          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-777           [-1, 1024, 1, 1]               0
          Linear-778                   [-1, 64]          65,536
            ReLU-779                   [-1, 64]               0
          Linear-780                 [-1, 1024]          65,536
         Sigmoid-781                 [-1, 1024]               0
         SELayer-782          [-1, 1024, 16, 8]               0
            ReLU-783          [-1, 1024, 16, 8]               0
      Bottleneck-784          [-1, 1024, 16, 8]               0
          Conv2d-785           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-786           [-1, 128, 16, 8]             256
     BatchNorm2d-787           [-1, 128, 16, 8]             256
             IBN-788           [-1, 256, 16, 8]               0
            ReLU-789           [-1, 256, 16, 8]               0
          Conv2d-790           [-1, 256, 16, 8]         589,824
     BatchNorm2d-791           [-1, 256, 16, 8]             512
            ReLU-792           [-1, 256, 16, 8]               0
          Conv2d-793          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-794          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-795           [-1, 1024, 1, 1]               0
          Linear-796                   [-1, 64]          65,536
            ReLU-797                   [-1, 64]               0
          Linear-798                 [-1, 1024]          65,536
         Sigmoid-799                 [-1, 1024]               0
         SELayer-800          [-1, 1024, 16, 8]               0
            ReLU-801          [-1, 1024, 16, 8]               0
      Bottleneck-802          [-1, 1024, 16, 8]               0
          Conv2d-803           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-804           [-1, 128, 16, 8]             256
     BatchNorm2d-805           [-1, 128, 16, 8]             256
             IBN-806           [-1, 256, 16, 8]               0
            ReLU-807           [-1, 256, 16, 8]               0
          Conv2d-808           [-1, 256, 16, 8]         589,824
     BatchNorm2d-809           [-1, 256, 16, 8]             512
            ReLU-810           [-1, 256, 16, 8]               0
          Conv2d-811          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-812          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-813           [-1, 1024, 1, 1]               0
          Linear-814                   [-1, 64]          65,536
            ReLU-815                   [-1, 64]               0
          Linear-816                 [-1, 1024]          65,536
         Sigmoid-817                 [-1, 1024]               0
         SELayer-818          [-1, 1024, 16, 8]               0
            ReLU-819          [-1, 1024, 16, 8]               0
      Bottleneck-820          [-1, 1024, 16, 8]               0
          Conv2d-821           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-822           [-1, 128, 16, 8]             256
     BatchNorm2d-823           [-1, 128, 16, 8]             256
             IBN-824           [-1, 256, 16, 8]               0
            ReLU-825           [-1, 256, 16, 8]               0
          Conv2d-826           [-1, 256, 16, 8]         589,824
     BatchNorm2d-827           [-1, 256, 16, 8]             512
            ReLU-828           [-1, 256, 16, 8]               0
          Conv2d-829          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-830          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-831           [-1, 1024, 1, 1]               0
          Linear-832                   [-1, 64]          65,536
            ReLU-833                   [-1, 64]               0
          Linear-834                 [-1, 1024]          65,536
         Sigmoid-835                 [-1, 1024]               0
         SELayer-836          [-1, 1024, 16, 8]               0
            ReLU-837          [-1, 1024, 16, 8]               0
      Bottleneck-838          [-1, 1024, 16, 8]               0
          Conv2d-839           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-840           [-1, 128, 16, 8]             256
     BatchNorm2d-841           [-1, 128, 16, 8]             256
             IBN-842           [-1, 256, 16, 8]               0
            ReLU-843           [-1, 256, 16, 8]               0
          Conv2d-844           [-1, 256, 16, 8]         589,824
     BatchNorm2d-845           [-1, 256, 16, 8]             512
            ReLU-846           [-1, 256, 16, 8]               0
          Conv2d-847          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-848          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-849           [-1, 1024, 1, 1]               0
          Linear-850                   [-1, 64]          65,536
            ReLU-851                   [-1, 64]               0
          Linear-852                 [-1, 1024]          65,536
         Sigmoid-853                 [-1, 1024]               0
         SELayer-854          [-1, 1024, 16, 8]               0
            ReLU-855          [-1, 1024, 16, 8]               0
      Bottleneck-856          [-1, 1024, 16, 8]               0
          Conv2d-857           [-1, 512, 16, 8]         524,288
     BatchNorm2d-858           [-1, 512, 16, 8]           1,024
            ReLU-859           [-1, 512, 16, 8]               0
          Conv2d-860           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-861           [-1, 512, 16, 8]           1,024
            ReLU-862           [-1, 512, 16, 8]               0
          Conv2d-863          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-864          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-865           [-1, 2048, 1, 1]               0
          Linear-866                  [-1, 128]         262,144
            ReLU-867                  [-1, 128]               0
          Linear-868                 [-1, 2048]         262,144
         Sigmoid-869                 [-1, 2048]               0
         SELayer-870          [-1, 2048, 16, 8]               0
          Conv2d-871          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-872          [-1, 2048, 16, 8]           4,096
            ReLU-873          [-1, 2048, 16, 8]               0
      Bottleneck-874          [-1, 2048, 16, 8]               0
          Conv2d-875           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-876           [-1, 512, 16, 8]           1,024
            ReLU-877           [-1, 512, 16, 8]               0
          Conv2d-878           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-879           [-1, 512, 16, 8]           1,024
            ReLU-880           [-1, 512, 16, 8]               0
          Conv2d-881          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-882          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-883           [-1, 2048, 1, 1]               0
          Linear-884                  [-1, 128]         262,144
            ReLU-885                  [-1, 128]               0
          Linear-886                 [-1, 2048]         262,144
         Sigmoid-887                 [-1, 2048]               0
         SELayer-888          [-1, 2048, 16, 8]               0
            ReLU-889          [-1, 2048, 16, 8]               0
      Bottleneck-890          [-1, 2048, 16, 8]               0
          Conv2d-891           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-892           [-1, 512, 16, 8]           1,024
            ReLU-893           [-1, 512, 16, 8]               0
          Conv2d-894           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-895           [-1, 512, 16, 8]           1,024
            ReLU-896           [-1, 512, 16, 8]               0
          Conv2d-897          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-898          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-899           [-1, 2048, 1, 1]               0
          Linear-900                  [-1, 128]         262,144
            ReLU-901                  [-1, 128]               0
          Linear-902                 [-1, 2048]         262,144
         Sigmoid-903                 [-1, 2048]               0
         SELayer-904          [-1, 2048, 16, 8]               0
            ReLU-905          [-1, 2048, 16, 8]               0
      Bottleneck-906          [-1, 2048, 16, 8]               0
================================================================
Total params: 64,721,984
Trainable params: 64,721,984
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 512.14
Params size (MB): 246.89
Estimated Total Size (MB): 759.41
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet152_se_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
   InstanceNorm2d-21          [-1, 256, 64, 32]             512
             ReLU-22          [-1, 256, 64, 32]               0
       Bottleneck-23          [-1, 256, 64, 32]               0
           Conv2d-24           [-1, 64, 64, 32]          16,384
      BatchNorm2d-25           [-1, 64, 64, 32]             128
             ReLU-26           [-1, 64, 64, 32]               0
           Conv2d-27           [-1, 64, 64, 32]          36,864
      BatchNorm2d-28           [-1, 64, 64, 32]             128
             ReLU-29           [-1, 64, 64, 32]               0
           Conv2d-30          [-1, 256, 64, 32]          16,384
      BatchNorm2d-31          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-32            [-1, 256, 1, 1]               0
           Linear-33                   [-1, 16]           4,096
             ReLU-34                   [-1, 16]               0
           Linear-35                  [-1, 256]           4,096
          Sigmoid-36                  [-1, 256]               0
          SELayer-37          [-1, 256, 64, 32]               0
   InstanceNorm2d-38          [-1, 256, 64, 32]             512
             ReLU-39          [-1, 256, 64, 32]               0
       Bottleneck-40          [-1, 256, 64, 32]               0
           Conv2d-41           [-1, 64, 64, 32]          16,384
      BatchNorm2d-42           [-1, 64, 64, 32]             128
             ReLU-43           [-1, 64, 64, 32]               0
           Conv2d-44           [-1, 64, 64, 32]          36,864
      BatchNorm2d-45           [-1, 64, 64, 32]             128
             ReLU-46           [-1, 64, 64, 32]               0
           Conv2d-47          [-1, 256, 64, 32]          16,384
      BatchNorm2d-48          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-49            [-1, 256, 1, 1]               0
           Linear-50                   [-1, 16]           4,096
             ReLU-51                   [-1, 16]               0
           Linear-52                  [-1, 256]           4,096
          Sigmoid-53                  [-1, 256]               0
          SELayer-54          [-1, 256, 64, 32]               0
   InstanceNorm2d-55          [-1, 256, 64, 32]             512
             ReLU-56          [-1, 256, 64, 32]               0
       Bottleneck-57          [-1, 256, 64, 32]               0
           Conv2d-58          [-1, 128, 64, 32]          32,768
      BatchNorm2d-59          [-1, 128, 64, 32]             256
             ReLU-60          [-1, 128, 64, 32]               0
           Conv2d-61          [-1, 128, 32, 16]         147,456
      BatchNorm2d-62          [-1, 128, 32, 16]             256
             ReLU-63          [-1, 128, 32, 16]               0
           Conv2d-64          [-1, 512, 32, 16]          65,536
      BatchNorm2d-65          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-66            [-1, 512, 1, 1]               0
           Linear-67                   [-1, 32]          16,384
             ReLU-68                   [-1, 32]               0
           Linear-69                  [-1, 512]          16,384
          Sigmoid-70                  [-1, 512]               0
          SELayer-71          [-1, 512, 32, 16]               0
           Conv2d-72          [-1, 512, 32, 16]         131,072
      BatchNorm2d-73          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-74          [-1, 512, 32, 16]           1,024
             ReLU-75          [-1, 512, 32, 16]               0
       Bottleneck-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 128, 32, 16]          65,536
      BatchNorm2d-78          [-1, 128, 32, 16]             256
             ReLU-79          [-1, 128, 32, 16]               0
           Conv2d-80          [-1, 128, 32, 16]         147,456
      BatchNorm2d-81          [-1, 128, 32, 16]             256
             ReLU-82          [-1, 128, 32, 16]               0
           Conv2d-83          [-1, 512, 32, 16]          65,536
      BatchNorm2d-84          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-85            [-1, 512, 1, 1]               0
           Linear-86                   [-1, 32]          16,384
             ReLU-87                   [-1, 32]               0
           Linear-88                  [-1, 512]          16,384
          Sigmoid-89                  [-1, 512]               0
          SELayer-90          [-1, 512, 32, 16]               0
   InstanceNorm2d-91          [-1, 512, 32, 16]           1,024
             ReLU-92          [-1, 512, 32, 16]               0
       Bottleneck-93          [-1, 512, 32, 16]               0
           Conv2d-94          [-1, 128, 32, 16]          65,536
      BatchNorm2d-95          [-1, 128, 32, 16]             256
             ReLU-96          [-1, 128, 32, 16]               0
           Conv2d-97          [-1, 128, 32, 16]         147,456
      BatchNorm2d-98          [-1, 128, 32, 16]             256
             ReLU-99          [-1, 128, 32, 16]               0
          Conv2d-100          [-1, 512, 32, 16]          65,536
     BatchNorm2d-101          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-102            [-1, 512, 1, 1]               0
          Linear-103                   [-1, 32]          16,384
            ReLU-104                   [-1, 32]               0
          Linear-105                  [-1, 512]          16,384
         Sigmoid-106                  [-1, 512]               0
         SELayer-107          [-1, 512, 32, 16]               0
  InstanceNorm2d-108          [-1, 512, 32, 16]           1,024
            ReLU-109          [-1, 512, 32, 16]               0
      Bottleneck-110          [-1, 512, 32, 16]               0
          Conv2d-111          [-1, 128, 32, 16]          65,536
     BatchNorm2d-112          [-1, 128, 32, 16]             256
            ReLU-113          [-1, 128, 32, 16]               0
          Conv2d-114          [-1, 128, 32, 16]         147,456
     BatchNorm2d-115          [-1, 128, 32, 16]             256
            ReLU-116          [-1, 128, 32, 16]               0
          Conv2d-117          [-1, 512, 32, 16]          65,536
     BatchNorm2d-118          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-119            [-1, 512, 1, 1]               0
          Linear-120                   [-1, 32]          16,384
            ReLU-121                   [-1, 32]               0
          Linear-122                  [-1, 512]          16,384
         Sigmoid-123                  [-1, 512]               0
         SELayer-124          [-1, 512, 32, 16]               0
  InstanceNorm2d-125          [-1, 512, 32, 16]           1,024
            ReLU-126          [-1, 512, 32, 16]               0
      Bottleneck-127          [-1, 512, 32, 16]               0
          Conv2d-128          [-1, 128, 32, 16]          65,536
     BatchNorm2d-129          [-1, 128, 32, 16]             256
            ReLU-130          [-1, 128, 32, 16]               0
          Conv2d-131          [-1, 128, 32, 16]         147,456
     BatchNorm2d-132          [-1, 128, 32, 16]             256
            ReLU-133          [-1, 128, 32, 16]               0
          Conv2d-134          [-1, 512, 32, 16]          65,536
     BatchNorm2d-135          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-136            [-1, 512, 1, 1]               0
          Linear-137                   [-1, 32]          16,384
            ReLU-138                   [-1, 32]               0
          Linear-139                  [-1, 512]          16,384
         Sigmoid-140                  [-1, 512]               0
         SELayer-141          [-1, 512, 32, 16]               0
  InstanceNorm2d-142          [-1, 512, 32, 16]           1,024
            ReLU-143          [-1, 512, 32, 16]               0
      Bottleneck-144          [-1, 512, 32, 16]               0
          Conv2d-145          [-1, 128, 32, 16]          65,536
     BatchNorm2d-146          [-1, 128, 32, 16]             256
            ReLU-147          [-1, 128, 32, 16]               0
          Conv2d-148          [-1, 128, 32, 16]         147,456
     BatchNorm2d-149          [-1, 128, 32, 16]             256
            ReLU-150          [-1, 128, 32, 16]               0
          Conv2d-151          [-1, 512, 32, 16]          65,536
     BatchNorm2d-152          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-153            [-1, 512, 1, 1]               0
          Linear-154                   [-1, 32]          16,384
            ReLU-155                   [-1, 32]               0
          Linear-156                  [-1, 512]          16,384
         Sigmoid-157                  [-1, 512]               0
         SELayer-158          [-1, 512, 32, 16]               0
  InstanceNorm2d-159          [-1, 512, 32, 16]           1,024
            ReLU-160          [-1, 512, 32, 16]               0
      Bottleneck-161          [-1, 512, 32, 16]               0
          Conv2d-162          [-1, 128, 32, 16]          65,536
     BatchNorm2d-163          [-1, 128, 32, 16]             256
            ReLU-164          [-1, 128, 32, 16]               0
          Conv2d-165          [-1, 128, 32, 16]         147,456
     BatchNorm2d-166          [-1, 128, 32, 16]             256
            ReLU-167          [-1, 128, 32, 16]               0
          Conv2d-168          [-1, 512, 32, 16]          65,536
     BatchNorm2d-169          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-170            [-1, 512, 1, 1]               0
          Linear-171                   [-1, 32]          16,384
            ReLU-172                   [-1, 32]               0
          Linear-173                  [-1, 512]          16,384
         Sigmoid-174                  [-1, 512]               0
         SELayer-175          [-1, 512, 32, 16]               0
  InstanceNorm2d-176          [-1, 512, 32, 16]           1,024
            ReLU-177          [-1, 512, 32, 16]               0
      Bottleneck-178          [-1, 512, 32, 16]               0
          Conv2d-179          [-1, 128, 32, 16]          65,536
     BatchNorm2d-180          [-1, 128, 32, 16]             256
            ReLU-181          [-1, 128, 32, 16]               0
          Conv2d-182          [-1, 128, 32, 16]         147,456
     BatchNorm2d-183          [-1, 128, 32, 16]             256
            ReLU-184          [-1, 128, 32, 16]               0
          Conv2d-185          [-1, 512, 32, 16]          65,536
     BatchNorm2d-186          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-187            [-1, 512, 1, 1]               0
          Linear-188                   [-1, 32]          16,384
            ReLU-189                   [-1, 32]               0
          Linear-190                  [-1, 512]          16,384
         Sigmoid-191                  [-1, 512]               0
         SELayer-192          [-1, 512, 32, 16]               0
  InstanceNorm2d-193          [-1, 512, 32, 16]           1,024
            ReLU-194          [-1, 512, 32, 16]               0
      Bottleneck-195          [-1, 512, 32, 16]               0
          Conv2d-196          [-1, 256, 32, 16]         131,072
     BatchNorm2d-197          [-1, 256, 32, 16]             512
            ReLU-198          [-1, 256, 32, 16]               0
          Conv2d-199           [-1, 256, 16, 8]         589,824
     BatchNorm2d-200           [-1, 256, 16, 8]             512
            ReLU-201           [-1, 256, 16, 8]               0
          Conv2d-202          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-203          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-204           [-1, 1024, 1, 1]               0
          Linear-205                   [-1, 64]          65,536
            ReLU-206                   [-1, 64]               0
          Linear-207                 [-1, 1024]          65,536
         Sigmoid-208                 [-1, 1024]               0
         SELayer-209          [-1, 1024, 16, 8]               0
          Conv2d-210          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-211          [-1, 1024, 16, 8]           2,048
            ReLU-212          [-1, 1024, 16, 8]               0
      Bottleneck-213          [-1, 1024, 16, 8]               0
          Conv2d-214           [-1, 256, 16, 8]         262,144
     BatchNorm2d-215           [-1, 256, 16, 8]             512
            ReLU-216           [-1, 256, 16, 8]               0
          Conv2d-217           [-1, 256, 16, 8]         589,824
     BatchNorm2d-218           [-1, 256, 16, 8]             512
            ReLU-219           [-1, 256, 16, 8]               0
          Conv2d-220          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-221          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-222           [-1, 1024, 1, 1]               0
          Linear-223                   [-1, 64]          65,536
            ReLU-224                   [-1, 64]               0
          Linear-225                 [-1, 1024]          65,536
         Sigmoid-226                 [-1, 1024]               0
         SELayer-227          [-1, 1024, 16, 8]               0
            ReLU-228          [-1, 1024, 16, 8]               0
      Bottleneck-229          [-1, 1024, 16, 8]               0
          Conv2d-230           [-1, 256, 16, 8]         262,144
     BatchNorm2d-231           [-1, 256, 16, 8]             512
            ReLU-232           [-1, 256, 16, 8]               0
          Conv2d-233           [-1, 256, 16, 8]         589,824
     BatchNorm2d-234           [-1, 256, 16, 8]             512
            ReLU-235           [-1, 256, 16, 8]               0
          Conv2d-236          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-237          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-238           [-1, 1024, 1, 1]               0
          Linear-239                   [-1, 64]          65,536
            ReLU-240                   [-1, 64]               0
          Linear-241                 [-1, 1024]          65,536
         Sigmoid-242                 [-1, 1024]               0
         SELayer-243          [-1, 1024, 16, 8]               0
            ReLU-244          [-1, 1024, 16, 8]               0
      Bottleneck-245          [-1, 1024, 16, 8]               0
          Conv2d-246           [-1, 256, 16, 8]         262,144
     BatchNorm2d-247           [-1, 256, 16, 8]             512
            ReLU-248           [-1, 256, 16, 8]               0
          Conv2d-249           [-1, 256, 16, 8]         589,824
     BatchNorm2d-250           [-1, 256, 16, 8]             512
            ReLU-251           [-1, 256, 16, 8]               0
          Conv2d-252          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-253          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-254           [-1, 1024, 1, 1]               0
          Linear-255                   [-1, 64]          65,536
            ReLU-256                   [-1, 64]               0
          Linear-257                 [-1, 1024]          65,536
         Sigmoid-258                 [-1, 1024]               0
         SELayer-259          [-1, 1024, 16, 8]               0
            ReLU-260          [-1, 1024, 16, 8]               0
      Bottleneck-261          [-1, 1024, 16, 8]               0
          Conv2d-262           [-1, 256, 16, 8]         262,144
     BatchNorm2d-263           [-1, 256, 16, 8]             512
            ReLU-264           [-1, 256, 16, 8]               0
          Conv2d-265           [-1, 256, 16, 8]         589,824
     BatchNorm2d-266           [-1, 256, 16, 8]             512
            ReLU-267           [-1, 256, 16, 8]               0
          Conv2d-268          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-269          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-270           [-1, 1024, 1, 1]               0
          Linear-271                   [-1, 64]          65,536
            ReLU-272                   [-1, 64]               0
          Linear-273                 [-1, 1024]          65,536
         Sigmoid-274                 [-1, 1024]               0
         SELayer-275          [-1, 1024, 16, 8]               0
            ReLU-276          [-1, 1024, 16, 8]               0
      Bottleneck-277          [-1, 1024, 16, 8]               0
          Conv2d-278           [-1, 256, 16, 8]         262,144
     BatchNorm2d-279           [-1, 256, 16, 8]             512
            ReLU-280           [-1, 256, 16, 8]               0
          Conv2d-281           [-1, 256, 16, 8]         589,824
     BatchNorm2d-282           [-1, 256, 16, 8]             512
            ReLU-283           [-1, 256, 16, 8]               0
          Conv2d-284          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-285          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-286           [-1, 1024, 1, 1]               0
          Linear-287                   [-1, 64]          65,536
            ReLU-288                   [-1, 64]               0
          Linear-289                 [-1, 1024]          65,536
         Sigmoid-290                 [-1, 1024]               0
         SELayer-291          [-1, 1024, 16, 8]               0
            ReLU-292          [-1, 1024, 16, 8]               0
      Bottleneck-293          [-1, 1024, 16, 8]               0
          Conv2d-294           [-1, 256, 16, 8]         262,144
     BatchNorm2d-295           [-1, 256, 16, 8]             512
            ReLU-296           [-1, 256, 16, 8]               0
          Conv2d-297           [-1, 256, 16, 8]         589,824
     BatchNorm2d-298           [-1, 256, 16, 8]             512
            ReLU-299           [-1, 256, 16, 8]               0
          Conv2d-300          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-301          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-302           [-1, 1024, 1, 1]               0
          Linear-303                   [-1, 64]          65,536
            ReLU-304                   [-1, 64]               0
          Linear-305                 [-1, 1024]          65,536
         Sigmoid-306                 [-1, 1024]               0
         SELayer-307          [-1, 1024, 16, 8]               0
            ReLU-308          [-1, 1024, 16, 8]               0
      Bottleneck-309          [-1, 1024, 16, 8]               0
          Conv2d-310           [-1, 256, 16, 8]         262,144
     BatchNorm2d-311           [-1, 256, 16, 8]             512
            ReLU-312           [-1, 256, 16, 8]               0
          Conv2d-313           [-1, 256, 16, 8]         589,824
     BatchNorm2d-314           [-1, 256, 16, 8]             512
            ReLU-315           [-1, 256, 16, 8]               0
          Conv2d-316          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-317          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-318           [-1, 1024, 1, 1]               0
          Linear-319                   [-1, 64]          65,536
            ReLU-320                   [-1, 64]               0
          Linear-321                 [-1, 1024]          65,536
         Sigmoid-322                 [-1, 1024]               0
         SELayer-323          [-1, 1024, 16, 8]               0
            ReLU-324          [-1, 1024, 16, 8]               0
      Bottleneck-325          [-1, 1024, 16, 8]               0
          Conv2d-326           [-1, 256, 16, 8]         262,144
     BatchNorm2d-327           [-1, 256, 16, 8]             512
            ReLU-328           [-1, 256, 16, 8]               0
          Conv2d-329           [-1, 256, 16, 8]         589,824
     BatchNorm2d-330           [-1, 256, 16, 8]             512
            ReLU-331           [-1, 256, 16, 8]               0
          Conv2d-332          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-333          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-334           [-1, 1024, 1, 1]               0
          Linear-335                   [-1, 64]          65,536
            ReLU-336                   [-1, 64]               0
          Linear-337                 [-1, 1024]          65,536
         Sigmoid-338                 [-1, 1024]               0
         SELayer-339          [-1, 1024, 16, 8]               0
            ReLU-340          [-1, 1024, 16, 8]               0
      Bottleneck-341          [-1, 1024, 16, 8]               0
          Conv2d-342           [-1, 256, 16, 8]         262,144
     BatchNorm2d-343           [-1, 256, 16, 8]             512
            ReLU-344           [-1, 256, 16, 8]               0
          Conv2d-345           [-1, 256, 16, 8]         589,824
     BatchNorm2d-346           [-1, 256, 16, 8]             512
            ReLU-347           [-1, 256, 16, 8]               0
          Conv2d-348          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-349          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-350           [-1, 1024, 1, 1]               0
          Linear-351                   [-1, 64]          65,536
            ReLU-352                   [-1, 64]               0
          Linear-353                 [-1, 1024]          65,536
         Sigmoid-354                 [-1, 1024]               0
         SELayer-355          [-1, 1024, 16, 8]               0
            ReLU-356          [-1, 1024, 16, 8]               0
      Bottleneck-357          [-1, 1024, 16, 8]               0
          Conv2d-358           [-1, 256, 16, 8]         262,144
     BatchNorm2d-359           [-1, 256, 16, 8]             512
            ReLU-360           [-1, 256, 16, 8]               0
          Conv2d-361           [-1, 256, 16, 8]         589,824
     BatchNorm2d-362           [-1, 256, 16, 8]             512
            ReLU-363           [-1, 256, 16, 8]               0
          Conv2d-364          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-365          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-366           [-1, 1024, 1, 1]               0
          Linear-367                   [-1, 64]          65,536
            ReLU-368                   [-1, 64]               0
          Linear-369                 [-1, 1024]          65,536
         Sigmoid-370                 [-1, 1024]               0
         SELayer-371          [-1, 1024, 16, 8]               0
            ReLU-372          [-1, 1024, 16, 8]               0
      Bottleneck-373          [-1, 1024, 16, 8]               0
          Conv2d-374           [-1, 256, 16, 8]         262,144
     BatchNorm2d-375           [-1, 256, 16, 8]             512
            ReLU-376           [-1, 256, 16, 8]               0
          Conv2d-377           [-1, 256, 16, 8]         589,824
     BatchNorm2d-378           [-1, 256, 16, 8]             512
            ReLU-379           [-1, 256, 16, 8]               0
          Conv2d-380          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-381          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-382           [-1, 1024, 1, 1]               0
          Linear-383                   [-1, 64]          65,536
            ReLU-384                   [-1, 64]               0
          Linear-385                 [-1, 1024]          65,536
         Sigmoid-386                 [-1, 1024]               0
         SELayer-387          [-1, 1024, 16, 8]               0
            ReLU-388          [-1, 1024, 16, 8]               0
      Bottleneck-389          [-1, 1024, 16, 8]               0
          Conv2d-390           [-1, 256, 16, 8]         262,144
     BatchNorm2d-391           [-1, 256, 16, 8]             512
            ReLU-392           [-1, 256, 16, 8]               0
          Conv2d-393           [-1, 256, 16, 8]         589,824
     BatchNorm2d-394           [-1, 256, 16, 8]             512
            ReLU-395           [-1, 256, 16, 8]               0
          Conv2d-396          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-397          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-398           [-1, 1024, 1, 1]               0
          Linear-399                   [-1, 64]          65,536
            ReLU-400                   [-1, 64]               0
          Linear-401                 [-1, 1024]          65,536
         Sigmoid-402                 [-1, 1024]               0
         SELayer-403          [-1, 1024, 16, 8]               0
            ReLU-404          [-1, 1024, 16, 8]               0
      Bottleneck-405          [-1, 1024, 16, 8]               0
          Conv2d-406           [-1, 256, 16, 8]         262,144
     BatchNorm2d-407           [-1, 256, 16, 8]             512
            ReLU-408           [-1, 256, 16, 8]               0
          Conv2d-409           [-1, 256, 16, 8]         589,824
     BatchNorm2d-410           [-1, 256, 16, 8]             512
            ReLU-411           [-1, 256, 16, 8]               0
          Conv2d-412          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-413          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-414           [-1, 1024, 1, 1]               0
          Linear-415                   [-1, 64]          65,536
            ReLU-416                   [-1, 64]               0
          Linear-417                 [-1, 1024]          65,536
         Sigmoid-418                 [-1, 1024]               0
         SELayer-419          [-1, 1024, 16, 8]               0
            ReLU-420          [-1, 1024, 16, 8]               0
      Bottleneck-421          [-1, 1024, 16, 8]               0
          Conv2d-422           [-1, 256, 16, 8]         262,144
     BatchNorm2d-423           [-1, 256, 16, 8]             512
            ReLU-424           [-1, 256, 16, 8]               0
          Conv2d-425           [-1, 256, 16, 8]         589,824
     BatchNorm2d-426           [-1, 256, 16, 8]             512
            ReLU-427           [-1, 256, 16, 8]               0
          Conv2d-428          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-429          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-430           [-1, 1024, 1, 1]               0
          Linear-431                   [-1, 64]          65,536
            ReLU-432                   [-1, 64]               0
          Linear-433                 [-1, 1024]          65,536
         Sigmoid-434                 [-1, 1024]               0
         SELayer-435          [-1, 1024, 16, 8]               0
            ReLU-436          [-1, 1024, 16, 8]               0
      Bottleneck-437          [-1, 1024, 16, 8]               0
          Conv2d-438           [-1, 256, 16, 8]         262,144
     BatchNorm2d-439           [-1, 256, 16, 8]             512
            ReLU-440           [-1, 256, 16, 8]               0
          Conv2d-441           [-1, 256, 16, 8]         589,824
     BatchNorm2d-442           [-1, 256, 16, 8]             512
            ReLU-443           [-1, 256, 16, 8]               0
          Conv2d-444          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-445          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-446           [-1, 1024, 1, 1]               0
          Linear-447                   [-1, 64]          65,536
            ReLU-448                   [-1, 64]               0
          Linear-449                 [-1, 1024]          65,536
         Sigmoid-450                 [-1, 1024]               0
         SELayer-451          [-1, 1024, 16, 8]               0
            ReLU-452          [-1, 1024, 16, 8]               0
      Bottleneck-453          [-1, 1024, 16, 8]               0
          Conv2d-454           [-1, 256, 16, 8]         262,144
     BatchNorm2d-455           [-1, 256, 16, 8]             512
            ReLU-456           [-1, 256, 16, 8]               0
          Conv2d-457           [-1, 256, 16, 8]         589,824
     BatchNorm2d-458           [-1, 256, 16, 8]             512
            ReLU-459           [-1, 256, 16, 8]               0
          Conv2d-460          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-461          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-462           [-1, 1024, 1, 1]               0
          Linear-463                   [-1, 64]          65,536
            ReLU-464                   [-1, 64]               0
          Linear-465                 [-1, 1024]          65,536
         Sigmoid-466                 [-1, 1024]               0
         SELayer-467          [-1, 1024, 16, 8]               0
            ReLU-468          [-1, 1024, 16, 8]               0
      Bottleneck-469          [-1, 1024, 16, 8]               0
          Conv2d-470           [-1, 256, 16, 8]         262,144
     BatchNorm2d-471           [-1, 256, 16, 8]             512
            ReLU-472           [-1, 256, 16, 8]               0
          Conv2d-473           [-1, 256, 16, 8]         589,824
     BatchNorm2d-474           [-1, 256, 16, 8]             512
            ReLU-475           [-1, 256, 16, 8]               0
          Conv2d-476          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-477          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-478           [-1, 1024, 1, 1]               0
          Linear-479                   [-1, 64]          65,536
            ReLU-480                   [-1, 64]               0
          Linear-481                 [-1, 1024]          65,536
         Sigmoid-482                 [-1, 1024]               0
         SELayer-483          [-1, 1024, 16, 8]               0
            ReLU-484          [-1, 1024, 16, 8]               0
      Bottleneck-485          [-1, 1024, 16, 8]               0
          Conv2d-486           [-1, 256, 16, 8]         262,144
     BatchNorm2d-487           [-1, 256, 16, 8]             512
            ReLU-488           [-1, 256, 16, 8]               0
          Conv2d-489           [-1, 256, 16, 8]         589,824
     BatchNorm2d-490           [-1, 256, 16, 8]             512
            ReLU-491           [-1, 256, 16, 8]               0
          Conv2d-492          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-493          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-494           [-1, 1024, 1, 1]               0
          Linear-495                   [-1, 64]          65,536
            ReLU-496                   [-1, 64]               0
          Linear-497                 [-1, 1024]          65,536
         Sigmoid-498                 [-1, 1024]               0
         SELayer-499          [-1, 1024, 16, 8]               0
            ReLU-500          [-1, 1024, 16, 8]               0
      Bottleneck-501          [-1, 1024, 16, 8]               0
          Conv2d-502           [-1, 256, 16, 8]         262,144
     BatchNorm2d-503           [-1, 256, 16, 8]             512
            ReLU-504           [-1, 256, 16, 8]               0
          Conv2d-505           [-1, 256, 16, 8]         589,824
     BatchNorm2d-506           [-1, 256, 16, 8]             512
            ReLU-507           [-1, 256, 16, 8]               0
          Conv2d-508          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-509          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-510           [-1, 1024, 1, 1]               0
          Linear-511                   [-1, 64]          65,536
            ReLU-512                   [-1, 64]               0
          Linear-513                 [-1, 1024]          65,536
         Sigmoid-514                 [-1, 1024]               0
         SELayer-515          [-1, 1024, 16, 8]               0
            ReLU-516          [-1, 1024, 16, 8]               0
      Bottleneck-517          [-1, 1024, 16, 8]               0
          Conv2d-518           [-1, 256, 16, 8]         262,144
     BatchNorm2d-519           [-1, 256, 16, 8]             512
            ReLU-520           [-1, 256, 16, 8]               0
          Conv2d-521           [-1, 256, 16, 8]         589,824
     BatchNorm2d-522           [-1, 256, 16, 8]             512
            ReLU-523           [-1, 256, 16, 8]               0
          Conv2d-524          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-525          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-526           [-1, 1024, 1, 1]               0
          Linear-527                   [-1, 64]          65,536
            ReLU-528                   [-1, 64]               0
          Linear-529                 [-1, 1024]          65,536
         Sigmoid-530                 [-1, 1024]               0
         SELayer-531          [-1, 1024, 16, 8]               0
            ReLU-532          [-1, 1024, 16, 8]               0
      Bottleneck-533          [-1, 1024, 16, 8]               0
          Conv2d-534           [-1, 256, 16, 8]         262,144
     BatchNorm2d-535           [-1, 256, 16, 8]             512
            ReLU-536           [-1, 256, 16, 8]               0
          Conv2d-537           [-1, 256, 16, 8]         589,824
     BatchNorm2d-538           [-1, 256, 16, 8]             512
            ReLU-539           [-1, 256, 16, 8]               0
          Conv2d-540          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-541          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-542           [-1, 1024, 1, 1]               0
          Linear-543                   [-1, 64]          65,536
            ReLU-544                   [-1, 64]               0
          Linear-545                 [-1, 1024]          65,536
         Sigmoid-546                 [-1, 1024]               0
         SELayer-547          [-1, 1024, 16, 8]               0
            ReLU-548          [-1, 1024, 16, 8]               0
      Bottleneck-549          [-1, 1024, 16, 8]               0
          Conv2d-550           [-1, 256, 16, 8]         262,144
     BatchNorm2d-551           [-1, 256, 16, 8]             512
            ReLU-552           [-1, 256, 16, 8]               0
          Conv2d-553           [-1, 256, 16, 8]         589,824
     BatchNorm2d-554           [-1, 256, 16, 8]             512
            ReLU-555           [-1, 256, 16, 8]               0
          Conv2d-556          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-557          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-558           [-1, 1024, 1, 1]               0
          Linear-559                   [-1, 64]          65,536
            ReLU-560                   [-1, 64]               0
          Linear-561                 [-1, 1024]          65,536
         Sigmoid-562                 [-1, 1024]               0
         SELayer-563          [-1, 1024, 16, 8]               0
            ReLU-564          [-1, 1024, 16, 8]               0
      Bottleneck-565          [-1, 1024, 16, 8]               0
          Conv2d-566           [-1, 256, 16, 8]         262,144
     BatchNorm2d-567           [-1, 256, 16, 8]             512
            ReLU-568           [-1, 256, 16, 8]               0
          Conv2d-569           [-1, 256, 16, 8]         589,824
     BatchNorm2d-570           [-1, 256, 16, 8]             512
            ReLU-571           [-1, 256, 16, 8]               0
          Conv2d-572          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-573          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-574           [-1, 1024, 1, 1]               0
          Linear-575                   [-1, 64]          65,536
            ReLU-576                   [-1, 64]               0
          Linear-577                 [-1, 1024]          65,536
         Sigmoid-578                 [-1, 1024]               0
         SELayer-579          [-1, 1024, 16, 8]               0
            ReLU-580          [-1, 1024, 16, 8]               0
      Bottleneck-581          [-1, 1024, 16, 8]               0
          Conv2d-582           [-1, 256, 16, 8]         262,144
     BatchNorm2d-583           [-1, 256, 16, 8]             512
            ReLU-584           [-1, 256, 16, 8]               0
          Conv2d-585           [-1, 256, 16, 8]         589,824
     BatchNorm2d-586           [-1, 256, 16, 8]             512
            ReLU-587           [-1, 256, 16, 8]               0
          Conv2d-588          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-589          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-590           [-1, 1024, 1, 1]               0
          Linear-591                   [-1, 64]          65,536
            ReLU-592                   [-1, 64]               0
          Linear-593                 [-1, 1024]          65,536
         Sigmoid-594                 [-1, 1024]               0
         SELayer-595          [-1, 1024, 16, 8]               0
            ReLU-596          [-1, 1024, 16, 8]               0
      Bottleneck-597          [-1, 1024, 16, 8]               0
          Conv2d-598           [-1, 256, 16, 8]         262,144
     BatchNorm2d-599           [-1, 256, 16, 8]             512
            ReLU-600           [-1, 256, 16, 8]               0
          Conv2d-601           [-1, 256, 16, 8]         589,824
     BatchNorm2d-602           [-1, 256, 16, 8]             512
            ReLU-603           [-1, 256, 16, 8]               0
          Conv2d-604          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-605          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-606           [-1, 1024, 1, 1]               0
          Linear-607                   [-1, 64]          65,536
            ReLU-608                   [-1, 64]               0
          Linear-609                 [-1, 1024]          65,536
         Sigmoid-610                 [-1, 1024]               0
         SELayer-611          [-1, 1024, 16, 8]               0
            ReLU-612          [-1, 1024, 16, 8]               0
      Bottleneck-613          [-1, 1024, 16, 8]               0
          Conv2d-614           [-1, 256, 16, 8]         262,144
     BatchNorm2d-615           [-1, 256, 16, 8]             512
            ReLU-616           [-1, 256, 16, 8]               0
          Conv2d-617           [-1, 256, 16, 8]         589,824
     BatchNorm2d-618           [-1, 256, 16, 8]             512
            ReLU-619           [-1, 256, 16, 8]               0
          Conv2d-620          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-621          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-622           [-1, 1024, 1, 1]               0
          Linear-623                   [-1, 64]          65,536
            ReLU-624                   [-1, 64]               0
          Linear-625                 [-1, 1024]          65,536
         Sigmoid-626                 [-1, 1024]               0
         SELayer-627          [-1, 1024, 16, 8]               0
            ReLU-628          [-1, 1024, 16, 8]               0
      Bottleneck-629          [-1, 1024, 16, 8]               0
          Conv2d-630           [-1, 256, 16, 8]         262,144
     BatchNorm2d-631           [-1, 256, 16, 8]             512
            ReLU-632           [-1, 256, 16, 8]               0
          Conv2d-633           [-1, 256, 16, 8]         589,824
     BatchNorm2d-634           [-1, 256, 16, 8]             512
            ReLU-635           [-1, 256, 16, 8]               0
          Conv2d-636          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-637          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-638           [-1, 1024, 1, 1]               0
          Linear-639                   [-1, 64]          65,536
            ReLU-640                   [-1, 64]               0
          Linear-641                 [-1, 1024]          65,536
         Sigmoid-642                 [-1, 1024]               0
         SELayer-643          [-1, 1024, 16, 8]               0
            ReLU-644          [-1, 1024, 16, 8]               0
      Bottleneck-645          [-1, 1024, 16, 8]               0
          Conv2d-646           [-1, 256, 16, 8]         262,144
     BatchNorm2d-647           [-1, 256, 16, 8]             512
            ReLU-648           [-1, 256, 16, 8]               0
          Conv2d-649           [-1, 256, 16, 8]         589,824
     BatchNorm2d-650           [-1, 256, 16, 8]             512
            ReLU-651           [-1, 256, 16, 8]               0
          Conv2d-652          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-653          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-654           [-1, 1024, 1, 1]               0
          Linear-655                   [-1, 64]          65,536
            ReLU-656                   [-1, 64]               0
          Linear-657                 [-1, 1024]          65,536
         Sigmoid-658                 [-1, 1024]               0
         SELayer-659          [-1, 1024, 16, 8]               0
            ReLU-660          [-1, 1024, 16, 8]               0
      Bottleneck-661          [-1, 1024, 16, 8]               0
          Conv2d-662           [-1, 256, 16, 8]         262,144
     BatchNorm2d-663           [-1, 256, 16, 8]             512
            ReLU-664           [-1, 256, 16, 8]               0
          Conv2d-665           [-1, 256, 16, 8]         589,824
     BatchNorm2d-666           [-1, 256, 16, 8]             512
            ReLU-667           [-1, 256, 16, 8]               0
          Conv2d-668          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-669          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-670           [-1, 1024, 1, 1]               0
          Linear-671                   [-1, 64]          65,536
            ReLU-672                   [-1, 64]               0
          Linear-673                 [-1, 1024]          65,536
         Sigmoid-674                 [-1, 1024]               0
         SELayer-675          [-1, 1024, 16, 8]               0
            ReLU-676          [-1, 1024, 16, 8]               0
      Bottleneck-677          [-1, 1024, 16, 8]               0
          Conv2d-678           [-1, 256, 16, 8]         262,144
     BatchNorm2d-679           [-1, 256, 16, 8]             512
            ReLU-680           [-1, 256, 16, 8]               0
          Conv2d-681           [-1, 256, 16, 8]         589,824
     BatchNorm2d-682           [-1, 256, 16, 8]             512
            ReLU-683           [-1, 256, 16, 8]               0
          Conv2d-684          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-685          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-686           [-1, 1024, 1, 1]               0
          Linear-687                   [-1, 64]          65,536
            ReLU-688                   [-1, 64]               0
          Linear-689                 [-1, 1024]          65,536
         Sigmoid-690                 [-1, 1024]               0
         SELayer-691          [-1, 1024, 16, 8]               0
            ReLU-692          [-1, 1024, 16, 8]               0
      Bottleneck-693          [-1, 1024, 16, 8]               0
          Conv2d-694           [-1, 256, 16, 8]         262,144
     BatchNorm2d-695           [-1, 256, 16, 8]             512
            ReLU-696           [-1, 256, 16, 8]               0
          Conv2d-697           [-1, 256, 16, 8]         589,824
     BatchNorm2d-698           [-1, 256, 16, 8]             512
            ReLU-699           [-1, 256, 16, 8]               0
          Conv2d-700          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-701          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-702           [-1, 1024, 1, 1]               0
          Linear-703                   [-1, 64]          65,536
            ReLU-704                   [-1, 64]               0
          Linear-705                 [-1, 1024]          65,536
         Sigmoid-706                 [-1, 1024]               0
         SELayer-707          [-1, 1024, 16, 8]               0
            ReLU-708          [-1, 1024, 16, 8]               0
      Bottleneck-709          [-1, 1024, 16, 8]               0
          Conv2d-710           [-1, 256, 16, 8]         262,144
     BatchNorm2d-711           [-1, 256, 16, 8]             512
            ReLU-712           [-1, 256, 16, 8]               0
          Conv2d-713           [-1, 256, 16, 8]         589,824
     BatchNorm2d-714           [-1, 256, 16, 8]             512
            ReLU-715           [-1, 256, 16, 8]               0
          Conv2d-716          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-717          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-718           [-1, 1024, 1, 1]               0
          Linear-719                   [-1, 64]          65,536
            ReLU-720                   [-1, 64]               0
          Linear-721                 [-1, 1024]          65,536
         Sigmoid-722                 [-1, 1024]               0
         SELayer-723          [-1, 1024, 16, 8]               0
            ReLU-724          [-1, 1024, 16, 8]               0
      Bottleneck-725          [-1, 1024, 16, 8]               0
          Conv2d-726           [-1, 256, 16, 8]         262,144
     BatchNorm2d-727           [-1, 256, 16, 8]             512
            ReLU-728           [-1, 256, 16, 8]               0
          Conv2d-729           [-1, 256, 16, 8]         589,824
     BatchNorm2d-730           [-1, 256, 16, 8]             512
            ReLU-731           [-1, 256, 16, 8]               0
          Conv2d-732          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-733          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-734           [-1, 1024, 1, 1]               0
          Linear-735                   [-1, 64]          65,536
            ReLU-736                   [-1, 64]               0
          Linear-737                 [-1, 1024]          65,536
         Sigmoid-738                 [-1, 1024]               0
         SELayer-739          [-1, 1024, 16, 8]               0
            ReLU-740          [-1, 1024, 16, 8]               0
      Bottleneck-741          [-1, 1024, 16, 8]               0
          Conv2d-742           [-1, 256, 16, 8]         262,144
     BatchNorm2d-743           [-1, 256, 16, 8]             512
            ReLU-744           [-1, 256, 16, 8]               0
          Conv2d-745           [-1, 256, 16, 8]         589,824
     BatchNorm2d-746           [-1, 256, 16, 8]             512
            ReLU-747           [-1, 256, 16, 8]               0
          Conv2d-748          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-749          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-750           [-1, 1024, 1, 1]               0
          Linear-751                   [-1, 64]          65,536
            ReLU-752                   [-1, 64]               0
          Linear-753                 [-1, 1024]          65,536
         Sigmoid-754                 [-1, 1024]               0
         SELayer-755          [-1, 1024, 16, 8]               0
            ReLU-756          [-1, 1024, 16, 8]               0
      Bottleneck-757          [-1, 1024, 16, 8]               0
          Conv2d-758           [-1, 256, 16, 8]         262,144
     BatchNorm2d-759           [-1, 256, 16, 8]             512
            ReLU-760           [-1, 256, 16, 8]               0
          Conv2d-761           [-1, 256, 16, 8]         589,824
     BatchNorm2d-762           [-1, 256, 16, 8]             512
            ReLU-763           [-1, 256, 16, 8]               0
          Conv2d-764          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-765          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-766           [-1, 1024, 1, 1]               0
          Linear-767                   [-1, 64]          65,536
            ReLU-768                   [-1, 64]               0
          Linear-769                 [-1, 1024]          65,536
         Sigmoid-770                 [-1, 1024]               0
         SELayer-771          [-1, 1024, 16, 8]               0
            ReLU-772          [-1, 1024, 16, 8]               0
      Bottleneck-773          [-1, 1024, 16, 8]               0
          Conv2d-774           [-1, 512, 16, 8]         524,288
     BatchNorm2d-775           [-1, 512, 16, 8]           1,024
            ReLU-776           [-1, 512, 16, 8]               0
          Conv2d-777           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-778           [-1, 512, 16, 8]           1,024
            ReLU-779           [-1, 512, 16, 8]               0
          Conv2d-780          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-781          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-782           [-1, 2048, 1, 1]               0
          Linear-783                  [-1, 128]         262,144
            ReLU-784                  [-1, 128]               0
          Linear-785                 [-1, 2048]         262,144
         Sigmoid-786                 [-1, 2048]               0
         SELayer-787          [-1, 2048, 16, 8]               0
          Conv2d-788          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-789          [-1, 2048, 16, 8]           4,096
            ReLU-790          [-1, 2048, 16, 8]               0
      Bottleneck-791          [-1, 2048, 16, 8]               0
          Conv2d-792           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-793           [-1, 512, 16, 8]           1,024
            ReLU-794           [-1, 512, 16, 8]               0
          Conv2d-795           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-796           [-1, 512, 16, 8]           1,024
            ReLU-797           [-1, 512, 16, 8]               0
          Conv2d-798          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-799          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-800           [-1, 2048, 1, 1]               0
          Linear-801                  [-1, 128]         262,144
            ReLU-802                  [-1, 128]               0
          Linear-803                 [-1, 2048]         262,144
         Sigmoid-804                 [-1, 2048]               0
         SELayer-805          [-1, 2048, 16, 8]               0
            ReLU-806          [-1, 2048, 16, 8]               0
      Bottleneck-807          [-1, 2048, 16, 8]               0
          Conv2d-808           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-809           [-1, 512, 16, 8]           1,024
            ReLU-810           [-1, 512, 16, 8]               0
          Conv2d-811           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-812           [-1, 512, 16, 8]           1,024
            ReLU-813           [-1, 512, 16, 8]               0
          Conv2d-814          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-815          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-816           [-1, 2048, 1, 1]               0
          Linear-817                  [-1, 128]         262,144
            ReLU-818                  [-1, 128]               0
          Linear-819                 [-1, 2048]         262,144
         Sigmoid-820                 [-1, 2048]               0
         SELayer-821          [-1, 2048, 16, 8]               0
            ReLU-822          [-1, 2048, 16, 8]               0
      Bottleneck-823          [-1, 2048, 16, 8]               0
================================================================
Total params: 64,731,712
Trainable params: 64,731,712
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 521.89
Params size (MB): 246.93
Estimated Total Size (MB): 769.20
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet152_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
    InstanceNorm2d-6           [-1, 32, 64, 32]              64
       BatchNorm2d-7           [-1, 32, 64, 32]              64
               IBN-8           [-1, 64, 64, 32]               0
              ReLU-9           [-1, 64, 64, 32]               0
           Conv2d-10           [-1, 64, 64, 32]          36,864
      BatchNorm2d-11           [-1, 64, 64, 32]             128
             ReLU-12           [-1, 64, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
           Conv2d-15          [-1, 256, 64, 32]          16,384
      BatchNorm2d-16          [-1, 256, 64, 32]             512
             ReLU-17          [-1, 256, 64, 32]               0
       Bottleneck-18          [-1, 256, 64, 32]               0
           Conv2d-19           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-20           [-1, 32, 64, 32]              64
      BatchNorm2d-21           [-1, 32, 64, 32]              64
              IBN-22           [-1, 64, 64, 32]               0
             ReLU-23           [-1, 64, 64, 32]               0
           Conv2d-24           [-1, 64, 64, 32]          36,864
      BatchNorm2d-25           [-1, 64, 64, 32]             128
             ReLU-26           [-1, 64, 64, 32]               0
           Conv2d-27          [-1, 256, 64, 32]          16,384
      BatchNorm2d-28          [-1, 256, 64, 32]             512
             ReLU-29          [-1, 256, 64, 32]               0
       Bottleneck-30          [-1, 256, 64, 32]               0
           Conv2d-31           [-1, 64, 64, 32]          16,384
   InstanceNorm2d-32           [-1, 32, 64, 32]              64
      BatchNorm2d-33           [-1, 32, 64, 32]              64
              IBN-34           [-1, 64, 64, 32]               0
             ReLU-35           [-1, 64, 64, 32]               0
           Conv2d-36           [-1, 64, 64, 32]          36,864
      BatchNorm2d-37           [-1, 64, 64, 32]             128
             ReLU-38           [-1, 64, 64, 32]               0
           Conv2d-39          [-1, 256, 64, 32]          16,384
      BatchNorm2d-40          [-1, 256, 64, 32]             512
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-44           [-1, 64, 64, 32]             128
      BatchNorm2d-45           [-1, 64, 64, 32]             128
              IBN-46          [-1, 128, 64, 32]               0
             ReLU-47          [-1, 128, 64, 32]               0
           Conv2d-48          [-1, 128, 32, 16]         147,456
      BatchNorm2d-49          [-1, 128, 32, 16]             256
             ReLU-50          [-1, 128, 32, 16]               0
           Conv2d-51          [-1, 512, 32, 16]          65,536
      BatchNorm2d-52          [-1, 512, 32, 16]           1,024
           Conv2d-53          [-1, 512, 32, 16]         131,072
      BatchNorm2d-54          [-1, 512, 32, 16]           1,024
             ReLU-55          [-1, 512, 32, 16]               0
       Bottleneck-56          [-1, 512, 32, 16]               0
           Conv2d-57          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-58           [-1, 64, 32, 16]             128
      BatchNorm2d-59           [-1, 64, 32, 16]             128
              IBN-60          [-1, 128, 32, 16]               0
             ReLU-61          [-1, 128, 32, 16]               0
           Conv2d-62          [-1, 128, 32, 16]         147,456
      BatchNorm2d-63          [-1, 128, 32, 16]             256
             ReLU-64          [-1, 128, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]          65,536
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-70           [-1, 64, 32, 16]             128
      BatchNorm2d-71           [-1, 64, 32, 16]             128
              IBN-72          [-1, 128, 32, 16]               0
             ReLU-73          [-1, 128, 32, 16]               0
           Conv2d-74          [-1, 128, 32, 16]         147,456
      BatchNorm2d-75          [-1, 128, 32, 16]             256
             ReLU-76          [-1, 128, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]          65,536
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-82           [-1, 64, 32, 16]             128
      BatchNorm2d-83           [-1, 64, 32, 16]             128
              IBN-84          [-1, 128, 32, 16]               0
             ReLU-85          [-1, 128, 32, 16]               0
           Conv2d-86          [-1, 128, 32, 16]         147,456
      BatchNorm2d-87          [-1, 128, 32, 16]             256
             ReLU-88          [-1, 128, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]          65,536
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
             ReLU-91          [-1, 512, 32, 16]               0
       Bottleneck-92          [-1, 512, 32, 16]               0
           Conv2d-93          [-1, 128, 32, 16]          65,536
   InstanceNorm2d-94           [-1, 64, 32, 16]             128
      BatchNorm2d-95           [-1, 64, 32, 16]             128
              IBN-96          [-1, 128, 32, 16]               0
             ReLU-97          [-1, 128, 32, 16]               0
           Conv2d-98          [-1, 128, 32, 16]         147,456
      BatchNorm2d-99          [-1, 128, 32, 16]             256
            ReLU-100          [-1, 128, 32, 16]               0
          Conv2d-101          [-1, 512, 32, 16]          65,536
     BatchNorm2d-102          [-1, 512, 32, 16]           1,024
            ReLU-103          [-1, 512, 32, 16]               0
      Bottleneck-104          [-1, 512, 32, 16]               0
          Conv2d-105          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-106           [-1, 64, 32, 16]             128
     BatchNorm2d-107           [-1, 64, 32, 16]             128
             IBN-108          [-1, 128, 32, 16]               0
            ReLU-109          [-1, 128, 32, 16]               0
          Conv2d-110          [-1, 128, 32, 16]         147,456
     BatchNorm2d-111          [-1, 128, 32, 16]             256
            ReLU-112          [-1, 128, 32, 16]               0
          Conv2d-113          [-1, 512, 32, 16]          65,536
     BatchNorm2d-114          [-1, 512, 32, 16]           1,024
            ReLU-115          [-1, 512, 32, 16]               0
      Bottleneck-116          [-1, 512, 32, 16]               0
          Conv2d-117          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-118           [-1, 64, 32, 16]             128
     BatchNorm2d-119           [-1, 64, 32, 16]             128
             IBN-120          [-1, 128, 32, 16]               0
            ReLU-121          [-1, 128, 32, 16]               0
          Conv2d-122          [-1, 128, 32, 16]         147,456
     BatchNorm2d-123          [-1, 128, 32, 16]             256
            ReLU-124          [-1, 128, 32, 16]               0
          Conv2d-125          [-1, 512, 32, 16]          65,536
     BatchNorm2d-126          [-1, 512, 32, 16]           1,024
            ReLU-127          [-1, 512, 32, 16]               0
      Bottleneck-128          [-1, 512, 32, 16]               0
          Conv2d-129          [-1, 128, 32, 16]          65,536
  InstanceNorm2d-130           [-1, 64, 32, 16]             128
     BatchNorm2d-131           [-1, 64, 32, 16]             128
             IBN-132          [-1, 128, 32, 16]               0
            ReLU-133          [-1, 128, 32, 16]               0
          Conv2d-134          [-1, 128, 32, 16]         147,456
     BatchNorm2d-135          [-1, 128, 32, 16]             256
            ReLU-136          [-1, 128, 32, 16]               0
          Conv2d-137          [-1, 512, 32, 16]          65,536
     BatchNorm2d-138          [-1, 512, 32, 16]           1,024
            ReLU-139          [-1, 512, 32, 16]               0
      Bottleneck-140          [-1, 512, 32, 16]               0
          Conv2d-141          [-1, 256, 32, 16]         131,072
  InstanceNorm2d-142          [-1, 128, 32, 16]             256
     BatchNorm2d-143          [-1, 128, 32, 16]             256
             IBN-144          [-1, 256, 32, 16]               0
            ReLU-145          [-1, 256, 32, 16]               0
          Conv2d-146           [-1, 256, 16, 8]         589,824
     BatchNorm2d-147           [-1, 256, 16, 8]             512
            ReLU-148           [-1, 256, 16, 8]               0
          Conv2d-149          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-150          [-1, 1024, 16, 8]           2,048
          Conv2d-151          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-156           [-1, 128, 16, 8]             256
     BatchNorm2d-157           [-1, 128, 16, 8]             256
             IBN-158           [-1, 256, 16, 8]               0
            ReLU-159           [-1, 256, 16, 8]               0
          Conv2d-160           [-1, 256, 16, 8]         589,824
     BatchNorm2d-161           [-1, 256, 16, 8]             512
            ReLU-162           [-1, 256, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
      Bottleneck-166          [-1, 1024, 16, 8]               0
          Conv2d-167           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-168           [-1, 128, 16, 8]             256
     BatchNorm2d-169           [-1, 128, 16, 8]             256
             IBN-170           [-1, 256, 16, 8]               0
            ReLU-171           [-1, 256, 16, 8]               0
          Conv2d-172           [-1, 256, 16, 8]         589,824
     BatchNorm2d-173           [-1, 256, 16, 8]             512
            ReLU-174           [-1, 256, 16, 8]               0
          Conv2d-175          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-176          [-1, 1024, 16, 8]           2,048
            ReLU-177          [-1, 1024, 16, 8]               0
      Bottleneck-178          [-1, 1024, 16, 8]               0
          Conv2d-179           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-180           [-1, 128, 16, 8]             256
     BatchNorm2d-181           [-1, 128, 16, 8]             256
             IBN-182           [-1, 256, 16, 8]               0
            ReLU-183           [-1, 256, 16, 8]               0
          Conv2d-184           [-1, 256, 16, 8]         589,824
     BatchNorm2d-185           [-1, 256, 16, 8]             512
            ReLU-186           [-1, 256, 16, 8]               0
          Conv2d-187          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-188          [-1, 1024, 16, 8]           2,048
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-192           [-1, 128, 16, 8]             256
     BatchNorm2d-193           [-1, 128, 16, 8]             256
             IBN-194           [-1, 256, 16, 8]               0
            ReLU-195           [-1, 256, 16, 8]               0
          Conv2d-196           [-1, 256, 16, 8]         589,824
     BatchNorm2d-197           [-1, 256, 16, 8]             512
            ReLU-198           [-1, 256, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-204           [-1, 128, 16, 8]             256
     BatchNorm2d-205           [-1, 128, 16, 8]             256
             IBN-206           [-1, 256, 16, 8]               0
            ReLU-207           [-1, 256, 16, 8]               0
          Conv2d-208           [-1, 256, 16, 8]         589,824
     BatchNorm2d-209           [-1, 256, 16, 8]             512
            ReLU-210           [-1, 256, 16, 8]               0
          Conv2d-211          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-212          [-1, 1024, 16, 8]           2,048
            ReLU-213          [-1, 1024, 16, 8]               0
      Bottleneck-214          [-1, 1024, 16, 8]               0
          Conv2d-215           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-216           [-1, 128, 16, 8]             256
     BatchNorm2d-217           [-1, 128, 16, 8]             256
             IBN-218           [-1, 256, 16, 8]               0
            ReLU-219           [-1, 256, 16, 8]               0
          Conv2d-220           [-1, 256, 16, 8]         589,824
     BatchNorm2d-221           [-1, 256, 16, 8]             512
            ReLU-222           [-1, 256, 16, 8]               0
          Conv2d-223          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-224          [-1, 1024, 16, 8]           2,048
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-228           [-1, 128, 16, 8]             256
     BatchNorm2d-229           [-1, 128, 16, 8]             256
             IBN-230           [-1, 256, 16, 8]               0
            ReLU-231           [-1, 256, 16, 8]               0
          Conv2d-232           [-1, 256, 16, 8]         589,824
     BatchNorm2d-233           [-1, 256, 16, 8]             512
            ReLU-234           [-1, 256, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
            ReLU-237          [-1, 1024, 16, 8]               0
      Bottleneck-238          [-1, 1024, 16, 8]               0
          Conv2d-239           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-240           [-1, 128, 16, 8]             256
     BatchNorm2d-241           [-1, 128, 16, 8]             256
             IBN-242           [-1, 256, 16, 8]               0
            ReLU-243           [-1, 256, 16, 8]               0
          Conv2d-244           [-1, 256, 16, 8]         589,824
     BatchNorm2d-245           [-1, 256, 16, 8]             512
            ReLU-246           [-1, 256, 16, 8]               0
          Conv2d-247          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-248          [-1, 1024, 16, 8]           2,048
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-252           [-1, 128, 16, 8]             256
     BatchNorm2d-253           [-1, 128, 16, 8]             256
             IBN-254           [-1, 256, 16, 8]               0
            ReLU-255           [-1, 256, 16, 8]               0
          Conv2d-256           [-1, 256, 16, 8]         589,824
     BatchNorm2d-257           [-1, 256, 16, 8]             512
            ReLU-258           [-1, 256, 16, 8]               0
          Conv2d-259          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-260          [-1, 1024, 16, 8]           2,048
            ReLU-261          [-1, 1024, 16, 8]               0
      Bottleneck-262          [-1, 1024, 16, 8]               0
          Conv2d-263           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-264           [-1, 128, 16, 8]             256
     BatchNorm2d-265           [-1, 128, 16, 8]             256
             IBN-266           [-1, 256, 16, 8]               0
            ReLU-267           [-1, 256, 16, 8]               0
          Conv2d-268           [-1, 256, 16, 8]         589,824
     BatchNorm2d-269           [-1, 256, 16, 8]             512
            ReLU-270           [-1, 256, 16, 8]               0
          Conv2d-271          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-272          [-1, 1024, 16, 8]           2,048
            ReLU-273          [-1, 1024, 16, 8]               0
      Bottleneck-274          [-1, 1024, 16, 8]               0
          Conv2d-275           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-276           [-1, 128, 16, 8]             256
     BatchNorm2d-277           [-1, 128, 16, 8]             256
             IBN-278           [-1, 256, 16, 8]               0
            ReLU-279           [-1, 256, 16, 8]               0
          Conv2d-280           [-1, 256, 16, 8]         589,824
     BatchNorm2d-281           [-1, 256, 16, 8]             512
            ReLU-282           [-1, 256, 16, 8]               0
          Conv2d-283          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-284          [-1, 1024, 16, 8]           2,048
            ReLU-285          [-1, 1024, 16, 8]               0
      Bottleneck-286          [-1, 1024, 16, 8]               0
          Conv2d-287           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-288           [-1, 128, 16, 8]             256
     BatchNorm2d-289           [-1, 128, 16, 8]             256
             IBN-290           [-1, 256, 16, 8]               0
            ReLU-291           [-1, 256, 16, 8]               0
          Conv2d-292           [-1, 256, 16, 8]         589,824
     BatchNorm2d-293           [-1, 256, 16, 8]             512
            ReLU-294           [-1, 256, 16, 8]               0
          Conv2d-295          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-296          [-1, 1024, 16, 8]           2,048
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-300           [-1, 128, 16, 8]             256
     BatchNorm2d-301           [-1, 128, 16, 8]             256
             IBN-302           [-1, 256, 16, 8]               0
            ReLU-303           [-1, 256, 16, 8]               0
          Conv2d-304           [-1, 256, 16, 8]         589,824
     BatchNorm2d-305           [-1, 256, 16, 8]             512
            ReLU-306           [-1, 256, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
            ReLU-309          [-1, 1024, 16, 8]               0
      Bottleneck-310          [-1, 1024, 16, 8]               0
          Conv2d-311           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-312           [-1, 128, 16, 8]             256
     BatchNorm2d-313           [-1, 128, 16, 8]             256
             IBN-314           [-1, 256, 16, 8]               0
            ReLU-315           [-1, 256, 16, 8]               0
          Conv2d-316           [-1, 256, 16, 8]         589,824
     BatchNorm2d-317           [-1, 256, 16, 8]             512
            ReLU-318           [-1, 256, 16, 8]               0
          Conv2d-319          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-320          [-1, 1024, 16, 8]           2,048
            ReLU-321          [-1, 1024, 16, 8]               0
      Bottleneck-322          [-1, 1024, 16, 8]               0
          Conv2d-323           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-324           [-1, 128, 16, 8]             256
     BatchNorm2d-325           [-1, 128, 16, 8]             256
             IBN-326           [-1, 256, 16, 8]               0
            ReLU-327           [-1, 256, 16, 8]               0
          Conv2d-328           [-1, 256, 16, 8]         589,824
     BatchNorm2d-329           [-1, 256, 16, 8]             512
            ReLU-330           [-1, 256, 16, 8]               0
          Conv2d-331          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-332          [-1, 1024, 16, 8]           2,048
            ReLU-333          [-1, 1024, 16, 8]               0
      Bottleneck-334          [-1, 1024, 16, 8]               0
          Conv2d-335           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-336           [-1, 128, 16, 8]             256
     BatchNorm2d-337           [-1, 128, 16, 8]             256
             IBN-338           [-1, 256, 16, 8]               0
            ReLU-339           [-1, 256, 16, 8]               0
          Conv2d-340           [-1, 256, 16, 8]         589,824
     BatchNorm2d-341           [-1, 256, 16, 8]             512
            ReLU-342           [-1, 256, 16, 8]               0
          Conv2d-343          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-344          [-1, 1024, 16, 8]           2,048
            ReLU-345          [-1, 1024, 16, 8]               0
      Bottleneck-346          [-1, 1024, 16, 8]               0
          Conv2d-347           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-348           [-1, 128, 16, 8]             256
     BatchNorm2d-349           [-1, 128, 16, 8]             256
             IBN-350           [-1, 256, 16, 8]               0
            ReLU-351           [-1, 256, 16, 8]               0
          Conv2d-352           [-1, 256, 16, 8]         589,824
     BatchNorm2d-353           [-1, 256, 16, 8]             512
            ReLU-354           [-1, 256, 16, 8]               0
          Conv2d-355          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-356          [-1, 1024, 16, 8]           2,048
            ReLU-357          [-1, 1024, 16, 8]               0
      Bottleneck-358          [-1, 1024, 16, 8]               0
          Conv2d-359           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-360           [-1, 128, 16, 8]             256
     BatchNorm2d-361           [-1, 128, 16, 8]             256
             IBN-362           [-1, 256, 16, 8]               0
            ReLU-363           [-1, 256, 16, 8]               0
          Conv2d-364           [-1, 256, 16, 8]         589,824
     BatchNorm2d-365           [-1, 256, 16, 8]             512
            ReLU-366           [-1, 256, 16, 8]               0
          Conv2d-367          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-368          [-1, 1024, 16, 8]           2,048
            ReLU-369          [-1, 1024, 16, 8]               0
      Bottleneck-370          [-1, 1024, 16, 8]               0
          Conv2d-371           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-372           [-1, 128, 16, 8]             256
     BatchNorm2d-373           [-1, 128, 16, 8]             256
             IBN-374           [-1, 256, 16, 8]               0
            ReLU-375           [-1, 256, 16, 8]               0
          Conv2d-376           [-1, 256, 16, 8]         589,824
     BatchNorm2d-377           [-1, 256, 16, 8]             512
            ReLU-378           [-1, 256, 16, 8]               0
          Conv2d-379          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-380          [-1, 1024, 16, 8]           2,048
            ReLU-381          [-1, 1024, 16, 8]               0
      Bottleneck-382          [-1, 1024, 16, 8]               0
          Conv2d-383           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-384           [-1, 128, 16, 8]             256
     BatchNorm2d-385           [-1, 128, 16, 8]             256
             IBN-386           [-1, 256, 16, 8]               0
            ReLU-387           [-1, 256, 16, 8]               0
          Conv2d-388           [-1, 256, 16, 8]         589,824
     BatchNorm2d-389           [-1, 256, 16, 8]             512
            ReLU-390           [-1, 256, 16, 8]               0
          Conv2d-391          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-392          [-1, 1024, 16, 8]           2,048
            ReLU-393          [-1, 1024, 16, 8]               0
      Bottleneck-394          [-1, 1024, 16, 8]               0
          Conv2d-395           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-396           [-1, 128, 16, 8]             256
     BatchNorm2d-397           [-1, 128, 16, 8]             256
             IBN-398           [-1, 256, 16, 8]               0
            ReLU-399           [-1, 256, 16, 8]               0
          Conv2d-400           [-1, 256, 16, 8]         589,824
     BatchNorm2d-401           [-1, 256, 16, 8]             512
            ReLU-402           [-1, 256, 16, 8]               0
          Conv2d-403          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-404          [-1, 1024, 16, 8]           2,048
            ReLU-405          [-1, 1024, 16, 8]               0
      Bottleneck-406          [-1, 1024, 16, 8]               0
          Conv2d-407           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-408           [-1, 128, 16, 8]             256
     BatchNorm2d-409           [-1, 128, 16, 8]             256
             IBN-410           [-1, 256, 16, 8]               0
            ReLU-411           [-1, 256, 16, 8]               0
          Conv2d-412           [-1, 256, 16, 8]         589,824
     BatchNorm2d-413           [-1, 256, 16, 8]             512
            ReLU-414           [-1, 256, 16, 8]               0
          Conv2d-415          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-416          [-1, 1024, 16, 8]           2,048
            ReLU-417          [-1, 1024, 16, 8]               0
      Bottleneck-418          [-1, 1024, 16, 8]               0
          Conv2d-419           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-420           [-1, 128, 16, 8]             256
     BatchNorm2d-421           [-1, 128, 16, 8]             256
             IBN-422           [-1, 256, 16, 8]               0
            ReLU-423           [-1, 256, 16, 8]               0
          Conv2d-424           [-1, 256, 16, 8]         589,824
     BatchNorm2d-425           [-1, 256, 16, 8]             512
            ReLU-426           [-1, 256, 16, 8]               0
          Conv2d-427          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-428          [-1, 1024, 16, 8]           2,048
            ReLU-429          [-1, 1024, 16, 8]               0
      Bottleneck-430          [-1, 1024, 16, 8]               0
          Conv2d-431           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-432           [-1, 128, 16, 8]             256
     BatchNorm2d-433           [-1, 128, 16, 8]             256
             IBN-434           [-1, 256, 16, 8]               0
            ReLU-435           [-1, 256, 16, 8]               0
          Conv2d-436           [-1, 256, 16, 8]         589,824
     BatchNorm2d-437           [-1, 256, 16, 8]             512
            ReLU-438           [-1, 256, 16, 8]               0
          Conv2d-439          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-440          [-1, 1024, 16, 8]           2,048
            ReLU-441          [-1, 1024, 16, 8]               0
      Bottleneck-442          [-1, 1024, 16, 8]               0
          Conv2d-443           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-444           [-1, 128, 16, 8]             256
     BatchNorm2d-445           [-1, 128, 16, 8]             256
             IBN-446           [-1, 256, 16, 8]               0
            ReLU-447           [-1, 256, 16, 8]               0
          Conv2d-448           [-1, 256, 16, 8]         589,824
     BatchNorm2d-449           [-1, 256, 16, 8]             512
            ReLU-450           [-1, 256, 16, 8]               0
          Conv2d-451          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-452          [-1, 1024, 16, 8]           2,048
            ReLU-453          [-1, 1024, 16, 8]               0
      Bottleneck-454          [-1, 1024, 16, 8]               0
          Conv2d-455           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-456           [-1, 128, 16, 8]             256
     BatchNorm2d-457           [-1, 128, 16, 8]             256
             IBN-458           [-1, 256, 16, 8]               0
            ReLU-459           [-1, 256, 16, 8]               0
          Conv2d-460           [-1, 256, 16, 8]         589,824
     BatchNorm2d-461           [-1, 256, 16, 8]             512
            ReLU-462           [-1, 256, 16, 8]               0
          Conv2d-463          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-464          [-1, 1024, 16, 8]           2,048
            ReLU-465          [-1, 1024, 16, 8]               0
      Bottleneck-466          [-1, 1024, 16, 8]               0
          Conv2d-467           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-468           [-1, 128, 16, 8]             256
     BatchNorm2d-469           [-1, 128, 16, 8]             256
             IBN-470           [-1, 256, 16, 8]               0
            ReLU-471           [-1, 256, 16, 8]               0
          Conv2d-472           [-1, 256, 16, 8]         589,824
     BatchNorm2d-473           [-1, 256, 16, 8]             512
            ReLU-474           [-1, 256, 16, 8]               0
          Conv2d-475          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-476          [-1, 1024, 16, 8]           2,048
            ReLU-477          [-1, 1024, 16, 8]               0
      Bottleneck-478          [-1, 1024, 16, 8]               0
          Conv2d-479           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-480           [-1, 128, 16, 8]             256
     BatchNorm2d-481           [-1, 128, 16, 8]             256
             IBN-482           [-1, 256, 16, 8]               0
            ReLU-483           [-1, 256, 16, 8]               0
          Conv2d-484           [-1, 256, 16, 8]         589,824
     BatchNorm2d-485           [-1, 256, 16, 8]             512
            ReLU-486           [-1, 256, 16, 8]               0
          Conv2d-487          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-488          [-1, 1024, 16, 8]           2,048
            ReLU-489          [-1, 1024, 16, 8]               0
      Bottleneck-490          [-1, 1024, 16, 8]               0
          Conv2d-491           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-492           [-1, 128, 16, 8]             256
     BatchNorm2d-493           [-1, 128, 16, 8]             256
             IBN-494           [-1, 256, 16, 8]               0
            ReLU-495           [-1, 256, 16, 8]               0
          Conv2d-496           [-1, 256, 16, 8]         589,824
     BatchNorm2d-497           [-1, 256, 16, 8]             512
            ReLU-498           [-1, 256, 16, 8]               0
          Conv2d-499          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-500          [-1, 1024, 16, 8]           2,048
            ReLU-501          [-1, 1024, 16, 8]               0
      Bottleneck-502          [-1, 1024, 16, 8]               0
          Conv2d-503           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-504           [-1, 128, 16, 8]             256
     BatchNorm2d-505           [-1, 128, 16, 8]             256
             IBN-506           [-1, 256, 16, 8]               0
            ReLU-507           [-1, 256, 16, 8]               0
          Conv2d-508           [-1, 256, 16, 8]         589,824
     BatchNorm2d-509           [-1, 256, 16, 8]             512
            ReLU-510           [-1, 256, 16, 8]               0
          Conv2d-511          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-512          [-1, 1024, 16, 8]           2,048
            ReLU-513          [-1, 1024, 16, 8]               0
      Bottleneck-514          [-1, 1024, 16, 8]               0
          Conv2d-515           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-516           [-1, 128, 16, 8]             256
     BatchNorm2d-517           [-1, 128, 16, 8]             256
             IBN-518           [-1, 256, 16, 8]               0
            ReLU-519           [-1, 256, 16, 8]               0
          Conv2d-520           [-1, 256, 16, 8]         589,824
     BatchNorm2d-521           [-1, 256, 16, 8]             512
            ReLU-522           [-1, 256, 16, 8]               0
          Conv2d-523          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-524          [-1, 1024, 16, 8]           2,048
            ReLU-525          [-1, 1024, 16, 8]               0
      Bottleneck-526          [-1, 1024, 16, 8]               0
          Conv2d-527           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-528           [-1, 128, 16, 8]             256
     BatchNorm2d-529           [-1, 128, 16, 8]             256
             IBN-530           [-1, 256, 16, 8]               0
            ReLU-531           [-1, 256, 16, 8]               0
          Conv2d-532           [-1, 256, 16, 8]         589,824
     BatchNorm2d-533           [-1, 256, 16, 8]             512
            ReLU-534           [-1, 256, 16, 8]               0
          Conv2d-535          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-536          [-1, 1024, 16, 8]           2,048
            ReLU-537          [-1, 1024, 16, 8]               0
      Bottleneck-538          [-1, 1024, 16, 8]               0
          Conv2d-539           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-540           [-1, 128, 16, 8]             256
     BatchNorm2d-541           [-1, 128, 16, 8]             256
             IBN-542           [-1, 256, 16, 8]               0
            ReLU-543           [-1, 256, 16, 8]               0
          Conv2d-544           [-1, 256, 16, 8]         589,824
     BatchNorm2d-545           [-1, 256, 16, 8]             512
            ReLU-546           [-1, 256, 16, 8]               0
          Conv2d-547          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-548          [-1, 1024, 16, 8]           2,048
            ReLU-549          [-1, 1024, 16, 8]               0
      Bottleneck-550          [-1, 1024, 16, 8]               0
          Conv2d-551           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-552           [-1, 128, 16, 8]             256
     BatchNorm2d-553           [-1, 128, 16, 8]             256
             IBN-554           [-1, 256, 16, 8]               0
            ReLU-555           [-1, 256, 16, 8]               0
          Conv2d-556           [-1, 256, 16, 8]         589,824
     BatchNorm2d-557           [-1, 256, 16, 8]             512
            ReLU-558           [-1, 256, 16, 8]               0
          Conv2d-559          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-560          [-1, 1024, 16, 8]           2,048
            ReLU-561          [-1, 1024, 16, 8]               0
      Bottleneck-562          [-1, 1024, 16, 8]               0
          Conv2d-563           [-1, 256, 16, 8]         262,144
  InstanceNorm2d-564           [-1, 128, 16, 8]             256
     BatchNorm2d-565           [-1, 128, 16, 8]             256
             IBN-566           [-1, 256, 16, 8]               0
            ReLU-567           [-1, 256, 16, 8]               0
          Conv2d-568           [-1, 256, 16, 8]         589,824
     BatchNorm2d-569           [-1, 256, 16, 8]             512
            ReLU-570           [-1, 256, 16, 8]               0
          Conv2d-571          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-572          [-1, 1024, 16, 8]           2,048
            ReLU-573          [-1, 1024, 16, 8]               0
      Bottleneck-574          [-1, 1024, 16, 8]               0
          Conv2d-575           [-1, 512, 16, 8]         524,288
     BatchNorm2d-576           [-1, 512, 16, 8]           1,024
            ReLU-577           [-1, 512, 16, 8]               0
          Conv2d-578           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-579           [-1, 512, 16, 8]           1,024
            ReLU-580           [-1, 512, 16, 8]               0
          Conv2d-581          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-582          [-1, 2048, 16, 8]           4,096
          Conv2d-583          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-584          [-1, 2048, 16, 8]           4,096
            ReLU-585          [-1, 2048, 16, 8]               0
      Bottleneck-586          [-1, 2048, 16, 8]               0
          Conv2d-587           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-588           [-1, 512, 16, 8]           1,024
            ReLU-589           [-1, 512, 16, 8]               0
          Conv2d-590           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-591           [-1, 512, 16, 8]           1,024
            ReLU-592           [-1, 512, 16, 8]               0
          Conv2d-593          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-594          [-1, 2048, 16, 8]           4,096
            ReLU-595          [-1, 2048, 16, 8]               0
      Bottleneck-596          [-1, 2048, 16, 8]               0
          Conv2d-597           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-598           [-1, 512, 16, 8]           1,024
            ReLU-599           [-1, 512, 16, 8]               0
          Conv2d-600           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-601           [-1, 512, 16, 8]           1,024
            ReLU-602           [-1, 512, 16, 8]               0
          Conv2d-603          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-604          [-1, 2048, 16, 8]           4,096
            ReLU-605          [-1, 2048, 16, 8]               0
      Bottleneck-606          [-1, 2048, 16, 8]               0
================================================================
Total params: 58,143,808
Trainable params: 58,143,808
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 441.00
Params size (MB): 221.80
Estimated Total Size (MB): 663.18
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnet152_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5           [-1, 64, 64, 32]           4,096
       BatchNorm2d-6           [-1, 64, 64, 32]             128
              ReLU-7           [-1, 64, 64, 32]               0
            Conv2d-8           [-1, 64, 64, 32]          36,864
       BatchNorm2d-9           [-1, 64, 64, 32]             128
             ReLU-10           [-1, 64, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          16,384
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
   InstanceNorm2d-15          [-1, 256, 64, 32]             512
             ReLU-16          [-1, 256, 64, 32]               0
       Bottleneck-17          [-1, 256, 64, 32]               0
           Conv2d-18           [-1, 64, 64, 32]          16,384
      BatchNorm2d-19           [-1, 64, 64, 32]             128
             ReLU-20           [-1, 64, 64, 32]               0
           Conv2d-21           [-1, 64, 64, 32]          36,864
      BatchNorm2d-22           [-1, 64, 64, 32]             128
             ReLU-23           [-1, 64, 64, 32]               0
           Conv2d-24          [-1, 256, 64, 32]          16,384
      BatchNorm2d-25          [-1, 256, 64, 32]             512
   InstanceNorm2d-26          [-1, 256, 64, 32]             512
             ReLU-27          [-1, 256, 64, 32]               0
       Bottleneck-28          [-1, 256, 64, 32]               0
           Conv2d-29           [-1, 64, 64, 32]          16,384
      BatchNorm2d-30           [-1, 64, 64, 32]             128
             ReLU-31           [-1, 64, 64, 32]               0
           Conv2d-32           [-1, 64, 64, 32]          36,864
      BatchNorm2d-33           [-1, 64, 64, 32]             128
             ReLU-34           [-1, 64, 64, 32]               0
           Conv2d-35          [-1, 256, 64, 32]          16,384
      BatchNorm2d-36          [-1, 256, 64, 32]             512
   InstanceNorm2d-37          [-1, 256, 64, 32]             512
             ReLU-38          [-1, 256, 64, 32]               0
       Bottleneck-39          [-1, 256, 64, 32]               0
           Conv2d-40          [-1, 128, 64, 32]          32,768
      BatchNorm2d-41          [-1, 128, 64, 32]             256
             ReLU-42          [-1, 128, 64, 32]               0
           Conv2d-43          [-1, 128, 32, 16]         147,456
      BatchNorm2d-44          [-1, 128, 32, 16]             256
             ReLU-45          [-1, 128, 32, 16]               0
           Conv2d-46          [-1, 512, 32, 16]          65,536
      BatchNorm2d-47          [-1, 512, 32, 16]           1,024
           Conv2d-48          [-1, 512, 32, 16]         131,072
      BatchNorm2d-49          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-50          [-1, 512, 32, 16]           1,024
             ReLU-51          [-1, 512, 32, 16]               0
       Bottleneck-52          [-1, 512, 32, 16]               0
           Conv2d-53          [-1, 128, 32, 16]          65,536
      BatchNorm2d-54          [-1, 128, 32, 16]             256
             ReLU-55          [-1, 128, 32, 16]               0
           Conv2d-56          [-1, 128, 32, 16]         147,456
      BatchNorm2d-57          [-1, 128, 32, 16]             256
             ReLU-58          [-1, 128, 32, 16]               0
           Conv2d-59          [-1, 512, 32, 16]          65,536
      BatchNorm2d-60          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-61          [-1, 512, 32, 16]           1,024
             ReLU-62          [-1, 512, 32, 16]               0
       Bottleneck-63          [-1, 512, 32, 16]               0
           Conv2d-64          [-1, 128, 32, 16]          65,536
      BatchNorm2d-65          [-1, 128, 32, 16]             256
             ReLU-66          [-1, 128, 32, 16]               0
           Conv2d-67          [-1, 128, 32, 16]         147,456
      BatchNorm2d-68          [-1, 128, 32, 16]             256
             ReLU-69          [-1, 128, 32, 16]               0
           Conv2d-70          [-1, 512, 32, 16]          65,536
      BatchNorm2d-71          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-72          [-1, 512, 32, 16]           1,024
             ReLU-73          [-1, 512, 32, 16]               0
       Bottleneck-74          [-1, 512, 32, 16]               0
           Conv2d-75          [-1, 128, 32, 16]          65,536
      BatchNorm2d-76          [-1, 128, 32, 16]             256
             ReLU-77          [-1, 128, 32, 16]               0
           Conv2d-78          [-1, 128, 32, 16]         147,456
      BatchNorm2d-79          [-1, 128, 32, 16]             256
             ReLU-80          [-1, 128, 32, 16]               0
           Conv2d-81          [-1, 512, 32, 16]          65,536
      BatchNorm2d-82          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-83          [-1, 512, 32, 16]           1,024
             ReLU-84          [-1, 512, 32, 16]               0
       Bottleneck-85          [-1, 512, 32, 16]               0
           Conv2d-86          [-1, 128, 32, 16]          65,536
      BatchNorm2d-87          [-1, 128, 32, 16]             256
             ReLU-88          [-1, 128, 32, 16]               0
           Conv2d-89          [-1, 128, 32, 16]         147,456
      BatchNorm2d-90          [-1, 128, 32, 16]             256
             ReLU-91          [-1, 128, 32, 16]               0
           Conv2d-92          [-1, 512, 32, 16]          65,536
      BatchNorm2d-93          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-94          [-1, 512, 32, 16]           1,024
             ReLU-95          [-1, 512, 32, 16]               0
       Bottleneck-96          [-1, 512, 32, 16]               0
           Conv2d-97          [-1, 128, 32, 16]          65,536
      BatchNorm2d-98          [-1, 128, 32, 16]             256
             ReLU-99          [-1, 128, 32, 16]               0
          Conv2d-100          [-1, 128, 32, 16]         147,456
     BatchNorm2d-101          [-1, 128, 32, 16]             256
            ReLU-102          [-1, 128, 32, 16]               0
          Conv2d-103          [-1, 512, 32, 16]          65,536
     BatchNorm2d-104          [-1, 512, 32, 16]           1,024
  InstanceNorm2d-105          [-1, 512, 32, 16]           1,024
            ReLU-106          [-1, 512, 32, 16]               0
      Bottleneck-107          [-1, 512, 32, 16]               0
          Conv2d-108          [-1, 128, 32, 16]          65,536
     BatchNorm2d-109          [-1, 128, 32, 16]             256
            ReLU-110          [-1, 128, 32, 16]               0
          Conv2d-111          [-1, 128, 32, 16]         147,456
     BatchNorm2d-112          [-1, 128, 32, 16]             256
            ReLU-113          [-1, 128, 32, 16]               0
          Conv2d-114          [-1, 512, 32, 16]          65,536
     BatchNorm2d-115          [-1, 512, 32, 16]           1,024
  InstanceNorm2d-116          [-1, 512, 32, 16]           1,024
            ReLU-117          [-1, 512, 32, 16]               0
      Bottleneck-118          [-1, 512, 32, 16]               0
          Conv2d-119          [-1, 128, 32, 16]          65,536
     BatchNorm2d-120          [-1, 128, 32, 16]             256
            ReLU-121          [-1, 128, 32, 16]               0
          Conv2d-122          [-1, 128, 32, 16]         147,456
     BatchNorm2d-123          [-1, 128, 32, 16]             256
            ReLU-124          [-1, 128, 32, 16]               0
          Conv2d-125          [-1, 512, 32, 16]          65,536
     BatchNorm2d-126          [-1, 512, 32, 16]           1,024
  InstanceNorm2d-127          [-1, 512, 32, 16]           1,024
            ReLU-128          [-1, 512, 32, 16]               0
      Bottleneck-129          [-1, 512, 32, 16]               0
          Conv2d-130          [-1, 256, 32, 16]         131,072
     BatchNorm2d-131          [-1, 256, 32, 16]             512
            ReLU-132          [-1, 256, 32, 16]               0
          Conv2d-133           [-1, 256, 16, 8]         589,824
     BatchNorm2d-134           [-1, 256, 16, 8]             512
            ReLU-135           [-1, 256, 16, 8]               0
          Conv2d-136          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-137          [-1, 1024, 16, 8]           2,048
          Conv2d-138          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-139          [-1, 1024, 16, 8]           2,048
            ReLU-140          [-1, 1024, 16, 8]               0
      Bottleneck-141          [-1, 1024, 16, 8]               0
          Conv2d-142           [-1, 256, 16, 8]         262,144
     BatchNorm2d-143           [-1, 256, 16, 8]             512
            ReLU-144           [-1, 256, 16, 8]               0
          Conv2d-145           [-1, 256, 16, 8]         589,824
     BatchNorm2d-146           [-1, 256, 16, 8]             512
            ReLU-147           [-1, 256, 16, 8]               0
          Conv2d-148          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-149          [-1, 1024, 16, 8]           2,048
            ReLU-150          [-1, 1024, 16, 8]               0
      Bottleneck-151          [-1, 1024, 16, 8]               0
          Conv2d-152           [-1, 256, 16, 8]         262,144
     BatchNorm2d-153           [-1, 256, 16, 8]             512
            ReLU-154           [-1, 256, 16, 8]               0
          Conv2d-155           [-1, 256, 16, 8]         589,824
     BatchNorm2d-156           [-1, 256, 16, 8]             512
            ReLU-157           [-1, 256, 16, 8]               0
          Conv2d-158          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-159          [-1, 1024, 16, 8]           2,048
            ReLU-160          [-1, 1024, 16, 8]               0
      Bottleneck-161          [-1, 1024, 16, 8]               0
          Conv2d-162           [-1, 256, 16, 8]         262,144
     BatchNorm2d-163           [-1, 256, 16, 8]             512
            ReLU-164           [-1, 256, 16, 8]               0
          Conv2d-165           [-1, 256, 16, 8]         589,824
     BatchNorm2d-166           [-1, 256, 16, 8]             512
            ReLU-167           [-1, 256, 16, 8]               0
          Conv2d-168          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-169          [-1, 1024, 16, 8]           2,048
            ReLU-170          [-1, 1024, 16, 8]               0
      Bottleneck-171          [-1, 1024, 16, 8]               0
          Conv2d-172           [-1, 256, 16, 8]         262,144
     BatchNorm2d-173           [-1, 256, 16, 8]             512
            ReLU-174           [-1, 256, 16, 8]               0
          Conv2d-175           [-1, 256, 16, 8]         589,824
     BatchNorm2d-176           [-1, 256, 16, 8]             512
            ReLU-177           [-1, 256, 16, 8]               0
          Conv2d-178          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-179          [-1, 1024, 16, 8]           2,048
            ReLU-180          [-1, 1024, 16, 8]               0
      Bottleneck-181          [-1, 1024, 16, 8]               0
          Conv2d-182           [-1, 256, 16, 8]         262,144
     BatchNorm2d-183           [-1, 256, 16, 8]             512
            ReLU-184           [-1, 256, 16, 8]               0
          Conv2d-185           [-1, 256, 16, 8]         589,824
     BatchNorm2d-186           [-1, 256, 16, 8]             512
            ReLU-187           [-1, 256, 16, 8]               0
          Conv2d-188          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-189          [-1, 1024, 16, 8]           2,048
            ReLU-190          [-1, 1024, 16, 8]               0
      Bottleneck-191          [-1, 1024, 16, 8]               0
          Conv2d-192           [-1, 256, 16, 8]         262,144
     BatchNorm2d-193           [-1, 256, 16, 8]             512
            ReLU-194           [-1, 256, 16, 8]               0
          Conv2d-195           [-1, 256, 16, 8]         589,824
     BatchNorm2d-196           [-1, 256, 16, 8]             512
            ReLU-197           [-1, 256, 16, 8]               0
          Conv2d-198          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-199          [-1, 1024, 16, 8]           2,048
            ReLU-200          [-1, 1024, 16, 8]               0
      Bottleneck-201          [-1, 1024, 16, 8]               0
          Conv2d-202           [-1, 256, 16, 8]         262,144
     BatchNorm2d-203           [-1, 256, 16, 8]             512
            ReLU-204           [-1, 256, 16, 8]               0
          Conv2d-205           [-1, 256, 16, 8]         589,824
     BatchNorm2d-206           [-1, 256, 16, 8]             512
            ReLU-207           [-1, 256, 16, 8]               0
          Conv2d-208          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-209          [-1, 1024, 16, 8]           2,048
            ReLU-210          [-1, 1024, 16, 8]               0
      Bottleneck-211          [-1, 1024, 16, 8]               0
          Conv2d-212           [-1, 256, 16, 8]         262,144
     BatchNorm2d-213           [-1, 256, 16, 8]             512
            ReLU-214           [-1, 256, 16, 8]               0
          Conv2d-215           [-1, 256, 16, 8]         589,824
     BatchNorm2d-216           [-1, 256, 16, 8]             512
            ReLU-217           [-1, 256, 16, 8]               0
          Conv2d-218          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-219          [-1, 1024, 16, 8]           2,048
            ReLU-220          [-1, 1024, 16, 8]               0
      Bottleneck-221          [-1, 1024, 16, 8]               0
          Conv2d-222           [-1, 256, 16, 8]         262,144
     BatchNorm2d-223           [-1, 256, 16, 8]             512
            ReLU-224           [-1, 256, 16, 8]               0
          Conv2d-225           [-1, 256, 16, 8]         589,824
     BatchNorm2d-226           [-1, 256, 16, 8]             512
            ReLU-227           [-1, 256, 16, 8]               0
          Conv2d-228          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-229          [-1, 1024, 16, 8]           2,048
            ReLU-230          [-1, 1024, 16, 8]               0
      Bottleneck-231          [-1, 1024, 16, 8]               0
          Conv2d-232           [-1, 256, 16, 8]         262,144
     BatchNorm2d-233           [-1, 256, 16, 8]             512
            ReLU-234           [-1, 256, 16, 8]               0
          Conv2d-235           [-1, 256, 16, 8]         589,824
     BatchNorm2d-236           [-1, 256, 16, 8]             512
            ReLU-237           [-1, 256, 16, 8]               0
          Conv2d-238          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-239          [-1, 1024, 16, 8]           2,048
            ReLU-240          [-1, 1024, 16, 8]               0
      Bottleneck-241          [-1, 1024, 16, 8]               0
          Conv2d-242           [-1, 256, 16, 8]         262,144
     BatchNorm2d-243           [-1, 256, 16, 8]             512
            ReLU-244           [-1, 256, 16, 8]               0
          Conv2d-245           [-1, 256, 16, 8]         589,824
     BatchNorm2d-246           [-1, 256, 16, 8]             512
            ReLU-247           [-1, 256, 16, 8]               0
          Conv2d-248          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-249          [-1, 1024, 16, 8]           2,048
            ReLU-250          [-1, 1024, 16, 8]               0
      Bottleneck-251          [-1, 1024, 16, 8]               0
          Conv2d-252           [-1, 256, 16, 8]         262,144
     BatchNorm2d-253           [-1, 256, 16, 8]             512
            ReLU-254           [-1, 256, 16, 8]               0
          Conv2d-255           [-1, 256, 16, 8]         589,824
     BatchNorm2d-256           [-1, 256, 16, 8]             512
            ReLU-257           [-1, 256, 16, 8]               0
          Conv2d-258          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-259          [-1, 1024, 16, 8]           2,048
            ReLU-260          [-1, 1024, 16, 8]               0
      Bottleneck-261          [-1, 1024, 16, 8]               0
          Conv2d-262           [-1, 256, 16, 8]         262,144
     BatchNorm2d-263           [-1, 256, 16, 8]             512
            ReLU-264           [-1, 256, 16, 8]               0
          Conv2d-265           [-1, 256, 16, 8]         589,824
     BatchNorm2d-266           [-1, 256, 16, 8]             512
            ReLU-267           [-1, 256, 16, 8]               0
          Conv2d-268          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-269          [-1, 1024, 16, 8]           2,048
            ReLU-270          [-1, 1024, 16, 8]               0
      Bottleneck-271          [-1, 1024, 16, 8]               0
          Conv2d-272           [-1, 256, 16, 8]         262,144
     BatchNorm2d-273           [-1, 256, 16, 8]             512
            ReLU-274           [-1, 256, 16, 8]               0
          Conv2d-275           [-1, 256, 16, 8]         589,824
     BatchNorm2d-276           [-1, 256, 16, 8]             512
            ReLU-277           [-1, 256, 16, 8]               0
          Conv2d-278          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-279          [-1, 1024, 16, 8]           2,048
            ReLU-280          [-1, 1024, 16, 8]               0
      Bottleneck-281          [-1, 1024, 16, 8]               0
          Conv2d-282           [-1, 256, 16, 8]         262,144
     BatchNorm2d-283           [-1, 256, 16, 8]             512
            ReLU-284           [-1, 256, 16, 8]               0
          Conv2d-285           [-1, 256, 16, 8]         589,824
     BatchNorm2d-286           [-1, 256, 16, 8]             512
            ReLU-287           [-1, 256, 16, 8]               0
          Conv2d-288          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-289          [-1, 1024, 16, 8]           2,048
            ReLU-290          [-1, 1024, 16, 8]               0
      Bottleneck-291          [-1, 1024, 16, 8]               0
          Conv2d-292           [-1, 256, 16, 8]         262,144
     BatchNorm2d-293           [-1, 256, 16, 8]             512
            ReLU-294           [-1, 256, 16, 8]               0
          Conv2d-295           [-1, 256, 16, 8]         589,824
     BatchNorm2d-296           [-1, 256, 16, 8]             512
            ReLU-297           [-1, 256, 16, 8]               0
          Conv2d-298          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-299          [-1, 1024, 16, 8]           2,048
            ReLU-300          [-1, 1024, 16, 8]               0
      Bottleneck-301          [-1, 1024, 16, 8]               0
          Conv2d-302           [-1, 256, 16, 8]         262,144
     BatchNorm2d-303           [-1, 256, 16, 8]             512
            ReLU-304           [-1, 256, 16, 8]               0
          Conv2d-305           [-1, 256, 16, 8]         589,824
     BatchNorm2d-306           [-1, 256, 16, 8]             512
            ReLU-307           [-1, 256, 16, 8]               0
          Conv2d-308          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-309          [-1, 1024, 16, 8]           2,048
            ReLU-310          [-1, 1024, 16, 8]               0
      Bottleneck-311          [-1, 1024, 16, 8]               0
          Conv2d-312           [-1, 256, 16, 8]         262,144
     BatchNorm2d-313           [-1, 256, 16, 8]             512
            ReLU-314           [-1, 256, 16, 8]               0
          Conv2d-315           [-1, 256, 16, 8]         589,824
     BatchNorm2d-316           [-1, 256, 16, 8]             512
            ReLU-317           [-1, 256, 16, 8]               0
          Conv2d-318          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-319          [-1, 1024, 16, 8]           2,048
            ReLU-320          [-1, 1024, 16, 8]               0
      Bottleneck-321          [-1, 1024, 16, 8]               0
          Conv2d-322           [-1, 256, 16, 8]         262,144
     BatchNorm2d-323           [-1, 256, 16, 8]             512
            ReLU-324           [-1, 256, 16, 8]               0
          Conv2d-325           [-1, 256, 16, 8]         589,824
     BatchNorm2d-326           [-1, 256, 16, 8]             512
            ReLU-327           [-1, 256, 16, 8]               0
          Conv2d-328          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-329          [-1, 1024, 16, 8]           2,048
            ReLU-330          [-1, 1024, 16, 8]               0
      Bottleneck-331          [-1, 1024, 16, 8]               0
          Conv2d-332           [-1, 256, 16, 8]         262,144
     BatchNorm2d-333           [-1, 256, 16, 8]             512
            ReLU-334           [-1, 256, 16, 8]               0
          Conv2d-335           [-1, 256, 16, 8]         589,824
     BatchNorm2d-336           [-1, 256, 16, 8]             512
            ReLU-337           [-1, 256, 16, 8]               0
          Conv2d-338          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-339          [-1, 1024, 16, 8]           2,048
            ReLU-340          [-1, 1024, 16, 8]               0
      Bottleneck-341          [-1, 1024, 16, 8]               0
          Conv2d-342           [-1, 256, 16, 8]         262,144
     BatchNorm2d-343           [-1, 256, 16, 8]             512
            ReLU-344           [-1, 256, 16, 8]               0
          Conv2d-345           [-1, 256, 16, 8]         589,824
     BatchNorm2d-346           [-1, 256, 16, 8]             512
            ReLU-347           [-1, 256, 16, 8]               0
          Conv2d-348          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-349          [-1, 1024, 16, 8]           2,048
            ReLU-350          [-1, 1024, 16, 8]               0
      Bottleneck-351          [-1, 1024, 16, 8]               0
          Conv2d-352           [-1, 256, 16, 8]         262,144
     BatchNorm2d-353           [-1, 256, 16, 8]             512
            ReLU-354           [-1, 256, 16, 8]               0
          Conv2d-355           [-1, 256, 16, 8]         589,824
     BatchNorm2d-356           [-1, 256, 16, 8]             512
            ReLU-357           [-1, 256, 16, 8]               0
          Conv2d-358          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-359          [-1, 1024, 16, 8]           2,048
            ReLU-360          [-1, 1024, 16, 8]               0
      Bottleneck-361          [-1, 1024, 16, 8]               0
          Conv2d-362           [-1, 256, 16, 8]         262,144
     BatchNorm2d-363           [-1, 256, 16, 8]             512
            ReLU-364           [-1, 256, 16, 8]               0
          Conv2d-365           [-1, 256, 16, 8]         589,824
     BatchNorm2d-366           [-1, 256, 16, 8]             512
            ReLU-367           [-1, 256, 16, 8]               0
          Conv2d-368          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-369          [-1, 1024, 16, 8]           2,048
            ReLU-370          [-1, 1024, 16, 8]               0
      Bottleneck-371          [-1, 1024, 16, 8]               0
          Conv2d-372           [-1, 256, 16, 8]         262,144
     BatchNorm2d-373           [-1, 256, 16, 8]             512
            ReLU-374           [-1, 256, 16, 8]               0
          Conv2d-375           [-1, 256, 16, 8]         589,824
     BatchNorm2d-376           [-1, 256, 16, 8]             512
            ReLU-377           [-1, 256, 16, 8]               0
          Conv2d-378          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-379          [-1, 1024, 16, 8]           2,048
            ReLU-380          [-1, 1024, 16, 8]               0
      Bottleneck-381          [-1, 1024, 16, 8]               0
          Conv2d-382           [-1, 256, 16, 8]         262,144
     BatchNorm2d-383           [-1, 256, 16, 8]             512
            ReLU-384           [-1, 256, 16, 8]               0
          Conv2d-385           [-1, 256, 16, 8]         589,824
     BatchNorm2d-386           [-1, 256, 16, 8]             512
            ReLU-387           [-1, 256, 16, 8]               0
          Conv2d-388          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-389          [-1, 1024, 16, 8]           2,048
            ReLU-390          [-1, 1024, 16, 8]               0
      Bottleneck-391          [-1, 1024, 16, 8]               0
          Conv2d-392           [-1, 256, 16, 8]         262,144
     BatchNorm2d-393           [-1, 256, 16, 8]             512
            ReLU-394           [-1, 256, 16, 8]               0
          Conv2d-395           [-1, 256, 16, 8]         589,824
     BatchNorm2d-396           [-1, 256, 16, 8]             512
            ReLU-397           [-1, 256, 16, 8]               0
          Conv2d-398          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-399          [-1, 1024, 16, 8]           2,048
            ReLU-400          [-1, 1024, 16, 8]               0
      Bottleneck-401          [-1, 1024, 16, 8]               0
          Conv2d-402           [-1, 256, 16, 8]         262,144
     BatchNorm2d-403           [-1, 256, 16, 8]             512
            ReLU-404           [-1, 256, 16, 8]               0
          Conv2d-405           [-1, 256, 16, 8]         589,824
     BatchNorm2d-406           [-1, 256, 16, 8]             512
            ReLU-407           [-1, 256, 16, 8]               0
          Conv2d-408          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-409          [-1, 1024, 16, 8]           2,048
            ReLU-410          [-1, 1024, 16, 8]               0
      Bottleneck-411          [-1, 1024, 16, 8]               0
          Conv2d-412           [-1, 256, 16, 8]         262,144
     BatchNorm2d-413           [-1, 256, 16, 8]             512
            ReLU-414           [-1, 256, 16, 8]               0
          Conv2d-415           [-1, 256, 16, 8]         589,824
     BatchNorm2d-416           [-1, 256, 16, 8]             512
            ReLU-417           [-1, 256, 16, 8]               0
          Conv2d-418          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-419          [-1, 1024, 16, 8]           2,048
            ReLU-420          [-1, 1024, 16, 8]               0
      Bottleneck-421          [-1, 1024, 16, 8]               0
          Conv2d-422           [-1, 256, 16, 8]         262,144
     BatchNorm2d-423           [-1, 256, 16, 8]             512
            ReLU-424           [-1, 256, 16, 8]               0
          Conv2d-425           [-1, 256, 16, 8]         589,824
     BatchNorm2d-426           [-1, 256, 16, 8]             512
            ReLU-427           [-1, 256, 16, 8]               0
          Conv2d-428          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-429          [-1, 1024, 16, 8]           2,048
            ReLU-430          [-1, 1024, 16, 8]               0
      Bottleneck-431          [-1, 1024, 16, 8]               0
          Conv2d-432           [-1, 256, 16, 8]         262,144
     BatchNorm2d-433           [-1, 256, 16, 8]             512
            ReLU-434           [-1, 256, 16, 8]               0
          Conv2d-435           [-1, 256, 16, 8]         589,824
     BatchNorm2d-436           [-1, 256, 16, 8]             512
            ReLU-437           [-1, 256, 16, 8]               0
          Conv2d-438          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-439          [-1, 1024, 16, 8]           2,048
            ReLU-440          [-1, 1024, 16, 8]               0
      Bottleneck-441          [-1, 1024, 16, 8]               0
          Conv2d-442           [-1, 256, 16, 8]         262,144
     BatchNorm2d-443           [-1, 256, 16, 8]             512
            ReLU-444           [-1, 256, 16, 8]               0
          Conv2d-445           [-1, 256, 16, 8]         589,824
     BatchNorm2d-446           [-1, 256, 16, 8]             512
            ReLU-447           [-1, 256, 16, 8]               0
          Conv2d-448          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-449          [-1, 1024, 16, 8]           2,048
            ReLU-450          [-1, 1024, 16, 8]               0
      Bottleneck-451          [-1, 1024, 16, 8]               0
          Conv2d-452           [-1, 256, 16, 8]         262,144
     BatchNorm2d-453           [-1, 256, 16, 8]             512
            ReLU-454           [-1, 256, 16, 8]               0
          Conv2d-455           [-1, 256, 16, 8]         589,824
     BatchNorm2d-456           [-1, 256, 16, 8]             512
            ReLU-457           [-1, 256, 16, 8]               0
          Conv2d-458          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-459          [-1, 1024, 16, 8]           2,048
            ReLU-460          [-1, 1024, 16, 8]               0
      Bottleneck-461          [-1, 1024, 16, 8]               0
          Conv2d-462           [-1, 256, 16, 8]         262,144
     BatchNorm2d-463           [-1, 256, 16, 8]             512
            ReLU-464           [-1, 256, 16, 8]               0
          Conv2d-465           [-1, 256, 16, 8]         589,824
     BatchNorm2d-466           [-1, 256, 16, 8]             512
            ReLU-467           [-1, 256, 16, 8]               0
          Conv2d-468          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-469          [-1, 1024, 16, 8]           2,048
            ReLU-470          [-1, 1024, 16, 8]               0
      Bottleneck-471          [-1, 1024, 16, 8]               0
          Conv2d-472           [-1, 256, 16, 8]         262,144
     BatchNorm2d-473           [-1, 256, 16, 8]             512
            ReLU-474           [-1, 256, 16, 8]               0
          Conv2d-475           [-1, 256, 16, 8]         589,824
     BatchNorm2d-476           [-1, 256, 16, 8]             512
            ReLU-477           [-1, 256, 16, 8]               0
          Conv2d-478          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-479          [-1, 1024, 16, 8]           2,048
            ReLU-480          [-1, 1024, 16, 8]               0
      Bottleneck-481          [-1, 1024, 16, 8]               0
          Conv2d-482           [-1, 256, 16, 8]         262,144
     BatchNorm2d-483           [-1, 256, 16, 8]             512
            ReLU-484           [-1, 256, 16, 8]               0
          Conv2d-485           [-1, 256, 16, 8]         589,824
     BatchNorm2d-486           [-1, 256, 16, 8]             512
            ReLU-487           [-1, 256, 16, 8]               0
          Conv2d-488          [-1, 1024, 16, 8]         262,144
     BatchNorm2d-489          [-1, 1024, 16, 8]           2,048
            ReLU-490          [-1, 1024, 16, 8]               0
      Bottleneck-491          [-1, 1024, 16, 8]               0
          Conv2d-492           [-1, 512, 16, 8]         524,288
     BatchNorm2d-493           [-1, 512, 16, 8]           1,024
            ReLU-494           [-1, 512, 16, 8]               0
          Conv2d-495           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-496           [-1, 512, 16, 8]           1,024
            ReLU-497           [-1, 512, 16, 8]               0
          Conv2d-498          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-499          [-1, 2048, 16, 8]           4,096
          Conv2d-500          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-501          [-1, 2048, 16, 8]           4,096
            ReLU-502          [-1, 2048, 16, 8]               0
      Bottleneck-503          [-1, 2048, 16, 8]               0
          Conv2d-504           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-505           [-1, 512, 16, 8]           1,024
            ReLU-506           [-1, 512, 16, 8]               0
          Conv2d-507           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-508           [-1, 512, 16, 8]           1,024
            ReLU-509           [-1, 512, 16, 8]               0
          Conv2d-510          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-511          [-1, 2048, 16, 8]           4,096
            ReLU-512          [-1, 2048, 16, 8]               0
      Bottleneck-513          [-1, 2048, 16, 8]               0
          Conv2d-514           [-1, 512, 16, 8]       1,048,576
     BatchNorm2d-515           [-1, 512, 16, 8]           1,024
            ReLU-516           [-1, 512, 16, 8]               0
          Conv2d-517           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-518           [-1, 512, 16, 8]           1,024
            ReLU-519           [-1, 512, 16, 8]               0
          Conv2d-520          [-1, 2048, 16, 8]       1,048,576
     BatchNorm2d-521          [-1, 2048, 16, 8]           4,096
            ReLU-522          [-1, 2048, 16, 8]               0
      Bottleneck-523          [-1, 2048, 16, 8]               0
================================================================
Total params: 58,153,536
Trainable params: 58,153,536
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 450.75
Params size (MB): 221.84
Estimated Total Size (MB): 672.96
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnext50_32x4d_se
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]           4,608
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
             ReLU-21          [-1, 256, 64, 32]               0
       Bottleneck-22          [-1, 256, 64, 32]               0
           Conv2d-23          [-1, 128, 64, 32]          32,768
      BatchNorm2d-24          [-1, 128, 64, 32]             256
             ReLU-25          [-1, 128, 64, 32]               0
           Conv2d-26          [-1, 128, 64, 32]           4,608
      BatchNorm2d-27          [-1, 128, 64, 32]             256
             ReLU-28          [-1, 128, 64, 32]               0
           Conv2d-29          [-1, 256, 64, 32]          32,768
      BatchNorm2d-30          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0
           Linear-32                   [-1, 16]           4,096
             ReLU-33                   [-1, 16]               0
           Linear-34                  [-1, 256]           4,096
          Sigmoid-35                  [-1, 256]               0
          SELayer-36          [-1, 256, 64, 32]               0
             ReLU-37          [-1, 256, 64, 32]               0
       Bottleneck-38          [-1, 256, 64, 32]               0
           Conv2d-39          [-1, 128, 64, 32]          32,768
      BatchNorm2d-40          [-1, 128, 64, 32]             256
             ReLU-41          [-1, 128, 64, 32]               0
           Conv2d-42          [-1, 128, 64, 32]           4,608
      BatchNorm2d-43          [-1, 128, 64, 32]             256
             ReLU-44          [-1, 128, 64, 32]               0
           Conv2d-45          [-1, 256, 64, 32]          32,768
      BatchNorm2d-46          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-47            [-1, 256, 1, 1]               0
           Linear-48                   [-1, 16]           4,096
             ReLU-49                   [-1, 16]               0
           Linear-50                  [-1, 256]           4,096
          Sigmoid-51                  [-1, 256]               0
          SELayer-52          [-1, 256, 64, 32]               0
             ReLU-53          [-1, 256, 64, 32]               0
       Bottleneck-54          [-1, 256, 64, 32]               0
           Conv2d-55          [-1, 256, 64, 32]          65,536
      BatchNorm2d-56          [-1, 256, 64, 32]             512
             ReLU-57          [-1, 256, 64, 32]               0
           Conv2d-58          [-1, 256, 32, 16]          18,432
      BatchNorm2d-59          [-1, 256, 32, 16]             512
             ReLU-60          [-1, 256, 32, 16]               0
           Conv2d-61          [-1, 512, 32, 16]         131,072
      BatchNorm2d-62          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-63            [-1, 512, 1, 1]               0
           Linear-64                   [-1, 32]          16,384
             ReLU-65                   [-1, 32]               0
           Linear-66                  [-1, 512]          16,384
          Sigmoid-67                  [-1, 512]               0
          SELayer-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         131,072
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
             ReLU-71          [-1, 512, 32, 16]               0
       Bottleneck-72          [-1, 512, 32, 16]               0
           Conv2d-73          [-1, 256, 32, 16]         131,072
      BatchNorm2d-74          [-1, 256, 32, 16]             512
             ReLU-75          [-1, 256, 32, 16]               0
           Conv2d-76          [-1, 256, 32, 16]          18,432
      BatchNorm2d-77          [-1, 256, 32, 16]             512
             ReLU-78          [-1, 256, 32, 16]               0
           Conv2d-79          [-1, 512, 32, 16]         131,072
      BatchNorm2d-80          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-81            [-1, 512, 1, 1]               0
           Linear-82                   [-1, 32]          16,384
             ReLU-83                   [-1, 32]               0
           Linear-84                  [-1, 512]          16,384
          Sigmoid-85                  [-1, 512]               0
          SELayer-86          [-1, 512, 32, 16]               0
             ReLU-87          [-1, 512, 32, 16]               0
       Bottleneck-88          [-1, 512, 32, 16]               0
           Conv2d-89          [-1, 256, 32, 16]         131,072
      BatchNorm2d-90          [-1, 256, 32, 16]             512
             ReLU-91          [-1, 256, 32, 16]               0
           Conv2d-92          [-1, 256, 32, 16]          18,432
      BatchNorm2d-93          [-1, 256, 32, 16]             512
             ReLU-94          [-1, 256, 32, 16]               0
           Conv2d-95          [-1, 512, 32, 16]         131,072
      BatchNorm2d-96          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-97            [-1, 512, 1, 1]               0
           Linear-98                   [-1, 32]          16,384
             ReLU-99                   [-1, 32]               0
          Linear-100                  [-1, 512]          16,384
         Sigmoid-101                  [-1, 512]               0
         SELayer-102          [-1, 512, 32, 16]               0
            ReLU-103          [-1, 512, 32, 16]               0
      Bottleneck-104          [-1, 512, 32, 16]               0
          Conv2d-105          [-1, 256, 32, 16]         131,072
     BatchNorm2d-106          [-1, 256, 32, 16]             512
            ReLU-107          [-1, 256, 32, 16]               0
          Conv2d-108          [-1, 256, 32, 16]          18,432
     BatchNorm2d-109          [-1, 256, 32, 16]             512
            ReLU-110          [-1, 256, 32, 16]               0
          Conv2d-111          [-1, 512, 32, 16]         131,072
     BatchNorm2d-112          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-113            [-1, 512, 1, 1]               0
          Linear-114                   [-1, 32]          16,384
            ReLU-115                   [-1, 32]               0
          Linear-116                  [-1, 512]          16,384
         Sigmoid-117                  [-1, 512]               0
         SELayer-118          [-1, 512, 32, 16]               0
            ReLU-119          [-1, 512, 32, 16]               0
      Bottleneck-120          [-1, 512, 32, 16]               0
          Conv2d-121          [-1, 512, 32, 16]         262,144
     BatchNorm2d-122          [-1, 512, 32, 16]           1,024
            ReLU-123          [-1, 512, 32, 16]               0
          Conv2d-124           [-1, 512, 16, 8]          73,728
     BatchNorm2d-125           [-1, 512, 16, 8]           1,024
            ReLU-126           [-1, 512, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-129           [-1, 1024, 1, 1]               0
          Linear-130                   [-1, 64]          65,536
            ReLU-131                   [-1, 64]               0
          Linear-132                 [-1, 1024]          65,536
         Sigmoid-133                 [-1, 1024]               0
         SELayer-134          [-1, 1024, 16, 8]               0
          Conv2d-135          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-136          [-1, 1024, 16, 8]           2,048
            ReLU-137          [-1, 1024, 16, 8]               0
      Bottleneck-138          [-1, 1024, 16, 8]               0
          Conv2d-139           [-1, 512, 16, 8]         524,288
     BatchNorm2d-140           [-1, 512, 16, 8]           1,024
            ReLU-141           [-1, 512, 16, 8]               0
          Conv2d-142           [-1, 512, 16, 8]          73,728
     BatchNorm2d-143           [-1, 512, 16, 8]           1,024
            ReLU-144           [-1, 512, 16, 8]               0
          Conv2d-145          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-146          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-147           [-1, 1024, 1, 1]               0
          Linear-148                   [-1, 64]          65,536
            ReLU-149                   [-1, 64]               0
          Linear-150                 [-1, 1024]          65,536
         Sigmoid-151                 [-1, 1024]               0
         SELayer-152          [-1, 1024, 16, 8]               0
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 512, 16, 8]         524,288
     BatchNorm2d-156           [-1, 512, 16, 8]           1,024
            ReLU-157           [-1, 512, 16, 8]               0
          Conv2d-158           [-1, 512, 16, 8]          73,728
     BatchNorm2d-159           [-1, 512, 16, 8]           1,024
            ReLU-160           [-1, 512, 16, 8]               0
          Conv2d-161          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-162          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-163           [-1, 1024, 1, 1]               0
          Linear-164                   [-1, 64]          65,536
            ReLU-165                   [-1, 64]               0
          Linear-166                 [-1, 1024]          65,536
         Sigmoid-167                 [-1, 1024]               0
         SELayer-168          [-1, 1024, 16, 8]               0
            ReLU-169          [-1, 1024, 16, 8]               0
      Bottleneck-170          [-1, 1024, 16, 8]               0
          Conv2d-171           [-1, 512, 16, 8]         524,288
     BatchNorm2d-172           [-1, 512, 16, 8]           1,024
            ReLU-173           [-1, 512, 16, 8]               0
          Conv2d-174           [-1, 512, 16, 8]          73,728
     BatchNorm2d-175           [-1, 512, 16, 8]           1,024
            ReLU-176           [-1, 512, 16, 8]               0
          Conv2d-177          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-178          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-179           [-1, 1024, 1, 1]               0
          Linear-180                   [-1, 64]          65,536
            ReLU-181                   [-1, 64]               0
          Linear-182                 [-1, 1024]          65,536
         Sigmoid-183                 [-1, 1024]               0
         SELayer-184          [-1, 1024, 16, 8]               0
            ReLU-185          [-1, 1024, 16, 8]               0
      Bottleneck-186          [-1, 1024, 16, 8]               0
          Conv2d-187           [-1, 512, 16, 8]         524,288
     BatchNorm2d-188           [-1, 512, 16, 8]           1,024
            ReLU-189           [-1, 512, 16, 8]               0
          Conv2d-190           [-1, 512, 16, 8]          73,728
     BatchNorm2d-191           [-1, 512, 16, 8]           1,024
            ReLU-192           [-1, 512, 16, 8]               0
          Conv2d-193          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-194          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-195           [-1, 1024, 1, 1]               0
          Linear-196                   [-1, 64]          65,536
            ReLU-197                   [-1, 64]               0
          Linear-198                 [-1, 1024]          65,536
         Sigmoid-199                 [-1, 1024]               0
         SELayer-200          [-1, 1024, 16, 8]               0
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203           [-1, 512, 16, 8]         524,288
     BatchNorm2d-204           [-1, 512, 16, 8]           1,024
            ReLU-205           [-1, 512, 16, 8]               0
          Conv2d-206           [-1, 512, 16, 8]          73,728
     BatchNorm2d-207           [-1, 512, 16, 8]           1,024
            ReLU-208           [-1, 512, 16, 8]               0
          Conv2d-209          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-210          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-211           [-1, 1024, 1, 1]               0
          Linear-212                   [-1, 64]          65,536
            ReLU-213                   [-1, 64]               0
          Linear-214                 [-1, 1024]          65,536
         Sigmoid-215                 [-1, 1024]               0
         SELayer-216          [-1, 1024, 16, 8]               0
            ReLU-217          [-1, 1024, 16, 8]               0
      Bottleneck-218          [-1, 1024, 16, 8]               0
          Conv2d-219          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-220          [-1, 1024, 16, 8]           2,048
            ReLU-221          [-1, 1024, 16, 8]               0
          Conv2d-222          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-223          [-1, 1024, 16, 8]           2,048
            ReLU-224          [-1, 1024, 16, 8]               0
          Conv2d-225          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-226          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-227           [-1, 2048, 1, 1]               0
          Linear-228                  [-1, 128]         262,144
            ReLU-229                  [-1, 128]               0
          Linear-230                 [-1, 2048]         262,144
         Sigmoid-231                 [-1, 2048]               0
         SELayer-232          [-1, 2048, 16, 8]               0
          Conv2d-233          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-234          [-1, 2048, 16, 8]           4,096
            ReLU-235          [-1, 2048, 16, 8]               0
      Bottleneck-236          [-1, 2048, 16, 8]               0
          Conv2d-237          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-238          [-1, 1024, 16, 8]           2,048
            ReLU-239          [-1, 1024, 16, 8]               0
          Conv2d-240          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-241          [-1, 1024, 16, 8]           2,048
            ReLU-242          [-1, 1024, 16, 8]               0
          Conv2d-243          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-244          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-245           [-1, 2048, 1, 1]               0
          Linear-246                  [-1, 128]         262,144
            ReLU-247                  [-1, 128]               0
          Linear-248                 [-1, 2048]         262,144
         Sigmoid-249                 [-1, 2048]               0
         SELayer-250          [-1, 2048, 16, 8]               0
            ReLU-251          [-1, 2048, 16, 8]               0
      Bottleneck-252          [-1, 2048, 16, 8]               0
          Conv2d-253          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-254          [-1, 1024, 16, 8]           2,048
            ReLU-255          [-1, 1024, 16, 8]               0
          Conv2d-256          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-257          [-1, 1024, 16, 8]           2,048
            ReLU-258          [-1, 1024, 16, 8]               0
          Conv2d-259          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-260          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-261           [-1, 2048, 1, 1]               0
          Linear-262                  [-1, 128]         262,144
            ReLU-263                  [-1, 128]               0
          Linear-264                 [-1, 2048]         262,144
         Sigmoid-265                 [-1, 2048]               0
         SELayer-266          [-1, 2048, 16, 8]               0
            ReLU-267          [-1, 2048, 16, 8]               0
      Bottleneck-268          [-1, 2048, 16, 8]               0
================================================================
Total params: 25,494,848
Trainable params: 25,494,848
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 300.86
Params size (MB): 97.26
Estimated Total Size (MB): 398.49
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnext50_32x4d_se_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
    InstanceNorm2d-6           [-1, 64, 64, 32]             128
       BatchNorm2d-7           [-1, 64, 64, 32]             128
               IBN-8          [-1, 128, 64, 32]               0
              ReLU-9          [-1, 128, 64, 32]               0
           Conv2d-10          [-1, 128, 64, 32]           4,608
      BatchNorm2d-11          [-1, 128, 64, 32]             256
             ReLU-12          [-1, 128, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          32,768
      BatchNorm2d-14          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-15            [-1, 256, 1, 1]               0
           Linear-16                   [-1, 16]           4,096
             ReLU-17                   [-1, 16]               0
           Linear-18                  [-1, 256]           4,096
          Sigmoid-19                  [-1, 256]               0
          SELayer-20          [-1, 256, 64, 32]               0
           Conv2d-21          [-1, 256, 64, 32]          16,384
      BatchNorm2d-22          [-1, 256, 64, 32]             512
             ReLU-23          [-1, 256, 64, 32]               0
       Bottleneck-24          [-1, 256, 64, 32]               0
           Conv2d-25          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-26           [-1, 64, 64, 32]             128
      BatchNorm2d-27           [-1, 64, 64, 32]             128
              IBN-28          [-1, 128, 64, 32]               0
             ReLU-29          [-1, 128, 64, 32]               0
           Conv2d-30          [-1, 128, 64, 32]           4,608
      BatchNorm2d-31          [-1, 128, 64, 32]             256
             ReLU-32          [-1, 128, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          32,768
      BatchNorm2d-34          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-35            [-1, 256, 1, 1]               0
           Linear-36                   [-1, 16]           4,096
             ReLU-37                   [-1, 16]               0
           Linear-38                  [-1, 256]           4,096
          Sigmoid-39                  [-1, 256]               0
          SELayer-40          [-1, 256, 64, 32]               0
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-44           [-1, 64, 64, 32]             128
      BatchNorm2d-45           [-1, 64, 64, 32]             128
              IBN-46          [-1, 128, 64, 32]               0
             ReLU-47          [-1, 128, 64, 32]               0
           Conv2d-48          [-1, 128, 64, 32]           4,608
      BatchNorm2d-49          [-1, 128, 64, 32]             256
             ReLU-50          [-1, 128, 64, 32]               0
           Conv2d-51          [-1, 256, 64, 32]          32,768
      BatchNorm2d-52          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-53            [-1, 256, 1, 1]               0
           Linear-54                   [-1, 16]           4,096
             ReLU-55                   [-1, 16]               0
           Linear-56                  [-1, 256]           4,096
          Sigmoid-57                  [-1, 256]               0
          SELayer-58          [-1, 256, 64, 32]               0
             ReLU-59          [-1, 256, 64, 32]               0
       Bottleneck-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 256, 64, 32]          65,536
   InstanceNorm2d-62          [-1, 128, 64, 32]             256
      BatchNorm2d-63          [-1, 128, 64, 32]             256
              IBN-64          [-1, 256, 64, 32]               0
             ReLU-65          [-1, 256, 64, 32]               0
           Conv2d-66          [-1, 256, 32, 16]          18,432
      BatchNorm2d-67          [-1, 256, 32, 16]             512
             ReLU-68          [-1, 256, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         131,072
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-71            [-1, 512, 1, 1]               0
           Linear-72                   [-1, 32]          16,384
             ReLU-73                   [-1, 32]               0
           Linear-74                  [-1, 512]          16,384
          Sigmoid-75                  [-1, 512]               0
          SELayer-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         131,072
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-82          [-1, 128, 32, 16]             256
      BatchNorm2d-83          [-1, 128, 32, 16]             256
              IBN-84          [-1, 256, 32, 16]               0
             ReLU-85          [-1, 256, 32, 16]               0
           Conv2d-86          [-1, 256, 32, 16]          18,432
      BatchNorm2d-87          [-1, 256, 32, 16]             512
             ReLU-88          [-1, 256, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]         131,072
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-91            [-1, 512, 1, 1]               0
           Linear-92                   [-1, 32]          16,384
             ReLU-93                   [-1, 32]               0
           Linear-94                  [-1, 512]          16,384
          Sigmoid-95                  [-1, 512]               0
          SELayer-96          [-1, 512, 32, 16]               0
             ReLU-97          [-1, 512, 32, 16]               0
       Bottleneck-98          [-1, 512, 32, 16]               0
           Conv2d-99          [-1, 256, 32, 16]         131,072
  InstanceNorm2d-100          [-1, 128, 32, 16]             256
     BatchNorm2d-101          [-1, 128, 32, 16]             256
             IBN-102          [-1, 256, 32, 16]               0
            ReLU-103          [-1, 256, 32, 16]               0
          Conv2d-104          [-1, 256, 32, 16]          18,432
     BatchNorm2d-105          [-1, 256, 32, 16]             512
            ReLU-106          [-1, 256, 32, 16]               0
          Conv2d-107          [-1, 512, 32, 16]         131,072
     BatchNorm2d-108          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-109            [-1, 512, 1, 1]               0
          Linear-110                   [-1, 32]          16,384
            ReLU-111                   [-1, 32]               0
          Linear-112                  [-1, 512]          16,384
         Sigmoid-113                  [-1, 512]               0
         SELayer-114          [-1, 512, 32, 16]               0
            ReLU-115          [-1, 512, 32, 16]               0
      Bottleneck-116          [-1, 512, 32, 16]               0
          Conv2d-117          [-1, 256, 32, 16]         131,072
  InstanceNorm2d-118          [-1, 128, 32, 16]             256
     BatchNorm2d-119          [-1, 128, 32, 16]             256
             IBN-120          [-1, 256, 32, 16]               0
            ReLU-121          [-1, 256, 32, 16]               0
          Conv2d-122          [-1, 256, 32, 16]          18,432
     BatchNorm2d-123          [-1, 256, 32, 16]             512
            ReLU-124          [-1, 256, 32, 16]               0
          Conv2d-125          [-1, 512, 32, 16]         131,072
     BatchNorm2d-126          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-127            [-1, 512, 1, 1]               0
          Linear-128                   [-1, 32]          16,384
            ReLU-129                   [-1, 32]               0
          Linear-130                  [-1, 512]          16,384
         Sigmoid-131                  [-1, 512]               0
         SELayer-132          [-1, 512, 32, 16]               0
            ReLU-133          [-1, 512, 32, 16]               0
      Bottleneck-134          [-1, 512, 32, 16]               0
          Conv2d-135          [-1, 512, 32, 16]         262,144
  InstanceNorm2d-136          [-1, 256, 32, 16]             512
     BatchNorm2d-137          [-1, 256, 32, 16]             512
             IBN-138          [-1, 512, 32, 16]               0
            ReLU-139          [-1, 512, 32, 16]               0
          Conv2d-140           [-1, 512, 16, 8]          73,728
     BatchNorm2d-141           [-1, 512, 16, 8]           1,024
            ReLU-142           [-1, 512, 16, 8]               0
          Conv2d-143          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-144          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-145           [-1, 1024, 1, 1]               0
          Linear-146                   [-1, 64]          65,536
            ReLU-147                   [-1, 64]               0
          Linear-148                 [-1, 1024]          65,536
         Sigmoid-149                 [-1, 1024]               0
         SELayer-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-156           [-1, 256, 16, 8]             512
     BatchNorm2d-157           [-1, 256, 16, 8]             512
             IBN-158           [-1, 512, 16, 8]               0
            ReLU-159           [-1, 512, 16, 8]               0
          Conv2d-160           [-1, 512, 16, 8]          73,728
     BatchNorm2d-161           [-1, 512, 16, 8]           1,024
            ReLU-162           [-1, 512, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-165           [-1, 1024, 1, 1]               0
          Linear-166                   [-1, 64]          65,536
            ReLU-167                   [-1, 64]               0
          Linear-168                 [-1, 1024]          65,536
         Sigmoid-169                 [-1, 1024]               0
         SELayer-170          [-1, 1024, 16, 8]               0
            ReLU-171          [-1, 1024, 16, 8]               0
      Bottleneck-172          [-1, 1024, 16, 8]               0
          Conv2d-173           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-174           [-1, 256, 16, 8]             512
     BatchNorm2d-175           [-1, 256, 16, 8]             512
             IBN-176           [-1, 512, 16, 8]               0
            ReLU-177           [-1, 512, 16, 8]               0
          Conv2d-178           [-1, 512, 16, 8]          73,728
     BatchNorm2d-179           [-1, 512, 16, 8]           1,024
            ReLU-180           [-1, 512, 16, 8]               0
          Conv2d-181          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-182          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-183           [-1, 1024, 1, 1]               0
          Linear-184                   [-1, 64]          65,536
            ReLU-185                   [-1, 64]               0
          Linear-186                 [-1, 1024]          65,536
         Sigmoid-187                 [-1, 1024]               0
         SELayer-188          [-1, 1024, 16, 8]               0
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-192           [-1, 256, 16, 8]             512
     BatchNorm2d-193           [-1, 256, 16, 8]             512
             IBN-194           [-1, 512, 16, 8]               0
            ReLU-195           [-1, 512, 16, 8]               0
          Conv2d-196           [-1, 512, 16, 8]          73,728
     BatchNorm2d-197           [-1, 512, 16, 8]           1,024
            ReLU-198           [-1, 512, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-201           [-1, 1024, 1, 1]               0
          Linear-202                   [-1, 64]          65,536
            ReLU-203                   [-1, 64]               0
          Linear-204                 [-1, 1024]          65,536
         Sigmoid-205                 [-1, 1024]               0
         SELayer-206          [-1, 1024, 16, 8]               0
            ReLU-207          [-1, 1024, 16, 8]               0
      Bottleneck-208          [-1, 1024, 16, 8]               0
          Conv2d-209           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-210           [-1, 256, 16, 8]             512
     BatchNorm2d-211           [-1, 256, 16, 8]             512
             IBN-212           [-1, 512, 16, 8]               0
            ReLU-213           [-1, 512, 16, 8]               0
          Conv2d-214           [-1, 512, 16, 8]          73,728
     BatchNorm2d-215           [-1, 512, 16, 8]           1,024
            ReLU-216           [-1, 512, 16, 8]               0
          Conv2d-217          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-218          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-219           [-1, 1024, 1, 1]               0
          Linear-220                   [-1, 64]          65,536
            ReLU-221                   [-1, 64]               0
          Linear-222                 [-1, 1024]          65,536
         Sigmoid-223                 [-1, 1024]               0
         SELayer-224          [-1, 1024, 16, 8]               0
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-228           [-1, 256, 16, 8]             512
     BatchNorm2d-229           [-1, 256, 16, 8]             512
             IBN-230           [-1, 512, 16, 8]               0
            ReLU-231           [-1, 512, 16, 8]               0
          Conv2d-232           [-1, 512, 16, 8]          73,728
     BatchNorm2d-233           [-1, 512, 16, 8]           1,024
            ReLU-234           [-1, 512, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-237           [-1, 1024, 1, 1]               0
          Linear-238                   [-1, 64]          65,536
            ReLU-239                   [-1, 64]               0
          Linear-240                 [-1, 1024]          65,536
         Sigmoid-241                 [-1, 1024]               0
         SELayer-242          [-1, 1024, 16, 8]               0
            ReLU-243          [-1, 1024, 16, 8]               0
      Bottleneck-244          [-1, 1024, 16, 8]               0
          Conv2d-245          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-246          [-1, 1024, 16, 8]           2,048
            ReLU-247          [-1, 1024, 16, 8]               0
          Conv2d-248          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-249          [-1, 1024, 16, 8]           2,048
            ReLU-250          [-1, 1024, 16, 8]               0
          Conv2d-251          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-252          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-253           [-1, 2048, 1, 1]               0
          Linear-254                  [-1, 128]         262,144
            ReLU-255                  [-1, 128]               0
          Linear-256                 [-1, 2048]         262,144
         Sigmoid-257                 [-1, 2048]               0
         SELayer-258          [-1, 2048, 16, 8]               0
          Conv2d-259          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-260          [-1, 2048, 16, 8]           4,096
            ReLU-261          [-1, 2048, 16, 8]               0
      Bottleneck-262          [-1, 2048, 16, 8]               0
          Conv2d-263          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-264          [-1, 1024, 16, 8]           2,048
            ReLU-265          [-1, 1024, 16, 8]               0
          Conv2d-266          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-267          [-1, 1024, 16, 8]           2,048
            ReLU-268          [-1, 1024, 16, 8]               0
          Conv2d-269          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-270          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-271           [-1, 2048, 1, 1]               0
          Linear-272                  [-1, 128]         262,144
            ReLU-273                  [-1, 128]               0
          Linear-274                 [-1, 2048]         262,144
         Sigmoid-275                 [-1, 2048]               0
         SELayer-276          [-1, 2048, 16, 8]               0
            ReLU-277          [-1, 2048, 16, 8]               0
      Bottleneck-278          [-1, 2048, 16, 8]               0
          Conv2d-279          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-280          [-1, 1024, 16, 8]           2,048
            ReLU-281          [-1, 1024, 16, 8]               0
          Conv2d-282          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-283          [-1, 1024, 16, 8]           2,048
            ReLU-284          [-1, 1024, 16, 8]               0
          Conv2d-285          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-286          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-287           [-1, 2048, 1, 1]               0
          Linear-288                  [-1, 128]         262,144
            ReLU-289                  [-1, 128]               0
          Linear-290                 [-1, 2048]         262,144
         Sigmoid-291                 [-1, 2048]               0
         SELayer-292          [-1, 2048, 16, 8]               0
            ReLU-293          [-1, 2048, 16, 8]               0
      Bottleneck-294          [-1, 2048, 16, 8]               0
================================================================
Total params: 25,494,848
Trainable params: 25,494,848
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 318.36
Params size (MB): 97.26
Estimated Total Size (MB): 415.99
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnext50_32x4d_se_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]           4,608
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
   InstanceNorm2d-21          [-1, 256, 64, 32]             512
             ReLU-22          [-1, 256, 64, 32]               0
       Bottleneck-23          [-1, 256, 64, 32]               0
           Conv2d-24          [-1, 128, 64, 32]          32,768
      BatchNorm2d-25          [-1, 128, 64, 32]             256
             ReLU-26          [-1, 128, 64, 32]               0
           Conv2d-27          [-1, 128, 64, 32]           4,608
      BatchNorm2d-28          [-1, 128, 64, 32]             256
             ReLU-29          [-1, 128, 64, 32]               0
           Conv2d-30          [-1, 256, 64, 32]          32,768
      BatchNorm2d-31          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-32            [-1, 256, 1, 1]               0
           Linear-33                   [-1, 16]           4,096
             ReLU-34                   [-1, 16]               0
           Linear-35                  [-1, 256]           4,096
          Sigmoid-36                  [-1, 256]               0
          SELayer-37          [-1, 256, 64, 32]               0
   InstanceNorm2d-38          [-1, 256, 64, 32]             512
             ReLU-39          [-1, 256, 64, 32]               0
       Bottleneck-40          [-1, 256, 64, 32]               0
           Conv2d-41          [-1, 128, 64, 32]          32,768
      BatchNorm2d-42          [-1, 128, 64, 32]             256
             ReLU-43          [-1, 128, 64, 32]               0
           Conv2d-44          [-1, 128, 64, 32]           4,608
      BatchNorm2d-45          [-1, 128, 64, 32]             256
             ReLU-46          [-1, 128, 64, 32]               0
           Conv2d-47          [-1, 256, 64, 32]          32,768
      BatchNorm2d-48          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-49            [-1, 256, 1, 1]               0
           Linear-50                   [-1, 16]           4,096
             ReLU-51                   [-1, 16]               0
           Linear-52                  [-1, 256]           4,096
          Sigmoid-53                  [-1, 256]               0
          SELayer-54          [-1, 256, 64, 32]               0
   InstanceNorm2d-55          [-1, 256, 64, 32]             512
             ReLU-56          [-1, 256, 64, 32]               0
       Bottleneck-57          [-1, 256, 64, 32]               0
           Conv2d-58          [-1, 256, 64, 32]          65,536
      BatchNorm2d-59          [-1, 256, 64, 32]             512
             ReLU-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 256, 32, 16]          18,432
      BatchNorm2d-62          [-1, 256, 32, 16]             512
             ReLU-63          [-1, 256, 32, 16]               0
           Conv2d-64          [-1, 512, 32, 16]         131,072
      BatchNorm2d-65          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-66            [-1, 512, 1, 1]               0
           Linear-67                   [-1, 32]          16,384
             ReLU-68                   [-1, 32]               0
           Linear-69                  [-1, 512]          16,384
          Sigmoid-70                  [-1, 512]               0
          SELayer-71          [-1, 512, 32, 16]               0
           Conv2d-72          [-1, 512, 32, 16]         131,072
      BatchNorm2d-73          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-74          [-1, 512, 32, 16]           1,024
             ReLU-75          [-1, 512, 32, 16]               0
       Bottleneck-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 256, 32, 16]         131,072
      BatchNorm2d-78          [-1, 256, 32, 16]             512
             ReLU-79          [-1, 256, 32, 16]               0
           Conv2d-80          [-1, 256, 32, 16]          18,432
      BatchNorm2d-81          [-1, 256, 32, 16]             512
             ReLU-82          [-1, 256, 32, 16]               0
           Conv2d-83          [-1, 512, 32, 16]         131,072
      BatchNorm2d-84          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-85            [-1, 512, 1, 1]               0
           Linear-86                   [-1, 32]          16,384
             ReLU-87                   [-1, 32]               0
           Linear-88                  [-1, 512]          16,384
          Sigmoid-89                  [-1, 512]               0
          SELayer-90          [-1, 512, 32, 16]               0
   InstanceNorm2d-91          [-1, 512, 32, 16]           1,024
             ReLU-92          [-1, 512, 32, 16]               0
       Bottleneck-93          [-1, 512, 32, 16]               0
           Conv2d-94          [-1, 256, 32, 16]         131,072
      BatchNorm2d-95          [-1, 256, 32, 16]             512
             ReLU-96          [-1, 256, 32, 16]               0
           Conv2d-97          [-1, 256, 32, 16]          18,432
      BatchNorm2d-98          [-1, 256, 32, 16]             512
             ReLU-99          [-1, 256, 32, 16]               0
          Conv2d-100          [-1, 512, 32, 16]         131,072
     BatchNorm2d-101          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-102            [-1, 512, 1, 1]               0
          Linear-103                   [-1, 32]          16,384
            ReLU-104                   [-1, 32]               0
          Linear-105                  [-1, 512]          16,384
         Sigmoid-106                  [-1, 512]               0
         SELayer-107          [-1, 512, 32, 16]               0
  InstanceNorm2d-108          [-1, 512, 32, 16]           1,024
            ReLU-109          [-1, 512, 32, 16]               0
      Bottleneck-110          [-1, 512, 32, 16]               0
          Conv2d-111          [-1, 256, 32, 16]         131,072
     BatchNorm2d-112          [-1, 256, 32, 16]             512
            ReLU-113          [-1, 256, 32, 16]               0
          Conv2d-114          [-1, 256, 32, 16]          18,432
     BatchNorm2d-115          [-1, 256, 32, 16]             512
            ReLU-116          [-1, 256, 32, 16]               0
          Conv2d-117          [-1, 512, 32, 16]         131,072
     BatchNorm2d-118          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-119            [-1, 512, 1, 1]               0
          Linear-120                   [-1, 32]          16,384
            ReLU-121                   [-1, 32]               0
          Linear-122                  [-1, 512]          16,384
         Sigmoid-123                  [-1, 512]               0
         SELayer-124          [-1, 512, 32, 16]               0
  InstanceNorm2d-125          [-1, 512, 32, 16]           1,024
            ReLU-126          [-1, 512, 32, 16]               0
      Bottleneck-127          [-1, 512, 32, 16]               0
          Conv2d-128          [-1, 512, 32, 16]         262,144
     BatchNorm2d-129          [-1, 512, 32, 16]           1,024
            ReLU-130          [-1, 512, 32, 16]               0
          Conv2d-131           [-1, 512, 16, 8]          73,728
     BatchNorm2d-132           [-1, 512, 16, 8]           1,024
            ReLU-133           [-1, 512, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-136           [-1, 1024, 1, 1]               0
          Linear-137                   [-1, 64]          65,536
            ReLU-138                   [-1, 64]               0
          Linear-139                 [-1, 1024]          65,536
         Sigmoid-140                 [-1, 1024]               0
         SELayer-141          [-1, 1024, 16, 8]               0
          Conv2d-142          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-143          [-1, 1024, 16, 8]           2,048
            ReLU-144          [-1, 1024, 16, 8]               0
      Bottleneck-145          [-1, 1024, 16, 8]               0
          Conv2d-146           [-1, 512, 16, 8]         524,288
     BatchNorm2d-147           [-1, 512, 16, 8]           1,024
            ReLU-148           [-1, 512, 16, 8]               0
          Conv2d-149           [-1, 512, 16, 8]          73,728
     BatchNorm2d-150           [-1, 512, 16, 8]           1,024
            ReLU-151           [-1, 512, 16, 8]               0
          Conv2d-152          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-153          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-154           [-1, 1024, 1, 1]               0
          Linear-155                   [-1, 64]          65,536
            ReLU-156                   [-1, 64]               0
          Linear-157                 [-1, 1024]          65,536
         Sigmoid-158                 [-1, 1024]               0
         SELayer-159          [-1, 1024, 16, 8]               0
            ReLU-160          [-1, 1024, 16, 8]               0
      Bottleneck-161          [-1, 1024, 16, 8]               0
          Conv2d-162           [-1, 512, 16, 8]         524,288
     BatchNorm2d-163           [-1, 512, 16, 8]           1,024
            ReLU-164           [-1, 512, 16, 8]               0
          Conv2d-165           [-1, 512, 16, 8]          73,728
     BatchNorm2d-166           [-1, 512, 16, 8]           1,024
            ReLU-167           [-1, 512, 16, 8]               0
          Conv2d-168          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-169          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-170           [-1, 1024, 1, 1]               0
          Linear-171                   [-1, 64]          65,536
            ReLU-172                   [-1, 64]               0
          Linear-173                 [-1, 1024]          65,536
         Sigmoid-174                 [-1, 1024]               0
         SELayer-175          [-1, 1024, 16, 8]               0
            ReLU-176          [-1, 1024, 16, 8]               0
      Bottleneck-177          [-1, 1024, 16, 8]               0
          Conv2d-178           [-1, 512, 16, 8]         524,288
     BatchNorm2d-179           [-1, 512, 16, 8]           1,024
            ReLU-180           [-1, 512, 16, 8]               0
          Conv2d-181           [-1, 512, 16, 8]          73,728
     BatchNorm2d-182           [-1, 512, 16, 8]           1,024
            ReLU-183           [-1, 512, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-186           [-1, 1024, 1, 1]               0
          Linear-187                   [-1, 64]          65,536
            ReLU-188                   [-1, 64]               0
          Linear-189                 [-1, 1024]          65,536
         Sigmoid-190                 [-1, 1024]               0
         SELayer-191          [-1, 1024, 16, 8]               0
            ReLU-192          [-1, 1024, 16, 8]               0
      Bottleneck-193          [-1, 1024, 16, 8]               0
          Conv2d-194           [-1, 512, 16, 8]         524,288
     BatchNorm2d-195           [-1, 512, 16, 8]           1,024
            ReLU-196           [-1, 512, 16, 8]               0
          Conv2d-197           [-1, 512, 16, 8]          73,728
     BatchNorm2d-198           [-1, 512, 16, 8]           1,024
            ReLU-199           [-1, 512, 16, 8]               0
          Conv2d-200          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-201          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-202           [-1, 1024, 1, 1]               0
          Linear-203                   [-1, 64]          65,536
            ReLU-204                   [-1, 64]               0
          Linear-205                 [-1, 1024]          65,536
         Sigmoid-206                 [-1, 1024]               0
         SELayer-207          [-1, 1024, 16, 8]               0
            ReLU-208          [-1, 1024, 16, 8]               0
      Bottleneck-209          [-1, 1024, 16, 8]               0
          Conv2d-210           [-1, 512, 16, 8]         524,288
     BatchNorm2d-211           [-1, 512, 16, 8]           1,024
            ReLU-212           [-1, 512, 16, 8]               0
          Conv2d-213           [-1, 512, 16, 8]          73,728
     BatchNorm2d-214           [-1, 512, 16, 8]           1,024
            ReLU-215           [-1, 512, 16, 8]               0
          Conv2d-216          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-217          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-218           [-1, 1024, 1, 1]               0
          Linear-219                   [-1, 64]          65,536
            ReLU-220                   [-1, 64]               0
          Linear-221                 [-1, 1024]          65,536
         Sigmoid-222                 [-1, 1024]               0
         SELayer-223          [-1, 1024, 16, 8]               0
            ReLU-224          [-1, 1024, 16, 8]               0
      Bottleneck-225          [-1, 1024, 16, 8]               0
          Conv2d-226          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-227          [-1, 1024, 16, 8]           2,048
            ReLU-228          [-1, 1024, 16, 8]               0
          Conv2d-229          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-230          [-1, 1024, 16, 8]           2,048
            ReLU-231          [-1, 1024, 16, 8]               0
          Conv2d-232          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-233          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-234           [-1, 2048, 1, 1]               0
          Linear-235                  [-1, 128]         262,144
            ReLU-236                  [-1, 128]               0
          Linear-237                 [-1, 2048]         262,144
         Sigmoid-238                 [-1, 2048]               0
         SELayer-239          [-1, 2048, 16, 8]               0
          Conv2d-240          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-241          [-1, 2048, 16, 8]           4,096
            ReLU-242          [-1, 2048, 16, 8]               0
      Bottleneck-243          [-1, 2048, 16, 8]               0
          Conv2d-244          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-245          [-1, 1024, 16, 8]           2,048
            ReLU-246          [-1, 1024, 16, 8]               0
          Conv2d-247          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-248          [-1, 1024, 16, 8]           2,048
            ReLU-249          [-1, 1024, 16, 8]               0
          Conv2d-250          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-251          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-252           [-1, 2048, 1, 1]               0
          Linear-253                  [-1, 128]         262,144
            ReLU-254                  [-1, 128]               0
          Linear-255                 [-1, 2048]         262,144
         Sigmoid-256                 [-1, 2048]               0
         SELayer-257          [-1, 2048, 16, 8]               0
            ReLU-258          [-1, 2048, 16, 8]               0
      Bottleneck-259          [-1, 2048, 16, 8]               0
          Conv2d-260          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-261          [-1, 1024, 16, 8]           2,048
            ReLU-262          [-1, 1024, 16, 8]               0
          Conv2d-263          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-264          [-1, 1024, 16, 8]           2,048
            ReLU-265          [-1, 1024, 16, 8]               0
          Conv2d-266          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-267          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-268           [-1, 2048, 1, 1]               0
          Linear-269                  [-1, 128]         262,144
            ReLU-270                  [-1, 128]               0
          Linear-271                 [-1, 2048]         262,144
         Sigmoid-272                 [-1, 2048]               0
         SELayer-273          [-1, 2048, 16, 8]               0
            ReLU-274          [-1, 2048, 16, 8]               0
      Bottleneck-275          [-1, 2048, 16, 8]               0
================================================================
Total params: 25,500,480
Trainable params: 25,500,480
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 320.86
Params size (MB): 97.28
Estimated Total Size (MB): 418.51
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnext50_32x4d_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
    InstanceNorm2d-6           [-1, 64, 64, 32]             128
       BatchNorm2d-7           [-1, 64, 64, 32]             128
               IBN-8          [-1, 128, 64, 32]               0
              ReLU-9          [-1, 128, 64, 32]               0
           Conv2d-10          [-1, 128, 64, 32]           4,608
      BatchNorm2d-11          [-1, 128, 64, 32]             256
             ReLU-12          [-1, 128, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          32,768
      BatchNorm2d-14          [-1, 256, 64, 32]             512
           Conv2d-15          [-1, 256, 64, 32]          16,384
      BatchNorm2d-16          [-1, 256, 64, 32]             512
             ReLU-17          [-1, 256, 64, 32]               0
       Bottleneck-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-20           [-1, 64, 64, 32]             128
      BatchNorm2d-21           [-1, 64, 64, 32]             128
              IBN-22          [-1, 128, 64, 32]               0
             ReLU-23          [-1, 128, 64, 32]               0
           Conv2d-24          [-1, 128, 64, 32]           4,608
      BatchNorm2d-25          [-1, 128, 64, 32]             256
             ReLU-26          [-1, 128, 64, 32]               0
           Conv2d-27          [-1, 256, 64, 32]          32,768
      BatchNorm2d-28          [-1, 256, 64, 32]             512
             ReLU-29          [-1, 256, 64, 32]               0
       Bottleneck-30          [-1, 256, 64, 32]               0
           Conv2d-31          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-32           [-1, 64, 64, 32]             128
      BatchNorm2d-33           [-1, 64, 64, 32]             128
              IBN-34          [-1, 128, 64, 32]               0
             ReLU-35          [-1, 128, 64, 32]               0
           Conv2d-36          [-1, 128, 64, 32]           4,608
      BatchNorm2d-37          [-1, 128, 64, 32]             256
             ReLU-38          [-1, 128, 64, 32]               0
           Conv2d-39          [-1, 256, 64, 32]          32,768
      BatchNorm2d-40          [-1, 256, 64, 32]             512
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 256, 64, 32]          65,536
   InstanceNorm2d-44          [-1, 128, 64, 32]             256
      BatchNorm2d-45          [-1, 128, 64, 32]             256
              IBN-46          [-1, 256, 64, 32]               0
             ReLU-47          [-1, 256, 64, 32]               0
           Conv2d-48          [-1, 256, 32, 16]          18,432
      BatchNorm2d-49          [-1, 256, 32, 16]             512
             ReLU-50          [-1, 256, 32, 16]               0
           Conv2d-51          [-1, 512, 32, 16]         131,072
      BatchNorm2d-52          [-1, 512, 32, 16]           1,024
           Conv2d-53          [-1, 512, 32, 16]         131,072
      BatchNorm2d-54          [-1, 512, 32, 16]           1,024
             ReLU-55          [-1, 512, 32, 16]               0
       Bottleneck-56          [-1, 512, 32, 16]               0
           Conv2d-57          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-58          [-1, 128, 32, 16]             256
      BatchNorm2d-59          [-1, 128, 32, 16]             256
              IBN-60          [-1, 256, 32, 16]               0
             ReLU-61          [-1, 256, 32, 16]               0
           Conv2d-62          [-1, 256, 32, 16]          18,432
      BatchNorm2d-63          [-1, 256, 32, 16]             512
             ReLU-64          [-1, 256, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]         131,072
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-70          [-1, 128, 32, 16]             256
      BatchNorm2d-71          [-1, 128, 32, 16]             256
              IBN-72          [-1, 256, 32, 16]               0
             ReLU-73          [-1, 256, 32, 16]               0
           Conv2d-74          [-1, 256, 32, 16]          18,432
      BatchNorm2d-75          [-1, 256, 32, 16]             512
             ReLU-76          [-1, 256, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         131,072
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-82          [-1, 128, 32, 16]             256
      BatchNorm2d-83          [-1, 128, 32, 16]             256
              IBN-84          [-1, 256, 32, 16]               0
             ReLU-85          [-1, 256, 32, 16]               0
           Conv2d-86          [-1, 256, 32, 16]          18,432
      BatchNorm2d-87          [-1, 256, 32, 16]             512
             ReLU-88          [-1, 256, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]         131,072
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
             ReLU-91          [-1, 512, 32, 16]               0
       Bottleneck-92          [-1, 512, 32, 16]               0
           Conv2d-93          [-1, 512, 32, 16]         262,144
   InstanceNorm2d-94          [-1, 256, 32, 16]             512
      BatchNorm2d-95          [-1, 256, 32, 16]             512
              IBN-96          [-1, 512, 32, 16]               0
             ReLU-97          [-1, 512, 32, 16]               0
           Conv2d-98           [-1, 512, 16, 8]          73,728
      BatchNorm2d-99           [-1, 512, 16, 8]           1,024
            ReLU-100           [-1, 512, 16, 8]               0
          Conv2d-101          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-102          [-1, 1024, 16, 8]           2,048
          Conv2d-103          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-104          [-1, 1024, 16, 8]           2,048
            ReLU-105          [-1, 1024, 16, 8]               0
      Bottleneck-106          [-1, 1024, 16, 8]               0
          Conv2d-107           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-108           [-1, 256, 16, 8]             512
     BatchNorm2d-109           [-1, 256, 16, 8]             512
             IBN-110           [-1, 512, 16, 8]               0
            ReLU-111           [-1, 512, 16, 8]               0
          Conv2d-112           [-1, 512, 16, 8]          73,728
     BatchNorm2d-113           [-1, 512, 16, 8]           1,024
            ReLU-114           [-1, 512, 16, 8]               0
          Conv2d-115          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-116          [-1, 1024, 16, 8]           2,048
            ReLU-117          [-1, 1024, 16, 8]               0
      Bottleneck-118          [-1, 1024, 16, 8]               0
          Conv2d-119           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-120           [-1, 256, 16, 8]             512
     BatchNorm2d-121           [-1, 256, 16, 8]             512
             IBN-122           [-1, 512, 16, 8]               0
            ReLU-123           [-1, 512, 16, 8]               0
          Conv2d-124           [-1, 512, 16, 8]          73,728
     BatchNorm2d-125           [-1, 512, 16, 8]           1,024
            ReLU-126           [-1, 512, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-132           [-1, 256, 16, 8]             512
     BatchNorm2d-133           [-1, 256, 16, 8]             512
             IBN-134           [-1, 512, 16, 8]               0
            ReLU-135           [-1, 512, 16, 8]               0
          Conv2d-136           [-1, 512, 16, 8]          73,728
     BatchNorm2d-137           [-1, 512, 16, 8]           1,024
            ReLU-138           [-1, 512, 16, 8]               0
          Conv2d-139          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-140          [-1, 1024, 16, 8]           2,048
            ReLU-141          [-1, 1024, 16, 8]               0
      Bottleneck-142          [-1, 1024, 16, 8]               0
          Conv2d-143           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-144           [-1, 256, 16, 8]             512
     BatchNorm2d-145           [-1, 256, 16, 8]             512
             IBN-146           [-1, 512, 16, 8]               0
            ReLU-147           [-1, 512, 16, 8]               0
          Conv2d-148           [-1, 512, 16, 8]          73,728
     BatchNorm2d-149           [-1, 512, 16, 8]           1,024
            ReLU-150           [-1, 512, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-156           [-1, 256, 16, 8]             512
     BatchNorm2d-157           [-1, 256, 16, 8]             512
             IBN-158           [-1, 512, 16, 8]               0
            ReLU-159           [-1, 512, 16, 8]               0
          Conv2d-160           [-1, 512, 16, 8]          73,728
     BatchNorm2d-161           [-1, 512, 16, 8]           1,024
            ReLU-162           [-1, 512, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
      Bottleneck-166          [-1, 1024, 16, 8]               0
          Conv2d-167          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-168          [-1, 1024, 16, 8]           2,048
            ReLU-169          [-1, 1024, 16, 8]               0
          Conv2d-170          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-171          [-1, 1024, 16, 8]           2,048
            ReLU-172          [-1, 1024, 16, 8]               0
          Conv2d-173          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-174          [-1, 2048, 16, 8]           4,096
          Conv2d-175          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-176          [-1, 2048, 16, 8]           4,096
            ReLU-177          [-1, 2048, 16, 8]               0
      Bottleneck-178          [-1, 2048, 16, 8]               0
          Conv2d-179          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-180          [-1, 1024, 16, 8]           2,048
            ReLU-181          [-1, 1024, 16, 8]               0
          Conv2d-182          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-183          [-1, 1024, 16, 8]           2,048
            ReLU-184          [-1, 1024, 16, 8]               0
          Conv2d-185          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-186          [-1, 2048, 16, 8]           4,096
            ReLU-187          [-1, 2048, 16, 8]               0
      Bottleneck-188          [-1, 2048, 16, 8]               0
          Conv2d-189          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-190          [-1, 1024, 16, 8]           2,048
            ReLU-191          [-1, 1024, 16, 8]               0
          Conv2d-192          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-193          [-1, 1024, 16, 8]           2,048
            ReLU-194          [-1, 1024, 16, 8]               0
          Conv2d-195          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-196          [-1, 2048, 16, 8]           4,096
            ReLU-197          [-1, 2048, 16, 8]               0
      Bottleneck-198          [-1, 2048, 16, 8]               0
================================================================
Total params: 22,979,904
Trainable params: 22,979,904
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 286.00
Params size (MB): 87.66
Estimated Total Size (MB): 374.04
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnext50_32x4d_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]           4,608
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
   InstanceNorm2d-15          [-1, 256, 64, 32]             512
             ReLU-16          [-1, 256, 64, 32]               0
       Bottleneck-17          [-1, 256, 64, 32]               0
           Conv2d-18          [-1, 128, 64, 32]          32,768
      BatchNorm2d-19          [-1, 128, 64, 32]             256
             ReLU-20          [-1, 128, 64, 32]               0
           Conv2d-21          [-1, 128, 64, 32]           4,608
      BatchNorm2d-22          [-1, 128, 64, 32]             256
             ReLU-23          [-1, 128, 64, 32]               0
           Conv2d-24          [-1, 256, 64, 32]          32,768
      BatchNorm2d-25          [-1, 256, 64, 32]             512
   InstanceNorm2d-26          [-1, 256, 64, 32]             512
             ReLU-27          [-1, 256, 64, 32]               0
       Bottleneck-28          [-1, 256, 64, 32]               0
           Conv2d-29          [-1, 128, 64, 32]          32,768
      BatchNorm2d-30          [-1, 128, 64, 32]             256
             ReLU-31          [-1, 128, 64, 32]               0
           Conv2d-32          [-1, 128, 64, 32]           4,608
      BatchNorm2d-33          [-1, 128, 64, 32]             256
             ReLU-34          [-1, 128, 64, 32]               0
           Conv2d-35          [-1, 256, 64, 32]          32,768
      BatchNorm2d-36          [-1, 256, 64, 32]             512
   InstanceNorm2d-37          [-1, 256, 64, 32]             512
             ReLU-38          [-1, 256, 64, 32]               0
       Bottleneck-39          [-1, 256, 64, 32]               0
           Conv2d-40          [-1, 256, 64, 32]          65,536
      BatchNorm2d-41          [-1, 256, 64, 32]             512
             ReLU-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 256, 32, 16]          18,432
      BatchNorm2d-44          [-1, 256, 32, 16]             512
             ReLU-45          [-1, 256, 32, 16]               0
           Conv2d-46          [-1, 512, 32, 16]         131,072
      BatchNorm2d-47          [-1, 512, 32, 16]           1,024
           Conv2d-48          [-1, 512, 32, 16]         131,072
      BatchNorm2d-49          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-50          [-1, 512, 32, 16]           1,024
             ReLU-51          [-1, 512, 32, 16]               0
       Bottleneck-52          [-1, 512, 32, 16]               0
           Conv2d-53          [-1, 256, 32, 16]         131,072
      BatchNorm2d-54          [-1, 256, 32, 16]             512
             ReLU-55          [-1, 256, 32, 16]               0
           Conv2d-56          [-1, 256, 32, 16]          18,432
      BatchNorm2d-57          [-1, 256, 32, 16]             512
             ReLU-58          [-1, 256, 32, 16]               0
           Conv2d-59          [-1, 512, 32, 16]         131,072
      BatchNorm2d-60          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-61          [-1, 512, 32, 16]           1,024
             ReLU-62          [-1, 512, 32, 16]               0
       Bottleneck-63          [-1, 512, 32, 16]               0
           Conv2d-64          [-1, 256, 32, 16]         131,072
      BatchNorm2d-65          [-1, 256, 32, 16]             512
             ReLU-66          [-1, 256, 32, 16]               0
           Conv2d-67          [-1, 256, 32, 16]          18,432
      BatchNorm2d-68          [-1, 256, 32, 16]             512
             ReLU-69          [-1, 256, 32, 16]               0
           Conv2d-70          [-1, 512, 32, 16]         131,072
      BatchNorm2d-71          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-72          [-1, 512, 32, 16]           1,024
             ReLU-73          [-1, 512, 32, 16]               0
       Bottleneck-74          [-1, 512, 32, 16]               0
           Conv2d-75          [-1, 256, 32, 16]         131,072
      BatchNorm2d-76          [-1, 256, 32, 16]             512
             ReLU-77          [-1, 256, 32, 16]               0
           Conv2d-78          [-1, 256, 32, 16]          18,432
      BatchNorm2d-79          [-1, 256, 32, 16]             512
             ReLU-80          [-1, 256, 32, 16]               0
           Conv2d-81          [-1, 512, 32, 16]         131,072
      BatchNorm2d-82          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-83          [-1, 512, 32, 16]           1,024
             ReLU-84          [-1, 512, 32, 16]               0
       Bottleneck-85          [-1, 512, 32, 16]               0
           Conv2d-86          [-1, 512, 32, 16]         262,144
      BatchNorm2d-87          [-1, 512, 32, 16]           1,024
             ReLU-88          [-1, 512, 32, 16]               0
           Conv2d-89           [-1, 512, 16, 8]          73,728
      BatchNorm2d-90           [-1, 512, 16, 8]           1,024
             ReLU-91           [-1, 512, 16, 8]               0
           Conv2d-92          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-93          [-1, 1024, 16, 8]           2,048
           Conv2d-94          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-95          [-1, 1024, 16, 8]           2,048
             ReLU-96          [-1, 1024, 16, 8]               0
       Bottleneck-97          [-1, 1024, 16, 8]               0
           Conv2d-98           [-1, 512, 16, 8]         524,288
      BatchNorm2d-99           [-1, 512, 16, 8]           1,024
            ReLU-100           [-1, 512, 16, 8]               0
          Conv2d-101           [-1, 512, 16, 8]          73,728
     BatchNorm2d-102           [-1, 512, 16, 8]           1,024
            ReLU-103           [-1, 512, 16, 8]               0
          Conv2d-104          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-105          [-1, 1024, 16, 8]           2,048
            ReLU-106          [-1, 1024, 16, 8]               0
      Bottleneck-107          [-1, 1024, 16, 8]               0
          Conv2d-108           [-1, 512, 16, 8]         524,288
     BatchNorm2d-109           [-1, 512, 16, 8]           1,024
            ReLU-110           [-1, 512, 16, 8]               0
          Conv2d-111           [-1, 512, 16, 8]          73,728
     BatchNorm2d-112           [-1, 512, 16, 8]           1,024
            ReLU-113           [-1, 512, 16, 8]               0
          Conv2d-114          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-115          [-1, 1024, 16, 8]           2,048
            ReLU-116          [-1, 1024, 16, 8]               0
      Bottleneck-117          [-1, 1024, 16, 8]               0
          Conv2d-118           [-1, 512, 16, 8]         524,288
     BatchNorm2d-119           [-1, 512, 16, 8]           1,024
            ReLU-120           [-1, 512, 16, 8]               0
          Conv2d-121           [-1, 512, 16, 8]          73,728
     BatchNorm2d-122           [-1, 512, 16, 8]           1,024
            ReLU-123           [-1, 512, 16, 8]               0
          Conv2d-124          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-125          [-1, 1024, 16, 8]           2,048
            ReLU-126          [-1, 1024, 16, 8]               0
      Bottleneck-127          [-1, 1024, 16, 8]               0
          Conv2d-128           [-1, 512, 16, 8]         524,288
     BatchNorm2d-129           [-1, 512, 16, 8]           1,024
            ReLU-130           [-1, 512, 16, 8]               0
          Conv2d-131           [-1, 512, 16, 8]          73,728
     BatchNorm2d-132           [-1, 512, 16, 8]           1,024
            ReLU-133           [-1, 512, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
            ReLU-136          [-1, 1024, 16, 8]               0
      Bottleneck-137          [-1, 1024, 16, 8]               0
          Conv2d-138           [-1, 512, 16, 8]         524,288
     BatchNorm2d-139           [-1, 512, 16, 8]           1,024
            ReLU-140           [-1, 512, 16, 8]               0
          Conv2d-141           [-1, 512, 16, 8]          73,728
     BatchNorm2d-142           [-1, 512, 16, 8]           1,024
            ReLU-143           [-1, 512, 16, 8]               0
          Conv2d-144          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-145          [-1, 1024, 16, 8]           2,048
            ReLU-146          [-1, 1024, 16, 8]               0
      Bottleneck-147          [-1, 1024, 16, 8]               0
          Conv2d-148          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-149          [-1, 1024, 16, 8]           2,048
            ReLU-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
          Conv2d-154          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-155          [-1, 2048, 16, 8]           4,096
          Conv2d-156          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-157          [-1, 2048, 16, 8]           4,096
            ReLU-158          [-1, 2048, 16, 8]               0
      Bottleneck-159          [-1, 2048, 16, 8]               0
          Conv2d-160          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-161          [-1, 1024, 16, 8]           2,048
            ReLU-162          [-1, 1024, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
          Conv2d-166          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-167          [-1, 2048, 16, 8]           4,096
            ReLU-168          [-1, 2048, 16, 8]               0
      Bottleneck-169          [-1, 2048, 16, 8]               0
          Conv2d-170          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-171          [-1, 1024, 16, 8]           2,048
            ReLU-172          [-1, 1024, 16, 8]               0
          Conv2d-173          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-174          [-1, 1024, 16, 8]           2,048
            ReLU-175          [-1, 1024, 16, 8]               0
          Conv2d-176          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-177          [-1, 2048, 16, 8]           4,096
            ReLU-178          [-1, 2048, 16, 8]               0
      Bottleneck-179          [-1, 2048, 16, 8]               0
================================================================
Total params: 22,985,536
Trainable params: 22,985,536
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 288.50
Params size (MB): 87.68
Estimated Total Size (MB): 376.56
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnext101_32x8d_se
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 256, 64, 32]          16,384
       BatchNorm2d-6          [-1, 256, 64, 32]             512
              ReLU-7          [-1, 256, 64, 32]               0
            Conv2d-8          [-1, 256, 64, 32]          18,432
       BatchNorm2d-9          [-1, 256, 64, 32]             512
             ReLU-10          [-1, 256, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          65,536
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
             ReLU-21          [-1, 256, 64, 32]               0
       Bottleneck-22          [-1, 256, 64, 32]               0
           Conv2d-23          [-1, 256, 64, 32]          65,536
      BatchNorm2d-24          [-1, 256, 64, 32]             512
             ReLU-25          [-1, 256, 64, 32]               0
           Conv2d-26          [-1, 256, 64, 32]          18,432
      BatchNorm2d-27          [-1, 256, 64, 32]             512
             ReLU-28          [-1, 256, 64, 32]               0
           Conv2d-29          [-1, 256, 64, 32]          65,536
      BatchNorm2d-30          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0
           Linear-32                   [-1, 16]           4,096
             ReLU-33                   [-1, 16]               0
           Linear-34                  [-1, 256]           4,096
          Sigmoid-35                  [-1, 256]               0
          SELayer-36          [-1, 256, 64, 32]               0
             ReLU-37          [-1, 256, 64, 32]               0
       Bottleneck-38          [-1, 256, 64, 32]               0
           Conv2d-39          [-1, 256, 64, 32]          65,536
      BatchNorm2d-40          [-1, 256, 64, 32]             512
             ReLU-41          [-1, 256, 64, 32]               0
           Conv2d-42          [-1, 256, 64, 32]          18,432
      BatchNorm2d-43          [-1, 256, 64, 32]             512
             ReLU-44          [-1, 256, 64, 32]               0
           Conv2d-45          [-1, 256, 64, 32]          65,536
      BatchNorm2d-46          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-47            [-1, 256, 1, 1]               0
           Linear-48                   [-1, 16]           4,096
             ReLU-49                   [-1, 16]               0
           Linear-50                  [-1, 256]           4,096
          Sigmoid-51                  [-1, 256]               0
          SELayer-52          [-1, 256, 64, 32]               0
             ReLU-53          [-1, 256, 64, 32]               0
       Bottleneck-54          [-1, 256, 64, 32]               0
           Conv2d-55          [-1, 512, 64, 32]         131,072
      BatchNorm2d-56          [-1, 512, 64, 32]           1,024
             ReLU-57          [-1, 512, 64, 32]               0
           Conv2d-58          [-1, 512, 32, 16]          73,728
      BatchNorm2d-59          [-1, 512, 32, 16]           1,024
             ReLU-60          [-1, 512, 32, 16]               0
           Conv2d-61          [-1, 512, 32, 16]         262,144
      BatchNorm2d-62          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-63            [-1, 512, 1, 1]               0
           Linear-64                   [-1, 32]          16,384
             ReLU-65                   [-1, 32]               0
           Linear-66                  [-1, 512]          16,384
          Sigmoid-67                  [-1, 512]               0
          SELayer-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         131,072
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
             ReLU-71          [-1, 512, 32, 16]               0
       Bottleneck-72          [-1, 512, 32, 16]               0
           Conv2d-73          [-1, 512, 32, 16]         262,144
      BatchNorm2d-74          [-1, 512, 32, 16]           1,024
             ReLU-75          [-1, 512, 32, 16]               0
           Conv2d-76          [-1, 512, 32, 16]          73,728
      BatchNorm2d-77          [-1, 512, 32, 16]           1,024
             ReLU-78          [-1, 512, 32, 16]               0
           Conv2d-79          [-1, 512, 32, 16]         262,144
      BatchNorm2d-80          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-81            [-1, 512, 1, 1]               0
           Linear-82                   [-1, 32]          16,384
             ReLU-83                   [-1, 32]               0
           Linear-84                  [-1, 512]          16,384
          Sigmoid-85                  [-1, 512]               0
          SELayer-86          [-1, 512, 32, 16]               0
             ReLU-87          [-1, 512, 32, 16]               0
       Bottleneck-88          [-1, 512, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]         262,144
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
             ReLU-91          [-1, 512, 32, 16]               0
           Conv2d-92          [-1, 512, 32, 16]          73,728
      BatchNorm2d-93          [-1, 512, 32, 16]           1,024
             ReLU-94          [-1, 512, 32, 16]               0
           Conv2d-95          [-1, 512, 32, 16]         262,144
      BatchNorm2d-96          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-97            [-1, 512, 1, 1]               0
           Linear-98                   [-1, 32]          16,384
             ReLU-99                   [-1, 32]               0
          Linear-100                  [-1, 512]          16,384
         Sigmoid-101                  [-1, 512]               0
         SELayer-102          [-1, 512, 32, 16]               0
            ReLU-103          [-1, 512, 32, 16]               0
      Bottleneck-104          [-1, 512, 32, 16]               0
          Conv2d-105          [-1, 512, 32, 16]         262,144
     BatchNorm2d-106          [-1, 512, 32, 16]           1,024
            ReLU-107          [-1, 512, 32, 16]               0
          Conv2d-108          [-1, 512, 32, 16]          73,728
     BatchNorm2d-109          [-1, 512, 32, 16]           1,024
            ReLU-110          [-1, 512, 32, 16]               0
          Conv2d-111          [-1, 512, 32, 16]         262,144
     BatchNorm2d-112          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-113            [-1, 512, 1, 1]               0
          Linear-114                   [-1, 32]          16,384
            ReLU-115                   [-1, 32]               0
          Linear-116                  [-1, 512]          16,384
         Sigmoid-117                  [-1, 512]               0
         SELayer-118          [-1, 512, 32, 16]               0
            ReLU-119          [-1, 512, 32, 16]               0
      Bottleneck-120          [-1, 512, 32, 16]               0
          Conv2d-121         [-1, 1024, 32, 16]         524,288
     BatchNorm2d-122         [-1, 1024, 32, 16]           2,048
            ReLU-123         [-1, 1024, 32, 16]               0
          Conv2d-124          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-125          [-1, 1024, 16, 8]           2,048
            ReLU-126          [-1, 1024, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-129           [-1, 1024, 1, 1]               0
          Linear-130                   [-1, 64]          65,536
            ReLU-131                   [-1, 64]               0
          Linear-132                 [-1, 1024]          65,536
         Sigmoid-133                 [-1, 1024]               0
         SELayer-134          [-1, 1024, 16, 8]               0
          Conv2d-135          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-136          [-1, 1024, 16, 8]           2,048
            ReLU-137          [-1, 1024, 16, 8]               0
      Bottleneck-138          [-1, 1024, 16, 8]               0
          Conv2d-139          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-140          [-1, 1024, 16, 8]           2,048
            ReLU-141          [-1, 1024, 16, 8]               0
          Conv2d-142          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-143          [-1, 1024, 16, 8]           2,048
            ReLU-144          [-1, 1024, 16, 8]               0
          Conv2d-145          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-146          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-147           [-1, 1024, 1, 1]               0
          Linear-148                   [-1, 64]          65,536
            ReLU-149                   [-1, 64]               0
          Linear-150                 [-1, 1024]          65,536
         Sigmoid-151                 [-1, 1024]               0
         SELayer-152          [-1, 1024, 16, 8]               0
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-156          [-1, 1024, 16, 8]           2,048
            ReLU-157          [-1, 1024, 16, 8]               0
          Conv2d-158          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-159          [-1, 1024, 16, 8]           2,048
            ReLU-160          [-1, 1024, 16, 8]               0
          Conv2d-161          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-162          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-163           [-1, 1024, 1, 1]               0
          Linear-164                   [-1, 64]          65,536
            ReLU-165                   [-1, 64]               0
          Linear-166                 [-1, 1024]          65,536
         Sigmoid-167                 [-1, 1024]               0
         SELayer-168          [-1, 1024, 16, 8]               0
            ReLU-169          [-1, 1024, 16, 8]               0
      Bottleneck-170          [-1, 1024, 16, 8]               0
          Conv2d-171          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-172          [-1, 1024, 16, 8]           2,048
            ReLU-173          [-1, 1024, 16, 8]               0
          Conv2d-174          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-175          [-1, 1024, 16, 8]           2,048
            ReLU-176          [-1, 1024, 16, 8]               0
          Conv2d-177          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-178          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-179           [-1, 1024, 1, 1]               0
          Linear-180                   [-1, 64]          65,536
            ReLU-181                   [-1, 64]               0
          Linear-182                 [-1, 1024]          65,536
         Sigmoid-183                 [-1, 1024]               0
         SELayer-184          [-1, 1024, 16, 8]               0
            ReLU-185          [-1, 1024, 16, 8]               0
      Bottleneck-186          [-1, 1024, 16, 8]               0
          Conv2d-187          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-188          [-1, 1024, 16, 8]           2,048
            ReLU-189          [-1, 1024, 16, 8]               0
          Conv2d-190          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-191          [-1, 1024, 16, 8]           2,048
            ReLU-192          [-1, 1024, 16, 8]               0
          Conv2d-193          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-194          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-195           [-1, 1024, 1, 1]               0
          Linear-196                   [-1, 64]          65,536
            ReLU-197                   [-1, 64]               0
          Linear-198                 [-1, 1024]          65,536
         Sigmoid-199                 [-1, 1024]               0
         SELayer-200          [-1, 1024, 16, 8]               0
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-204          [-1, 1024, 16, 8]           2,048
            ReLU-205          [-1, 1024, 16, 8]               0
          Conv2d-206          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-207          [-1, 1024, 16, 8]           2,048
            ReLU-208          [-1, 1024, 16, 8]               0
          Conv2d-209          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-210          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-211           [-1, 1024, 1, 1]               0
          Linear-212                   [-1, 64]          65,536
            ReLU-213                   [-1, 64]               0
          Linear-214                 [-1, 1024]          65,536
         Sigmoid-215                 [-1, 1024]               0
         SELayer-216          [-1, 1024, 16, 8]               0
            ReLU-217          [-1, 1024, 16, 8]               0
      Bottleneck-218          [-1, 1024, 16, 8]               0
          Conv2d-219          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-220          [-1, 1024, 16, 8]           2,048
            ReLU-221          [-1, 1024, 16, 8]               0
          Conv2d-222          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-223          [-1, 1024, 16, 8]           2,048
            ReLU-224          [-1, 1024, 16, 8]               0
          Conv2d-225          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-226          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-227           [-1, 1024, 1, 1]               0
          Linear-228                   [-1, 64]          65,536
            ReLU-229                   [-1, 64]               0
          Linear-230                 [-1, 1024]          65,536
         Sigmoid-231                 [-1, 1024]               0
         SELayer-232          [-1, 1024, 16, 8]               0
            ReLU-233          [-1, 1024, 16, 8]               0
      Bottleneck-234          [-1, 1024, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
            ReLU-237          [-1, 1024, 16, 8]               0
          Conv2d-238          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-239          [-1, 1024, 16, 8]           2,048
            ReLU-240          [-1, 1024, 16, 8]               0
          Conv2d-241          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-242          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-243           [-1, 1024, 1, 1]               0
          Linear-244                   [-1, 64]          65,536
            ReLU-245                   [-1, 64]               0
          Linear-246                 [-1, 1024]          65,536
         Sigmoid-247                 [-1, 1024]               0
         SELayer-248          [-1, 1024, 16, 8]               0
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-252          [-1, 1024, 16, 8]           2,048
            ReLU-253          [-1, 1024, 16, 8]               0
          Conv2d-254          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-255          [-1, 1024, 16, 8]           2,048
            ReLU-256          [-1, 1024, 16, 8]               0
          Conv2d-257          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-258          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-259           [-1, 1024, 1, 1]               0
          Linear-260                   [-1, 64]          65,536
            ReLU-261                   [-1, 64]               0
          Linear-262                 [-1, 1024]          65,536
         Sigmoid-263                 [-1, 1024]               0
         SELayer-264          [-1, 1024, 16, 8]               0
            ReLU-265          [-1, 1024, 16, 8]               0
      Bottleneck-266          [-1, 1024, 16, 8]               0
          Conv2d-267          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-268          [-1, 1024, 16, 8]           2,048
            ReLU-269          [-1, 1024, 16, 8]               0
          Conv2d-270          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-271          [-1, 1024, 16, 8]           2,048
            ReLU-272          [-1, 1024, 16, 8]               0
          Conv2d-273          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-274          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-275           [-1, 1024, 1, 1]               0
          Linear-276                   [-1, 64]          65,536
            ReLU-277                   [-1, 64]               0
          Linear-278                 [-1, 1024]          65,536
         Sigmoid-279                 [-1, 1024]               0
         SELayer-280          [-1, 1024, 16, 8]               0
            ReLU-281          [-1, 1024, 16, 8]               0
      Bottleneck-282          [-1, 1024, 16, 8]               0
          Conv2d-283          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-284          [-1, 1024, 16, 8]           2,048
            ReLU-285          [-1, 1024, 16, 8]               0
          Conv2d-286          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-287          [-1, 1024, 16, 8]           2,048
            ReLU-288          [-1, 1024, 16, 8]               0
          Conv2d-289          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-290          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-291           [-1, 1024, 1, 1]               0
          Linear-292                   [-1, 64]          65,536
            ReLU-293                   [-1, 64]               0
          Linear-294                 [-1, 1024]          65,536
         Sigmoid-295                 [-1, 1024]               0
         SELayer-296          [-1, 1024, 16, 8]               0
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-300          [-1, 1024, 16, 8]           2,048
            ReLU-301          [-1, 1024, 16, 8]               0
          Conv2d-302          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-303          [-1, 1024, 16, 8]           2,048
            ReLU-304          [-1, 1024, 16, 8]               0
          Conv2d-305          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-306          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-307           [-1, 1024, 1, 1]               0
          Linear-308                   [-1, 64]          65,536
            ReLU-309                   [-1, 64]               0
          Linear-310                 [-1, 1024]          65,536
         Sigmoid-311                 [-1, 1024]               0
         SELayer-312          [-1, 1024, 16, 8]               0
            ReLU-313          [-1, 1024, 16, 8]               0
      Bottleneck-314          [-1, 1024, 16, 8]               0
          Conv2d-315          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-316          [-1, 1024, 16, 8]           2,048
            ReLU-317          [-1, 1024, 16, 8]               0
          Conv2d-318          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-319          [-1, 1024, 16, 8]           2,048
            ReLU-320          [-1, 1024, 16, 8]               0
          Conv2d-321          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-322          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-323           [-1, 1024, 1, 1]               0
          Linear-324                   [-1, 64]          65,536
            ReLU-325                   [-1, 64]               0
          Linear-326                 [-1, 1024]          65,536
         Sigmoid-327                 [-1, 1024]               0
         SELayer-328          [-1, 1024, 16, 8]               0
            ReLU-329          [-1, 1024, 16, 8]               0
      Bottleneck-330          [-1, 1024, 16, 8]               0
          Conv2d-331          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-332          [-1, 1024, 16, 8]           2,048
            ReLU-333          [-1, 1024, 16, 8]               0
          Conv2d-334          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-335          [-1, 1024, 16, 8]           2,048
            ReLU-336          [-1, 1024, 16, 8]               0
          Conv2d-337          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-338          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-339           [-1, 1024, 1, 1]               0
          Linear-340                   [-1, 64]          65,536
            ReLU-341                   [-1, 64]               0
          Linear-342                 [-1, 1024]          65,536
         Sigmoid-343                 [-1, 1024]               0
         SELayer-344          [-1, 1024, 16, 8]               0
            ReLU-345          [-1, 1024, 16, 8]               0
      Bottleneck-346          [-1, 1024, 16, 8]               0
          Conv2d-347          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-348          [-1, 1024, 16, 8]           2,048
            ReLU-349          [-1, 1024, 16, 8]               0
          Conv2d-350          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-351          [-1, 1024, 16, 8]           2,048
            ReLU-352          [-1, 1024, 16, 8]               0
          Conv2d-353          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-354          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-355           [-1, 1024, 1, 1]               0
          Linear-356                   [-1, 64]          65,536
            ReLU-357                   [-1, 64]               0
          Linear-358                 [-1, 1024]          65,536
         Sigmoid-359                 [-1, 1024]               0
         SELayer-360          [-1, 1024, 16, 8]               0
            ReLU-361          [-1, 1024, 16, 8]               0
      Bottleneck-362          [-1, 1024, 16, 8]               0
          Conv2d-363          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-364          [-1, 1024, 16, 8]           2,048
            ReLU-365          [-1, 1024, 16, 8]               0
          Conv2d-366          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-367          [-1, 1024, 16, 8]           2,048
            ReLU-368          [-1, 1024, 16, 8]               0
          Conv2d-369          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-370          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-371           [-1, 1024, 1, 1]               0
          Linear-372                   [-1, 64]          65,536
            ReLU-373                   [-1, 64]               0
          Linear-374                 [-1, 1024]          65,536
         Sigmoid-375                 [-1, 1024]               0
         SELayer-376          [-1, 1024, 16, 8]               0
            ReLU-377          [-1, 1024, 16, 8]               0
      Bottleneck-378          [-1, 1024, 16, 8]               0
          Conv2d-379          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-380          [-1, 1024, 16, 8]           2,048
            ReLU-381          [-1, 1024, 16, 8]               0
          Conv2d-382          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-383          [-1, 1024, 16, 8]           2,048
            ReLU-384          [-1, 1024, 16, 8]               0
          Conv2d-385          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-386          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-387           [-1, 1024, 1, 1]               0
          Linear-388                   [-1, 64]          65,536
            ReLU-389                   [-1, 64]               0
          Linear-390                 [-1, 1024]          65,536
         Sigmoid-391                 [-1, 1024]               0
         SELayer-392          [-1, 1024, 16, 8]               0
            ReLU-393          [-1, 1024, 16, 8]               0
      Bottleneck-394          [-1, 1024, 16, 8]               0
          Conv2d-395          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-396          [-1, 1024, 16, 8]           2,048
            ReLU-397          [-1, 1024, 16, 8]               0
          Conv2d-398          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-399          [-1, 1024, 16, 8]           2,048
            ReLU-400          [-1, 1024, 16, 8]               0
          Conv2d-401          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-402          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-403           [-1, 1024, 1, 1]               0
          Linear-404                   [-1, 64]          65,536
            ReLU-405                   [-1, 64]               0
          Linear-406                 [-1, 1024]          65,536
         Sigmoid-407                 [-1, 1024]               0
         SELayer-408          [-1, 1024, 16, 8]               0
            ReLU-409          [-1, 1024, 16, 8]               0
      Bottleneck-410          [-1, 1024, 16, 8]               0
          Conv2d-411          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-412          [-1, 1024, 16, 8]           2,048
            ReLU-413          [-1, 1024, 16, 8]               0
          Conv2d-414          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-415          [-1, 1024, 16, 8]           2,048
            ReLU-416          [-1, 1024, 16, 8]               0
          Conv2d-417          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-418          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-419           [-1, 1024, 1, 1]               0
          Linear-420                   [-1, 64]          65,536
            ReLU-421                   [-1, 64]               0
          Linear-422                 [-1, 1024]          65,536
         Sigmoid-423                 [-1, 1024]               0
         SELayer-424          [-1, 1024, 16, 8]               0
            ReLU-425          [-1, 1024, 16, 8]               0
      Bottleneck-426          [-1, 1024, 16, 8]               0
          Conv2d-427          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-428          [-1, 1024, 16, 8]           2,048
            ReLU-429          [-1, 1024, 16, 8]               0
          Conv2d-430          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-431          [-1, 1024, 16, 8]           2,048
            ReLU-432          [-1, 1024, 16, 8]               0
          Conv2d-433          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-434          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-435           [-1, 1024, 1, 1]               0
          Linear-436                   [-1, 64]          65,536
            ReLU-437                   [-1, 64]               0
          Linear-438                 [-1, 1024]          65,536
         Sigmoid-439                 [-1, 1024]               0
         SELayer-440          [-1, 1024, 16, 8]               0
            ReLU-441          [-1, 1024, 16, 8]               0
      Bottleneck-442          [-1, 1024, 16, 8]               0
          Conv2d-443          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-444          [-1, 1024, 16, 8]           2,048
            ReLU-445          [-1, 1024, 16, 8]               0
          Conv2d-446          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-447          [-1, 1024, 16, 8]           2,048
            ReLU-448          [-1, 1024, 16, 8]               0
          Conv2d-449          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-450          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-451           [-1, 1024, 1, 1]               0
          Linear-452                   [-1, 64]          65,536
            ReLU-453                   [-1, 64]               0
          Linear-454                 [-1, 1024]          65,536
         Sigmoid-455                 [-1, 1024]               0
         SELayer-456          [-1, 1024, 16, 8]               0
            ReLU-457          [-1, 1024, 16, 8]               0
      Bottleneck-458          [-1, 1024, 16, 8]               0
          Conv2d-459          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-460          [-1, 1024, 16, 8]           2,048
            ReLU-461          [-1, 1024, 16, 8]               0
          Conv2d-462          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-463          [-1, 1024, 16, 8]           2,048
            ReLU-464          [-1, 1024, 16, 8]               0
          Conv2d-465          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-466          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-467           [-1, 1024, 1, 1]               0
          Linear-468                   [-1, 64]          65,536
            ReLU-469                   [-1, 64]               0
          Linear-470                 [-1, 1024]          65,536
         Sigmoid-471                 [-1, 1024]               0
         SELayer-472          [-1, 1024, 16, 8]               0
            ReLU-473          [-1, 1024, 16, 8]               0
      Bottleneck-474          [-1, 1024, 16, 8]               0
          Conv2d-475          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-476          [-1, 1024, 16, 8]           2,048
            ReLU-477          [-1, 1024, 16, 8]               0
          Conv2d-478          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-479          [-1, 1024, 16, 8]           2,048
            ReLU-480          [-1, 1024, 16, 8]               0
          Conv2d-481          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-482          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-483           [-1, 1024, 1, 1]               0
          Linear-484                   [-1, 64]          65,536
            ReLU-485                   [-1, 64]               0
          Linear-486                 [-1, 1024]          65,536
         Sigmoid-487                 [-1, 1024]               0
         SELayer-488          [-1, 1024, 16, 8]               0
            ReLU-489          [-1, 1024, 16, 8]               0
      Bottleneck-490          [-1, 1024, 16, 8]               0
          Conv2d-491          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-492          [-1, 2048, 16, 8]           4,096
            ReLU-493          [-1, 2048, 16, 8]               0
          Conv2d-494          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-495          [-1, 2048, 16, 8]           4,096
            ReLU-496          [-1, 2048, 16, 8]               0
          Conv2d-497          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-498          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-499           [-1, 2048, 1, 1]               0
          Linear-500                  [-1, 128]         262,144
            ReLU-501                  [-1, 128]               0
          Linear-502                 [-1, 2048]         262,144
         Sigmoid-503                 [-1, 2048]               0
         SELayer-504          [-1, 2048, 16, 8]               0
          Conv2d-505          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-506          [-1, 2048, 16, 8]           4,096
            ReLU-507          [-1, 2048, 16, 8]               0
      Bottleneck-508          [-1, 2048, 16, 8]               0
          Conv2d-509          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-510          [-1, 2048, 16, 8]           4,096
            ReLU-511          [-1, 2048, 16, 8]               0
          Conv2d-512          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-513          [-1, 2048, 16, 8]           4,096
            ReLU-514          [-1, 2048, 16, 8]               0
          Conv2d-515          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-516          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-517           [-1, 2048, 1, 1]               0
          Linear-518                  [-1, 128]         262,144
            ReLU-519                  [-1, 128]               0
          Linear-520                 [-1, 2048]         262,144
         Sigmoid-521                 [-1, 2048]               0
         SELayer-522          [-1, 2048, 16, 8]               0
            ReLU-523          [-1, 2048, 16, 8]               0
      Bottleneck-524          [-1, 2048, 16, 8]               0
          Conv2d-525          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-526          [-1, 2048, 16, 8]           4,096
            ReLU-527          [-1, 2048, 16, 8]               0
          Conv2d-528          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-529          [-1, 2048, 16, 8]           4,096
            ReLU-530          [-1, 2048, 16, 8]               0
          Conv2d-531          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-532          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-533           [-1, 2048, 1, 1]               0
          Linear-534                  [-1, 128]         262,144
            ReLU-535                  [-1, 128]               0
          Linear-536                 [-1, 2048]         262,144
         Sigmoid-537                 [-1, 2048]               0
         SELayer-538          [-1, 2048, 16, 8]               0
            ReLU-539          [-1, 2048, 16, 8]               0
      Bottleneck-540          [-1, 2048, 16, 8]               0
================================================================
Total params: 91,485,504
Trainable params: 91,485,504
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 597.78
Params size (MB): 348.99
Estimated Total Size (MB): 947.14
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnext101_32x8d_se_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 256, 64, 32]          16,384
    InstanceNorm2d-6          [-1, 128, 64, 32]             256
       BatchNorm2d-7          [-1, 128, 64, 32]             256
               IBN-8          [-1, 256, 64, 32]               0
              ReLU-9          [-1, 256, 64, 32]               0
           Conv2d-10          [-1, 256, 64, 32]          18,432
      BatchNorm2d-11          [-1, 256, 64, 32]             512
             ReLU-12          [-1, 256, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          65,536
      BatchNorm2d-14          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-15            [-1, 256, 1, 1]               0
           Linear-16                   [-1, 16]           4,096
             ReLU-17                   [-1, 16]               0
           Linear-18                  [-1, 256]           4,096
          Sigmoid-19                  [-1, 256]               0
          SELayer-20          [-1, 256, 64, 32]               0
           Conv2d-21          [-1, 256, 64, 32]          16,384
      BatchNorm2d-22          [-1, 256, 64, 32]             512
             ReLU-23          [-1, 256, 64, 32]               0
       Bottleneck-24          [-1, 256, 64, 32]               0
           Conv2d-25          [-1, 256, 64, 32]          65,536
   InstanceNorm2d-26          [-1, 128, 64, 32]             256
      BatchNorm2d-27          [-1, 128, 64, 32]             256
              IBN-28          [-1, 256, 64, 32]               0
             ReLU-29          [-1, 256, 64, 32]               0
           Conv2d-30          [-1, 256, 64, 32]          18,432
      BatchNorm2d-31          [-1, 256, 64, 32]             512
             ReLU-32          [-1, 256, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          65,536
      BatchNorm2d-34          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-35            [-1, 256, 1, 1]               0
           Linear-36                   [-1, 16]           4,096
             ReLU-37                   [-1, 16]               0
           Linear-38                  [-1, 256]           4,096
          Sigmoid-39                  [-1, 256]               0
          SELayer-40          [-1, 256, 64, 32]               0
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 256, 64, 32]          65,536
   InstanceNorm2d-44          [-1, 128, 64, 32]             256
      BatchNorm2d-45          [-1, 128, 64, 32]             256
              IBN-46          [-1, 256, 64, 32]               0
             ReLU-47          [-1, 256, 64, 32]               0
           Conv2d-48          [-1, 256, 64, 32]          18,432
      BatchNorm2d-49          [-1, 256, 64, 32]             512
             ReLU-50          [-1, 256, 64, 32]               0
           Conv2d-51          [-1, 256, 64, 32]          65,536
      BatchNorm2d-52          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-53            [-1, 256, 1, 1]               0
           Linear-54                   [-1, 16]           4,096
             ReLU-55                   [-1, 16]               0
           Linear-56                  [-1, 256]           4,096
          Sigmoid-57                  [-1, 256]               0
          SELayer-58          [-1, 256, 64, 32]               0
             ReLU-59          [-1, 256, 64, 32]               0
       Bottleneck-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 512, 64, 32]         131,072
   InstanceNorm2d-62          [-1, 256, 64, 32]             512
      BatchNorm2d-63          [-1, 256, 64, 32]             512
              IBN-64          [-1, 512, 64, 32]               0
             ReLU-65          [-1, 512, 64, 32]               0
           Conv2d-66          [-1, 512, 32, 16]          73,728
      BatchNorm2d-67          [-1, 512, 32, 16]           1,024
             ReLU-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         262,144
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-71            [-1, 512, 1, 1]               0
           Linear-72                   [-1, 32]          16,384
             ReLU-73                   [-1, 32]               0
           Linear-74                  [-1, 512]          16,384
          Sigmoid-75                  [-1, 512]               0
          SELayer-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         131,072
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 512, 32, 16]         262,144
   InstanceNorm2d-82          [-1, 256, 32, 16]             512
      BatchNorm2d-83          [-1, 256, 32, 16]             512
              IBN-84          [-1, 512, 32, 16]               0
             ReLU-85          [-1, 512, 32, 16]               0
           Conv2d-86          [-1, 512, 32, 16]          73,728
      BatchNorm2d-87          [-1, 512, 32, 16]           1,024
             ReLU-88          [-1, 512, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]         262,144
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-91            [-1, 512, 1, 1]               0
           Linear-92                   [-1, 32]          16,384
             ReLU-93                   [-1, 32]               0
           Linear-94                  [-1, 512]          16,384
          Sigmoid-95                  [-1, 512]               0
          SELayer-96          [-1, 512, 32, 16]               0
             ReLU-97          [-1, 512, 32, 16]               0
       Bottleneck-98          [-1, 512, 32, 16]               0
           Conv2d-99          [-1, 512, 32, 16]         262,144
  InstanceNorm2d-100          [-1, 256, 32, 16]             512
     BatchNorm2d-101          [-1, 256, 32, 16]             512
             IBN-102          [-1, 512, 32, 16]               0
            ReLU-103          [-1, 512, 32, 16]               0
          Conv2d-104          [-1, 512, 32, 16]          73,728
     BatchNorm2d-105          [-1, 512, 32, 16]           1,024
            ReLU-106          [-1, 512, 32, 16]               0
          Conv2d-107          [-1, 512, 32, 16]         262,144
     BatchNorm2d-108          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-109            [-1, 512, 1, 1]               0
          Linear-110                   [-1, 32]          16,384
            ReLU-111                   [-1, 32]               0
          Linear-112                  [-1, 512]          16,384
         Sigmoid-113                  [-1, 512]               0
         SELayer-114          [-1, 512, 32, 16]               0
            ReLU-115          [-1, 512, 32, 16]               0
      Bottleneck-116          [-1, 512, 32, 16]               0
          Conv2d-117          [-1, 512, 32, 16]         262,144
  InstanceNorm2d-118          [-1, 256, 32, 16]             512
     BatchNorm2d-119          [-1, 256, 32, 16]             512
             IBN-120          [-1, 512, 32, 16]               0
            ReLU-121          [-1, 512, 32, 16]               0
          Conv2d-122          [-1, 512, 32, 16]          73,728
     BatchNorm2d-123          [-1, 512, 32, 16]           1,024
            ReLU-124          [-1, 512, 32, 16]               0
          Conv2d-125          [-1, 512, 32, 16]         262,144
     BatchNorm2d-126          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-127            [-1, 512, 1, 1]               0
          Linear-128                   [-1, 32]          16,384
            ReLU-129                   [-1, 32]               0
          Linear-130                  [-1, 512]          16,384
         Sigmoid-131                  [-1, 512]               0
         SELayer-132          [-1, 512, 32, 16]               0
            ReLU-133          [-1, 512, 32, 16]               0
      Bottleneck-134          [-1, 512, 32, 16]               0
          Conv2d-135         [-1, 1024, 32, 16]         524,288
  InstanceNorm2d-136          [-1, 512, 32, 16]           1,024
     BatchNorm2d-137          [-1, 512, 32, 16]           1,024
             IBN-138         [-1, 1024, 32, 16]               0
            ReLU-139         [-1, 1024, 32, 16]               0
          Conv2d-140          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-141          [-1, 1024, 16, 8]           2,048
            ReLU-142          [-1, 1024, 16, 8]               0
          Conv2d-143          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-144          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-145           [-1, 1024, 1, 1]               0
          Linear-146                   [-1, 64]          65,536
            ReLU-147                   [-1, 64]               0
          Linear-148                 [-1, 1024]          65,536
         Sigmoid-149                 [-1, 1024]               0
         SELayer-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-156           [-1, 512, 16, 8]           1,024
     BatchNorm2d-157           [-1, 512, 16, 8]           1,024
             IBN-158          [-1, 1024, 16, 8]               0
            ReLU-159          [-1, 1024, 16, 8]               0
          Conv2d-160          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-161          [-1, 1024, 16, 8]           2,048
            ReLU-162          [-1, 1024, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-165           [-1, 1024, 1, 1]               0
          Linear-166                   [-1, 64]          65,536
            ReLU-167                   [-1, 64]               0
          Linear-168                 [-1, 1024]          65,536
         Sigmoid-169                 [-1, 1024]               0
         SELayer-170          [-1, 1024, 16, 8]               0
            ReLU-171          [-1, 1024, 16, 8]               0
      Bottleneck-172          [-1, 1024, 16, 8]               0
          Conv2d-173          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-174           [-1, 512, 16, 8]           1,024
     BatchNorm2d-175           [-1, 512, 16, 8]           1,024
             IBN-176          [-1, 1024, 16, 8]               0
            ReLU-177          [-1, 1024, 16, 8]               0
          Conv2d-178          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-179          [-1, 1024, 16, 8]           2,048
            ReLU-180          [-1, 1024, 16, 8]               0
          Conv2d-181          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-182          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-183           [-1, 1024, 1, 1]               0
          Linear-184                   [-1, 64]          65,536
            ReLU-185                   [-1, 64]               0
          Linear-186                 [-1, 1024]          65,536
         Sigmoid-187                 [-1, 1024]               0
         SELayer-188          [-1, 1024, 16, 8]               0
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-192           [-1, 512, 16, 8]           1,024
     BatchNorm2d-193           [-1, 512, 16, 8]           1,024
             IBN-194          [-1, 1024, 16, 8]               0
            ReLU-195          [-1, 1024, 16, 8]               0
          Conv2d-196          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-197          [-1, 1024, 16, 8]           2,048
            ReLU-198          [-1, 1024, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-201           [-1, 1024, 1, 1]               0
          Linear-202                   [-1, 64]          65,536
            ReLU-203                   [-1, 64]               0
          Linear-204                 [-1, 1024]          65,536
         Sigmoid-205                 [-1, 1024]               0
         SELayer-206          [-1, 1024, 16, 8]               0
            ReLU-207          [-1, 1024, 16, 8]               0
      Bottleneck-208          [-1, 1024, 16, 8]               0
          Conv2d-209          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-210           [-1, 512, 16, 8]           1,024
     BatchNorm2d-211           [-1, 512, 16, 8]           1,024
             IBN-212          [-1, 1024, 16, 8]               0
            ReLU-213          [-1, 1024, 16, 8]               0
          Conv2d-214          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-215          [-1, 1024, 16, 8]           2,048
            ReLU-216          [-1, 1024, 16, 8]               0
          Conv2d-217          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-218          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-219           [-1, 1024, 1, 1]               0
          Linear-220                   [-1, 64]          65,536
            ReLU-221                   [-1, 64]               0
          Linear-222                 [-1, 1024]          65,536
         Sigmoid-223                 [-1, 1024]               0
         SELayer-224          [-1, 1024, 16, 8]               0
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-228           [-1, 512, 16, 8]           1,024
     BatchNorm2d-229           [-1, 512, 16, 8]           1,024
             IBN-230          [-1, 1024, 16, 8]               0
            ReLU-231          [-1, 1024, 16, 8]               0
          Conv2d-232          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-233          [-1, 1024, 16, 8]           2,048
            ReLU-234          [-1, 1024, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-237           [-1, 1024, 1, 1]               0
          Linear-238                   [-1, 64]          65,536
            ReLU-239                   [-1, 64]               0
          Linear-240                 [-1, 1024]          65,536
         Sigmoid-241                 [-1, 1024]               0
         SELayer-242          [-1, 1024, 16, 8]               0
            ReLU-243          [-1, 1024, 16, 8]               0
      Bottleneck-244          [-1, 1024, 16, 8]               0
          Conv2d-245          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-246           [-1, 512, 16, 8]           1,024
     BatchNorm2d-247           [-1, 512, 16, 8]           1,024
             IBN-248          [-1, 1024, 16, 8]               0
            ReLU-249          [-1, 1024, 16, 8]               0
          Conv2d-250          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-251          [-1, 1024, 16, 8]           2,048
            ReLU-252          [-1, 1024, 16, 8]               0
          Conv2d-253          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-254          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-255           [-1, 1024, 1, 1]               0
          Linear-256                   [-1, 64]          65,536
            ReLU-257                   [-1, 64]               0
          Linear-258                 [-1, 1024]          65,536
         Sigmoid-259                 [-1, 1024]               0
         SELayer-260          [-1, 1024, 16, 8]               0
            ReLU-261          [-1, 1024, 16, 8]               0
      Bottleneck-262          [-1, 1024, 16, 8]               0
          Conv2d-263          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-264           [-1, 512, 16, 8]           1,024
     BatchNorm2d-265           [-1, 512, 16, 8]           1,024
             IBN-266          [-1, 1024, 16, 8]               0
            ReLU-267          [-1, 1024, 16, 8]               0
          Conv2d-268          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-269          [-1, 1024, 16, 8]           2,048
            ReLU-270          [-1, 1024, 16, 8]               0
          Conv2d-271          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-272          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-273           [-1, 1024, 1, 1]               0
          Linear-274                   [-1, 64]          65,536
            ReLU-275                   [-1, 64]               0
          Linear-276                 [-1, 1024]          65,536
         Sigmoid-277                 [-1, 1024]               0
         SELayer-278          [-1, 1024, 16, 8]               0
            ReLU-279          [-1, 1024, 16, 8]               0
      Bottleneck-280          [-1, 1024, 16, 8]               0
          Conv2d-281          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-282           [-1, 512, 16, 8]           1,024
     BatchNorm2d-283           [-1, 512, 16, 8]           1,024
             IBN-284          [-1, 1024, 16, 8]               0
            ReLU-285          [-1, 1024, 16, 8]               0
          Conv2d-286          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-287          [-1, 1024, 16, 8]           2,048
            ReLU-288          [-1, 1024, 16, 8]               0
          Conv2d-289          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-290          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-291           [-1, 1024, 1, 1]               0
          Linear-292                   [-1, 64]          65,536
            ReLU-293                   [-1, 64]               0
          Linear-294                 [-1, 1024]          65,536
         Sigmoid-295                 [-1, 1024]               0
         SELayer-296          [-1, 1024, 16, 8]               0
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-300           [-1, 512, 16, 8]           1,024
     BatchNorm2d-301           [-1, 512, 16, 8]           1,024
             IBN-302          [-1, 1024, 16, 8]               0
            ReLU-303          [-1, 1024, 16, 8]               0
          Conv2d-304          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-305          [-1, 1024, 16, 8]           2,048
            ReLU-306          [-1, 1024, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-309           [-1, 1024, 1, 1]               0
          Linear-310                   [-1, 64]          65,536
            ReLU-311                   [-1, 64]               0
          Linear-312                 [-1, 1024]          65,536
         Sigmoid-313                 [-1, 1024]               0
         SELayer-314          [-1, 1024, 16, 8]               0
            ReLU-315          [-1, 1024, 16, 8]               0
      Bottleneck-316          [-1, 1024, 16, 8]               0
          Conv2d-317          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-318           [-1, 512, 16, 8]           1,024
     BatchNorm2d-319           [-1, 512, 16, 8]           1,024
             IBN-320          [-1, 1024, 16, 8]               0
            ReLU-321          [-1, 1024, 16, 8]               0
          Conv2d-322          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-323          [-1, 1024, 16, 8]           2,048
            ReLU-324          [-1, 1024, 16, 8]               0
          Conv2d-325          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-326          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-327           [-1, 1024, 1, 1]               0
          Linear-328                   [-1, 64]          65,536
            ReLU-329                   [-1, 64]               0
          Linear-330                 [-1, 1024]          65,536
         Sigmoid-331                 [-1, 1024]               0
         SELayer-332          [-1, 1024, 16, 8]               0
            ReLU-333          [-1, 1024, 16, 8]               0
      Bottleneck-334          [-1, 1024, 16, 8]               0
          Conv2d-335          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-336           [-1, 512, 16, 8]           1,024
     BatchNorm2d-337           [-1, 512, 16, 8]           1,024
             IBN-338          [-1, 1024, 16, 8]               0
            ReLU-339          [-1, 1024, 16, 8]               0
          Conv2d-340          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-341          [-1, 1024, 16, 8]           2,048
            ReLU-342          [-1, 1024, 16, 8]               0
          Conv2d-343          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-344          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-345           [-1, 1024, 1, 1]               0
          Linear-346                   [-1, 64]          65,536
            ReLU-347                   [-1, 64]               0
          Linear-348                 [-1, 1024]          65,536
         Sigmoid-349                 [-1, 1024]               0
         SELayer-350          [-1, 1024, 16, 8]               0
            ReLU-351          [-1, 1024, 16, 8]               0
      Bottleneck-352          [-1, 1024, 16, 8]               0
          Conv2d-353          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-354           [-1, 512, 16, 8]           1,024
     BatchNorm2d-355           [-1, 512, 16, 8]           1,024
             IBN-356          [-1, 1024, 16, 8]               0
            ReLU-357          [-1, 1024, 16, 8]               0
          Conv2d-358          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-359          [-1, 1024, 16, 8]           2,048
            ReLU-360          [-1, 1024, 16, 8]               0
          Conv2d-361          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-362          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-363           [-1, 1024, 1, 1]               0
          Linear-364                   [-1, 64]          65,536
            ReLU-365                   [-1, 64]               0
          Linear-366                 [-1, 1024]          65,536
         Sigmoid-367                 [-1, 1024]               0
         SELayer-368          [-1, 1024, 16, 8]               0
            ReLU-369          [-1, 1024, 16, 8]               0
      Bottleneck-370          [-1, 1024, 16, 8]               0
          Conv2d-371          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-372           [-1, 512, 16, 8]           1,024
     BatchNorm2d-373           [-1, 512, 16, 8]           1,024
             IBN-374          [-1, 1024, 16, 8]               0
            ReLU-375          [-1, 1024, 16, 8]               0
          Conv2d-376          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-377          [-1, 1024, 16, 8]           2,048
            ReLU-378          [-1, 1024, 16, 8]               0
          Conv2d-379          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-380          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-381           [-1, 1024, 1, 1]               0
          Linear-382                   [-1, 64]          65,536
            ReLU-383                   [-1, 64]               0
          Linear-384                 [-1, 1024]          65,536
         Sigmoid-385                 [-1, 1024]               0
         SELayer-386          [-1, 1024, 16, 8]               0
            ReLU-387          [-1, 1024, 16, 8]               0
      Bottleneck-388          [-1, 1024, 16, 8]               0
          Conv2d-389          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-390           [-1, 512, 16, 8]           1,024
     BatchNorm2d-391           [-1, 512, 16, 8]           1,024
             IBN-392          [-1, 1024, 16, 8]               0
            ReLU-393          [-1, 1024, 16, 8]               0
          Conv2d-394          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-395          [-1, 1024, 16, 8]           2,048
            ReLU-396          [-1, 1024, 16, 8]               0
          Conv2d-397          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-398          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-399           [-1, 1024, 1, 1]               0
          Linear-400                   [-1, 64]          65,536
            ReLU-401                   [-1, 64]               0
          Linear-402                 [-1, 1024]          65,536
         Sigmoid-403                 [-1, 1024]               0
         SELayer-404          [-1, 1024, 16, 8]               0
            ReLU-405          [-1, 1024, 16, 8]               0
      Bottleneck-406          [-1, 1024, 16, 8]               0
          Conv2d-407          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-408           [-1, 512, 16, 8]           1,024
     BatchNorm2d-409           [-1, 512, 16, 8]           1,024
             IBN-410          [-1, 1024, 16, 8]               0
            ReLU-411          [-1, 1024, 16, 8]               0
          Conv2d-412          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-413          [-1, 1024, 16, 8]           2,048
            ReLU-414          [-1, 1024, 16, 8]               0
          Conv2d-415          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-416          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-417           [-1, 1024, 1, 1]               0
          Linear-418                   [-1, 64]          65,536
            ReLU-419                   [-1, 64]               0
          Linear-420                 [-1, 1024]          65,536
         Sigmoid-421                 [-1, 1024]               0
         SELayer-422          [-1, 1024, 16, 8]               0
            ReLU-423          [-1, 1024, 16, 8]               0
      Bottleneck-424          [-1, 1024, 16, 8]               0
          Conv2d-425          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-426           [-1, 512, 16, 8]           1,024
     BatchNorm2d-427           [-1, 512, 16, 8]           1,024
             IBN-428          [-1, 1024, 16, 8]               0
            ReLU-429          [-1, 1024, 16, 8]               0
          Conv2d-430          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-431          [-1, 1024, 16, 8]           2,048
            ReLU-432          [-1, 1024, 16, 8]               0
          Conv2d-433          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-434          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-435           [-1, 1024, 1, 1]               0
          Linear-436                   [-1, 64]          65,536
            ReLU-437                   [-1, 64]               0
          Linear-438                 [-1, 1024]          65,536
         Sigmoid-439                 [-1, 1024]               0
         SELayer-440          [-1, 1024, 16, 8]               0
            ReLU-441          [-1, 1024, 16, 8]               0
      Bottleneck-442          [-1, 1024, 16, 8]               0
          Conv2d-443          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-444           [-1, 512, 16, 8]           1,024
     BatchNorm2d-445           [-1, 512, 16, 8]           1,024
             IBN-446          [-1, 1024, 16, 8]               0
            ReLU-447          [-1, 1024, 16, 8]               0
          Conv2d-448          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-449          [-1, 1024, 16, 8]           2,048
            ReLU-450          [-1, 1024, 16, 8]               0
          Conv2d-451          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-452          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-453           [-1, 1024, 1, 1]               0
          Linear-454                   [-1, 64]          65,536
            ReLU-455                   [-1, 64]               0
          Linear-456                 [-1, 1024]          65,536
         Sigmoid-457                 [-1, 1024]               0
         SELayer-458          [-1, 1024, 16, 8]               0
            ReLU-459          [-1, 1024, 16, 8]               0
      Bottleneck-460          [-1, 1024, 16, 8]               0
          Conv2d-461          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-462           [-1, 512, 16, 8]           1,024
     BatchNorm2d-463           [-1, 512, 16, 8]           1,024
             IBN-464          [-1, 1024, 16, 8]               0
            ReLU-465          [-1, 1024, 16, 8]               0
          Conv2d-466          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-467          [-1, 1024, 16, 8]           2,048
            ReLU-468          [-1, 1024, 16, 8]               0
          Conv2d-469          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-470          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-471           [-1, 1024, 1, 1]               0
          Linear-472                   [-1, 64]          65,536
            ReLU-473                   [-1, 64]               0
          Linear-474                 [-1, 1024]          65,536
         Sigmoid-475                 [-1, 1024]               0
         SELayer-476          [-1, 1024, 16, 8]               0
            ReLU-477          [-1, 1024, 16, 8]               0
      Bottleneck-478          [-1, 1024, 16, 8]               0
          Conv2d-479          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-480           [-1, 512, 16, 8]           1,024
     BatchNorm2d-481           [-1, 512, 16, 8]           1,024
             IBN-482          [-1, 1024, 16, 8]               0
            ReLU-483          [-1, 1024, 16, 8]               0
          Conv2d-484          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-485          [-1, 1024, 16, 8]           2,048
            ReLU-486          [-1, 1024, 16, 8]               0
          Conv2d-487          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-488          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-489           [-1, 1024, 1, 1]               0
          Linear-490                   [-1, 64]          65,536
            ReLU-491                   [-1, 64]               0
          Linear-492                 [-1, 1024]          65,536
         Sigmoid-493                 [-1, 1024]               0
         SELayer-494          [-1, 1024, 16, 8]               0
            ReLU-495          [-1, 1024, 16, 8]               0
      Bottleneck-496          [-1, 1024, 16, 8]               0
          Conv2d-497          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-498           [-1, 512, 16, 8]           1,024
     BatchNorm2d-499           [-1, 512, 16, 8]           1,024
             IBN-500          [-1, 1024, 16, 8]               0
            ReLU-501          [-1, 1024, 16, 8]               0
          Conv2d-502          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-503          [-1, 1024, 16, 8]           2,048
            ReLU-504          [-1, 1024, 16, 8]               0
          Conv2d-505          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-506          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-507           [-1, 1024, 1, 1]               0
          Linear-508                   [-1, 64]          65,536
            ReLU-509                   [-1, 64]               0
          Linear-510                 [-1, 1024]          65,536
         Sigmoid-511                 [-1, 1024]               0
         SELayer-512          [-1, 1024, 16, 8]               0
            ReLU-513          [-1, 1024, 16, 8]               0
      Bottleneck-514          [-1, 1024, 16, 8]               0
          Conv2d-515          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-516           [-1, 512, 16, 8]           1,024
     BatchNorm2d-517           [-1, 512, 16, 8]           1,024
             IBN-518          [-1, 1024, 16, 8]               0
            ReLU-519          [-1, 1024, 16, 8]               0
          Conv2d-520          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-521          [-1, 1024, 16, 8]           2,048
            ReLU-522          [-1, 1024, 16, 8]               0
          Conv2d-523          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-524          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-525           [-1, 1024, 1, 1]               0
          Linear-526                   [-1, 64]          65,536
            ReLU-527                   [-1, 64]               0
          Linear-528                 [-1, 1024]          65,536
         Sigmoid-529                 [-1, 1024]               0
         SELayer-530          [-1, 1024, 16, 8]               0
            ReLU-531          [-1, 1024, 16, 8]               0
      Bottleneck-532          [-1, 1024, 16, 8]               0
          Conv2d-533          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-534           [-1, 512, 16, 8]           1,024
     BatchNorm2d-535           [-1, 512, 16, 8]           1,024
             IBN-536          [-1, 1024, 16, 8]               0
            ReLU-537          [-1, 1024, 16, 8]               0
          Conv2d-538          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-539          [-1, 1024, 16, 8]           2,048
            ReLU-540          [-1, 1024, 16, 8]               0
          Conv2d-541          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-542          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-543           [-1, 1024, 1, 1]               0
          Linear-544                   [-1, 64]          65,536
            ReLU-545                   [-1, 64]               0
          Linear-546                 [-1, 1024]          65,536
         Sigmoid-547                 [-1, 1024]               0
         SELayer-548          [-1, 1024, 16, 8]               0
            ReLU-549          [-1, 1024, 16, 8]               0
      Bottleneck-550          [-1, 1024, 16, 8]               0
          Conv2d-551          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-552          [-1, 2048, 16, 8]           4,096
            ReLU-553          [-1, 2048, 16, 8]               0
          Conv2d-554          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-555          [-1, 2048, 16, 8]           4,096
            ReLU-556          [-1, 2048, 16, 8]               0
          Conv2d-557          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-558          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-559           [-1, 2048, 1, 1]               0
          Linear-560                  [-1, 128]         262,144
            ReLU-561                  [-1, 128]               0
          Linear-562                 [-1, 2048]         262,144
         Sigmoid-563                 [-1, 2048]               0
         SELayer-564          [-1, 2048, 16, 8]               0
          Conv2d-565          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-566          [-1, 2048, 16, 8]           4,096
            ReLU-567          [-1, 2048, 16, 8]               0
      Bottleneck-568          [-1, 2048, 16, 8]               0
          Conv2d-569          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-570          [-1, 2048, 16, 8]           4,096
            ReLU-571          [-1, 2048, 16, 8]               0
          Conv2d-572          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-573          [-1, 2048, 16, 8]           4,096
            ReLU-574          [-1, 2048, 16, 8]               0
          Conv2d-575          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-576          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-577           [-1, 2048, 1, 1]               0
          Linear-578                  [-1, 128]         262,144
            ReLU-579                  [-1, 128]               0
          Linear-580                 [-1, 2048]         262,144
         Sigmoid-581                 [-1, 2048]               0
         SELayer-582          [-1, 2048, 16, 8]               0
            ReLU-583          [-1, 2048, 16, 8]               0
      Bottleneck-584          [-1, 2048, 16, 8]               0
          Conv2d-585          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-586          [-1, 2048, 16, 8]           4,096
            ReLU-587          [-1, 2048, 16, 8]               0
          Conv2d-588          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-589          [-1, 2048, 16, 8]           4,096
            ReLU-590          [-1, 2048, 16, 8]               0
          Conv2d-591          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-592          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-593           [-1, 2048, 1, 1]               0
          Linear-594                  [-1, 128]         262,144
            ReLU-595                  [-1, 128]               0
          Linear-596                 [-1, 2048]         262,144
         Sigmoid-597                 [-1, 2048]               0
         SELayer-598          [-1, 2048, 16, 8]               0
            ReLU-599          [-1, 2048, 16, 8]               0
      Bottleneck-600          [-1, 2048, 16, 8]               0
================================================================
Total params: 91,485,504
Trainable params: 91,485,504
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 649.78
Params size (MB): 348.99
Estimated Total Size (MB): 999.14
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnext101_32x8d_se_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 256, 64, 32]          16,384
       BatchNorm2d-6          [-1, 256, 64, 32]             512
              ReLU-7          [-1, 256, 64, 32]               0
            Conv2d-8          [-1, 256, 64, 32]          18,432
       BatchNorm2d-9          [-1, 256, 64, 32]             512
             ReLU-10          [-1, 256, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          65,536
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
   InstanceNorm2d-21          [-1, 256, 64, 32]             512
             ReLU-22          [-1, 256, 64, 32]               0
       Bottleneck-23          [-1, 256, 64, 32]               0
           Conv2d-24          [-1, 256, 64, 32]          65,536
      BatchNorm2d-25          [-1, 256, 64, 32]             512
             ReLU-26          [-1, 256, 64, 32]               0
           Conv2d-27          [-1, 256, 64, 32]          18,432
      BatchNorm2d-28          [-1, 256, 64, 32]             512
             ReLU-29          [-1, 256, 64, 32]               0
           Conv2d-30          [-1, 256, 64, 32]          65,536
      BatchNorm2d-31          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-32            [-1, 256, 1, 1]               0
           Linear-33                   [-1, 16]           4,096
             ReLU-34                   [-1, 16]               0
           Linear-35                  [-1, 256]           4,096
          Sigmoid-36                  [-1, 256]               0
          SELayer-37          [-1, 256, 64, 32]               0
   InstanceNorm2d-38          [-1, 256, 64, 32]             512
             ReLU-39          [-1, 256, 64, 32]               0
       Bottleneck-40          [-1, 256, 64, 32]               0
           Conv2d-41          [-1, 256, 64, 32]          65,536
      BatchNorm2d-42          [-1, 256, 64, 32]             512
             ReLU-43          [-1, 256, 64, 32]               0
           Conv2d-44          [-1, 256, 64, 32]          18,432
      BatchNorm2d-45          [-1, 256, 64, 32]             512
             ReLU-46          [-1, 256, 64, 32]               0
           Conv2d-47          [-1, 256, 64, 32]          65,536
      BatchNorm2d-48          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-49            [-1, 256, 1, 1]               0
           Linear-50                   [-1, 16]           4,096
             ReLU-51                   [-1, 16]               0
           Linear-52                  [-1, 256]           4,096
          Sigmoid-53                  [-1, 256]               0
          SELayer-54          [-1, 256, 64, 32]               0
   InstanceNorm2d-55          [-1, 256, 64, 32]             512
             ReLU-56          [-1, 256, 64, 32]               0
       Bottleneck-57          [-1, 256, 64, 32]               0
           Conv2d-58          [-1, 512, 64, 32]         131,072
      BatchNorm2d-59          [-1, 512, 64, 32]           1,024
             ReLU-60          [-1, 512, 64, 32]               0
           Conv2d-61          [-1, 512, 32, 16]          73,728
      BatchNorm2d-62          [-1, 512, 32, 16]           1,024
             ReLU-63          [-1, 512, 32, 16]               0
           Conv2d-64          [-1, 512, 32, 16]         262,144
      BatchNorm2d-65          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-66            [-1, 512, 1, 1]               0
           Linear-67                   [-1, 32]          16,384
             ReLU-68                   [-1, 32]               0
           Linear-69                  [-1, 512]          16,384
          Sigmoid-70                  [-1, 512]               0
          SELayer-71          [-1, 512, 32, 16]               0
           Conv2d-72          [-1, 512, 32, 16]         131,072
      BatchNorm2d-73          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-74          [-1, 512, 32, 16]           1,024
             ReLU-75          [-1, 512, 32, 16]               0
       Bottleneck-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         262,144
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
           Conv2d-80          [-1, 512, 32, 16]          73,728
      BatchNorm2d-81          [-1, 512, 32, 16]           1,024
             ReLU-82          [-1, 512, 32, 16]               0
           Conv2d-83          [-1, 512, 32, 16]         262,144
      BatchNorm2d-84          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-85            [-1, 512, 1, 1]               0
           Linear-86                   [-1, 32]          16,384
             ReLU-87                   [-1, 32]               0
           Linear-88                  [-1, 512]          16,384
          Sigmoid-89                  [-1, 512]               0
          SELayer-90          [-1, 512, 32, 16]               0
   InstanceNorm2d-91          [-1, 512, 32, 16]           1,024
             ReLU-92          [-1, 512, 32, 16]               0
       Bottleneck-93          [-1, 512, 32, 16]               0
           Conv2d-94          [-1, 512, 32, 16]         262,144
      BatchNorm2d-95          [-1, 512, 32, 16]           1,024
             ReLU-96          [-1, 512, 32, 16]               0
           Conv2d-97          [-1, 512, 32, 16]          73,728
      BatchNorm2d-98          [-1, 512, 32, 16]           1,024
             ReLU-99          [-1, 512, 32, 16]               0
          Conv2d-100          [-1, 512, 32, 16]         262,144
     BatchNorm2d-101          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-102            [-1, 512, 1, 1]               0
          Linear-103                   [-1, 32]          16,384
            ReLU-104                   [-1, 32]               0
          Linear-105                  [-1, 512]          16,384
         Sigmoid-106                  [-1, 512]               0
         SELayer-107          [-1, 512, 32, 16]               0
  InstanceNorm2d-108          [-1, 512, 32, 16]           1,024
            ReLU-109          [-1, 512, 32, 16]               0
      Bottleneck-110          [-1, 512, 32, 16]               0
          Conv2d-111          [-1, 512, 32, 16]         262,144
     BatchNorm2d-112          [-1, 512, 32, 16]           1,024
            ReLU-113          [-1, 512, 32, 16]               0
          Conv2d-114          [-1, 512, 32, 16]          73,728
     BatchNorm2d-115          [-1, 512, 32, 16]           1,024
            ReLU-116          [-1, 512, 32, 16]               0
          Conv2d-117          [-1, 512, 32, 16]         262,144
     BatchNorm2d-118          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-119            [-1, 512, 1, 1]               0
          Linear-120                   [-1, 32]          16,384
            ReLU-121                   [-1, 32]               0
          Linear-122                  [-1, 512]          16,384
         Sigmoid-123                  [-1, 512]               0
         SELayer-124          [-1, 512, 32, 16]               0
  InstanceNorm2d-125          [-1, 512, 32, 16]           1,024
            ReLU-126          [-1, 512, 32, 16]               0
      Bottleneck-127          [-1, 512, 32, 16]               0
          Conv2d-128         [-1, 1024, 32, 16]         524,288
     BatchNorm2d-129         [-1, 1024, 32, 16]           2,048
            ReLU-130         [-1, 1024, 32, 16]               0
          Conv2d-131          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-132          [-1, 1024, 16, 8]           2,048
            ReLU-133          [-1, 1024, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-136           [-1, 1024, 1, 1]               0
          Linear-137                   [-1, 64]          65,536
            ReLU-138                   [-1, 64]               0
          Linear-139                 [-1, 1024]          65,536
         Sigmoid-140                 [-1, 1024]               0
         SELayer-141          [-1, 1024, 16, 8]               0
          Conv2d-142          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-143          [-1, 1024, 16, 8]           2,048
            ReLU-144          [-1, 1024, 16, 8]               0
      Bottleneck-145          [-1, 1024, 16, 8]               0
          Conv2d-146          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-147          [-1, 1024, 16, 8]           2,048
            ReLU-148          [-1, 1024, 16, 8]               0
          Conv2d-149          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-150          [-1, 1024, 16, 8]           2,048
            ReLU-151          [-1, 1024, 16, 8]               0
          Conv2d-152          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-153          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-154           [-1, 1024, 1, 1]               0
          Linear-155                   [-1, 64]          65,536
            ReLU-156                   [-1, 64]               0
          Linear-157                 [-1, 1024]          65,536
         Sigmoid-158                 [-1, 1024]               0
         SELayer-159          [-1, 1024, 16, 8]               0
            ReLU-160          [-1, 1024, 16, 8]               0
      Bottleneck-161          [-1, 1024, 16, 8]               0
          Conv2d-162          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-163          [-1, 1024, 16, 8]           2,048
            ReLU-164          [-1, 1024, 16, 8]               0
          Conv2d-165          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-166          [-1, 1024, 16, 8]           2,048
            ReLU-167          [-1, 1024, 16, 8]               0
          Conv2d-168          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-169          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-170           [-1, 1024, 1, 1]               0
          Linear-171                   [-1, 64]          65,536
            ReLU-172                   [-1, 64]               0
          Linear-173                 [-1, 1024]          65,536
         Sigmoid-174                 [-1, 1024]               0
         SELayer-175          [-1, 1024, 16, 8]               0
            ReLU-176          [-1, 1024, 16, 8]               0
      Bottleneck-177          [-1, 1024, 16, 8]               0
          Conv2d-178          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-179          [-1, 1024, 16, 8]           2,048
            ReLU-180          [-1, 1024, 16, 8]               0
          Conv2d-181          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-182          [-1, 1024, 16, 8]           2,048
            ReLU-183          [-1, 1024, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-186           [-1, 1024, 1, 1]               0
          Linear-187                   [-1, 64]          65,536
            ReLU-188                   [-1, 64]               0
          Linear-189                 [-1, 1024]          65,536
         Sigmoid-190                 [-1, 1024]               0
         SELayer-191          [-1, 1024, 16, 8]               0
            ReLU-192          [-1, 1024, 16, 8]               0
      Bottleneck-193          [-1, 1024, 16, 8]               0
          Conv2d-194          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-195          [-1, 1024, 16, 8]           2,048
            ReLU-196          [-1, 1024, 16, 8]               0
          Conv2d-197          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-198          [-1, 1024, 16, 8]           2,048
            ReLU-199          [-1, 1024, 16, 8]               0
          Conv2d-200          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-201          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-202           [-1, 1024, 1, 1]               0
          Linear-203                   [-1, 64]          65,536
            ReLU-204                   [-1, 64]               0
          Linear-205                 [-1, 1024]          65,536
         Sigmoid-206                 [-1, 1024]               0
         SELayer-207          [-1, 1024, 16, 8]               0
            ReLU-208          [-1, 1024, 16, 8]               0
      Bottleneck-209          [-1, 1024, 16, 8]               0
          Conv2d-210          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-211          [-1, 1024, 16, 8]           2,048
            ReLU-212          [-1, 1024, 16, 8]               0
          Conv2d-213          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-214          [-1, 1024, 16, 8]           2,048
            ReLU-215          [-1, 1024, 16, 8]               0
          Conv2d-216          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-217          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-218           [-1, 1024, 1, 1]               0
          Linear-219                   [-1, 64]          65,536
            ReLU-220                   [-1, 64]               0
          Linear-221                 [-1, 1024]          65,536
         Sigmoid-222                 [-1, 1024]               0
         SELayer-223          [-1, 1024, 16, 8]               0
            ReLU-224          [-1, 1024, 16, 8]               0
      Bottleneck-225          [-1, 1024, 16, 8]               0
          Conv2d-226          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-227          [-1, 1024, 16, 8]           2,048
            ReLU-228          [-1, 1024, 16, 8]               0
          Conv2d-229          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-230          [-1, 1024, 16, 8]           2,048
            ReLU-231          [-1, 1024, 16, 8]               0
          Conv2d-232          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-233          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-234           [-1, 1024, 1, 1]               0
          Linear-235                   [-1, 64]          65,536
            ReLU-236                   [-1, 64]               0
          Linear-237                 [-1, 1024]          65,536
         Sigmoid-238                 [-1, 1024]               0
         SELayer-239          [-1, 1024, 16, 8]               0
            ReLU-240          [-1, 1024, 16, 8]               0
      Bottleneck-241          [-1, 1024, 16, 8]               0
          Conv2d-242          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-243          [-1, 1024, 16, 8]           2,048
            ReLU-244          [-1, 1024, 16, 8]               0
          Conv2d-245          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-246          [-1, 1024, 16, 8]           2,048
            ReLU-247          [-1, 1024, 16, 8]               0
          Conv2d-248          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-249          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-250           [-1, 1024, 1, 1]               0
          Linear-251                   [-1, 64]          65,536
            ReLU-252                   [-1, 64]               0
          Linear-253                 [-1, 1024]          65,536
         Sigmoid-254                 [-1, 1024]               0
         SELayer-255          [-1, 1024, 16, 8]               0
            ReLU-256          [-1, 1024, 16, 8]               0
      Bottleneck-257          [-1, 1024, 16, 8]               0
          Conv2d-258          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-259          [-1, 1024, 16, 8]           2,048
            ReLU-260          [-1, 1024, 16, 8]               0
          Conv2d-261          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-262          [-1, 1024, 16, 8]           2,048
            ReLU-263          [-1, 1024, 16, 8]               0
          Conv2d-264          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-265          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-266           [-1, 1024, 1, 1]               0
          Linear-267                   [-1, 64]          65,536
            ReLU-268                   [-1, 64]               0
          Linear-269                 [-1, 1024]          65,536
         Sigmoid-270                 [-1, 1024]               0
         SELayer-271          [-1, 1024, 16, 8]               0
            ReLU-272          [-1, 1024, 16, 8]               0
      Bottleneck-273          [-1, 1024, 16, 8]               0
          Conv2d-274          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-275          [-1, 1024, 16, 8]           2,048
            ReLU-276          [-1, 1024, 16, 8]               0
          Conv2d-277          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-278          [-1, 1024, 16, 8]           2,048
            ReLU-279          [-1, 1024, 16, 8]               0
          Conv2d-280          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-281          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-282           [-1, 1024, 1, 1]               0
          Linear-283                   [-1, 64]          65,536
            ReLU-284                   [-1, 64]               0
          Linear-285                 [-1, 1024]          65,536
         Sigmoid-286                 [-1, 1024]               0
         SELayer-287          [-1, 1024, 16, 8]               0
            ReLU-288          [-1, 1024, 16, 8]               0
      Bottleneck-289          [-1, 1024, 16, 8]               0
          Conv2d-290          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-291          [-1, 1024, 16, 8]           2,048
            ReLU-292          [-1, 1024, 16, 8]               0
          Conv2d-293          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-294          [-1, 1024, 16, 8]           2,048
            ReLU-295          [-1, 1024, 16, 8]               0
          Conv2d-296          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-297          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-298           [-1, 1024, 1, 1]               0
          Linear-299                   [-1, 64]          65,536
            ReLU-300                   [-1, 64]               0
          Linear-301                 [-1, 1024]          65,536
         Sigmoid-302                 [-1, 1024]               0
         SELayer-303          [-1, 1024, 16, 8]               0
            ReLU-304          [-1, 1024, 16, 8]               0
      Bottleneck-305          [-1, 1024, 16, 8]               0
          Conv2d-306          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-307          [-1, 1024, 16, 8]           2,048
            ReLU-308          [-1, 1024, 16, 8]               0
          Conv2d-309          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-310          [-1, 1024, 16, 8]           2,048
            ReLU-311          [-1, 1024, 16, 8]               0
          Conv2d-312          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-313          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-314           [-1, 1024, 1, 1]               0
          Linear-315                   [-1, 64]          65,536
            ReLU-316                   [-1, 64]               0
          Linear-317                 [-1, 1024]          65,536
         Sigmoid-318                 [-1, 1024]               0
         SELayer-319          [-1, 1024, 16, 8]               0
            ReLU-320          [-1, 1024, 16, 8]               0
      Bottleneck-321          [-1, 1024, 16, 8]               0
          Conv2d-322          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-323          [-1, 1024, 16, 8]           2,048
            ReLU-324          [-1, 1024, 16, 8]               0
          Conv2d-325          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-326          [-1, 1024, 16, 8]           2,048
            ReLU-327          [-1, 1024, 16, 8]               0
          Conv2d-328          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-329          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-330           [-1, 1024, 1, 1]               0
          Linear-331                   [-1, 64]          65,536
            ReLU-332                   [-1, 64]               0
          Linear-333                 [-1, 1024]          65,536
         Sigmoid-334                 [-1, 1024]               0
         SELayer-335          [-1, 1024, 16, 8]               0
            ReLU-336          [-1, 1024, 16, 8]               0
      Bottleneck-337          [-1, 1024, 16, 8]               0
          Conv2d-338          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-339          [-1, 1024, 16, 8]           2,048
            ReLU-340          [-1, 1024, 16, 8]               0
          Conv2d-341          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-342          [-1, 1024, 16, 8]           2,048
            ReLU-343          [-1, 1024, 16, 8]               0
          Conv2d-344          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-345          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-346           [-1, 1024, 1, 1]               0
          Linear-347                   [-1, 64]          65,536
            ReLU-348                   [-1, 64]               0
          Linear-349                 [-1, 1024]          65,536
         Sigmoid-350                 [-1, 1024]               0
         SELayer-351          [-1, 1024, 16, 8]               0
            ReLU-352          [-1, 1024, 16, 8]               0
      Bottleneck-353          [-1, 1024, 16, 8]               0
          Conv2d-354          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-355          [-1, 1024, 16, 8]           2,048
            ReLU-356          [-1, 1024, 16, 8]               0
          Conv2d-357          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-358          [-1, 1024, 16, 8]           2,048
            ReLU-359          [-1, 1024, 16, 8]               0
          Conv2d-360          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-361          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-362           [-1, 1024, 1, 1]               0
          Linear-363                   [-1, 64]          65,536
            ReLU-364                   [-1, 64]               0
          Linear-365                 [-1, 1024]          65,536
         Sigmoid-366                 [-1, 1024]               0
         SELayer-367          [-1, 1024, 16, 8]               0
            ReLU-368          [-1, 1024, 16, 8]               0
      Bottleneck-369          [-1, 1024, 16, 8]               0
          Conv2d-370          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-371          [-1, 1024, 16, 8]           2,048
            ReLU-372          [-1, 1024, 16, 8]               0
          Conv2d-373          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-374          [-1, 1024, 16, 8]           2,048
            ReLU-375          [-1, 1024, 16, 8]               0
          Conv2d-376          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-377          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-378           [-1, 1024, 1, 1]               0
          Linear-379                   [-1, 64]          65,536
            ReLU-380                   [-1, 64]               0
          Linear-381                 [-1, 1024]          65,536
         Sigmoid-382                 [-1, 1024]               0
         SELayer-383          [-1, 1024, 16, 8]               0
            ReLU-384          [-1, 1024, 16, 8]               0
      Bottleneck-385          [-1, 1024, 16, 8]               0
          Conv2d-386          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-387          [-1, 1024, 16, 8]           2,048
            ReLU-388          [-1, 1024, 16, 8]               0
          Conv2d-389          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-390          [-1, 1024, 16, 8]           2,048
            ReLU-391          [-1, 1024, 16, 8]               0
          Conv2d-392          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-393          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-394           [-1, 1024, 1, 1]               0
          Linear-395                   [-1, 64]          65,536
            ReLU-396                   [-1, 64]               0
          Linear-397                 [-1, 1024]          65,536
         Sigmoid-398                 [-1, 1024]               0
         SELayer-399          [-1, 1024, 16, 8]               0
            ReLU-400          [-1, 1024, 16, 8]               0
      Bottleneck-401          [-1, 1024, 16, 8]               0
          Conv2d-402          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-403          [-1, 1024, 16, 8]           2,048
            ReLU-404          [-1, 1024, 16, 8]               0
          Conv2d-405          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-406          [-1, 1024, 16, 8]           2,048
            ReLU-407          [-1, 1024, 16, 8]               0
          Conv2d-408          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-409          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-410           [-1, 1024, 1, 1]               0
          Linear-411                   [-1, 64]          65,536
            ReLU-412                   [-1, 64]               0
          Linear-413                 [-1, 1024]          65,536
         Sigmoid-414                 [-1, 1024]               0
         SELayer-415          [-1, 1024, 16, 8]               0
            ReLU-416          [-1, 1024, 16, 8]               0
      Bottleneck-417          [-1, 1024, 16, 8]               0
          Conv2d-418          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-419          [-1, 1024, 16, 8]           2,048
            ReLU-420          [-1, 1024, 16, 8]               0
          Conv2d-421          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-422          [-1, 1024, 16, 8]           2,048
            ReLU-423          [-1, 1024, 16, 8]               0
          Conv2d-424          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-425          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-426           [-1, 1024, 1, 1]               0
          Linear-427                   [-1, 64]          65,536
            ReLU-428                   [-1, 64]               0
          Linear-429                 [-1, 1024]          65,536
         Sigmoid-430                 [-1, 1024]               0
         SELayer-431          [-1, 1024, 16, 8]               0
            ReLU-432          [-1, 1024, 16, 8]               0
      Bottleneck-433          [-1, 1024, 16, 8]               0
          Conv2d-434          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-435          [-1, 1024, 16, 8]           2,048
            ReLU-436          [-1, 1024, 16, 8]               0
          Conv2d-437          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-438          [-1, 1024, 16, 8]           2,048
            ReLU-439          [-1, 1024, 16, 8]               0
          Conv2d-440          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-441          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-442           [-1, 1024, 1, 1]               0
          Linear-443                   [-1, 64]          65,536
            ReLU-444                   [-1, 64]               0
          Linear-445                 [-1, 1024]          65,536
         Sigmoid-446                 [-1, 1024]               0
         SELayer-447          [-1, 1024, 16, 8]               0
            ReLU-448          [-1, 1024, 16, 8]               0
      Bottleneck-449          [-1, 1024, 16, 8]               0
          Conv2d-450          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-451          [-1, 1024, 16, 8]           2,048
            ReLU-452          [-1, 1024, 16, 8]               0
          Conv2d-453          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-454          [-1, 1024, 16, 8]           2,048
            ReLU-455          [-1, 1024, 16, 8]               0
          Conv2d-456          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-457          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-458           [-1, 1024, 1, 1]               0
          Linear-459                   [-1, 64]          65,536
            ReLU-460                   [-1, 64]               0
          Linear-461                 [-1, 1024]          65,536
         Sigmoid-462                 [-1, 1024]               0
         SELayer-463          [-1, 1024, 16, 8]               0
            ReLU-464          [-1, 1024, 16, 8]               0
      Bottleneck-465          [-1, 1024, 16, 8]               0
          Conv2d-466          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-467          [-1, 1024, 16, 8]           2,048
            ReLU-468          [-1, 1024, 16, 8]               0
          Conv2d-469          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-470          [-1, 1024, 16, 8]           2,048
            ReLU-471          [-1, 1024, 16, 8]               0
          Conv2d-472          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-473          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-474           [-1, 1024, 1, 1]               0
          Linear-475                   [-1, 64]          65,536
            ReLU-476                   [-1, 64]               0
          Linear-477                 [-1, 1024]          65,536
         Sigmoid-478                 [-1, 1024]               0
         SELayer-479          [-1, 1024, 16, 8]               0
            ReLU-480          [-1, 1024, 16, 8]               0
      Bottleneck-481          [-1, 1024, 16, 8]               0
          Conv2d-482          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-483          [-1, 1024, 16, 8]           2,048
            ReLU-484          [-1, 1024, 16, 8]               0
          Conv2d-485          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-486          [-1, 1024, 16, 8]           2,048
            ReLU-487          [-1, 1024, 16, 8]               0
          Conv2d-488          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-489          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-490           [-1, 1024, 1, 1]               0
          Linear-491                   [-1, 64]          65,536
            ReLU-492                   [-1, 64]               0
          Linear-493                 [-1, 1024]          65,536
         Sigmoid-494                 [-1, 1024]               0
         SELayer-495          [-1, 1024, 16, 8]               0
            ReLU-496          [-1, 1024, 16, 8]               0
      Bottleneck-497          [-1, 1024, 16, 8]               0
          Conv2d-498          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-499          [-1, 2048, 16, 8]           4,096
            ReLU-500          [-1, 2048, 16, 8]               0
          Conv2d-501          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-502          [-1, 2048, 16, 8]           4,096
            ReLU-503          [-1, 2048, 16, 8]               0
          Conv2d-504          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-505          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-506           [-1, 2048, 1, 1]               0
          Linear-507                  [-1, 128]         262,144
            ReLU-508                  [-1, 128]               0
          Linear-509                 [-1, 2048]         262,144
         Sigmoid-510                 [-1, 2048]               0
         SELayer-511          [-1, 2048, 16, 8]               0
          Conv2d-512          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-513          [-1, 2048, 16, 8]           4,096
            ReLU-514          [-1, 2048, 16, 8]               0
      Bottleneck-515          [-1, 2048, 16, 8]               0
          Conv2d-516          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-517          [-1, 2048, 16, 8]           4,096
            ReLU-518          [-1, 2048, 16, 8]               0
          Conv2d-519          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-520          [-1, 2048, 16, 8]           4,096
            ReLU-521          [-1, 2048, 16, 8]               0
          Conv2d-522          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-523          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-524           [-1, 2048, 1, 1]               0
          Linear-525                  [-1, 128]         262,144
            ReLU-526                  [-1, 128]               0
          Linear-527                 [-1, 2048]         262,144
         Sigmoid-528                 [-1, 2048]               0
         SELayer-529          [-1, 2048, 16, 8]               0
            ReLU-530          [-1, 2048, 16, 8]               0
      Bottleneck-531          [-1, 2048, 16, 8]               0
          Conv2d-532          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-533          [-1, 2048, 16, 8]           4,096
            ReLU-534          [-1, 2048, 16, 8]               0
          Conv2d-535          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-536          [-1, 2048, 16, 8]           4,096
            ReLU-537          [-1, 2048, 16, 8]               0
          Conv2d-538          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-539          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-540           [-1, 2048, 1, 1]               0
          Linear-541                  [-1, 128]         262,144
            ReLU-542                  [-1, 128]               0
          Linear-543                 [-1, 2048]         262,144
         Sigmoid-544                 [-1, 2048]               0
         SELayer-545          [-1, 2048, 16, 8]               0
            ReLU-546          [-1, 2048, 16, 8]               0
      Bottleneck-547          [-1, 2048, 16, 8]               0
================================================================
Total params: 91,491,136
Trainable params: 91,491,136
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 617.78
Params size (MB): 349.01
Estimated Total Size (MB): 967.16
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnext101_32x8d_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 256, 64, 32]          16,384
    InstanceNorm2d-6          [-1, 128, 64, 32]             256
       BatchNorm2d-7          [-1, 128, 64, 32]             256
               IBN-8          [-1, 256, 64, 32]               0
              ReLU-9          [-1, 256, 64, 32]               0
           Conv2d-10          [-1, 256, 64, 32]          18,432
      BatchNorm2d-11          [-1, 256, 64, 32]             512
             ReLU-12          [-1, 256, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          65,536
      BatchNorm2d-14          [-1, 256, 64, 32]             512
           Conv2d-15          [-1, 256, 64, 32]          16,384
      BatchNorm2d-16          [-1, 256, 64, 32]             512
             ReLU-17          [-1, 256, 64, 32]               0
       Bottleneck-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          65,536
   InstanceNorm2d-20          [-1, 128, 64, 32]             256
      BatchNorm2d-21          [-1, 128, 64, 32]             256
              IBN-22          [-1, 256, 64, 32]               0
             ReLU-23          [-1, 256, 64, 32]               0
           Conv2d-24          [-1, 256, 64, 32]          18,432
      BatchNorm2d-25          [-1, 256, 64, 32]             512
             ReLU-26          [-1, 256, 64, 32]               0
           Conv2d-27          [-1, 256, 64, 32]          65,536
      BatchNorm2d-28          [-1, 256, 64, 32]             512
             ReLU-29          [-1, 256, 64, 32]               0
       Bottleneck-30          [-1, 256, 64, 32]               0
           Conv2d-31          [-1, 256, 64, 32]          65,536
   InstanceNorm2d-32          [-1, 128, 64, 32]             256
      BatchNorm2d-33          [-1, 128, 64, 32]             256
              IBN-34          [-1, 256, 64, 32]               0
             ReLU-35          [-1, 256, 64, 32]               0
           Conv2d-36          [-1, 256, 64, 32]          18,432
      BatchNorm2d-37          [-1, 256, 64, 32]             512
             ReLU-38          [-1, 256, 64, 32]               0
           Conv2d-39          [-1, 256, 64, 32]          65,536
      BatchNorm2d-40          [-1, 256, 64, 32]             512
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 512, 64, 32]         131,072
   InstanceNorm2d-44          [-1, 256, 64, 32]             512
      BatchNorm2d-45          [-1, 256, 64, 32]             512
              IBN-46          [-1, 512, 64, 32]               0
             ReLU-47          [-1, 512, 64, 32]               0
           Conv2d-48          [-1, 512, 32, 16]          73,728
      BatchNorm2d-49          [-1, 512, 32, 16]           1,024
             ReLU-50          [-1, 512, 32, 16]               0
           Conv2d-51          [-1, 512, 32, 16]         262,144
      BatchNorm2d-52          [-1, 512, 32, 16]           1,024
           Conv2d-53          [-1, 512, 32, 16]         131,072
      BatchNorm2d-54          [-1, 512, 32, 16]           1,024
             ReLU-55          [-1, 512, 32, 16]               0
       Bottleneck-56          [-1, 512, 32, 16]               0
           Conv2d-57          [-1, 512, 32, 16]         262,144
   InstanceNorm2d-58          [-1, 256, 32, 16]             512
      BatchNorm2d-59          [-1, 256, 32, 16]             512
              IBN-60          [-1, 512, 32, 16]               0
             ReLU-61          [-1, 512, 32, 16]               0
           Conv2d-62          [-1, 512, 32, 16]          73,728
      BatchNorm2d-63          [-1, 512, 32, 16]           1,024
             ReLU-64          [-1, 512, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]         262,144
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         262,144
   InstanceNorm2d-70          [-1, 256, 32, 16]             512
      BatchNorm2d-71          [-1, 256, 32, 16]             512
              IBN-72          [-1, 512, 32, 16]               0
             ReLU-73          [-1, 512, 32, 16]               0
           Conv2d-74          [-1, 512, 32, 16]          73,728
      BatchNorm2d-75          [-1, 512, 32, 16]           1,024
             ReLU-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         262,144
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 512, 32, 16]         262,144
   InstanceNorm2d-82          [-1, 256, 32, 16]             512
      BatchNorm2d-83          [-1, 256, 32, 16]             512
              IBN-84          [-1, 512, 32, 16]               0
             ReLU-85          [-1, 512, 32, 16]               0
           Conv2d-86          [-1, 512, 32, 16]          73,728
      BatchNorm2d-87          [-1, 512, 32, 16]           1,024
             ReLU-88          [-1, 512, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]         262,144
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
             ReLU-91          [-1, 512, 32, 16]               0
       Bottleneck-92          [-1, 512, 32, 16]               0
           Conv2d-93         [-1, 1024, 32, 16]         524,288
   InstanceNorm2d-94          [-1, 512, 32, 16]           1,024
      BatchNorm2d-95          [-1, 512, 32, 16]           1,024
              IBN-96         [-1, 1024, 32, 16]               0
             ReLU-97         [-1, 1024, 32, 16]               0
           Conv2d-98          [-1, 1024, 16, 8]         294,912
      BatchNorm2d-99          [-1, 1024, 16, 8]           2,048
            ReLU-100          [-1, 1024, 16, 8]               0
          Conv2d-101          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-102          [-1, 1024, 16, 8]           2,048
          Conv2d-103          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-104          [-1, 1024, 16, 8]           2,048
            ReLU-105          [-1, 1024, 16, 8]               0
      Bottleneck-106          [-1, 1024, 16, 8]               0
          Conv2d-107          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-108           [-1, 512, 16, 8]           1,024
     BatchNorm2d-109           [-1, 512, 16, 8]           1,024
             IBN-110          [-1, 1024, 16, 8]               0
            ReLU-111          [-1, 1024, 16, 8]               0
          Conv2d-112          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-113          [-1, 1024, 16, 8]           2,048
            ReLU-114          [-1, 1024, 16, 8]               0
          Conv2d-115          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-116          [-1, 1024, 16, 8]           2,048
            ReLU-117          [-1, 1024, 16, 8]               0
      Bottleneck-118          [-1, 1024, 16, 8]               0
          Conv2d-119          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-120           [-1, 512, 16, 8]           1,024
     BatchNorm2d-121           [-1, 512, 16, 8]           1,024
             IBN-122          [-1, 1024, 16, 8]               0
            ReLU-123          [-1, 1024, 16, 8]               0
          Conv2d-124          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-125          [-1, 1024, 16, 8]           2,048
            ReLU-126          [-1, 1024, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-132           [-1, 512, 16, 8]           1,024
     BatchNorm2d-133           [-1, 512, 16, 8]           1,024
             IBN-134          [-1, 1024, 16, 8]               0
            ReLU-135          [-1, 1024, 16, 8]               0
          Conv2d-136          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-137          [-1, 1024, 16, 8]           2,048
            ReLU-138          [-1, 1024, 16, 8]               0
          Conv2d-139          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-140          [-1, 1024, 16, 8]           2,048
            ReLU-141          [-1, 1024, 16, 8]               0
      Bottleneck-142          [-1, 1024, 16, 8]               0
          Conv2d-143          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-144           [-1, 512, 16, 8]           1,024
     BatchNorm2d-145           [-1, 512, 16, 8]           1,024
             IBN-146          [-1, 1024, 16, 8]               0
            ReLU-147          [-1, 1024, 16, 8]               0
          Conv2d-148          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-149          [-1, 1024, 16, 8]           2,048
            ReLU-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-156           [-1, 512, 16, 8]           1,024
     BatchNorm2d-157           [-1, 512, 16, 8]           1,024
             IBN-158          [-1, 1024, 16, 8]               0
            ReLU-159          [-1, 1024, 16, 8]               0
          Conv2d-160          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-161          [-1, 1024, 16, 8]           2,048
            ReLU-162          [-1, 1024, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
      Bottleneck-166          [-1, 1024, 16, 8]               0
          Conv2d-167          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-168           [-1, 512, 16, 8]           1,024
     BatchNorm2d-169           [-1, 512, 16, 8]           1,024
             IBN-170          [-1, 1024, 16, 8]               0
            ReLU-171          [-1, 1024, 16, 8]               0
          Conv2d-172          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-173          [-1, 1024, 16, 8]           2,048
            ReLU-174          [-1, 1024, 16, 8]               0
          Conv2d-175          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-176          [-1, 1024, 16, 8]           2,048
            ReLU-177          [-1, 1024, 16, 8]               0
      Bottleneck-178          [-1, 1024, 16, 8]               0
          Conv2d-179          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-180           [-1, 512, 16, 8]           1,024
     BatchNorm2d-181           [-1, 512, 16, 8]           1,024
             IBN-182          [-1, 1024, 16, 8]               0
            ReLU-183          [-1, 1024, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
            ReLU-186          [-1, 1024, 16, 8]               0
          Conv2d-187          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-188          [-1, 1024, 16, 8]           2,048
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-192           [-1, 512, 16, 8]           1,024
     BatchNorm2d-193           [-1, 512, 16, 8]           1,024
             IBN-194          [-1, 1024, 16, 8]               0
            ReLU-195          [-1, 1024, 16, 8]               0
          Conv2d-196          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-197          [-1, 1024, 16, 8]           2,048
            ReLU-198          [-1, 1024, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-204           [-1, 512, 16, 8]           1,024
     BatchNorm2d-205           [-1, 512, 16, 8]           1,024
             IBN-206          [-1, 1024, 16, 8]               0
            ReLU-207          [-1, 1024, 16, 8]               0
          Conv2d-208          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-209          [-1, 1024, 16, 8]           2,048
            ReLU-210          [-1, 1024, 16, 8]               0
          Conv2d-211          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-212          [-1, 1024, 16, 8]           2,048
            ReLU-213          [-1, 1024, 16, 8]               0
      Bottleneck-214          [-1, 1024, 16, 8]               0
          Conv2d-215          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-216           [-1, 512, 16, 8]           1,024
     BatchNorm2d-217           [-1, 512, 16, 8]           1,024
             IBN-218          [-1, 1024, 16, 8]               0
            ReLU-219          [-1, 1024, 16, 8]               0
          Conv2d-220          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-221          [-1, 1024, 16, 8]           2,048
            ReLU-222          [-1, 1024, 16, 8]               0
          Conv2d-223          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-224          [-1, 1024, 16, 8]           2,048
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-228           [-1, 512, 16, 8]           1,024
     BatchNorm2d-229           [-1, 512, 16, 8]           1,024
             IBN-230          [-1, 1024, 16, 8]               0
            ReLU-231          [-1, 1024, 16, 8]               0
          Conv2d-232          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-233          [-1, 1024, 16, 8]           2,048
            ReLU-234          [-1, 1024, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
            ReLU-237          [-1, 1024, 16, 8]               0
      Bottleneck-238          [-1, 1024, 16, 8]               0
          Conv2d-239          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-240           [-1, 512, 16, 8]           1,024
     BatchNorm2d-241           [-1, 512, 16, 8]           1,024
             IBN-242          [-1, 1024, 16, 8]               0
            ReLU-243          [-1, 1024, 16, 8]               0
          Conv2d-244          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-245          [-1, 1024, 16, 8]           2,048
            ReLU-246          [-1, 1024, 16, 8]               0
          Conv2d-247          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-248          [-1, 1024, 16, 8]           2,048
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-252           [-1, 512, 16, 8]           1,024
     BatchNorm2d-253           [-1, 512, 16, 8]           1,024
             IBN-254          [-1, 1024, 16, 8]               0
            ReLU-255          [-1, 1024, 16, 8]               0
          Conv2d-256          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-257          [-1, 1024, 16, 8]           2,048
            ReLU-258          [-1, 1024, 16, 8]               0
          Conv2d-259          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-260          [-1, 1024, 16, 8]           2,048
            ReLU-261          [-1, 1024, 16, 8]               0
      Bottleneck-262          [-1, 1024, 16, 8]               0
          Conv2d-263          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-264           [-1, 512, 16, 8]           1,024
     BatchNorm2d-265           [-1, 512, 16, 8]           1,024
             IBN-266          [-1, 1024, 16, 8]               0
            ReLU-267          [-1, 1024, 16, 8]               0
          Conv2d-268          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-269          [-1, 1024, 16, 8]           2,048
            ReLU-270          [-1, 1024, 16, 8]               0
          Conv2d-271          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-272          [-1, 1024, 16, 8]           2,048
            ReLU-273          [-1, 1024, 16, 8]               0
      Bottleneck-274          [-1, 1024, 16, 8]               0
          Conv2d-275          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-276           [-1, 512, 16, 8]           1,024
     BatchNorm2d-277           [-1, 512, 16, 8]           1,024
             IBN-278          [-1, 1024, 16, 8]               0
            ReLU-279          [-1, 1024, 16, 8]               0
          Conv2d-280          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-281          [-1, 1024, 16, 8]           2,048
            ReLU-282          [-1, 1024, 16, 8]               0
          Conv2d-283          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-284          [-1, 1024, 16, 8]           2,048
            ReLU-285          [-1, 1024, 16, 8]               0
      Bottleneck-286          [-1, 1024, 16, 8]               0
          Conv2d-287          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-288           [-1, 512, 16, 8]           1,024
     BatchNorm2d-289           [-1, 512, 16, 8]           1,024
             IBN-290          [-1, 1024, 16, 8]               0
            ReLU-291          [-1, 1024, 16, 8]               0
          Conv2d-292          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-293          [-1, 1024, 16, 8]           2,048
            ReLU-294          [-1, 1024, 16, 8]               0
          Conv2d-295          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-296          [-1, 1024, 16, 8]           2,048
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-300           [-1, 512, 16, 8]           1,024
     BatchNorm2d-301           [-1, 512, 16, 8]           1,024
             IBN-302          [-1, 1024, 16, 8]               0
            ReLU-303          [-1, 1024, 16, 8]               0
          Conv2d-304          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-305          [-1, 1024, 16, 8]           2,048
            ReLU-306          [-1, 1024, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
            ReLU-309          [-1, 1024, 16, 8]               0
      Bottleneck-310          [-1, 1024, 16, 8]               0
          Conv2d-311          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-312           [-1, 512, 16, 8]           1,024
     BatchNorm2d-313           [-1, 512, 16, 8]           1,024
             IBN-314          [-1, 1024, 16, 8]               0
            ReLU-315          [-1, 1024, 16, 8]               0
          Conv2d-316          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-317          [-1, 1024, 16, 8]           2,048
            ReLU-318          [-1, 1024, 16, 8]               0
          Conv2d-319          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-320          [-1, 1024, 16, 8]           2,048
            ReLU-321          [-1, 1024, 16, 8]               0
      Bottleneck-322          [-1, 1024, 16, 8]               0
          Conv2d-323          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-324           [-1, 512, 16, 8]           1,024
     BatchNorm2d-325           [-1, 512, 16, 8]           1,024
             IBN-326          [-1, 1024, 16, 8]               0
            ReLU-327          [-1, 1024, 16, 8]               0
          Conv2d-328          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-329          [-1, 1024, 16, 8]           2,048
            ReLU-330          [-1, 1024, 16, 8]               0
          Conv2d-331          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-332          [-1, 1024, 16, 8]           2,048
            ReLU-333          [-1, 1024, 16, 8]               0
      Bottleneck-334          [-1, 1024, 16, 8]               0
          Conv2d-335          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-336           [-1, 512, 16, 8]           1,024
     BatchNorm2d-337           [-1, 512, 16, 8]           1,024
             IBN-338          [-1, 1024, 16, 8]               0
            ReLU-339          [-1, 1024, 16, 8]               0
          Conv2d-340          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-341          [-1, 1024, 16, 8]           2,048
            ReLU-342          [-1, 1024, 16, 8]               0
          Conv2d-343          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-344          [-1, 1024, 16, 8]           2,048
            ReLU-345          [-1, 1024, 16, 8]               0
      Bottleneck-346          [-1, 1024, 16, 8]               0
          Conv2d-347          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-348           [-1, 512, 16, 8]           1,024
     BatchNorm2d-349           [-1, 512, 16, 8]           1,024
             IBN-350          [-1, 1024, 16, 8]               0
            ReLU-351          [-1, 1024, 16, 8]               0
          Conv2d-352          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-353          [-1, 1024, 16, 8]           2,048
            ReLU-354          [-1, 1024, 16, 8]               0
          Conv2d-355          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-356          [-1, 1024, 16, 8]           2,048
            ReLU-357          [-1, 1024, 16, 8]               0
      Bottleneck-358          [-1, 1024, 16, 8]               0
          Conv2d-359          [-1, 1024, 16, 8]       1,048,576
  InstanceNorm2d-360           [-1, 512, 16, 8]           1,024
     BatchNorm2d-361           [-1, 512, 16, 8]           1,024
             IBN-362          [-1, 1024, 16, 8]               0
            ReLU-363          [-1, 1024, 16, 8]               0
          Conv2d-364          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-365          [-1, 1024, 16, 8]           2,048
            ReLU-366          [-1, 1024, 16, 8]               0
          Conv2d-367          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-368          [-1, 1024, 16, 8]           2,048
            ReLU-369          [-1, 1024, 16, 8]               0
      Bottleneck-370          [-1, 1024, 16, 8]               0
          Conv2d-371          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-372          [-1, 2048, 16, 8]           4,096
            ReLU-373          [-1, 2048, 16, 8]               0
          Conv2d-374          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-375          [-1, 2048, 16, 8]           4,096
            ReLU-376          [-1, 2048, 16, 8]               0
          Conv2d-377          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-378          [-1, 2048, 16, 8]           4,096
          Conv2d-379          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-380          [-1, 2048, 16, 8]           4,096
            ReLU-381          [-1, 2048, 16, 8]               0
      Bottleneck-382          [-1, 2048, 16, 8]               0
          Conv2d-383          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-384          [-1, 2048, 16, 8]           4,096
            ReLU-385          [-1, 2048, 16, 8]               0
          Conv2d-386          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-387          [-1, 2048, 16, 8]           4,096
            ReLU-388          [-1, 2048, 16, 8]               0
          Conv2d-389          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-390          [-1, 2048, 16, 8]           4,096
            ReLU-391          [-1, 2048, 16, 8]               0
      Bottleneck-392          [-1, 2048, 16, 8]               0
          Conv2d-393          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-394          [-1, 2048, 16, 8]           4,096
            ReLU-395          [-1, 2048, 16, 8]               0
          Conv2d-396          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-397          [-1, 2048, 16, 8]           4,096
            ReLU-398          [-1, 2048, 16, 8]               0
          Conv2d-399          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-400          [-1, 2048, 16, 8]           4,096
            ReLU-401          [-1, 2048, 16, 8]               0
      Bottleneck-402          [-1, 2048, 16, 8]               0
================================================================
Total params: 86,742,336
Trainable params: 86,742,336
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 600.00
Params size (MB): 330.90
Estimated Total Size (MB): 931.27
----------------------------------------------------------------
**********************************************************************
**********************************************************************
resnext101_32x8d_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 256, 64, 32]          16,384
       BatchNorm2d-6          [-1, 256, 64, 32]             512
              ReLU-7          [-1, 256, 64, 32]               0
            Conv2d-8          [-1, 256, 64, 32]          18,432
       BatchNorm2d-9          [-1, 256, 64, 32]             512
             ReLU-10          [-1, 256, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          65,536
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
   InstanceNorm2d-15          [-1, 256, 64, 32]             512
             ReLU-16          [-1, 256, 64, 32]               0
       Bottleneck-17          [-1, 256, 64, 32]               0
           Conv2d-18          [-1, 256, 64, 32]          65,536
      BatchNorm2d-19          [-1, 256, 64, 32]             512
             ReLU-20          [-1, 256, 64, 32]               0
           Conv2d-21          [-1, 256, 64, 32]          18,432
      BatchNorm2d-22          [-1, 256, 64, 32]             512
             ReLU-23          [-1, 256, 64, 32]               0
           Conv2d-24          [-1, 256, 64, 32]          65,536
      BatchNorm2d-25          [-1, 256, 64, 32]             512
   InstanceNorm2d-26          [-1, 256, 64, 32]             512
             ReLU-27          [-1, 256, 64, 32]               0
       Bottleneck-28          [-1, 256, 64, 32]               0
           Conv2d-29          [-1, 256, 64, 32]          65,536
      BatchNorm2d-30          [-1, 256, 64, 32]             512
             ReLU-31          [-1, 256, 64, 32]               0
           Conv2d-32          [-1, 256, 64, 32]          18,432
      BatchNorm2d-33          [-1, 256, 64, 32]             512
             ReLU-34          [-1, 256, 64, 32]               0
           Conv2d-35          [-1, 256, 64, 32]          65,536
      BatchNorm2d-36          [-1, 256, 64, 32]             512
   InstanceNorm2d-37          [-1, 256, 64, 32]             512
             ReLU-38          [-1, 256, 64, 32]               0
       Bottleneck-39          [-1, 256, 64, 32]               0
           Conv2d-40          [-1, 512, 64, 32]         131,072
      BatchNorm2d-41          [-1, 512, 64, 32]           1,024
             ReLU-42          [-1, 512, 64, 32]               0
           Conv2d-43          [-1, 512, 32, 16]          73,728
      BatchNorm2d-44          [-1, 512, 32, 16]           1,024
             ReLU-45          [-1, 512, 32, 16]               0
           Conv2d-46          [-1, 512, 32, 16]         262,144
      BatchNorm2d-47          [-1, 512, 32, 16]           1,024
           Conv2d-48          [-1, 512, 32, 16]         131,072
      BatchNorm2d-49          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-50          [-1, 512, 32, 16]           1,024
             ReLU-51          [-1, 512, 32, 16]               0
       Bottleneck-52          [-1, 512, 32, 16]               0
           Conv2d-53          [-1, 512, 32, 16]         262,144
      BatchNorm2d-54          [-1, 512, 32, 16]           1,024
             ReLU-55          [-1, 512, 32, 16]               0
           Conv2d-56          [-1, 512, 32, 16]          73,728
      BatchNorm2d-57          [-1, 512, 32, 16]           1,024
             ReLU-58          [-1, 512, 32, 16]               0
           Conv2d-59          [-1, 512, 32, 16]         262,144
      BatchNorm2d-60          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-61          [-1, 512, 32, 16]           1,024
             ReLU-62          [-1, 512, 32, 16]               0
       Bottleneck-63          [-1, 512, 32, 16]               0
           Conv2d-64          [-1, 512, 32, 16]         262,144
      BatchNorm2d-65          [-1, 512, 32, 16]           1,024
             ReLU-66          [-1, 512, 32, 16]               0
           Conv2d-67          [-1, 512, 32, 16]          73,728
      BatchNorm2d-68          [-1, 512, 32, 16]           1,024
             ReLU-69          [-1, 512, 32, 16]               0
           Conv2d-70          [-1, 512, 32, 16]         262,144
      BatchNorm2d-71          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-72          [-1, 512, 32, 16]           1,024
             ReLU-73          [-1, 512, 32, 16]               0
       Bottleneck-74          [-1, 512, 32, 16]               0
           Conv2d-75          [-1, 512, 32, 16]         262,144
      BatchNorm2d-76          [-1, 512, 32, 16]           1,024
             ReLU-77          [-1, 512, 32, 16]               0
           Conv2d-78          [-1, 512, 32, 16]          73,728
      BatchNorm2d-79          [-1, 512, 32, 16]           1,024
             ReLU-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 512, 32, 16]         262,144
      BatchNorm2d-82          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-83          [-1, 512, 32, 16]           1,024
             ReLU-84          [-1, 512, 32, 16]               0
       Bottleneck-85          [-1, 512, 32, 16]               0
           Conv2d-86         [-1, 1024, 32, 16]         524,288
      BatchNorm2d-87         [-1, 1024, 32, 16]           2,048
             ReLU-88         [-1, 1024, 32, 16]               0
           Conv2d-89          [-1, 1024, 16, 8]         294,912
      BatchNorm2d-90          [-1, 1024, 16, 8]           2,048
             ReLU-91          [-1, 1024, 16, 8]               0
           Conv2d-92          [-1, 1024, 16, 8]       1,048,576
      BatchNorm2d-93          [-1, 1024, 16, 8]           2,048
           Conv2d-94          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-95          [-1, 1024, 16, 8]           2,048
             ReLU-96          [-1, 1024, 16, 8]               0
       Bottleneck-97          [-1, 1024, 16, 8]               0
           Conv2d-98          [-1, 1024, 16, 8]       1,048,576
      BatchNorm2d-99          [-1, 1024, 16, 8]           2,048
            ReLU-100          [-1, 1024, 16, 8]               0
          Conv2d-101          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-102          [-1, 1024, 16, 8]           2,048
            ReLU-103          [-1, 1024, 16, 8]               0
          Conv2d-104          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-105          [-1, 1024, 16, 8]           2,048
            ReLU-106          [-1, 1024, 16, 8]               0
      Bottleneck-107          [-1, 1024, 16, 8]               0
          Conv2d-108          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-109          [-1, 1024, 16, 8]           2,048
            ReLU-110          [-1, 1024, 16, 8]               0
          Conv2d-111          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-112          [-1, 1024, 16, 8]           2,048
            ReLU-113          [-1, 1024, 16, 8]               0
          Conv2d-114          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-115          [-1, 1024, 16, 8]           2,048
            ReLU-116          [-1, 1024, 16, 8]               0
      Bottleneck-117          [-1, 1024, 16, 8]               0
          Conv2d-118          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-119          [-1, 1024, 16, 8]           2,048
            ReLU-120          [-1, 1024, 16, 8]               0
          Conv2d-121          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-122          [-1, 1024, 16, 8]           2,048
            ReLU-123          [-1, 1024, 16, 8]               0
          Conv2d-124          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-125          [-1, 1024, 16, 8]           2,048
            ReLU-126          [-1, 1024, 16, 8]               0
      Bottleneck-127          [-1, 1024, 16, 8]               0
          Conv2d-128          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-129          [-1, 1024, 16, 8]           2,048
            ReLU-130          [-1, 1024, 16, 8]               0
          Conv2d-131          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-132          [-1, 1024, 16, 8]           2,048
            ReLU-133          [-1, 1024, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
            ReLU-136          [-1, 1024, 16, 8]               0
      Bottleneck-137          [-1, 1024, 16, 8]               0
          Conv2d-138          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-139          [-1, 1024, 16, 8]           2,048
            ReLU-140          [-1, 1024, 16, 8]               0
          Conv2d-141          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-142          [-1, 1024, 16, 8]           2,048
            ReLU-143          [-1, 1024, 16, 8]               0
          Conv2d-144          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-145          [-1, 1024, 16, 8]           2,048
            ReLU-146          [-1, 1024, 16, 8]               0
      Bottleneck-147          [-1, 1024, 16, 8]               0
          Conv2d-148          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-149          [-1, 1024, 16, 8]           2,048
            ReLU-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
          Conv2d-154          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-155          [-1, 1024, 16, 8]           2,048
            ReLU-156          [-1, 1024, 16, 8]               0
      Bottleneck-157          [-1, 1024, 16, 8]               0
          Conv2d-158          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-159          [-1, 1024, 16, 8]           2,048
            ReLU-160          [-1, 1024, 16, 8]               0
          Conv2d-161          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-162          [-1, 1024, 16, 8]           2,048
            ReLU-163          [-1, 1024, 16, 8]               0
          Conv2d-164          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-165          [-1, 1024, 16, 8]           2,048
            ReLU-166          [-1, 1024, 16, 8]               0
      Bottleneck-167          [-1, 1024, 16, 8]               0
          Conv2d-168          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-169          [-1, 1024, 16, 8]           2,048
            ReLU-170          [-1, 1024, 16, 8]               0
          Conv2d-171          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-172          [-1, 1024, 16, 8]           2,048
            ReLU-173          [-1, 1024, 16, 8]               0
          Conv2d-174          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-175          [-1, 1024, 16, 8]           2,048
            ReLU-176          [-1, 1024, 16, 8]               0
      Bottleneck-177          [-1, 1024, 16, 8]               0
          Conv2d-178          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-179          [-1, 1024, 16, 8]           2,048
            ReLU-180          [-1, 1024, 16, 8]               0
          Conv2d-181          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-182          [-1, 1024, 16, 8]           2,048
            ReLU-183          [-1, 1024, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
            ReLU-186          [-1, 1024, 16, 8]               0
      Bottleneck-187          [-1, 1024, 16, 8]               0
          Conv2d-188          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-189          [-1, 1024, 16, 8]           2,048
            ReLU-190          [-1, 1024, 16, 8]               0
          Conv2d-191          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-192          [-1, 1024, 16, 8]           2,048
            ReLU-193          [-1, 1024, 16, 8]               0
          Conv2d-194          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-195          [-1, 1024, 16, 8]           2,048
            ReLU-196          [-1, 1024, 16, 8]               0
      Bottleneck-197          [-1, 1024, 16, 8]               0
          Conv2d-198          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-199          [-1, 1024, 16, 8]           2,048
            ReLU-200          [-1, 1024, 16, 8]               0
          Conv2d-201          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-202          [-1, 1024, 16, 8]           2,048
            ReLU-203          [-1, 1024, 16, 8]               0
          Conv2d-204          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-205          [-1, 1024, 16, 8]           2,048
            ReLU-206          [-1, 1024, 16, 8]               0
      Bottleneck-207          [-1, 1024, 16, 8]               0
          Conv2d-208          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-209          [-1, 1024, 16, 8]           2,048
            ReLU-210          [-1, 1024, 16, 8]               0
          Conv2d-211          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-212          [-1, 1024, 16, 8]           2,048
            ReLU-213          [-1, 1024, 16, 8]               0
          Conv2d-214          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-215          [-1, 1024, 16, 8]           2,048
            ReLU-216          [-1, 1024, 16, 8]               0
      Bottleneck-217          [-1, 1024, 16, 8]               0
          Conv2d-218          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-219          [-1, 1024, 16, 8]           2,048
            ReLU-220          [-1, 1024, 16, 8]               0
          Conv2d-221          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-222          [-1, 1024, 16, 8]           2,048
            ReLU-223          [-1, 1024, 16, 8]               0
          Conv2d-224          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-225          [-1, 1024, 16, 8]           2,048
            ReLU-226          [-1, 1024, 16, 8]               0
      Bottleneck-227          [-1, 1024, 16, 8]               0
          Conv2d-228          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-229          [-1, 1024, 16, 8]           2,048
            ReLU-230          [-1, 1024, 16, 8]               0
          Conv2d-231          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-232          [-1, 1024, 16, 8]           2,048
            ReLU-233          [-1, 1024, 16, 8]               0
          Conv2d-234          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-235          [-1, 1024, 16, 8]           2,048
            ReLU-236          [-1, 1024, 16, 8]               0
      Bottleneck-237          [-1, 1024, 16, 8]               0
          Conv2d-238          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-239          [-1, 1024, 16, 8]           2,048
            ReLU-240          [-1, 1024, 16, 8]               0
          Conv2d-241          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-242          [-1, 1024, 16, 8]           2,048
            ReLU-243          [-1, 1024, 16, 8]               0
          Conv2d-244          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-245          [-1, 1024, 16, 8]           2,048
            ReLU-246          [-1, 1024, 16, 8]               0
      Bottleneck-247          [-1, 1024, 16, 8]               0
          Conv2d-248          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-249          [-1, 1024, 16, 8]           2,048
            ReLU-250          [-1, 1024, 16, 8]               0
          Conv2d-251          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-252          [-1, 1024, 16, 8]           2,048
            ReLU-253          [-1, 1024, 16, 8]               0
          Conv2d-254          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-255          [-1, 1024, 16, 8]           2,048
            ReLU-256          [-1, 1024, 16, 8]               0
      Bottleneck-257          [-1, 1024, 16, 8]               0
          Conv2d-258          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-259          [-1, 1024, 16, 8]           2,048
            ReLU-260          [-1, 1024, 16, 8]               0
          Conv2d-261          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-262          [-1, 1024, 16, 8]           2,048
            ReLU-263          [-1, 1024, 16, 8]               0
          Conv2d-264          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-265          [-1, 1024, 16, 8]           2,048
            ReLU-266          [-1, 1024, 16, 8]               0
      Bottleneck-267          [-1, 1024, 16, 8]               0
          Conv2d-268          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-269          [-1, 1024, 16, 8]           2,048
            ReLU-270          [-1, 1024, 16, 8]               0
          Conv2d-271          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-272          [-1, 1024, 16, 8]           2,048
            ReLU-273          [-1, 1024, 16, 8]               0
          Conv2d-274          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-275          [-1, 1024, 16, 8]           2,048
            ReLU-276          [-1, 1024, 16, 8]               0
      Bottleneck-277          [-1, 1024, 16, 8]               0
          Conv2d-278          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-279          [-1, 1024, 16, 8]           2,048
            ReLU-280          [-1, 1024, 16, 8]               0
          Conv2d-281          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-282          [-1, 1024, 16, 8]           2,048
            ReLU-283          [-1, 1024, 16, 8]               0
          Conv2d-284          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-285          [-1, 1024, 16, 8]           2,048
            ReLU-286          [-1, 1024, 16, 8]               0
      Bottleneck-287          [-1, 1024, 16, 8]               0
          Conv2d-288          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-289          [-1, 1024, 16, 8]           2,048
            ReLU-290          [-1, 1024, 16, 8]               0
          Conv2d-291          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-292          [-1, 1024, 16, 8]           2,048
            ReLU-293          [-1, 1024, 16, 8]               0
          Conv2d-294          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-295          [-1, 1024, 16, 8]           2,048
            ReLU-296          [-1, 1024, 16, 8]               0
      Bottleneck-297          [-1, 1024, 16, 8]               0
          Conv2d-298          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-299          [-1, 1024, 16, 8]           2,048
            ReLU-300          [-1, 1024, 16, 8]               0
          Conv2d-301          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-302          [-1, 1024, 16, 8]           2,048
            ReLU-303          [-1, 1024, 16, 8]               0
          Conv2d-304          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-305          [-1, 1024, 16, 8]           2,048
            ReLU-306          [-1, 1024, 16, 8]               0
      Bottleneck-307          [-1, 1024, 16, 8]               0
          Conv2d-308          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-309          [-1, 1024, 16, 8]           2,048
            ReLU-310          [-1, 1024, 16, 8]               0
          Conv2d-311          [-1, 1024, 16, 8]         294,912
     BatchNorm2d-312          [-1, 1024, 16, 8]           2,048
            ReLU-313          [-1, 1024, 16, 8]               0
          Conv2d-314          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-315          [-1, 1024, 16, 8]           2,048
            ReLU-316          [-1, 1024, 16, 8]               0
      Bottleneck-317          [-1, 1024, 16, 8]               0
          Conv2d-318          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-319          [-1, 2048, 16, 8]           4,096
            ReLU-320          [-1, 2048, 16, 8]               0
          Conv2d-321          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-322          [-1, 2048, 16, 8]           4,096
            ReLU-323          [-1, 2048, 16, 8]               0
          Conv2d-324          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-325          [-1, 2048, 16, 8]           4,096
          Conv2d-326          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-327          [-1, 2048, 16, 8]           4,096
            ReLU-328          [-1, 2048, 16, 8]               0
      Bottleneck-329          [-1, 2048, 16, 8]               0
          Conv2d-330          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-331          [-1, 2048, 16, 8]           4,096
            ReLU-332          [-1, 2048, 16, 8]               0
          Conv2d-333          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-334          [-1, 2048, 16, 8]           4,096
            ReLU-335          [-1, 2048, 16, 8]               0
          Conv2d-336          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-337          [-1, 2048, 16, 8]           4,096
            ReLU-338          [-1, 2048, 16, 8]               0
      Bottleneck-339          [-1, 2048, 16, 8]               0
          Conv2d-340          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-341          [-1, 2048, 16, 8]           4,096
            ReLU-342          [-1, 2048, 16, 8]               0
          Conv2d-343          [-1, 2048, 16, 8]       1,179,648
     BatchNorm2d-344          [-1, 2048, 16, 8]           4,096
            ReLU-345          [-1, 2048, 16, 8]               0
          Conv2d-346          [-1, 2048, 16, 8]       4,194,304
     BatchNorm2d-347          [-1, 2048, 16, 8]           4,096
            ReLU-348          [-1, 2048, 16, 8]               0
      Bottleneck-349          [-1, 2048, 16, 8]               0
================================================================
Total params: 86,747,968
Trainable params: 86,747,968
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 568.00
Params size (MB): 330.92
Estimated Total Size (MB): 899.29
----------------------------------------------------------------
**********************************************************************
**********************************************************************
wide_resnet50_2_se
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]         147,456
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
             ReLU-21          [-1, 256, 64, 32]               0
       Bottleneck-22          [-1, 256, 64, 32]               0
           Conv2d-23          [-1, 128, 64, 32]          32,768
      BatchNorm2d-24          [-1, 128, 64, 32]             256
             ReLU-25          [-1, 128, 64, 32]               0
           Conv2d-26          [-1, 128, 64, 32]         147,456
      BatchNorm2d-27          [-1, 128, 64, 32]             256
             ReLU-28          [-1, 128, 64, 32]               0
           Conv2d-29          [-1, 256, 64, 32]          32,768
      BatchNorm2d-30          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0
           Linear-32                   [-1, 16]           4,096
             ReLU-33                   [-1, 16]               0
           Linear-34                  [-1, 256]           4,096
          Sigmoid-35                  [-1, 256]               0
          SELayer-36          [-1, 256, 64, 32]               0
             ReLU-37          [-1, 256, 64, 32]               0
       Bottleneck-38          [-1, 256, 64, 32]               0
           Conv2d-39          [-1, 128, 64, 32]          32,768
      BatchNorm2d-40          [-1, 128, 64, 32]             256
             ReLU-41          [-1, 128, 64, 32]               0
           Conv2d-42          [-1, 128, 64, 32]         147,456
      BatchNorm2d-43          [-1, 128, 64, 32]             256
             ReLU-44          [-1, 128, 64, 32]               0
           Conv2d-45          [-1, 256, 64, 32]          32,768
      BatchNorm2d-46          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-47            [-1, 256, 1, 1]               0
           Linear-48                   [-1, 16]           4,096
             ReLU-49                   [-1, 16]               0
           Linear-50                  [-1, 256]           4,096
          Sigmoid-51                  [-1, 256]               0
          SELayer-52          [-1, 256, 64, 32]               0
             ReLU-53          [-1, 256, 64, 32]               0
       Bottleneck-54          [-1, 256, 64, 32]               0
           Conv2d-55          [-1, 256, 64, 32]          65,536
      BatchNorm2d-56          [-1, 256, 64, 32]             512
             ReLU-57          [-1, 256, 64, 32]               0
           Conv2d-58          [-1, 256, 32, 16]         589,824
      BatchNorm2d-59          [-1, 256, 32, 16]             512
             ReLU-60          [-1, 256, 32, 16]               0
           Conv2d-61          [-1, 512, 32, 16]         131,072
      BatchNorm2d-62          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-63            [-1, 512, 1, 1]               0
           Linear-64                   [-1, 32]          16,384
             ReLU-65                   [-1, 32]               0
           Linear-66                  [-1, 512]          16,384
          Sigmoid-67                  [-1, 512]               0
          SELayer-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         131,072
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
             ReLU-71          [-1, 512, 32, 16]               0
       Bottleneck-72          [-1, 512, 32, 16]               0
           Conv2d-73          [-1, 256, 32, 16]         131,072
      BatchNorm2d-74          [-1, 256, 32, 16]             512
             ReLU-75          [-1, 256, 32, 16]               0
           Conv2d-76          [-1, 256, 32, 16]         589,824
      BatchNorm2d-77          [-1, 256, 32, 16]             512
             ReLU-78          [-1, 256, 32, 16]               0
           Conv2d-79          [-1, 512, 32, 16]         131,072
      BatchNorm2d-80          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-81            [-1, 512, 1, 1]               0
           Linear-82                   [-1, 32]          16,384
             ReLU-83                   [-1, 32]               0
           Linear-84                  [-1, 512]          16,384
          Sigmoid-85                  [-1, 512]               0
          SELayer-86          [-1, 512, 32, 16]               0
             ReLU-87          [-1, 512, 32, 16]               0
       Bottleneck-88          [-1, 512, 32, 16]               0
           Conv2d-89          [-1, 256, 32, 16]         131,072
      BatchNorm2d-90          [-1, 256, 32, 16]             512
             ReLU-91          [-1, 256, 32, 16]               0
           Conv2d-92          [-1, 256, 32, 16]         589,824
      BatchNorm2d-93          [-1, 256, 32, 16]             512
             ReLU-94          [-1, 256, 32, 16]               0
           Conv2d-95          [-1, 512, 32, 16]         131,072
      BatchNorm2d-96          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-97            [-1, 512, 1, 1]               0
           Linear-98                   [-1, 32]          16,384
             ReLU-99                   [-1, 32]               0
          Linear-100                  [-1, 512]          16,384
         Sigmoid-101                  [-1, 512]               0
         SELayer-102          [-1, 512, 32, 16]               0
            ReLU-103          [-1, 512, 32, 16]               0
      Bottleneck-104          [-1, 512, 32, 16]               0
          Conv2d-105          [-1, 256, 32, 16]         131,072
     BatchNorm2d-106          [-1, 256, 32, 16]             512
            ReLU-107          [-1, 256, 32, 16]               0
          Conv2d-108          [-1, 256, 32, 16]         589,824
     BatchNorm2d-109          [-1, 256, 32, 16]             512
            ReLU-110          [-1, 256, 32, 16]               0
          Conv2d-111          [-1, 512, 32, 16]         131,072
     BatchNorm2d-112          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-113            [-1, 512, 1, 1]               0
          Linear-114                   [-1, 32]          16,384
            ReLU-115                   [-1, 32]               0
          Linear-116                  [-1, 512]          16,384
         Sigmoid-117                  [-1, 512]               0
         SELayer-118          [-1, 512, 32, 16]               0
            ReLU-119          [-1, 512, 32, 16]               0
      Bottleneck-120          [-1, 512, 32, 16]               0
          Conv2d-121          [-1, 512, 32, 16]         262,144
     BatchNorm2d-122          [-1, 512, 32, 16]           1,024
            ReLU-123          [-1, 512, 32, 16]               0
          Conv2d-124           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-125           [-1, 512, 16, 8]           1,024
            ReLU-126           [-1, 512, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-129           [-1, 1024, 1, 1]               0
          Linear-130                   [-1, 64]          65,536
            ReLU-131                   [-1, 64]               0
          Linear-132                 [-1, 1024]          65,536
         Sigmoid-133                 [-1, 1024]               0
         SELayer-134          [-1, 1024, 16, 8]               0
          Conv2d-135          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-136          [-1, 1024, 16, 8]           2,048
            ReLU-137          [-1, 1024, 16, 8]               0
      Bottleneck-138          [-1, 1024, 16, 8]               0
          Conv2d-139           [-1, 512, 16, 8]         524,288
     BatchNorm2d-140           [-1, 512, 16, 8]           1,024
            ReLU-141           [-1, 512, 16, 8]               0
          Conv2d-142           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-143           [-1, 512, 16, 8]           1,024
            ReLU-144           [-1, 512, 16, 8]               0
          Conv2d-145          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-146          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-147           [-1, 1024, 1, 1]               0
          Linear-148                   [-1, 64]          65,536
            ReLU-149                   [-1, 64]               0
          Linear-150                 [-1, 1024]          65,536
         Sigmoid-151                 [-1, 1024]               0
         SELayer-152          [-1, 1024, 16, 8]               0
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 512, 16, 8]         524,288
     BatchNorm2d-156           [-1, 512, 16, 8]           1,024
            ReLU-157           [-1, 512, 16, 8]               0
          Conv2d-158           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-159           [-1, 512, 16, 8]           1,024
            ReLU-160           [-1, 512, 16, 8]               0
          Conv2d-161          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-162          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-163           [-1, 1024, 1, 1]               0
          Linear-164                   [-1, 64]          65,536
            ReLU-165                   [-1, 64]               0
          Linear-166                 [-1, 1024]          65,536
         Sigmoid-167                 [-1, 1024]               0
         SELayer-168          [-1, 1024, 16, 8]               0
            ReLU-169          [-1, 1024, 16, 8]               0
      Bottleneck-170          [-1, 1024, 16, 8]               0
          Conv2d-171           [-1, 512, 16, 8]         524,288
     BatchNorm2d-172           [-1, 512, 16, 8]           1,024
            ReLU-173           [-1, 512, 16, 8]               0
          Conv2d-174           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-175           [-1, 512, 16, 8]           1,024
            ReLU-176           [-1, 512, 16, 8]               0
          Conv2d-177          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-178          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-179           [-1, 1024, 1, 1]               0
          Linear-180                   [-1, 64]          65,536
            ReLU-181                   [-1, 64]               0
          Linear-182                 [-1, 1024]          65,536
         Sigmoid-183                 [-1, 1024]               0
         SELayer-184          [-1, 1024, 16, 8]               0
            ReLU-185          [-1, 1024, 16, 8]               0
      Bottleneck-186          [-1, 1024, 16, 8]               0
          Conv2d-187           [-1, 512, 16, 8]         524,288
     BatchNorm2d-188           [-1, 512, 16, 8]           1,024
            ReLU-189           [-1, 512, 16, 8]               0
          Conv2d-190           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-191           [-1, 512, 16, 8]           1,024
            ReLU-192           [-1, 512, 16, 8]               0
          Conv2d-193          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-194          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-195           [-1, 1024, 1, 1]               0
          Linear-196                   [-1, 64]          65,536
            ReLU-197                   [-1, 64]               0
          Linear-198                 [-1, 1024]          65,536
         Sigmoid-199                 [-1, 1024]               0
         SELayer-200          [-1, 1024, 16, 8]               0
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203           [-1, 512, 16, 8]         524,288
     BatchNorm2d-204           [-1, 512, 16, 8]           1,024
            ReLU-205           [-1, 512, 16, 8]               0
          Conv2d-206           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-207           [-1, 512, 16, 8]           1,024
            ReLU-208           [-1, 512, 16, 8]               0
          Conv2d-209          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-210          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-211           [-1, 1024, 1, 1]               0
          Linear-212                   [-1, 64]          65,536
            ReLU-213                   [-1, 64]               0
          Linear-214                 [-1, 1024]          65,536
         Sigmoid-215                 [-1, 1024]               0
         SELayer-216          [-1, 1024, 16, 8]               0
            ReLU-217          [-1, 1024, 16, 8]               0
      Bottleneck-218          [-1, 1024, 16, 8]               0
          Conv2d-219          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-220          [-1, 1024, 16, 8]           2,048
            ReLU-221          [-1, 1024, 16, 8]               0
          Conv2d-222          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-223          [-1, 1024, 16, 8]           2,048
            ReLU-224          [-1, 1024, 16, 8]               0
          Conv2d-225          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-226          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-227           [-1, 2048, 1, 1]               0
          Linear-228                  [-1, 128]         262,144
            ReLU-229                  [-1, 128]               0
          Linear-230                 [-1, 2048]         262,144
         Sigmoid-231                 [-1, 2048]               0
         SELayer-232          [-1, 2048, 16, 8]               0
          Conv2d-233          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-234          [-1, 2048, 16, 8]           4,096
            ReLU-235          [-1, 2048, 16, 8]               0
      Bottleneck-236          [-1, 2048, 16, 8]               0
          Conv2d-237          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-238          [-1, 1024, 16, 8]           2,048
            ReLU-239          [-1, 1024, 16, 8]               0
          Conv2d-240          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-241          [-1, 1024, 16, 8]           2,048
            ReLU-242          [-1, 1024, 16, 8]               0
          Conv2d-243          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-244          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-245           [-1, 2048, 1, 1]               0
          Linear-246                  [-1, 128]         262,144
            ReLU-247                  [-1, 128]               0
          Linear-248                 [-1, 2048]         262,144
         Sigmoid-249                 [-1, 2048]               0
         SELayer-250          [-1, 2048, 16, 8]               0
            ReLU-251          [-1, 2048, 16, 8]               0
      Bottleneck-252          [-1, 2048, 16, 8]               0
          Conv2d-253          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-254          [-1, 1024, 16, 8]           2,048
            ReLU-255          [-1, 1024, 16, 8]               0
          Conv2d-256          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-257          [-1, 1024, 16, 8]           2,048
            ReLU-258          [-1, 1024, 16, 8]               0
          Conv2d-259          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-260          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-261           [-1, 2048, 1, 1]               0
          Linear-262                  [-1, 128]         262,144
            ReLU-263                  [-1, 128]               0
          Linear-264                 [-1, 2048]         262,144
         Sigmoid-265                 [-1, 2048]               0
         SELayer-266          [-1, 2048, 16, 8]               0
            ReLU-267          [-1, 2048, 16, 8]               0
      Bottleneck-268          [-1, 2048, 16, 8]               0
================================================================
Total params: 69,349,184
Trainable params: 69,349,184
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 300.86
Params size (MB): 264.55
Estimated Total Size (MB): 565.78
----------------------------------------------------------------
**********************************************************************
**********************************************************************
wide_resnet50_2_se_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
    InstanceNorm2d-6           [-1, 64, 64, 32]             128
       BatchNorm2d-7           [-1, 64, 64, 32]             128
               IBN-8          [-1, 128, 64, 32]               0
              ReLU-9          [-1, 128, 64, 32]               0
           Conv2d-10          [-1, 128, 64, 32]         147,456
      BatchNorm2d-11          [-1, 128, 64, 32]             256
             ReLU-12          [-1, 128, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          32,768
      BatchNorm2d-14          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-15            [-1, 256, 1, 1]               0
           Linear-16                   [-1, 16]           4,096
             ReLU-17                   [-1, 16]               0
           Linear-18                  [-1, 256]           4,096
          Sigmoid-19                  [-1, 256]               0
          SELayer-20          [-1, 256, 64, 32]               0
           Conv2d-21          [-1, 256, 64, 32]          16,384
      BatchNorm2d-22          [-1, 256, 64, 32]             512
             ReLU-23          [-1, 256, 64, 32]               0
       Bottleneck-24          [-1, 256, 64, 32]               0
           Conv2d-25          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-26           [-1, 64, 64, 32]             128
      BatchNorm2d-27           [-1, 64, 64, 32]             128
              IBN-28          [-1, 128, 64, 32]               0
             ReLU-29          [-1, 128, 64, 32]               0
           Conv2d-30          [-1, 128, 64, 32]         147,456
      BatchNorm2d-31          [-1, 128, 64, 32]             256
             ReLU-32          [-1, 128, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          32,768
      BatchNorm2d-34          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-35            [-1, 256, 1, 1]               0
           Linear-36                   [-1, 16]           4,096
             ReLU-37                   [-1, 16]               0
           Linear-38                  [-1, 256]           4,096
          Sigmoid-39                  [-1, 256]               0
          SELayer-40          [-1, 256, 64, 32]               0
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-44           [-1, 64, 64, 32]             128
      BatchNorm2d-45           [-1, 64, 64, 32]             128
              IBN-46          [-1, 128, 64, 32]               0
             ReLU-47          [-1, 128, 64, 32]               0
           Conv2d-48          [-1, 128, 64, 32]         147,456
      BatchNorm2d-49          [-1, 128, 64, 32]             256
             ReLU-50          [-1, 128, 64, 32]               0
           Conv2d-51          [-1, 256, 64, 32]          32,768
      BatchNorm2d-52          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-53            [-1, 256, 1, 1]               0
           Linear-54                   [-1, 16]           4,096
             ReLU-55                   [-1, 16]               0
           Linear-56                  [-1, 256]           4,096
          Sigmoid-57                  [-1, 256]               0
          SELayer-58          [-1, 256, 64, 32]               0
             ReLU-59          [-1, 256, 64, 32]               0
       Bottleneck-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 256, 64, 32]          65,536
   InstanceNorm2d-62          [-1, 128, 64, 32]             256
      BatchNorm2d-63          [-1, 128, 64, 32]             256
              IBN-64          [-1, 256, 64, 32]               0
             ReLU-65          [-1, 256, 64, 32]               0
           Conv2d-66          [-1, 256, 32, 16]         589,824
      BatchNorm2d-67          [-1, 256, 32, 16]             512
             ReLU-68          [-1, 256, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         131,072
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-71            [-1, 512, 1, 1]               0
           Linear-72                   [-1, 32]          16,384
             ReLU-73                   [-1, 32]               0
           Linear-74                  [-1, 512]          16,384
          Sigmoid-75                  [-1, 512]               0
          SELayer-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         131,072
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-82          [-1, 128, 32, 16]             256
      BatchNorm2d-83          [-1, 128, 32, 16]             256
              IBN-84          [-1, 256, 32, 16]               0
             ReLU-85          [-1, 256, 32, 16]               0
           Conv2d-86          [-1, 256, 32, 16]         589,824
      BatchNorm2d-87          [-1, 256, 32, 16]             512
             ReLU-88          [-1, 256, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]         131,072
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-91            [-1, 512, 1, 1]               0
           Linear-92                   [-1, 32]          16,384
             ReLU-93                   [-1, 32]               0
           Linear-94                  [-1, 512]          16,384
          Sigmoid-95                  [-1, 512]               0
          SELayer-96          [-1, 512, 32, 16]               0
             ReLU-97          [-1, 512, 32, 16]               0
       Bottleneck-98          [-1, 512, 32, 16]               0
           Conv2d-99          [-1, 256, 32, 16]         131,072
  InstanceNorm2d-100          [-1, 128, 32, 16]             256
     BatchNorm2d-101          [-1, 128, 32, 16]             256
             IBN-102          [-1, 256, 32, 16]               0
            ReLU-103          [-1, 256, 32, 16]               0
          Conv2d-104          [-1, 256, 32, 16]         589,824
     BatchNorm2d-105          [-1, 256, 32, 16]             512
            ReLU-106          [-1, 256, 32, 16]               0
          Conv2d-107          [-1, 512, 32, 16]         131,072
     BatchNorm2d-108          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-109            [-1, 512, 1, 1]               0
          Linear-110                   [-1, 32]          16,384
            ReLU-111                   [-1, 32]               0
          Linear-112                  [-1, 512]          16,384
         Sigmoid-113                  [-1, 512]               0
         SELayer-114          [-1, 512, 32, 16]               0
            ReLU-115          [-1, 512, 32, 16]               0
      Bottleneck-116          [-1, 512, 32, 16]               0
          Conv2d-117          [-1, 256, 32, 16]         131,072
  InstanceNorm2d-118          [-1, 128, 32, 16]             256
     BatchNorm2d-119          [-1, 128, 32, 16]             256
             IBN-120          [-1, 256, 32, 16]               0
            ReLU-121          [-1, 256, 32, 16]               0
          Conv2d-122          [-1, 256, 32, 16]         589,824
     BatchNorm2d-123          [-1, 256, 32, 16]             512
            ReLU-124          [-1, 256, 32, 16]               0
          Conv2d-125          [-1, 512, 32, 16]         131,072
     BatchNorm2d-126          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-127            [-1, 512, 1, 1]               0
          Linear-128                   [-1, 32]          16,384
            ReLU-129                   [-1, 32]               0
          Linear-130                  [-1, 512]          16,384
         Sigmoid-131                  [-1, 512]               0
         SELayer-132          [-1, 512, 32, 16]               0
            ReLU-133          [-1, 512, 32, 16]               0
      Bottleneck-134          [-1, 512, 32, 16]               0
          Conv2d-135          [-1, 512, 32, 16]         262,144
  InstanceNorm2d-136          [-1, 256, 32, 16]             512
     BatchNorm2d-137          [-1, 256, 32, 16]             512
             IBN-138          [-1, 512, 32, 16]               0
            ReLU-139          [-1, 512, 32, 16]               0
          Conv2d-140           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-141           [-1, 512, 16, 8]           1,024
            ReLU-142           [-1, 512, 16, 8]               0
          Conv2d-143          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-144          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-145           [-1, 1024, 1, 1]               0
          Linear-146                   [-1, 64]          65,536
            ReLU-147                   [-1, 64]               0
          Linear-148                 [-1, 1024]          65,536
         Sigmoid-149                 [-1, 1024]               0
         SELayer-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-156           [-1, 256, 16, 8]             512
     BatchNorm2d-157           [-1, 256, 16, 8]             512
             IBN-158           [-1, 512, 16, 8]               0
            ReLU-159           [-1, 512, 16, 8]               0
          Conv2d-160           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-161           [-1, 512, 16, 8]           1,024
            ReLU-162           [-1, 512, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-165           [-1, 1024, 1, 1]               0
          Linear-166                   [-1, 64]          65,536
            ReLU-167                   [-1, 64]               0
          Linear-168                 [-1, 1024]          65,536
         Sigmoid-169                 [-1, 1024]               0
         SELayer-170          [-1, 1024, 16, 8]               0
            ReLU-171          [-1, 1024, 16, 8]               0
      Bottleneck-172          [-1, 1024, 16, 8]               0
          Conv2d-173           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-174           [-1, 256, 16, 8]             512
     BatchNorm2d-175           [-1, 256, 16, 8]             512
             IBN-176           [-1, 512, 16, 8]               0
            ReLU-177           [-1, 512, 16, 8]               0
          Conv2d-178           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-179           [-1, 512, 16, 8]           1,024
            ReLU-180           [-1, 512, 16, 8]               0
          Conv2d-181          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-182          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-183           [-1, 1024, 1, 1]               0
          Linear-184                   [-1, 64]          65,536
            ReLU-185                   [-1, 64]               0
          Linear-186                 [-1, 1024]          65,536
         Sigmoid-187                 [-1, 1024]               0
         SELayer-188          [-1, 1024, 16, 8]               0
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-192           [-1, 256, 16, 8]             512
     BatchNorm2d-193           [-1, 256, 16, 8]             512
             IBN-194           [-1, 512, 16, 8]               0
            ReLU-195           [-1, 512, 16, 8]               0
          Conv2d-196           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-197           [-1, 512, 16, 8]           1,024
            ReLU-198           [-1, 512, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-201           [-1, 1024, 1, 1]               0
          Linear-202                   [-1, 64]          65,536
            ReLU-203                   [-1, 64]               0
          Linear-204                 [-1, 1024]          65,536
         Sigmoid-205                 [-1, 1024]               0
         SELayer-206          [-1, 1024, 16, 8]               0
            ReLU-207          [-1, 1024, 16, 8]               0
      Bottleneck-208          [-1, 1024, 16, 8]               0
          Conv2d-209           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-210           [-1, 256, 16, 8]             512
     BatchNorm2d-211           [-1, 256, 16, 8]             512
             IBN-212           [-1, 512, 16, 8]               0
            ReLU-213           [-1, 512, 16, 8]               0
          Conv2d-214           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-215           [-1, 512, 16, 8]           1,024
            ReLU-216           [-1, 512, 16, 8]               0
          Conv2d-217          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-218          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-219           [-1, 1024, 1, 1]               0
          Linear-220                   [-1, 64]          65,536
            ReLU-221                   [-1, 64]               0
          Linear-222                 [-1, 1024]          65,536
         Sigmoid-223                 [-1, 1024]               0
         SELayer-224          [-1, 1024, 16, 8]               0
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-228           [-1, 256, 16, 8]             512
     BatchNorm2d-229           [-1, 256, 16, 8]             512
             IBN-230           [-1, 512, 16, 8]               0
            ReLU-231           [-1, 512, 16, 8]               0
          Conv2d-232           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-233           [-1, 512, 16, 8]           1,024
            ReLU-234           [-1, 512, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-237           [-1, 1024, 1, 1]               0
          Linear-238                   [-1, 64]          65,536
            ReLU-239                   [-1, 64]               0
          Linear-240                 [-1, 1024]          65,536
         Sigmoid-241                 [-1, 1024]               0
         SELayer-242          [-1, 1024, 16, 8]               0
            ReLU-243          [-1, 1024, 16, 8]               0
      Bottleneck-244          [-1, 1024, 16, 8]               0
          Conv2d-245          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-246          [-1, 1024, 16, 8]           2,048
            ReLU-247          [-1, 1024, 16, 8]               0
          Conv2d-248          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-249          [-1, 1024, 16, 8]           2,048
            ReLU-250          [-1, 1024, 16, 8]               0
          Conv2d-251          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-252          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-253           [-1, 2048, 1, 1]               0
          Linear-254                  [-1, 128]         262,144
            ReLU-255                  [-1, 128]               0
          Linear-256                 [-1, 2048]         262,144
         Sigmoid-257                 [-1, 2048]               0
         SELayer-258          [-1, 2048, 16, 8]               0
          Conv2d-259          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-260          [-1, 2048, 16, 8]           4,096
            ReLU-261          [-1, 2048, 16, 8]               0
      Bottleneck-262          [-1, 2048, 16, 8]               0
          Conv2d-263          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-264          [-1, 1024, 16, 8]           2,048
            ReLU-265          [-1, 1024, 16, 8]               0
          Conv2d-266          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-267          [-1, 1024, 16, 8]           2,048
            ReLU-268          [-1, 1024, 16, 8]               0
          Conv2d-269          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-270          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-271           [-1, 2048, 1, 1]               0
          Linear-272                  [-1, 128]         262,144
            ReLU-273                  [-1, 128]               0
          Linear-274                 [-1, 2048]         262,144
         Sigmoid-275                 [-1, 2048]               0
         SELayer-276          [-1, 2048, 16, 8]               0
            ReLU-277          [-1, 2048, 16, 8]               0
      Bottleneck-278          [-1, 2048, 16, 8]               0
          Conv2d-279          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-280          [-1, 1024, 16, 8]           2,048
            ReLU-281          [-1, 1024, 16, 8]               0
          Conv2d-282          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-283          [-1, 1024, 16, 8]           2,048
            ReLU-284          [-1, 1024, 16, 8]               0
          Conv2d-285          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-286          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-287           [-1, 2048, 1, 1]               0
          Linear-288                  [-1, 128]         262,144
            ReLU-289                  [-1, 128]               0
          Linear-290                 [-1, 2048]         262,144
         Sigmoid-291                 [-1, 2048]               0
         SELayer-292          [-1, 2048, 16, 8]               0
            ReLU-293          [-1, 2048, 16, 8]               0
      Bottleneck-294          [-1, 2048, 16, 8]               0
================================================================
Total params: 69,349,184
Trainable params: 69,349,184
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 318.36
Params size (MB): 264.55
Estimated Total Size (MB): 583.28
----------------------------------------------------------------
**********************************************************************
**********************************************************************
wide_resnet50_2_se_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]         147,456
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
   InstanceNorm2d-21          [-1, 256, 64, 32]             512
             ReLU-22          [-1, 256, 64, 32]               0
       Bottleneck-23          [-1, 256, 64, 32]               0
           Conv2d-24          [-1, 128, 64, 32]          32,768
      BatchNorm2d-25          [-1, 128, 64, 32]             256
             ReLU-26          [-1, 128, 64, 32]               0
           Conv2d-27          [-1, 128, 64, 32]         147,456
      BatchNorm2d-28          [-1, 128, 64, 32]             256
             ReLU-29          [-1, 128, 64, 32]               0
           Conv2d-30          [-1, 256, 64, 32]          32,768
      BatchNorm2d-31          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-32            [-1, 256, 1, 1]               0
           Linear-33                   [-1, 16]           4,096
             ReLU-34                   [-1, 16]               0
           Linear-35                  [-1, 256]           4,096
          Sigmoid-36                  [-1, 256]               0
          SELayer-37          [-1, 256, 64, 32]               0
   InstanceNorm2d-38          [-1, 256, 64, 32]             512
             ReLU-39          [-1, 256, 64, 32]               0
       Bottleneck-40          [-1, 256, 64, 32]               0
           Conv2d-41          [-1, 128, 64, 32]          32,768
      BatchNorm2d-42          [-1, 128, 64, 32]             256
             ReLU-43          [-1, 128, 64, 32]               0
           Conv2d-44          [-1, 128, 64, 32]         147,456
      BatchNorm2d-45          [-1, 128, 64, 32]             256
             ReLU-46          [-1, 128, 64, 32]               0
           Conv2d-47          [-1, 256, 64, 32]          32,768
      BatchNorm2d-48          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-49            [-1, 256, 1, 1]               0
           Linear-50                   [-1, 16]           4,096
             ReLU-51                   [-1, 16]               0
           Linear-52                  [-1, 256]           4,096
          Sigmoid-53                  [-1, 256]               0
          SELayer-54          [-1, 256, 64, 32]               0
   InstanceNorm2d-55          [-1, 256, 64, 32]             512
             ReLU-56          [-1, 256, 64, 32]               0
       Bottleneck-57          [-1, 256, 64, 32]               0
           Conv2d-58          [-1, 256, 64, 32]          65,536
      BatchNorm2d-59          [-1, 256, 64, 32]             512
             ReLU-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 256, 32, 16]         589,824
      BatchNorm2d-62          [-1, 256, 32, 16]             512
             ReLU-63          [-1, 256, 32, 16]               0
           Conv2d-64          [-1, 512, 32, 16]         131,072
      BatchNorm2d-65          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-66            [-1, 512, 1, 1]               0
           Linear-67                   [-1, 32]          16,384
             ReLU-68                   [-1, 32]               0
           Linear-69                  [-1, 512]          16,384
          Sigmoid-70                  [-1, 512]               0
          SELayer-71          [-1, 512, 32, 16]               0
           Conv2d-72          [-1, 512, 32, 16]         131,072
      BatchNorm2d-73          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-74          [-1, 512, 32, 16]           1,024
             ReLU-75          [-1, 512, 32, 16]               0
       Bottleneck-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 256, 32, 16]         131,072
      BatchNorm2d-78          [-1, 256, 32, 16]             512
             ReLU-79          [-1, 256, 32, 16]               0
           Conv2d-80          [-1, 256, 32, 16]         589,824
      BatchNorm2d-81          [-1, 256, 32, 16]             512
             ReLU-82          [-1, 256, 32, 16]               0
           Conv2d-83          [-1, 512, 32, 16]         131,072
      BatchNorm2d-84          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-85            [-1, 512, 1, 1]               0
           Linear-86                   [-1, 32]          16,384
             ReLU-87                   [-1, 32]               0
           Linear-88                  [-1, 512]          16,384
          Sigmoid-89                  [-1, 512]               0
          SELayer-90          [-1, 512, 32, 16]               0
   InstanceNorm2d-91          [-1, 512, 32, 16]           1,024
             ReLU-92          [-1, 512, 32, 16]               0
       Bottleneck-93          [-1, 512, 32, 16]               0
           Conv2d-94          [-1, 256, 32, 16]         131,072
      BatchNorm2d-95          [-1, 256, 32, 16]             512
             ReLU-96          [-1, 256, 32, 16]               0
           Conv2d-97          [-1, 256, 32, 16]         589,824
      BatchNorm2d-98          [-1, 256, 32, 16]             512
             ReLU-99          [-1, 256, 32, 16]               0
          Conv2d-100          [-1, 512, 32, 16]         131,072
     BatchNorm2d-101          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-102            [-1, 512, 1, 1]               0
          Linear-103                   [-1, 32]          16,384
            ReLU-104                   [-1, 32]               0
          Linear-105                  [-1, 512]          16,384
         Sigmoid-106                  [-1, 512]               0
         SELayer-107          [-1, 512, 32, 16]               0
  InstanceNorm2d-108          [-1, 512, 32, 16]           1,024
            ReLU-109          [-1, 512, 32, 16]               0
      Bottleneck-110          [-1, 512, 32, 16]               0
          Conv2d-111          [-1, 256, 32, 16]         131,072
     BatchNorm2d-112          [-1, 256, 32, 16]             512
            ReLU-113          [-1, 256, 32, 16]               0
          Conv2d-114          [-1, 256, 32, 16]         589,824
     BatchNorm2d-115          [-1, 256, 32, 16]             512
            ReLU-116          [-1, 256, 32, 16]               0
          Conv2d-117          [-1, 512, 32, 16]         131,072
     BatchNorm2d-118          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-119            [-1, 512, 1, 1]               0
          Linear-120                   [-1, 32]          16,384
            ReLU-121                   [-1, 32]               0
          Linear-122                  [-1, 512]          16,384
         Sigmoid-123                  [-1, 512]               0
         SELayer-124          [-1, 512, 32, 16]               0
  InstanceNorm2d-125          [-1, 512, 32, 16]           1,024
            ReLU-126          [-1, 512, 32, 16]               0
      Bottleneck-127          [-1, 512, 32, 16]               0
          Conv2d-128          [-1, 512, 32, 16]         262,144
     BatchNorm2d-129          [-1, 512, 32, 16]           1,024
            ReLU-130          [-1, 512, 32, 16]               0
          Conv2d-131           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-132           [-1, 512, 16, 8]           1,024
            ReLU-133           [-1, 512, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-136           [-1, 1024, 1, 1]               0
          Linear-137                   [-1, 64]          65,536
            ReLU-138                   [-1, 64]               0
          Linear-139                 [-1, 1024]          65,536
         Sigmoid-140                 [-1, 1024]               0
         SELayer-141          [-1, 1024, 16, 8]               0
          Conv2d-142          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-143          [-1, 1024, 16, 8]           2,048
            ReLU-144          [-1, 1024, 16, 8]               0
      Bottleneck-145          [-1, 1024, 16, 8]               0
          Conv2d-146           [-1, 512, 16, 8]         524,288
     BatchNorm2d-147           [-1, 512, 16, 8]           1,024
            ReLU-148           [-1, 512, 16, 8]               0
          Conv2d-149           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-150           [-1, 512, 16, 8]           1,024
            ReLU-151           [-1, 512, 16, 8]               0
          Conv2d-152          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-153          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-154           [-1, 1024, 1, 1]               0
          Linear-155                   [-1, 64]          65,536
            ReLU-156                   [-1, 64]               0
          Linear-157                 [-1, 1024]          65,536
         Sigmoid-158                 [-1, 1024]               0
         SELayer-159          [-1, 1024, 16, 8]               0
            ReLU-160          [-1, 1024, 16, 8]               0
      Bottleneck-161          [-1, 1024, 16, 8]               0
          Conv2d-162           [-1, 512, 16, 8]         524,288
     BatchNorm2d-163           [-1, 512, 16, 8]           1,024
            ReLU-164           [-1, 512, 16, 8]               0
          Conv2d-165           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-166           [-1, 512, 16, 8]           1,024
            ReLU-167           [-1, 512, 16, 8]               0
          Conv2d-168          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-169          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-170           [-1, 1024, 1, 1]               0
          Linear-171                   [-1, 64]          65,536
            ReLU-172                   [-1, 64]               0
          Linear-173                 [-1, 1024]          65,536
         Sigmoid-174                 [-1, 1024]               0
         SELayer-175          [-1, 1024, 16, 8]               0
            ReLU-176          [-1, 1024, 16, 8]               0
      Bottleneck-177          [-1, 1024, 16, 8]               0
          Conv2d-178           [-1, 512, 16, 8]         524,288
     BatchNorm2d-179           [-1, 512, 16, 8]           1,024
            ReLU-180           [-1, 512, 16, 8]               0
          Conv2d-181           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-182           [-1, 512, 16, 8]           1,024
            ReLU-183           [-1, 512, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-186           [-1, 1024, 1, 1]               0
          Linear-187                   [-1, 64]          65,536
            ReLU-188                   [-1, 64]               0
          Linear-189                 [-1, 1024]          65,536
         Sigmoid-190                 [-1, 1024]               0
         SELayer-191          [-1, 1024, 16, 8]               0
            ReLU-192          [-1, 1024, 16, 8]               0
      Bottleneck-193          [-1, 1024, 16, 8]               0
          Conv2d-194           [-1, 512, 16, 8]         524,288
     BatchNorm2d-195           [-1, 512, 16, 8]           1,024
            ReLU-196           [-1, 512, 16, 8]               0
          Conv2d-197           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-198           [-1, 512, 16, 8]           1,024
            ReLU-199           [-1, 512, 16, 8]               0
          Conv2d-200          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-201          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-202           [-1, 1024, 1, 1]               0
          Linear-203                   [-1, 64]          65,536
            ReLU-204                   [-1, 64]               0
          Linear-205                 [-1, 1024]          65,536
         Sigmoid-206                 [-1, 1024]               0
         SELayer-207          [-1, 1024, 16, 8]               0
            ReLU-208          [-1, 1024, 16, 8]               0
      Bottleneck-209          [-1, 1024, 16, 8]               0
          Conv2d-210           [-1, 512, 16, 8]         524,288
     BatchNorm2d-211           [-1, 512, 16, 8]           1,024
            ReLU-212           [-1, 512, 16, 8]               0
          Conv2d-213           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-214           [-1, 512, 16, 8]           1,024
            ReLU-215           [-1, 512, 16, 8]               0
          Conv2d-216          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-217          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-218           [-1, 1024, 1, 1]               0
          Linear-219                   [-1, 64]          65,536
            ReLU-220                   [-1, 64]               0
          Linear-221                 [-1, 1024]          65,536
         Sigmoid-222                 [-1, 1024]               0
         SELayer-223          [-1, 1024, 16, 8]               0
            ReLU-224          [-1, 1024, 16, 8]               0
      Bottleneck-225          [-1, 1024, 16, 8]               0
          Conv2d-226          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-227          [-1, 1024, 16, 8]           2,048
            ReLU-228          [-1, 1024, 16, 8]               0
          Conv2d-229          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-230          [-1, 1024, 16, 8]           2,048
            ReLU-231          [-1, 1024, 16, 8]               0
          Conv2d-232          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-233          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-234           [-1, 2048, 1, 1]               0
          Linear-235                  [-1, 128]         262,144
            ReLU-236                  [-1, 128]               0
          Linear-237                 [-1, 2048]         262,144
         Sigmoid-238                 [-1, 2048]               0
         SELayer-239          [-1, 2048, 16, 8]               0
          Conv2d-240          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-241          [-1, 2048, 16, 8]           4,096
            ReLU-242          [-1, 2048, 16, 8]               0
      Bottleneck-243          [-1, 2048, 16, 8]               0
          Conv2d-244          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-245          [-1, 1024, 16, 8]           2,048
            ReLU-246          [-1, 1024, 16, 8]               0
          Conv2d-247          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-248          [-1, 1024, 16, 8]           2,048
            ReLU-249          [-1, 1024, 16, 8]               0
          Conv2d-250          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-251          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-252           [-1, 2048, 1, 1]               0
          Linear-253                  [-1, 128]         262,144
            ReLU-254                  [-1, 128]               0
          Linear-255                 [-1, 2048]         262,144
         Sigmoid-256                 [-1, 2048]               0
         SELayer-257          [-1, 2048, 16, 8]               0
            ReLU-258          [-1, 2048, 16, 8]               0
      Bottleneck-259          [-1, 2048, 16, 8]               0
          Conv2d-260          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-261          [-1, 1024, 16, 8]           2,048
            ReLU-262          [-1, 1024, 16, 8]               0
          Conv2d-263          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-264          [-1, 1024, 16, 8]           2,048
            ReLU-265          [-1, 1024, 16, 8]               0
          Conv2d-266          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-267          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-268           [-1, 2048, 1, 1]               0
          Linear-269                  [-1, 128]         262,144
            ReLU-270                  [-1, 128]               0
          Linear-271                 [-1, 2048]         262,144
         Sigmoid-272                 [-1, 2048]               0
         SELayer-273          [-1, 2048, 16, 8]               0
            ReLU-274          [-1, 2048, 16, 8]               0
      Bottleneck-275          [-1, 2048, 16, 8]               0
================================================================
Total params: 69,354,816
Trainable params: 69,354,816
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 320.86
Params size (MB): 264.57
Estimated Total Size (MB): 585.80
----------------------------------------------------------------
**********************************************************************
**********************************************************************
wide_resnet50_2_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
    InstanceNorm2d-6           [-1, 64, 64, 32]             128
       BatchNorm2d-7           [-1, 64, 64, 32]             128
               IBN-8          [-1, 128, 64, 32]               0
              ReLU-9          [-1, 128, 64, 32]               0
           Conv2d-10          [-1, 128, 64, 32]         147,456
      BatchNorm2d-11          [-1, 128, 64, 32]             256
             ReLU-12          [-1, 128, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          32,768
      BatchNorm2d-14          [-1, 256, 64, 32]             512
           Conv2d-15          [-1, 256, 64, 32]          16,384
      BatchNorm2d-16          [-1, 256, 64, 32]             512
             ReLU-17          [-1, 256, 64, 32]               0
       Bottleneck-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-20           [-1, 64, 64, 32]             128
      BatchNorm2d-21           [-1, 64, 64, 32]             128
              IBN-22          [-1, 128, 64, 32]               0
             ReLU-23          [-1, 128, 64, 32]               0
           Conv2d-24          [-1, 128, 64, 32]         147,456
      BatchNorm2d-25          [-1, 128, 64, 32]             256
             ReLU-26          [-1, 128, 64, 32]               0
           Conv2d-27          [-1, 256, 64, 32]          32,768
      BatchNorm2d-28          [-1, 256, 64, 32]             512
             ReLU-29          [-1, 256, 64, 32]               0
       Bottleneck-30          [-1, 256, 64, 32]               0
           Conv2d-31          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-32           [-1, 64, 64, 32]             128
      BatchNorm2d-33           [-1, 64, 64, 32]             128
              IBN-34          [-1, 128, 64, 32]               0
             ReLU-35          [-1, 128, 64, 32]               0
           Conv2d-36          [-1, 128, 64, 32]         147,456
      BatchNorm2d-37          [-1, 128, 64, 32]             256
             ReLU-38          [-1, 128, 64, 32]               0
           Conv2d-39          [-1, 256, 64, 32]          32,768
      BatchNorm2d-40          [-1, 256, 64, 32]             512
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 256, 64, 32]          65,536
   InstanceNorm2d-44          [-1, 128, 64, 32]             256
      BatchNorm2d-45          [-1, 128, 64, 32]             256
              IBN-46          [-1, 256, 64, 32]               0
             ReLU-47          [-1, 256, 64, 32]               0
           Conv2d-48          [-1, 256, 32, 16]         589,824
      BatchNorm2d-49          [-1, 256, 32, 16]             512
             ReLU-50          [-1, 256, 32, 16]               0
           Conv2d-51          [-1, 512, 32, 16]         131,072
      BatchNorm2d-52          [-1, 512, 32, 16]           1,024
           Conv2d-53          [-1, 512, 32, 16]         131,072
      BatchNorm2d-54          [-1, 512, 32, 16]           1,024
             ReLU-55          [-1, 512, 32, 16]               0
       Bottleneck-56          [-1, 512, 32, 16]               0
           Conv2d-57          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-58          [-1, 128, 32, 16]             256
      BatchNorm2d-59          [-1, 128, 32, 16]             256
              IBN-60          [-1, 256, 32, 16]               0
             ReLU-61          [-1, 256, 32, 16]               0
           Conv2d-62          [-1, 256, 32, 16]         589,824
      BatchNorm2d-63          [-1, 256, 32, 16]             512
             ReLU-64          [-1, 256, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]         131,072
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-70          [-1, 128, 32, 16]             256
      BatchNorm2d-71          [-1, 128, 32, 16]             256
              IBN-72          [-1, 256, 32, 16]               0
             ReLU-73          [-1, 256, 32, 16]               0
           Conv2d-74          [-1, 256, 32, 16]         589,824
      BatchNorm2d-75          [-1, 256, 32, 16]             512
             ReLU-76          [-1, 256, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         131,072
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-82          [-1, 128, 32, 16]             256
      BatchNorm2d-83          [-1, 128, 32, 16]             256
              IBN-84          [-1, 256, 32, 16]               0
             ReLU-85          [-1, 256, 32, 16]               0
           Conv2d-86          [-1, 256, 32, 16]         589,824
      BatchNorm2d-87          [-1, 256, 32, 16]             512
             ReLU-88          [-1, 256, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]         131,072
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
             ReLU-91          [-1, 512, 32, 16]               0
       Bottleneck-92          [-1, 512, 32, 16]               0
           Conv2d-93          [-1, 512, 32, 16]         262,144
   InstanceNorm2d-94          [-1, 256, 32, 16]             512
      BatchNorm2d-95          [-1, 256, 32, 16]             512
              IBN-96          [-1, 512, 32, 16]               0
             ReLU-97          [-1, 512, 32, 16]               0
           Conv2d-98           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-99           [-1, 512, 16, 8]           1,024
            ReLU-100           [-1, 512, 16, 8]               0
          Conv2d-101          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-102          [-1, 1024, 16, 8]           2,048
          Conv2d-103          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-104          [-1, 1024, 16, 8]           2,048
            ReLU-105          [-1, 1024, 16, 8]               0
      Bottleneck-106          [-1, 1024, 16, 8]               0
          Conv2d-107           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-108           [-1, 256, 16, 8]             512
     BatchNorm2d-109           [-1, 256, 16, 8]             512
             IBN-110           [-1, 512, 16, 8]               0
            ReLU-111           [-1, 512, 16, 8]               0
          Conv2d-112           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-113           [-1, 512, 16, 8]           1,024
            ReLU-114           [-1, 512, 16, 8]               0
          Conv2d-115          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-116          [-1, 1024, 16, 8]           2,048
            ReLU-117          [-1, 1024, 16, 8]               0
      Bottleneck-118          [-1, 1024, 16, 8]               0
          Conv2d-119           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-120           [-1, 256, 16, 8]             512
     BatchNorm2d-121           [-1, 256, 16, 8]             512
             IBN-122           [-1, 512, 16, 8]               0
            ReLU-123           [-1, 512, 16, 8]               0
          Conv2d-124           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-125           [-1, 512, 16, 8]           1,024
            ReLU-126           [-1, 512, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-132           [-1, 256, 16, 8]             512
     BatchNorm2d-133           [-1, 256, 16, 8]             512
             IBN-134           [-1, 512, 16, 8]               0
            ReLU-135           [-1, 512, 16, 8]               0
          Conv2d-136           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-137           [-1, 512, 16, 8]           1,024
            ReLU-138           [-1, 512, 16, 8]               0
          Conv2d-139          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-140          [-1, 1024, 16, 8]           2,048
            ReLU-141          [-1, 1024, 16, 8]               0
      Bottleneck-142          [-1, 1024, 16, 8]               0
          Conv2d-143           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-144           [-1, 256, 16, 8]             512
     BatchNorm2d-145           [-1, 256, 16, 8]             512
             IBN-146           [-1, 512, 16, 8]               0
            ReLU-147           [-1, 512, 16, 8]               0
          Conv2d-148           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-149           [-1, 512, 16, 8]           1,024
            ReLU-150           [-1, 512, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-156           [-1, 256, 16, 8]             512
     BatchNorm2d-157           [-1, 256, 16, 8]             512
             IBN-158           [-1, 512, 16, 8]               0
            ReLU-159           [-1, 512, 16, 8]               0
          Conv2d-160           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-161           [-1, 512, 16, 8]           1,024
            ReLU-162           [-1, 512, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
      Bottleneck-166          [-1, 1024, 16, 8]               0
          Conv2d-167          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-168          [-1, 1024, 16, 8]           2,048
            ReLU-169          [-1, 1024, 16, 8]               0
          Conv2d-170          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-171          [-1, 1024, 16, 8]           2,048
            ReLU-172          [-1, 1024, 16, 8]               0
          Conv2d-173          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-174          [-1, 2048, 16, 8]           4,096
          Conv2d-175          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-176          [-1, 2048, 16, 8]           4,096
            ReLU-177          [-1, 2048, 16, 8]               0
      Bottleneck-178          [-1, 2048, 16, 8]               0
          Conv2d-179          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-180          [-1, 1024, 16, 8]           2,048
            ReLU-181          [-1, 1024, 16, 8]               0
          Conv2d-182          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-183          [-1, 1024, 16, 8]           2,048
            ReLU-184          [-1, 1024, 16, 8]               0
          Conv2d-185          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-186          [-1, 2048, 16, 8]           4,096
            ReLU-187          [-1, 2048, 16, 8]               0
      Bottleneck-188          [-1, 2048, 16, 8]               0
          Conv2d-189          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-190          [-1, 1024, 16, 8]           2,048
            ReLU-191          [-1, 1024, 16, 8]               0
          Conv2d-192          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-193          [-1, 1024, 16, 8]           2,048
            ReLU-194          [-1, 1024, 16, 8]               0
          Conv2d-195          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-196          [-1, 2048, 16, 8]           4,096
            ReLU-197          [-1, 2048, 16, 8]               0
      Bottleneck-198          [-1, 2048, 16, 8]               0
================================================================
Total params: 66,834,240
Trainable params: 66,834,240
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 286.00
Params size (MB): 254.95
Estimated Total Size (MB): 541.33
----------------------------------------------------------------
**********************************************************************
**********************************************************************
wide_resnet50_2_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]         147,456
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
   InstanceNorm2d-15          [-1, 256, 64, 32]             512
             ReLU-16          [-1, 256, 64, 32]               0
       Bottleneck-17          [-1, 256, 64, 32]               0
           Conv2d-18          [-1, 128, 64, 32]          32,768
      BatchNorm2d-19          [-1, 128, 64, 32]             256
             ReLU-20          [-1, 128, 64, 32]               0
           Conv2d-21          [-1, 128, 64, 32]         147,456
      BatchNorm2d-22          [-1, 128, 64, 32]             256
             ReLU-23          [-1, 128, 64, 32]               0
           Conv2d-24          [-1, 256, 64, 32]          32,768
      BatchNorm2d-25          [-1, 256, 64, 32]             512
   InstanceNorm2d-26          [-1, 256, 64, 32]             512
             ReLU-27          [-1, 256, 64, 32]               0
       Bottleneck-28          [-1, 256, 64, 32]               0
           Conv2d-29          [-1, 128, 64, 32]          32,768
      BatchNorm2d-30          [-1, 128, 64, 32]             256
             ReLU-31          [-1, 128, 64, 32]               0
           Conv2d-32          [-1, 128, 64, 32]         147,456
      BatchNorm2d-33          [-1, 128, 64, 32]             256
             ReLU-34          [-1, 128, 64, 32]               0
           Conv2d-35          [-1, 256, 64, 32]          32,768
      BatchNorm2d-36          [-1, 256, 64, 32]             512
   InstanceNorm2d-37          [-1, 256, 64, 32]             512
             ReLU-38          [-1, 256, 64, 32]               0
       Bottleneck-39          [-1, 256, 64, 32]               0
           Conv2d-40          [-1, 256, 64, 32]          65,536
      BatchNorm2d-41          [-1, 256, 64, 32]             512
             ReLU-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 256, 32, 16]         589,824
      BatchNorm2d-44          [-1, 256, 32, 16]             512
             ReLU-45          [-1, 256, 32, 16]               0
           Conv2d-46          [-1, 512, 32, 16]         131,072
      BatchNorm2d-47          [-1, 512, 32, 16]           1,024
           Conv2d-48          [-1, 512, 32, 16]         131,072
      BatchNorm2d-49          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-50          [-1, 512, 32, 16]           1,024
             ReLU-51          [-1, 512, 32, 16]               0
       Bottleneck-52          [-1, 512, 32, 16]               0
           Conv2d-53          [-1, 256, 32, 16]         131,072
      BatchNorm2d-54          [-1, 256, 32, 16]             512
             ReLU-55          [-1, 256, 32, 16]               0
           Conv2d-56          [-1, 256, 32, 16]         589,824
      BatchNorm2d-57          [-1, 256, 32, 16]             512
             ReLU-58          [-1, 256, 32, 16]               0
           Conv2d-59          [-1, 512, 32, 16]         131,072
      BatchNorm2d-60          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-61          [-1, 512, 32, 16]           1,024
             ReLU-62          [-1, 512, 32, 16]               0
       Bottleneck-63          [-1, 512, 32, 16]               0
           Conv2d-64          [-1, 256, 32, 16]         131,072
      BatchNorm2d-65          [-1, 256, 32, 16]             512
             ReLU-66          [-1, 256, 32, 16]               0
           Conv2d-67          [-1, 256, 32, 16]         589,824
      BatchNorm2d-68          [-1, 256, 32, 16]             512
             ReLU-69          [-1, 256, 32, 16]               0
           Conv2d-70          [-1, 512, 32, 16]         131,072
      BatchNorm2d-71          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-72          [-1, 512, 32, 16]           1,024
             ReLU-73          [-1, 512, 32, 16]               0
       Bottleneck-74          [-1, 512, 32, 16]               0
           Conv2d-75          [-1, 256, 32, 16]         131,072
      BatchNorm2d-76          [-1, 256, 32, 16]             512
             ReLU-77          [-1, 256, 32, 16]               0
           Conv2d-78          [-1, 256, 32, 16]         589,824
      BatchNorm2d-79          [-1, 256, 32, 16]             512
             ReLU-80          [-1, 256, 32, 16]               0
           Conv2d-81          [-1, 512, 32, 16]         131,072
      BatchNorm2d-82          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-83          [-1, 512, 32, 16]           1,024
             ReLU-84          [-1, 512, 32, 16]               0
       Bottleneck-85          [-1, 512, 32, 16]               0
           Conv2d-86          [-1, 512, 32, 16]         262,144
      BatchNorm2d-87          [-1, 512, 32, 16]           1,024
             ReLU-88          [-1, 512, 32, 16]               0
           Conv2d-89           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-90           [-1, 512, 16, 8]           1,024
             ReLU-91           [-1, 512, 16, 8]               0
           Conv2d-92          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-93          [-1, 1024, 16, 8]           2,048
           Conv2d-94          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-95          [-1, 1024, 16, 8]           2,048
             ReLU-96          [-1, 1024, 16, 8]               0
       Bottleneck-97          [-1, 1024, 16, 8]               0
           Conv2d-98           [-1, 512, 16, 8]         524,288
      BatchNorm2d-99           [-1, 512, 16, 8]           1,024
            ReLU-100           [-1, 512, 16, 8]               0
          Conv2d-101           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-102           [-1, 512, 16, 8]           1,024
            ReLU-103           [-1, 512, 16, 8]               0
          Conv2d-104          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-105          [-1, 1024, 16, 8]           2,048
            ReLU-106          [-1, 1024, 16, 8]               0
      Bottleneck-107          [-1, 1024, 16, 8]               0
          Conv2d-108           [-1, 512, 16, 8]         524,288
     BatchNorm2d-109           [-1, 512, 16, 8]           1,024
            ReLU-110           [-1, 512, 16, 8]               0
          Conv2d-111           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-112           [-1, 512, 16, 8]           1,024
            ReLU-113           [-1, 512, 16, 8]               0
          Conv2d-114          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-115          [-1, 1024, 16, 8]           2,048
            ReLU-116          [-1, 1024, 16, 8]               0
      Bottleneck-117          [-1, 1024, 16, 8]               0
          Conv2d-118           [-1, 512, 16, 8]         524,288
     BatchNorm2d-119           [-1, 512, 16, 8]           1,024
            ReLU-120           [-1, 512, 16, 8]               0
          Conv2d-121           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-122           [-1, 512, 16, 8]           1,024
            ReLU-123           [-1, 512, 16, 8]               0
          Conv2d-124          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-125          [-1, 1024, 16, 8]           2,048
            ReLU-126          [-1, 1024, 16, 8]               0
      Bottleneck-127          [-1, 1024, 16, 8]               0
          Conv2d-128           [-1, 512, 16, 8]         524,288
     BatchNorm2d-129           [-1, 512, 16, 8]           1,024
            ReLU-130           [-1, 512, 16, 8]               0
          Conv2d-131           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-132           [-1, 512, 16, 8]           1,024
            ReLU-133           [-1, 512, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
            ReLU-136          [-1, 1024, 16, 8]               0
      Bottleneck-137          [-1, 1024, 16, 8]               0
          Conv2d-138           [-1, 512, 16, 8]         524,288
     BatchNorm2d-139           [-1, 512, 16, 8]           1,024
            ReLU-140           [-1, 512, 16, 8]               0
          Conv2d-141           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-142           [-1, 512, 16, 8]           1,024
            ReLU-143           [-1, 512, 16, 8]               0
          Conv2d-144          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-145          [-1, 1024, 16, 8]           2,048
            ReLU-146          [-1, 1024, 16, 8]               0
      Bottleneck-147          [-1, 1024, 16, 8]               0
          Conv2d-148          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-149          [-1, 1024, 16, 8]           2,048
            ReLU-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
          Conv2d-154          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-155          [-1, 2048, 16, 8]           4,096
          Conv2d-156          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-157          [-1, 2048, 16, 8]           4,096
            ReLU-158          [-1, 2048, 16, 8]               0
      Bottleneck-159          [-1, 2048, 16, 8]               0
          Conv2d-160          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-161          [-1, 1024, 16, 8]           2,048
            ReLU-162          [-1, 1024, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
          Conv2d-166          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-167          [-1, 2048, 16, 8]           4,096
            ReLU-168          [-1, 2048, 16, 8]               0
      Bottleneck-169          [-1, 2048, 16, 8]               0
          Conv2d-170          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-171          [-1, 1024, 16, 8]           2,048
            ReLU-172          [-1, 1024, 16, 8]               0
          Conv2d-173          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-174          [-1, 1024, 16, 8]           2,048
            ReLU-175          [-1, 1024, 16, 8]               0
          Conv2d-176          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-177          [-1, 2048, 16, 8]           4,096
            ReLU-178          [-1, 2048, 16, 8]               0
      Bottleneck-179          [-1, 2048, 16, 8]               0
================================================================
Total params: 66,839,872
Trainable params: 66,839,872
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 288.50
Params size (MB): 254.97
Estimated Total Size (MB): 543.85
----------------------------------------------------------------
**********************************************************************
**********************************************************************
wide_resnet101_2_se
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]         147,456
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
             ReLU-21          [-1, 256, 64, 32]               0
       Bottleneck-22          [-1, 256, 64, 32]               0
           Conv2d-23          [-1, 128, 64, 32]          32,768
      BatchNorm2d-24          [-1, 128, 64, 32]             256
             ReLU-25          [-1, 128, 64, 32]               0
           Conv2d-26          [-1, 128, 64, 32]         147,456
      BatchNorm2d-27          [-1, 128, 64, 32]             256
             ReLU-28          [-1, 128, 64, 32]               0
           Conv2d-29          [-1, 256, 64, 32]          32,768
      BatchNorm2d-30          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-31            [-1, 256, 1, 1]               0
           Linear-32                   [-1, 16]           4,096
             ReLU-33                   [-1, 16]               0
           Linear-34                  [-1, 256]           4,096
          Sigmoid-35                  [-1, 256]               0
          SELayer-36          [-1, 256, 64, 32]               0
             ReLU-37          [-1, 256, 64, 32]               0
       Bottleneck-38          [-1, 256, 64, 32]               0
           Conv2d-39          [-1, 128, 64, 32]          32,768
      BatchNorm2d-40          [-1, 128, 64, 32]             256
             ReLU-41          [-1, 128, 64, 32]               0
           Conv2d-42          [-1, 128, 64, 32]         147,456
      BatchNorm2d-43          [-1, 128, 64, 32]             256
             ReLU-44          [-1, 128, 64, 32]               0
           Conv2d-45          [-1, 256, 64, 32]          32,768
      BatchNorm2d-46          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-47            [-1, 256, 1, 1]               0
           Linear-48                   [-1, 16]           4,096
             ReLU-49                   [-1, 16]               0
           Linear-50                  [-1, 256]           4,096
          Sigmoid-51                  [-1, 256]               0
          SELayer-52          [-1, 256, 64, 32]               0
             ReLU-53          [-1, 256, 64, 32]               0
       Bottleneck-54          [-1, 256, 64, 32]               0
           Conv2d-55          [-1, 256, 64, 32]          65,536
      BatchNorm2d-56          [-1, 256, 64, 32]             512
             ReLU-57          [-1, 256, 64, 32]               0
           Conv2d-58          [-1, 256, 32, 16]         589,824
      BatchNorm2d-59          [-1, 256, 32, 16]             512
             ReLU-60          [-1, 256, 32, 16]               0
           Conv2d-61          [-1, 512, 32, 16]         131,072
      BatchNorm2d-62          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-63            [-1, 512, 1, 1]               0
           Linear-64                   [-1, 32]          16,384
             ReLU-65                   [-1, 32]               0
           Linear-66                  [-1, 512]          16,384
          Sigmoid-67                  [-1, 512]               0
          SELayer-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         131,072
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
             ReLU-71          [-1, 512, 32, 16]               0
       Bottleneck-72          [-1, 512, 32, 16]               0
           Conv2d-73          [-1, 256, 32, 16]         131,072
      BatchNorm2d-74          [-1, 256, 32, 16]             512
             ReLU-75          [-1, 256, 32, 16]               0
           Conv2d-76          [-1, 256, 32, 16]         589,824
      BatchNorm2d-77          [-1, 256, 32, 16]             512
             ReLU-78          [-1, 256, 32, 16]               0
           Conv2d-79          [-1, 512, 32, 16]         131,072
      BatchNorm2d-80          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-81            [-1, 512, 1, 1]               0
           Linear-82                   [-1, 32]          16,384
             ReLU-83                   [-1, 32]               0
           Linear-84                  [-1, 512]          16,384
          Sigmoid-85                  [-1, 512]               0
          SELayer-86          [-1, 512, 32, 16]               0
             ReLU-87          [-1, 512, 32, 16]               0
       Bottleneck-88          [-1, 512, 32, 16]               0
           Conv2d-89          [-1, 256, 32, 16]         131,072
      BatchNorm2d-90          [-1, 256, 32, 16]             512
             ReLU-91          [-1, 256, 32, 16]               0
           Conv2d-92          [-1, 256, 32, 16]         589,824
      BatchNorm2d-93          [-1, 256, 32, 16]             512
             ReLU-94          [-1, 256, 32, 16]               0
           Conv2d-95          [-1, 512, 32, 16]         131,072
      BatchNorm2d-96          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-97            [-1, 512, 1, 1]               0
           Linear-98                   [-1, 32]          16,384
             ReLU-99                   [-1, 32]               0
          Linear-100                  [-1, 512]          16,384
         Sigmoid-101                  [-1, 512]               0
         SELayer-102          [-1, 512, 32, 16]               0
            ReLU-103          [-1, 512, 32, 16]               0
      Bottleneck-104          [-1, 512, 32, 16]               0
          Conv2d-105          [-1, 256, 32, 16]         131,072
     BatchNorm2d-106          [-1, 256, 32, 16]             512
            ReLU-107          [-1, 256, 32, 16]               0
          Conv2d-108          [-1, 256, 32, 16]         589,824
     BatchNorm2d-109          [-1, 256, 32, 16]             512
            ReLU-110          [-1, 256, 32, 16]               0
          Conv2d-111          [-1, 512, 32, 16]         131,072
     BatchNorm2d-112          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-113            [-1, 512, 1, 1]               0
          Linear-114                   [-1, 32]          16,384
            ReLU-115                   [-1, 32]               0
          Linear-116                  [-1, 512]          16,384
         Sigmoid-117                  [-1, 512]               0
         SELayer-118          [-1, 512, 32, 16]               0
            ReLU-119          [-1, 512, 32, 16]               0
      Bottleneck-120          [-1, 512, 32, 16]               0
          Conv2d-121          [-1, 512, 32, 16]         262,144
     BatchNorm2d-122          [-1, 512, 32, 16]           1,024
            ReLU-123          [-1, 512, 32, 16]               0
          Conv2d-124           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-125           [-1, 512, 16, 8]           1,024
            ReLU-126           [-1, 512, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-129           [-1, 1024, 1, 1]               0
          Linear-130                   [-1, 64]          65,536
            ReLU-131                   [-1, 64]               0
          Linear-132                 [-1, 1024]          65,536
         Sigmoid-133                 [-1, 1024]               0
         SELayer-134          [-1, 1024, 16, 8]               0
          Conv2d-135          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-136          [-1, 1024, 16, 8]           2,048
            ReLU-137          [-1, 1024, 16, 8]               0
      Bottleneck-138          [-1, 1024, 16, 8]               0
          Conv2d-139           [-1, 512, 16, 8]         524,288
     BatchNorm2d-140           [-1, 512, 16, 8]           1,024
            ReLU-141           [-1, 512, 16, 8]               0
          Conv2d-142           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-143           [-1, 512, 16, 8]           1,024
            ReLU-144           [-1, 512, 16, 8]               0
          Conv2d-145          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-146          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-147           [-1, 1024, 1, 1]               0
          Linear-148                   [-1, 64]          65,536
            ReLU-149                   [-1, 64]               0
          Linear-150                 [-1, 1024]          65,536
         Sigmoid-151                 [-1, 1024]               0
         SELayer-152          [-1, 1024, 16, 8]               0
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 512, 16, 8]         524,288
     BatchNorm2d-156           [-1, 512, 16, 8]           1,024
            ReLU-157           [-1, 512, 16, 8]               0
          Conv2d-158           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-159           [-1, 512, 16, 8]           1,024
            ReLU-160           [-1, 512, 16, 8]               0
          Conv2d-161          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-162          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-163           [-1, 1024, 1, 1]               0
          Linear-164                   [-1, 64]          65,536
            ReLU-165                   [-1, 64]               0
          Linear-166                 [-1, 1024]          65,536
         Sigmoid-167                 [-1, 1024]               0
         SELayer-168          [-1, 1024, 16, 8]               0
            ReLU-169          [-1, 1024, 16, 8]               0
      Bottleneck-170          [-1, 1024, 16, 8]               0
          Conv2d-171           [-1, 512, 16, 8]         524,288
     BatchNorm2d-172           [-1, 512, 16, 8]           1,024
            ReLU-173           [-1, 512, 16, 8]               0
          Conv2d-174           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-175           [-1, 512, 16, 8]           1,024
            ReLU-176           [-1, 512, 16, 8]               0
          Conv2d-177          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-178          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-179           [-1, 1024, 1, 1]               0
          Linear-180                   [-1, 64]          65,536
            ReLU-181                   [-1, 64]               0
          Linear-182                 [-1, 1024]          65,536
         Sigmoid-183                 [-1, 1024]               0
         SELayer-184          [-1, 1024, 16, 8]               0
            ReLU-185          [-1, 1024, 16, 8]               0
      Bottleneck-186          [-1, 1024, 16, 8]               0
          Conv2d-187           [-1, 512, 16, 8]         524,288
     BatchNorm2d-188           [-1, 512, 16, 8]           1,024
            ReLU-189           [-1, 512, 16, 8]               0
          Conv2d-190           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-191           [-1, 512, 16, 8]           1,024
            ReLU-192           [-1, 512, 16, 8]               0
          Conv2d-193          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-194          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-195           [-1, 1024, 1, 1]               0
          Linear-196                   [-1, 64]          65,536
            ReLU-197                   [-1, 64]               0
          Linear-198                 [-1, 1024]          65,536
         Sigmoid-199                 [-1, 1024]               0
         SELayer-200          [-1, 1024, 16, 8]               0
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203           [-1, 512, 16, 8]         524,288
     BatchNorm2d-204           [-1, 512, 16, 8]           1,024
            ReLU-205           [-1, 512, 16, 8]               0
          Conv2d-206           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-207           [-1, 512, 16, 8]           1,024
            ReLU-208           [-1, 512, 16, 8]               0
          Conv2d-209          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-210          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-211           [-1, 1024, 1, 1]               0
          Linear-212                   [-1, 64]          65,536
            ReLU-213                   [-1, 64]               0
          Linear-214                 [-1, 1024]          65,536
         Sigmoid-215                 [-1, 1024]               0
         SELayer-216          [-1, 1024, 16, 8]               0
            ReLU-217          [-1, 1024, 16, 8]               0
      Bottleneck-218          [-1, 1024, 16, 8]               0
          Conv2d-219           [-1, 512, 16, 8]         524,288
     BatchNorm2d-220           [-1, 512, 16, 8]           1,024
            ReLU-221           [-1, 512, 16, 8]               0
          Conv2d-222           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-223           [-1, 512, 16, 8]           1,024
            ReLU-224           [-1, 512, 16, 8]               0
          Conv2d-225          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-226          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-227           [-1, 1024, 1, 1]               0
          Linear-228                   [-1, 64]          65,536
            ReLU-229                   [-1, 64]               0
          Linear-230                 [-1, 1024]          65,536
         Sigmoid-231                 [-1, 1024]               0
         SELayer-232          [-1, 1024, 16, 8]               0
            ReLU-233          [-1, 1024, 16, 8]               0
      Bottleneck-234          [-1, 1024, 16, 8]               0
          Conv2d-235           [-1, 512, 16, 8]         524,288
     BatchNorm2d-236           [-1, 512, 16, 8]           1,024
            ReLU-237           [-1, 512, 16, 8]               0
          Conv2d-238           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-239           [-1, 512, 16, 8]           1,024
            ReLU-240           [-1, 512, 16, 8]               0
          Conv2d-241          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-242          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-243           [-1, 1024, 1, 1]               0
          Linear-244                   [-1, 64]          65,536
            ReLU-245                   [-1, 64]               0
          Linear-246                 [-1, 1024]          65,536
         Sigmoid-247                 [-1, 1024]               0
         SELayer-248          [-1, 1024, 16, 8]               0
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251           [-1, 512, 16, 8]         524,288
     BatchNorm2d-252           [-1, 512, 16, 8]           1,024
            ReLU-253           [-1, 512, 16, 8]               0
          Conv2d-254           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-255           [-1, 512, 16, 8]           1,024
            ReLU-256           [-1, 512, 16, 8]               0
          Conv2d-257          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-258          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-259           [-1, 1024, 1, 1]               0
          Linear-260                   [-1, 64]          65,536
            ReLU-261                   [-1, 64]               0
          Linear-262                 [-1, 1024]          65,536
         Sigmoid-263                 [-1, 1024]               0
         SELayer-264          [-1, 1024, 16, 8]               0
            ReLU-265          [-1, 1024, 16, 8]               0
      Bottleneck-266          [-1, 1024, 16, 8]               0
          Conv2d-267           [-1, 512, 16, 8]         524,288
     BatchNorm2d-268           [-1, 512, 16, 8]           1,024
            ReLU-269           [-1, 512, 16, 8]               0
          Conv2d-270           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-271           [-1, 512, 16, 8]           1,024
            ReLU-272           [-1, 512, 16, 8]               0
          Conv2d-273          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-274          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-275           [-1, 1024, 1, 1]               0
          Linear-276                   [-1, 64]          65,536
            ReLU-277                   [-1, 64]               0
          Linear-278                 [-1, 1024]          65,536
         Sigmoid-279                 [-1, 1024]               0
         SELayer-280          [-1, 1024, 16, 8]               0
            ReLU-281          [-1, 1024, 16, 8]               0
      Bottleneck-282          [-1, 1024, 16, 8]               0
          Conv2d-283           [-1, 512, 16, 8]         524,288
     BatchNorm2d-284           [-1, 512, 16, 8]           1,024
            ReLU-285           [-1, 512, 16, 8]               0
          Conv2d-286           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-287           [-1, 512, 16, 8]           1,024
            ReLU-288           [-1, 512, 16, 8]               0
          Conv2d-289          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-290          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-291           [-1, 1024, 1, 1]               0
          Linear-292                   [-1, 64]          65,536
            ReLU-293                   [-1, 64]               0
          Linear-294                 [-1, 1024]          65,536
         Sigmoid-295                 [-1, 1024]               0
         SELayer-296          [-1, 1024, 16, 8]               0
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299           [-1, 512, 16, 8]         524,288
     BatchNorm2d-300           [-1, 512, 16, 8]           1,024
            ReLU-301           [-1, 512, 16, 8]               0
          Conv2d-302           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-303           [-1, 512, 16, 8]           1,024
            ReLU-304           [-1, 512, 16, 8]               0
          Conv2d-305          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-306          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-307           [-1, 1024, 1, 1]               0
          Linear-308                   [-1, 64]          65,536
            ReLU-309                   [-1, 64]               0
          Linear-310                 [-1, 1024]          65,536
         Sigmoid-311                 [-1, 1024]               0
         SELayer-312          [-1, 1024, 16, 8]               0
            ReLU-313          [-1, 1024, 16, 8]               0
      Bottleneck-314          [-1, 1024, 16, 8]               0
          Conv2d-315           [-1, 512, 16, 8]         524,288
     BatchNorm2d-316           [-1, 512, 16, 8]           1,024
            ReLU-317           [-1, 512, 16, 8]               0
          Conv2d-318           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-319           [-1, 512, 16, 8]           1,024
            ReLU-320           [-1, 512, 16, 8]               0
          Conv2d-321          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-322          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-323           [-1, 1024, 1, 1]               0
          Linear-324                   [-1, 64]          65,536
            ReLU-325                   [-1, 64]               0
          Linear-326                 [-1, 1024]          65,536
         Sigmoid-327                 [-1, 1024]               0
         SELayer-328          [-1, 1024, 16, 8]               0
            ReLU-329          [-1, 1024, 16, 8]               0
      Bottleneck-330          [-1, 1024, 16, 8]               0
          Conv2d-331           [-1, 512, 16, 8]         524,288
     BatchNorm2d-332           [-1, 512, 16, 8]           1,024
            ReLU-333           [-1, 512, 16, 8]               0
          Conv2d-334           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-335           [-1, 512, 16, 8]           1,024
            ReLU-336           [-1, 512, 16, 8]               0
          Conv2d-337          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-338          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-339           [-1, 1024, 1, 1]               0
          Linear-340                   [-1, 64]          65,536
            ReLU-341                   [-1, 64]               0
          Linear-342                 [-1, 1024]          65,536
         Sigmoid-343                 [-1, 1024]               0
         SELayer-344          [-1, 1024, 16, 8]               0
            ReLU-345          [-1, 1024, 16, 8]               0
      Bottleneck-346          [-1, 1024, 16, 8]               0
          Conv2d-347           [-1, 512, 16, 8]         524,288
     BatchNorm2d-348           [-1, 512, 16, 8]           1,024
            ReLU-349           [-1, 512, 16, 8]               0
          Conv2d-350           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-351           [-1, 512, 16, 8]           1,024
            ReLU-352           [-1, 512, 16, 8]               0
          Conv2d-353          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-354          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-355           [-1, 1024, 1, 1]               0
          Linear-356                   [-1, 64]          65,536
            ReLU-357                   [-1, 64]               0
          Linear-358                 [-1, 1024]          65,536
         Sigmoid-359                 [-1, 1024]               0
         SELayer-360          [-1, 1024, 16, 8]               0
            ReLU-361          [-1, 1024, 16, 8]               0
      Bottleneck-362          [-1, 1024, 16, 8]               0
          Conv2d-363           [-1, 512, 16, 8]         524,288
     BatchNorm2d-364           [-1, 512, 16, 8]           1,024
            ReLU-365           [-1, 512, 16, 8]               0
          Conv2d-366           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-367           [-1, 512, 16, 8]           1,024
            ReLU-368           [-1, 512, 16, 8]               0
          Conv2d-369          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-370          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-371           [-1, 1024, 1, 1]               0
          Linear-372                   [-1, 64]          65,536
            ReLU-373                   [-1, 64]               0
          Linear-374                 [-1, 1024]          65,536
         Sigmoid-375                 [-1, 1024]               0
         SELayer-376          [-1, 1024, 16, 8]               0
            ReLU-377          [-1, 1024, 16, 8]               0
      Bottleneck-378          [-1, 1024, 16, 8]               0
          Conv2d-379           [-1, 512, 16, 8]         524,288
     BatchNorm2d-380           [-1, 512, 16, 8]           1,024
            ReLU-381           [-1, 512, 16, 8]               0
          Conv2d-382           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-383           [-1, 512, 16, 8]           1,024
            ReLU-384           [-1, 512, 16, 8]               0
          Conv2d-385          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-386          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-387           [-1, 1024, 1, 1]               0
          Linear-388                   [-1, 64]          65,536
            ReLU-389                   [-1, 64]               0
          Linear-390                 [-1, 1024]          65,536
         Sigmoid-391                 [-1, 1024]               0
         SELayer-392          [-1, 1024, 16, 8]               0
            ReLU-393          [-1, 1024, 16, 8]               0
      Bottleneck-394          [-1, 1024, 16, 8]               0
          Conv2d-395           [-1, 512, 16, 8]         524,288
     BatchNorm2d-396           [-1, 512, 16, 8]           1,024
            ReLU-397           [-1, 512, 16, 8]               0
          Conv2d-398           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-399           [-1, 512, 16, 8]           1,024
            ReLU-400           [-1, 512, 16, 8]               0
          Conv2d-401          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-402          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-403           [-1, 1024, 1, 1]               0
          Linear-404                   [-1, 64]          65,536
            ReLU-405                   [-1, 64]               0
          Linear-406                 [-1, 1024]          65,536
         Sigmoid-407                 [-1, 1024]               0
         SELayer-408          [-1, 1024, 16, 8]               0
            ReLU-409          [-1, 1024, 16, 8]               0
      Bottleneck-410          [-1, 1024, 16, 8]               0
          Conv2d-411           [-1, 512, 16, 8]         524,288
     BatchNorm2d-412           [-1, 512, 16, 8]           1,024
            ReLU-413           [-1, 512, 16, 8]               0
          Conv2d-414           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-415           [-1, 512, 16, 8]           1,024
            ReLU-416           [-1, 512, 16, 8]               0
          Conv2d-417          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-418          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-419           [-1, 1024, 1, 1]               0
          Linear-420                   [-1, 64]          65,536
            ReLU-421                   [-1, 64]               0
          Linear-422                 [-1, 1024]          65,536
         Sigmoid-423                 [-1, 1024]               0
         SELayer-424          [-1, 1024, 16, 8]               0
            ReLU-425          [-1, 1024, 16, 8]               0
      Bottleneck-426          [-1, 1024, 16, 8]               0
          Conv2d-427           [-1, 512, 16, 8]         524,288
     BatchNorm2d-428           [-1, 512, 16, 8]           1,024
            ReLU-429           [-1, 512, 16, 8]               0
          Conv2d-430           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-431           [-1, 512, 16, 8]           1,024
            ReLU-432           [-1, 512, 16, 8]               0
          Conv2d-433          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-434          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-435           [-1, 1024, 1, 1]               0
          Linear-436                   [-1, 64]          65,536
            ReLU-437                   [-1, 64]               0
          Linear-438                 [-1, 1024]          65,536
         Sigmoid-439                 [-1, 1024]               0
         SELayer-440          [-1, 1024, 16, 8]               0
            ReLU-441          [-1, 1024, 16, 8]               0
      Bottleneck-442          [-1, 1024, 16, 8]               0
          Conv2d-443           [-1, 512, 16, 8]         524,288
     BatchNorm2d-444           [-1, 512, 16, 8]           1,024
            ReLU-445           [-1, 512, 16, 8]               0
          Conv2d-446           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-447           [-1, 512, 16, 8]           1,024
            ReLU-448           [-1, 512, 16, 8]               0
          Conv2d-449          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-450          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-451           [-1, 1024, 1, 1]               0
          Linear-452                   [-1, 64]          65,536
            ReLU-453                   [-1, 64]               0
          Linear-454                 [-1, 1024]          65,536
         Sigmoid-455                 [-1, 1024]               0
         SELayer-456          [-1, 1024, 16, 8]               0
            ReLU-457          [-1, 1024, 16, 8]               0
      Bottleneck-458          [-1, 1024, 16, 8]               0
          Conv2d-459           [-1, 512, 16, 8]         524,288
     BatchNorm2d-460           [-1, 512, 16, 8]           1,024
            ReLU-461           [-1, 512, 16, 8]               0
          Conv2d-462           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-463           [-1, 512, 16, 8]           1,024
            ReLU-464           [-1, 512, 16, 8]               0
          Conv2d-465          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-466          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-467           [-1, 1024, 1, 1]               0
          Linear-468                   [-1, 64]          65,536
            ReLU-469                   [-1, 64]               0
          Linear-470                 [-1, 1024]          65,536
         Sigmoid-471                 [-1, 1024]               0
         SELayer-472          [-1, 1024, 16, 8]               0
            ReLU-473          [-1, 1024, 16, 8]               0
      Bottleneck-474          [-1, 1024, 16, 8]               0
          Conv2d-475           [-1, 512, 16, 8]         524,288
     BatchNorm2d-476           [-1, 512, 16, 8]           1,024
            ReLU-477           [-1, 512, 16, 8]               0
          Conv2d-478           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-479           [-1, 512, 16, 8]           1,024
            ReLU-480           [-1, 512, 16, 8]               0
          Conv2d-481          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-482          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-483           [-1, 1024, 1, 1]               0
          Linear-484                   [-1, 64]          65,536
            ReLU-485                   [-1, 64]               0
          Linear-486                 [-1, 1024]          65,536
         Sigmoid-487                 [-1, 1024]               0
         SELayer-488          [-1, 1024, 16, 8]               0
            ReLU-489          [-1, 1024, 16, 8]               0
      Bottleneck-490          [-1, 1024, 16, 8]               0
          Conv2d-491          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-492          [-1, 1024, 16, 8]           2,048
            ReLU-493          [-1, 1024, 16, 8]               0
          Conv2d-494          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-495          [-1, 1024, 16, 8]           2,048
            ReLU-496          [-1, 1024, 16, 8]               0
          Conv2d-497          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-498          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-499           [-1, 2048, 1, 1]               0
          Linear-500                  [-1, 128]         262,144
            ReLU-501                  [-1, 128]               0
          Linear-502                 [-1, 2048]         262,144
         Sigmoid-503                 [-1, 2048]               0
         SELayer-504          [-1, 2048, 16, 8]               0
          Conv2d-505          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-506          [-1, 2048, 16, 8]           4,096
            ReLU-507          [-1, 2048, 16, 8]               0
      Bottleneck-508          [-1, 2048, 16, 8]               0
          Conv2d-509          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-510          [-1, 1024, 16, 8]           2,048
            ReLU-511          [-1, 1024, 16, 8]               0
          Conv2d-512          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-513          [-1, 1024, 16, 8]           2,048
            ReLU-514          [-1, 1024, 16, 8]               0
          Conv2d-515          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-516          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-517           [-1, 2048, 1, 1]               0
          Linear-518                  [-1, 128]         262,144
            ReLU-519                  [-1, 128]               0
          Linear-520                 [-1, 2048]         262,144
         Sigmoid-521                 [-1, 2048]               0
         SELayer-522          [-1, 2048, 16, 8]               0
            ReLU-523          [-1, 2048, 16, 8]               0
      Bottleneck-524          [-1, 2048, 16, 8]               0
          Conv2d-525          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-526          [-1, 1024, 16, 8]           2,048
            ReLU-527          [-1, 1024, 16, 8]               0
          Conv2d-528          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-529          [-1, 1024, 16, 8]           2,048
            ReLU-530          [-1, 1024, 16, 8]               0
          Conv2d-531          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-532          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-533           [-1, 2048, 1, 1]               0
          Linear-534                  [-1, 128]         262,144
            ReLU-535                  [-1, 128]               0
          Linear-536                 [-1, 2048]         262,144
         Sigmoid-537                 [-1, 2048]               0
         SELayer-538          [-1, 2048, 16, 8]               0
            ReLU-539          [-1, 2048, 16, 8]               0
      Bottleneck-540          [-1, 2048, 16, 8]               0
================================================================
Total params: 129,580,864
Trainable params: 129,580,864
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 437.28
Params size (MB): 494.31
Estimated Total Size (MB): 931.96
----------------------------------------------------------------
**********************************************************************
**********************************************************************
wide_resnet101_2_se_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
    InstanceNorm2d-6           [-1, 64, 64, 32]             128
       BatchNorm2d-7           [-1, 64, 64, 32]             128
               IBN-8          [-1, 128, 64, 32]               0
              ReLU-9          [-1, 128, 64, 32]               0
           Conv2d-10          [-1, 128, 64, 32]         147,456
      BatchNorm2d-11          [-1, 128, 64, 32]             256
             ReLU-12          [-1, 128, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          32,768
      BatchNorm2d-14          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-15            [-1, 256, 1, 1]               0
           Linear-16                   [-1, 16]           4,096
             ReLU-17                   [-1, 16]               0
           Linear-18                  [-1, 256]           4,096
          Sigmoid-19                  [-1, 256]               0
          SELayer-20          [-1, 256, 64, 32]               0
           Conv2d-21          [-1, 256, 64, 32]          16,384
      BatchNorm2d-22          [-1, 256, 64, 32]             512
             ReLU-23          [-1, 256, 64, 32]               0
       Bottleneck-24          [-1, 256, 64, 32]               0
           Conv2d-25          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-26           [-1, 64, 64, 32]             128
      BatchNorm2d-27           [-1, 64, 64, 32]             128
              IBN-28          [-1, 128, 64, 32]               0
             ReLU-29          [-1, 128, 64, 32]               0
           Conv2d-30          [-1, 128, 64, 32]         147,456
      BatchNorm2d-31          [-1, 128, 64, 32]             256
             ReLU-32          [-1, 128, 64, 32]               0
           Conv2d-33          [-1, 256, 64, 32]          32,768
      BatchNorm2d-34          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-35            [-1, 256, 1, 1]               0
           Linear-36                   [-1, 16]           4,096
             ReLU-37                   [-1, 16]               0
           Linear-38                  [-1, 256]           4,096
          Sigmoid-39                  [-1, 256]               0
          SELayer-40          [-1, 256, 64, 32]               0
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-44           [-1, 64, 64, 32]             128
      BatchNorm2d-45           [-1, 64, 64, 32]             128
              IBN-46          [-1, 128, 64, 32]               0
             ReLU-47          [-1, 128, 64, 32]               0
           Conv2d-48          [-1, 128, 64, 32]         147,456
      BatchNorm2d-49          [-1, 128, 64, 32]             256
             ReLU-50          [-1, 128, 64, 32]               0
           Conv2d-51          [-1, 256, 64, 32]          32,768
      BatchNorm2d-52          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-53            [-1, 256, 1, 1]               0
           Linear-54                   [-1, 16]           4,096
             ReLU-55                   [-1, 16]               0
           Linear-56                  [-1, 256]           4,096
          Sigmoid-57                  [-1, 256]               0
          SELayer-58          [-1, 256, 64, 32]               0
             ReLU-59          [-1, 256, 64, 32]               0
       Bottleneck-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 256, 64, 32]          65,536
   InstanceNorm2d-62          [-1, 128, 64, 32]             256
      BatchNorm2d-63          [-1, 128, 64, 32]             256
              IBN-64          [-1, 256, 64, 32]               0
             ReLU-65          [-1, 256, 64, 32]               0
           Conv2d-66          [-1, 256, 32, 16]         589,824
      BatchNorm2d-67          [-1, 256, 32, 16]             512
             ReLU-68          [-1, 256, 32, 16]               0
           Conv2d-69          [-1, 512, 32, 16]         131,072
      BatchNorm2d-70          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-71            [-1, 512, 1, 1]               0
           Linear-72                   [-1, 32]          16,384
             ReLU-73                   [-1, 32]               0
           Linear-74                  [-1, 512]          16,384
          Sigmoid-75                  [-1, 512]               0
          SELayer-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         131,072
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-82          [-1, 128, 32, 16]             256
      BatchNorm2d-83          [-1, 128, 32, 16]             256
              IBN-84          [-1, 256, 32, 16]               0
             ReLU-85          [-1, 256, 32, 16]               0
           Conv2d-86          [-1, 256, 32, 16]         589,824
      BatchNorm2d-87          [-1, 256, 32, 16]             512
             ReLU-88          [-1, 256, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]         131,072
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-91            [-1, 512, 1, 1]               0
           Linear-92                   [-1, 32]          16,384
             ReLU-93                   [-1, 32]               0
           Linear-94                  [-1, 512]          16,384
          Sigmoid-95                  [-1, 512]               0
          SELayer-96          [-1, 512, 32, 16]               0
             ReLU-97          [-1, 512, 32, 16]               0
       Bottleneck-98          [-1, 512, 32, 16]               0
           Conv2d-99          [-1, 256, 32, 16]         131,072
  InstanceNorm2d-100          [-1, 128, 32, 16]             256
     BatchNorm2d-101          [-1, 128, 32, 16]             256
             IBN-102          [-1, 256, 32, 16]               0
            ReLU-103          [-1, 256, 32, 16]               0
          Conv2d-104          [-1, 256, 32, 16]         589,824
     BatchNorm2d-105          [-1, 256, 32, 16]             512
            ReLU-106          [-1, 256, 32, 16]               0
          Conv2d-107          [-1, 512, 32, 16]         131,072
     BatchNorm2d-108          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-109            [-1, 512, 1, 1]               0
          Linear-110                   [-1, 32]          16,384
            ReLU-111                   [-1, 32]               0
          Linear-112                  [-1, 512]          16,384
         Sigmoid-113                  [-1, 512]               0
         SELayer-114          [-1, 512, 32, 16]               0
            ReLU-115          [-1, 512, 32, 16]               0
      Bottleneck-116          [-1, 512, 32, 16]               0
          Conv2d-117          [-1, 256, 32, 16]         131,072
  InstanceNorm2d-118          [-1, 128, 32, 16]             256
     BatchNorm2d-119          [-1, 128, 32, 16]             256
             IBN-120          [-1, 256, 32, 16]               0
            ReLU-121          [-1, 256, 32, 16]               0
          Conv2d-122          [-1, 256, 32, 16]         589,824
     BatchNorm2d-123          [-1, 256, 32, 16]             512
            ReLU-124          [-1, 256, 32, 16]               0
          Conv2d-125          [-1, 512, 32, 16]         131,072
     BatchNorm2d-126          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-127            [-1, 512, 1, 1]               0
          Linear-128                   [-1, 32]          16,384
            ReLU-129                   [-1, 32]               0
          Linear-130                  [-1, 512]          16,384
         Sigmoid-131                  [-1, 512]               0
         SELayer-132          [-1, 512, 32, 16]               0
            ReLU-133          [-1, 512, 32, 16]               0
      Bottleneck-134          [-1, 512, 32, 16]               0
          Conv2d-135          [-1, 512, 32, 16]         262,144
  InstanceNorm2d-136          [-1, 256, 32, 16]             512
     BatchNorm2d-137          [-1, 256, 32, 16]             512
             IBN-138          [-1, 512, 32, 16]               0
            ReLU-139          [-1, 512, 32, 16]               0
          Conv2d-140           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-141           [-1, 512, 16, 8]           1,024
            ReLU-142           [-1, 512, 16, 8]               0
          Conv2d-143          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-144          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-145           [-1, 1024, 1, 1]               0
          Linear-146                   [-1, 64]          65,536
            ReLU-147                   [-1, 64]               0
          Linear-148                 [-1, 1024]          65,536
         Sigmoid-149                 [-1, 1024]               0
         SELayer-150          [-1, 1024, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-156           [-1, 256, 16, 8]             512
     BatchNorm2d-157           [-1, 256, 16, 8]             512
             IBN-158           [-1, 512, 16, 8]               0
            ReLU-159           [-1, 512, 16, 8]               0
          Conv2d-160           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-161           [-1, 512, 16, 8]           1,024
            ReLU-162           [-1, 512, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-165           [-1, 1024, 1, 1]               0
          Linear-166                   [-1, 64]          65,536
            ReLU-167                   [-1, 64]               0
          Linear-168                 [-1, 1024]          65,536
         Sigmoid-169                 [-1, 1024]               0
         SELayer-170          [-1, 1024, 16, 8]               0
            ReLU-171          [-1, 1024, 16, 8]               0
      Bottleneck-172          [-1, 1024, 16, 8]               0
          Conv2d-173           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-174           [-1, 256, 16, 8]             512
     BatchNorm2d-175           [-1, 256, 16, 8]             512
             IBN-176           [-1, 512, 16, 8]               0
            ReLU-177           [-1, 512, 16, 8]               0
          Conv2d-178           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-179           [-1, 512, 16, 8]           1,024
            ReLU-180           [-1, 512, 16, 8]               0
          Conv2d-181          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-182          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-183           [-1, 1024, 1, 1]               0
          Linear-184                   [-1, 64]          65,536
            ReLU-185                   [-1, 64]               0
          Linear-186                 [-1, 1024]          65,536
         Sigmoid-187                 [-1, 1024]               0
         SELayer-188          [-1, 1024, 16, 8]               0
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-192           [-1, 256, 16, 8]             512
     BatchNorm2d-193           [-1, 256, 16, 8]             512
             IBN-194           [-1, 512, 16, 8]               0
            ReLU-195           [-1, 512, 16, 8]               0
          Conv2d-196           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-197           [-1, 512, 16, 8]           1,024
            ReLU-198           [-1, 512, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-201           [-1, 1024, 1, 1]               0
          Linear-202                   [-1, 64]          65,536
            ReLU-203                   [-1, 64]               0
          Linear-204                 [-1, 1024]          65,536
         Sigmoid-205                 [-1, 1024]               0
         SELayer-206          [-1, 1024, 16, 8]               0
            ReLU-207          [-1, 1024, 16, 8]               0
      Bottleneck-208          [-1, 1024, 16, 8]               0
          Conv2d-209           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-210           [-1, 256, 16, 8]             512
     BatchNorm2d-211           [-1, 256, 16, 8]             512
             IBN-212           [-1, 512, 16, 8]               0
            ReLU-213           [-1, 512, 16, 8]               0
          Conv2d-214           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-215           [-1, 512, 16, 8]           1,024
            ReLU-216           [-1, 512, 16, 8]               0
          Conv2d-217          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-218          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-219           [-1, 1024, 1, 1]               0
          Linear-220                   [-1, 64]          65,536
            ReLU-221                   [-1, 64]               0
          Linear-222                 [-1, 1024]          65,536
         Sigmoid-223                 [-1, 1024]               0
         SELayer-224          [-1, 1024, 16, 8]               0
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-228           [-1, 256, 16, 8]             512
     BatchNorm2d-229           [-1, 256, 16, 8]             512
             IBN-230           [-1, 512, 16, 8]               0
            ReLU-231           [-1, 512, 16, 8]               0
          Conv2d-232           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-233           [-1, 512, 16, 8]           1,024
            ReLU-234           [-1, 512, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-237           [-1, 1024, 1, 1]               0
          Linear-238                   [-1, 64]          65,536
            ReLU-239                   [-1, 64]               0
          Linear-240                 [-1, 1024]          65,536
         Sigmoid-241                 [-1, 1024]               0
         SELayer-242          [-1, 1024, 16, 8]               0
            ReLU-243          [-1, 1024, 16, 8]               0
      Bottleneck-244          [-1, 1024, 16, 8]               0
          Conv2d-245           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-246           [-1, 256, 16, 8]             512
     BatchNorm2d-247           [-1, 256, 16, 8]             512
             IBN-248           [-1, 512, 16, 8]               0
            ReLU-249           [-1, 512, 16, 8]               0
          Conv2d-250           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-251           [-1, 512, 16, 8]           1,024
            ReLU-252           [-1, 512, 16, 8]               0
          Conv2d-253          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-254          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-255           [-1, 1024, 1, 1]               0
          Linear-256                   [-1, 64]          65,536
            ReLU-257                   [-1, 64]               0
          Linear-258                 [-1, 1024]          65,536
         Sigmoid-259                 [-1, 1024]               0
         SELayer-260          [-1, 1024, 16, 8]               0
            ReLU-261          [-1, 1024, 16, 8]               0
      Bottleneck-262          [-1, 1024, 16, 8]               0
          Conv2d-263           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-264           [-1, 256, 16, 8]             512
     BatchNorm2d-265           [-1, 256, 16, 8]             512
             IBN-266           [-1, 512, 16, 8]               0
            ReLU-267           [-1, 512, 16, 8]               0
          Conv2d-268           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-269           [-1, 512, 16, 8]           1,024
            ReLU-270           [-1, 512, 16, 8]               0
          Conv2d-271          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-272          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-273           [-1, 1024, 1, 1]               0
          Linear-274                   [-1, 64]          65,536
            ReLU-275                   [-1, 64]               0
          Linear-276                 [-1, 1024]          65,536
         Sigmoid-277                 [-1, 1024]               0
         SELayer-278          [-1, 1024, 16, 8]               0
            ReLU-279          [-1, 1024, 16, 8]               0
      Bottleneck-280          [-1, 1024, 16, 8]               0
          Conv2d-281           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-282           [-1, 256, 16, 8]             512
     BatchNorm2d-283           [-1, 256, 16, 8]             512
             IBN-284           [-1, 512, 16, 8]               0
            ReLU-285           [-1, 512, 16, 8]               0
          Conv2d-286           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-287           [-1, 512, 16, 8]           1,024
            ReLU-288           [-1, 512, 16, 8]               0
          Conv2d-289          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-290          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-291           [-1, 1024, 1, 1]               0
          Linear-292                   [-1, 64]          65,536
            ReLU-293                   [-1, 64]               0
          Linear-294                 [-1, 1024]          65,536
         Sigmoid-295                 [-1, 1024]               0
         SELayer-296          [-1, 1024, 16, 8]               0
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-300           [-1, 256, 16, 8]             512
     BatchNorm2d-301           [-1, 256, 16, 8]             512
             IBN-302           [-1, 512, 16, 8]               0
            ReLU-303           [-1, 512, 16, 8]               0
          Conv2d-304           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-305           [-1, 512, 16, 8]           1,024
            ReLU-306           [-1, 512, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-309           [-1, 1024, 1, 1]               0
          Linear-310                   [-1, 64]          65,536
            ReLU-311                   [-1, 64]               0
          Linear-312                 [-1, 1024]          65,536
         Sigmoid-313                 [-1, 1024]               0
         SELayer-314          [-1, 1024, 16, 8]               0
            ReLU-315          [-1, 1024, 16, 8]               0
      Bottleneck-316          [-1, 1024, 16, 8]               0
          Conv2d-317           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-318           [-1, 256, 16, 8]             512
     BatchNorm2d-319           [-1, 256, 16, 8]             512
             IBN-320           [-1, 512, 16, 8]               0
            ReLU-321           [-1, 512, 16, 8]               0
          Conv2d-322           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-323           [-1, 512, 16, 8]           1,024
            ReLU-324           [-1, 512, 16, 8]               0
          Conv2d-325          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-326          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-327           [-1, 1024, 1, 1]               0
          Linear-328                   [-1, 64]          65,536
            ReLU-329                   [-1, 64]               0
          Linear-330                 [-1, 1024]          65,536
         Sigmoid-331                 [-1, 1024]               0
         SELayer-332          [-1, 1024, 16, 8]               0
            ReLU-333          [-1, 1024, 16, 8]               0
      Bottleneck-334          [-1, 1024, 16, 8]               0
          Conv2d-335           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-336           [-1, 256, 16, 8]             512
     BatchNorm2d-337           [-1, 256, 16, 8]             512
             IBN-338           [-1, 512, 16, 8]               0
            ReLU-339           [-1, 512, 16, 8]               0
          Conv2d-340           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-341           [-1, 512, 16, 8]           1,024
            ReLU-342           [-1, 512, 16, 8]               0
          Conv2d-343          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-344          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-345           [-1, 1024, 1, 1]               0
          Linear-346                   [-1, 64]          65,536
            ReLU-347                   [-1, 64]               0
          Linear-348                 [-1, 1024]          65,536
         Sigmoid-349                 [-1, 1024]               0
         SELayer-350          [-1, 1024, 16, 8]               0
            ReLU-351          [-1, 1024, 16, 8]               0
      Bottleneck-352          [-1, 1024, 16, 8]               0
          Conv2d-353           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-354           [-1, 256, 16, 8]             512
     BatchNorm2d-355           [-1, 256, 16, 8]             512
             IBN-356           [-1, 512, 16, 8]               0
            ReLU-357           [-1, 512, 16, 8]               0
          Conv2d-358           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-359           [-1, 512, 16, 8]           1,024
            ReLU-360           [-1, 512, 16, 8]               0
          Conv2d-361          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-362          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-363           [-1, 1024, 1, 1]               0
          Linear-364                   [-1, 64]          65,536
            ReLU-365                   [-1, 64]               0
          Linear-366                 [-1, 1024]          65,536
         Sigmoid-367                 [-1, 1024]               0
         SELayer-368          [-1, 1024, 16, 8]               0
            ReLU-369          [-1, 1024, 16, 8]               0
      Bottleneck-370          [-1, 1024, 16, 8]               0
          Conv2d-371           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-372           [-1, 256, 16, 8]             512
     BatchNorm2d-373           [-1, 256, 16, 8]             512
             IBN-374           [-1, 512, 16, 8]               0
            ReLU-375           [-1, 512, 16, 8]               0
          Conv2d-376           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-377           [-1, 512, 16, 8]           1,024
            ReLU-378           [-1, 512, 16, 8]               0
          Conv2d-379          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-380          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-381           [-1, 1024, 1, 1]               0
          Linear-382                   [-1, 64]          65,536
            ReLU-383                   [-1, 64]               0
          Linear-384                 [-1, 1024]          65,536
         Sigmoid-385                 [-1, 1024]               0
         SELayer-386          [-1, 1024, 16, 8]               0
            ReLU-387          [-1, 1024, 16, 8]               0
      Bottleneck-388          [-1, 1024, 16, 8]               0
          Conv2d-389           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-390           [-1, 256, 16, 8]             512
     BatchNorm2d-391           [-1, 256, 16, 8]             512
             IBN-392           [-1, 512, 16, 8]               0
            ReLU-393           [-1, 512, 16, 8]               0
          Conv2d-394           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-395           [-1, 512, 16, 8]           1,024
            ReLU-396           [-1, 512, 16, 8]               0
          Conv2d-397          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-398          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-399           [-1, 1024, 1, 1]               0
          Linear-400                   [-1, 64]          65,536
            ReLU-401                   [-1, 64]               0
          Linear-402                 [-1, 1024]          65,536
         Sigmoid-403                 [-1, 1024]               0
         SELayer-404          [-1, 1024, 16, 8]               0
            ReLU-405          [-1, 1024, 16, 8]               0
      Bottleneck-406          [-1, 1024, 16, 8]               0
          Conv2d-407           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-408           [-1, 256, 16, 8]             512
     BatchNorm2d-409           [-1, 256, 16, 8]             512
             IBN-410           [-1, 512, 16, 8]               0
            ReLU-411           [-1, 512, 16, 8]               0
          Conv2d-412           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-413           [-1, 512, 16, 8]           1,024
            ReLU-414           [-1, 512, 16, 8]               0
          Conv2d-415          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-416          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-417           [-1, 1024, 1, 1]               0
          Linear-418                   [-1, 64]          65,536
            ReLU-419                   [-1, 64]               0
          Linear-420                 [-1, 1024]          65,536
         Sigmoid-421                 [-1, 1024]               0
         SELayer-422          [-1, 1024, 16, 8]               0
            ReLU-423          [-1, 1024, 16, 8]               0
      Bottleneck-424          [-1, 1024, 16, 8]               0
          Conv2d-425           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-426           [-1, 256, 16, 8]             512
     BatchNorm2d-427           [-1, 256, 16, 8]             512
             IBN-428           [-1, 512, 16, 8]               0
            ReLU-429           [-1, 512, 16, 8]               0
          Conv2d-430           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-431           [-1, 512, 16, 8]           1,024
            ReLU-432           [-1, 512, 16, 8]               0
          Conv2d-433          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-434          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-435           [-1, 1024, 1, 1]               0
          Linear-436                   [-1, 64]          65,536
            ReLU-437                   [-1, 64]               0
          Linear-438                 [-1, 1024]          65,536
         Sigmoid-439                 [-1, 1024]               0
         SELayer-440          [-1, 1024, 16, 8]               0
            ReLU-441          [-1, 1024, 16, 8]               0
      Bottleneck-442          [-1, 1024, 16, 8]               0
          Conv2d-443           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-444           [-1, 256, 16, 8]             512
     BatchNorm2d-445           [-1, 256, 16, 8]             512
             IBN-446           [-1, 512, 16, 8]               0
            ReLU-447           [-1, 512, 16, 8]               0
          Conv2d-448           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-449           [-1, 512, 16, 8]           1,024
            ReLU-450           [-1, 512, 16, 8]               0
          Conv2d-451          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-452          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-453           [-1, 1024, 1, 1]               0
          Linear-454                   [-1, 64]          65,536
            ReLU-455                   [-1, 64]               0
          Linear-456                 [-1, 1024]          65,536
         Sigmoid-457                 [-1, 1024]               0
         SELayer-458          [-1, 1024, 16, 8]               0
            ReLU-459          [-1, 1024, 16, 8]               0
      Bottleneck-460          [-1, 1024, 16, 8]               0
          Conv2d-461           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-462           [-1, 256, 16, 8]             512
     BatchNorm2d-463           [-1, 256, 16, 8]             512
             IBN-464           [-1, 512, 16, 8]               0
            ReLU-465           [-1, 512, 16, 8]               0
          Conv2d-466           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-467           [-1, 512, 16, 8]           1,024
            ReLU-468           [-1, 512, 16, 8]               0
          Conv2d-469          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-470          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-471           [-1, 1024, 1, 1]               0
          Linear-472                   [-1, 64]          65,536
            ReLU-473                   [-1, 64]               0
          Linear-474                 [-1, 1024]          65,536
         Sigmoid-475                 [-1, 1024]               0
         SELayer-476          [-1, 1024, 16, 8]               0
            ReLU-477          [-1, 1024, 16, 8]               0
      Bottleneck-478          [-1, 1024, 16, 8]               0
          Conv2d-479           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-480           [-1, 256, 16, 8]             512
     BatchNorm2d-481           [-1, 256, 16, 8]             512
             IBN-482           [-1, 512, 16, 8]               0
            ReLU-483           [-1, 512, 16, 8]               0
          Conv2d-484           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-485           [-1, 512, 16, 8]           1,024
            ReLU-486           [-1, 512, 16, 8]               0
          Conv2d-487          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-488          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-489           [-1, 1024, 1, 1]               0
          Linear-490                   [-1, 64]          65,536
            ReLU-491                   [-1, 64]               0
          Linear-492                 [-1, 1024]          65,536
         Sigmoid-493                 [-1, 1024]               0
         SELayer-494          [-1, 1024, 16, 8]               0
            ReLU-495          [-1, 1024, 16, 8]               0
      Bottleneck-496          [-1, 1024, 16, 8]               0
          Conv2d-497           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-498           [-1, 256, 16, 8]             512
     BatchNorm2d-499           [-1, 256, 16, 8]             512
             IBN-500           [-1, 512, 16, 8]               0
            ReLU-501           [-1, 512, 16, 8]               0
          Conv2d-502           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-503           [-1, 512, 16, 8]           1,024
            ReLU-504           [-1, 512, 16, 8]               0
          Conv2d-505          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-506          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-507           [-1, 1024, 1, 1]               0
          Linear-508                   [-1, 64]          65,536
            ReLU-509                   [-1, 64]               0
          Linear-510                 [-1, 1024]          65,536
         Sigmoid-511                 [-1, 1024]               0
         SELayer-512          [-1, 1024, 16, 8]               0
            ReLU-513          [-1, 1024, 16, 8]               0
      Bottleneck-514          [-1, 1024, 16, 8]               0
          Conv2d-515           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-516           [-1, 256, 16, 8]             512
     BatchNorm2d-517           [-1, 256, 16, 8]             512
             IBN-518           [-1, 512, 16, 8]               0
            ReLU-519           [-1, 512, 16, 8]               0
          Conv2d-520           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-521           [-1, 512, 16, 8]           1,024
            ReLU-522           [-1, 512, 16, 8]               0
          Conv2d-523          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-524          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-525           [-1, 1024, 1, 1]               0
          Linear-526                   [-1, 64]          65,536
            ReLU-527                   [-1, 64]               0
          Linear-528                 [-1, 1024]          65,536
         Sigmoid-529                 [-1, 1024]               0
         SELayer-530          [-1, 1024, 16, 8]               0
            ReLU-531          [-1, 1024, 16, 8]               0
      Bottleneck-532          [-1, 1024, 16, 8]               0
          Conv2d-533           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-534           [-1, 256, 16, 8]             512
     BatchNorm2d-535           [-1, 256, 16, 8]             512
             IBN-536           [-1, 512, 16, 8]               0
            ReLU-537           [-1, 512, 16, 8]               0
          Conv2d-538           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-539           [-1, 512, 16, 8]           1,024
            ReLU-540           [-1, 512, 16, 8]               0
          Conv2d-541          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-542          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-543           [-1, 1024, 1, 1]               0
          Linear-544                   [-1, 64]          65,536
            ReLU-545                   [-1, 64]               0
          Linear-546                 [-1, 1024]          65,536
         Sigmoid-547                 [-1, 1024]               0
         SELayer-548          [-1, 1024, 16, 8]               0
            ReLU-549          [-1, 1024, 16, 8]               0
      Bottleneck-550          [-1, 1024, 16, 8]               0
          Conv2d-551          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-552          [-1, 1024, 16, 8]           2,048
            ReLU-553          [-1, 1024, 16, 8]               0
          Conv2d-554          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-555          [-1, 1024, 16, 8]           2,048
            ReLU-556          [-1, 1024, 16, 8]               0
          Conv2d-557          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-558          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-559           [-1, 2048, 1, 1]               0
          Linear-560                  [-1, 128]         262,144
            ReLU-561                  [-1, 128]               0
          Linear-562                 [-1, 2048]         262,144
         Sigmoid-563                 [-1, 2048]               0
         SELayer-564          [-1, 2048, 16, 8]               0
          Conv2d-565          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-566          [-1, 2048, 16, 8]           4,096
            ReLU-567          [-1, 2048, 16, 8]               0
      Bottleneck-568          [-1, 2048, 16, 8]               0
          Conv2d-569          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-570          [-1, 1024, 16, 8]           2,048
            ReLU-571          [-1, 1024, 16, 8]               0
          Conv2d-572          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-573          [-1, 1024, 16, 8]           2,048
            ReLU-574          [-1, 1024, 16, 8]               0
          Conv2d-575          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-576          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-577           [-1, 2048, 1, 1]               0
          Linear-578                  [-1, 128]         262,144
            ReLU-579                  [-1, 128]               0
          Linear-580                 [-1, 2048]         262,144
         Sigmoid-581                 [-1, 2048]               0
         SELayer-582          [-1, 2048, 16, 8]               0
            ReLU-583          [-1, 2048, 16, 8]               0
      Bottleneck-584          [-1, 2048, 16, 8]               0
          Conv2d-585          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-586          [-1, 1024, 16, 8]           2,048
            ReLU-587          [-1, 1024, 16, 8]               0
          Conv2d-588          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-589          [-1, 1024, 16, 8]           2,048
            ReLU-590          [-1, 1024, 16, 8]               0
          Conv2d-591          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-592          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-593           [-1, 2048, 1, 1]               0
          Linear-594                  [-1, 128]         262,144
            ReLU-595                  [-1, 128]               0
          Linear-596                 [-1, 2048]         262,144
         Sigmoid-597                 [-1, 2048]               0
         SELayer-598          [-1, 2048, 16, 8]               0
            ReLU-599          [-1, 2048, 16, 8]               0
      Bottleneck-600          [-1, 2048, 16, 8]               0
================================================================
Total params: 129,580,864
Trainable params: 129,580,864
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 463.28
Params size (MB): 494.31
Estimated Total Size (MB): 957.96
----------------------------------------------------------------
**********************************************************************
**********************************************************************
wide_resnet101_2_se_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]         147,456
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-13            [-1, 256, 1, 1]               0
           Linear-14                   [-1, 16]           4,096
             ReLU-15                   [-1, 16]               0
           Linear-16                  [-1, 256]           4,096
          Sigmoid-17                  [-1, 256]               0
          SELayer-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 256, 64, 32]          16,384
      BatchNorm2d-20          [-1, 256, 64, 32]             512
   InstanceNorm2d-21          [-1, 256, 64, 32]             512
             ReLU-22          [-1, 256, 64, 32]               0
       Bottleneck-23          [-1, 256, 64, 32]               0
           Conv2d-24          [-1, 128, 64, 32]          32,768
      BatchNorm2d-25          [-1, 128, 64, 32]             256
             ReLU-26          [-1, 128, 64, 32]               0
           Conv2d-27          [-1, 128, 64, 32]         147,456
      BatchNorm2d-28          [-1, 128, 64, 32]             256
             ReLU-29          [-1, 128, 64, 32]               0
           Conv2d-30          [-1, 256, 64, 32]          32,768
      BatchNorm2d-31          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-32            [-1, 256, 1, 1]               0
           Linear-33                   [-1, 16]           4,096
             ReLU-34                   [-1, 16]               0
           Linear-35                  [-1, 256]           4,096
          Sigmoid-36                  [-1, 256]               0
          SELayer-37          [-1, 256, 64, 32]               0
   InstanceNorm2d-38          [-1, 256, 64, 32]             512
             ReLU-39          [-1, 256, 64, 32]               0
       Bottleneck-40          [-1, 256, 64, 32]               0
           Conv2d-41          [-1, 128, 64, 32]          32,768
      BatchNorm2d-42          [-1, 128, 64, 32]             256
             ReLU-43          [-1, 128, 64, 32]               0
           Conv2d-44          [-1, 128, 64, 32]         147,456
      BatchNorm2d-45          [-1, 128, 64, 32]             256
             ReLU-46          [-1, 128, 64, 32]               0
           Conv2d-47          [-1, 256, 64, 32]          32,768
      BatchNorm2d-48          [-1, 256, 64, 32]             512
AdaptiveAvgPool2d-49            [-1, 256, 1, 1]               0
           Linear-50                   [-1, 16]           4,096
             ReLU-51                   [-1, 16]               0
           Linear-52                  [-1, 256]           4,096
          Sigmoid-53                  [-1, 256]               0
          SELayer-54          [-1, 256, 64, 32]               0
   InstanceNorm2d-55          [-1, 256, 64, 32]             512
             ReLU-56          [-1, 256, 64, 32]               0
       Bottleneck-57          [-1, 256, 64, 32]               0
           Conv2d-58          [-1, 256, 64, 32]          65,536
      BatchNorm2d-59          [-1, 256, 64, 32]             512
             ReLU-60          [-1, 256, 64, 32]               0
           Conv2d-61          [-1, 256, 32, 16]         589,824
      BatchNorm2d-62          [-1, 256, 32, 16]             512
             ReLU-63          [-1, 256, 32, 16]               0
           Conv2d-64          [-1, 512, 32, 16]         131,072
      BatchNorm2d-65          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-66            [-1, 512, 1, 1]               0
           Linear-67                   [-1, 32]          16,384
             ReLU-68                   [-1, 32]               0
           Linear-69                  [-1, 512]          16,384
          Sigmoid-70                  [-1, 512]               0
          SELayer-71          [-1, 512, 32, 16]               0
           Conv2d-72          [-1, 512, 32, 16]         131,072
      BatchNorm2d-73          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-74          [-1, 512, 32, 16]           1,024
             ReLU-75          [-1, 512, 32, 16]               0
       Bottleneck-76          [-1, 512, 32, 16]               0
           Conv2d-77          [-1, 256, 32, 16]         131,072
      BatchNorm2d-78          [-1, 256, 32, 16]             512
             ReLU-79          [-1, 256, 32, 16]               0
           Conv2d-80          [-1, 256, 32, 16]         589,824
      BatchNorm2d-81          [-1, 256, 32, 16]             512
             ReLU-82          [-1, 256, 32, 16]               0
           Conv2d-83          [-1, 512, 32, 16]         131,072
      BatchNorm2d-84          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-85            [-1, 512, 1, 1]               0
           Linear-86                   [-1, 32]          16,384
             ReLU-87                   [-1, 32]               0
           Linear-88                  [-1, 512]          16,384
          Sigmoid-89                  [-1, 512]               0
          SELayer-90          [-1, 512, 32, 16]               0
   InstanceNorm2d-91          [-1, 512, 32, 16]           1,024
             ReLU-92          [-1, 512, 32, 16]               0
       Bottleneck-93          [-1, 512, 32, 16]               0
           Conv2d-94          [-1, 256, 32, 16]         131,072
      BatchNorm2d-95          [-1, 256, 32, 16]             512
             ReLU-96          [-1, 256, 32, 16]               0
           Conv2d-97          [-1, 256, 32, 16]         589,824
      BatchNorm2d-98          [-1, 256, 32, 16]             512
             ReLU-99          [-1, 256, 32, 16]               0
          Conv2d-100          [-1, 512, 32, 16]         131,072
     BatchNorm2d-101          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-102            [-1, 512, 1, 1]               0
          Linear-103                   [-1, 32]          16,384
            ReLU-104                   [-1, 32]               0
          Linear-105                  [-1, 512]          16,384
         Sigmoid-106                  [-1, 512]               0
         SELayer-107          [-1, 512, 32, 16]               0
  InstanceNorm2d-108          [-1, 512, 32, 16]           1,024
            ReLU-109          [-1, 512, 32, 16]               0
      Bottleneck-110          [-1, 512, 32, 16]               0
          Conv2d-111          [-1, 256, 32, 16]         131,072
     BatchNorm2d-112          [-1, 256, 32, 16]             512
            ReLU-113          [-1, 256, 32, 16]               0
          Conv2d-114          [-1, 256, 32, 16]         589,824
     BatchNorm2d-115          [-1, 256, 32, 16]             512
            ReLU-116          [-1, 256, 32, 16]               0
          Conv2d-117          [-1, 512, 32, 16]         131,072
     BatchNorm2d-118          [-1, 512, 32, 16]           1,024
AdaptiveAvgPool2d-119            [-1, 512, 1, 1]               0
          Linear-120                   [-1, 32]          16,384
            ReLU-121                   [-1, 32]               0
          Linear-122                  [-1, 512]          16,384
         Sigmoid-123                  [-1, 512]               0
         SELayer-124          [-1, 512, 32, 16]               0
  InstanceNorm2d-125          [-1, 512, 32, 16]           1,024
            ReLU-126          [-1, 512, 32, 16]               0
      Bottleneck-127          [-1, 512, 32, 16]               0
          Conv2d-128          [-1, 512, 32, 16]         262,144
     BatchNorm2d-129          [-1, 512, 32, 16]           1,024
            ReLU-130          [-1, 512, 32, 16]               0
          Conv2d-131           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-132           [-1, 512, 16, 8]           1,024
            ReLU-133           [-1, 512, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-136           [-1, 1024, 1, 1]               0
          Linear-137                   [-1, 64]          65,536
            ReLU-138                   [-1, 64]               0
          Linear-139                 [-1, 1024]          65,536
         Sigmoid-140                 [-1, 1024]               0
         SELayer-141          [-1, 1024, 16, 8]               0
          Conv2d-142          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-143          [-1, 1024, 16, 8]           2,048
            ReLU-144          [-1, 1024, 16, 8]               0
      Bottleneck-145          [-1, 1024, 16, 8]               0
          Conv2d-146           [-1, 512, 16, 8]         524,288
     BatchNorm2d-147           [-1, 512, 16, 8]           1,024
            ReLU-148           [-1, 512, 16, 8]               0
          Conv2d-149           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-150           [-1, 512, 16, 8]           1,024
            ReLU-151           [-1, 512, 16, 8]               0
          Conv2d-152          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-153          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-154           [-1, 1024, 1, 1]               0
          Linear-155                   [-1, 64]          65,536
            ReLU-156                   [-1, 64]               0
          Linear-157                 [-1, 1024]          65,536
         Sigmoid-158                 [-1, 1024]               0
         SELayer-159          [-1, 1024, 16, 8]               0
            ReLU-160          [-1, 1024, 16, 8]               0
      Bottleneck-161          [-1, 1024, 16, 8]               0
          Conv2d-162           [-1, 512, 16, 8]         524,288
     BatchNorm2d-163           [-1, 512, 16, 8]           1,024
            ReLU-164           [-1, 512, 16, 8]               0
          Conv2d-165           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-166           [-1, 512, 16, 8]           1,024
            ReLU-167           [-1, 512, 16, 8]               0
          Conv2d-168          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-169          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-170           [-1, 1024, 1, 1]               0
          Linear-171                   [-1, 64]          65,536
            ReLU-172                   [-1, 64]               0
          Linear-173                 [-1, 1024]          65,536
         Sigmoid-174                 [-1, 1024]               0
         SELayer-175          [-1, 1024, 16, 8]               0
            ReLU-176          [-1, 1024, 16, 8]               0
      Bottleneck-177          [-1, 1024, 16, 8]               0
          Conv2d-178           [-1, 512, 16, 8]         524,288
     BatchNorm2d-179           [-1, 512, 16, 8]           1,024
            ReLU-180           [-1, 512, 16, 8]               0
          Conv2d-181           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-182           [-1, 512, 16, 8]           1,024
            ReLU-183           [-1, 512, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-186           [-1, 1024, 1, 1]               0
          Linear-187                   [-1, 64]          65,536
            ReLU-188                   [-1, 64]               0
          Linear-189                 [-1, 1024]          65,536
         Sigmoid-190                 [-1, 1024]               0
         SELayer-191          [-1, 1024, 16, 8]               0
            ReLU-192          [-1, 1024, 16, 8]               0
      Bottleneck-193          [-1, 1024, 16, 8]               0
          Conv2d-194           [-1, 512, 16, 8]         524,288
     BatchNorm2d-195           [-1, 512, 16, 8]           1,024
            ReLU-196           [-1, 512, 16, 8]               0
          Conv2d-197           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-198           [-1, 512, 16, 8]           1,024
            ReLU-199           [-1, 512, 16, 8]               0
          Conv2d-200          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-201          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-202           [-1, 1024, 1, 1]               0
          Linear-203                   [-1, 64]          65,536
            ReLU-204                   [-1, 64]               0
          Linear-205                 [-1, 1024]          65,536
         Sigmoid-206                 [-1, 1024]               0
         SELayer-207          [-1, 1024, 16, 8]               0
            ReLU-208          [-1, 1024, 16, 8]               0
      Bottleneck-209          [-1, 1024, 16, 8]               0
          Conv2d-210           [-1, 512, 16, 8]         524,288
     BatchNorm2d-211           [-1, 512, 16, 8]           1,024
            ReLU-212           [-1, 512, 16, 8]               0
          Conv2d-213           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-214           [-1, 512, 16, 8]           1,024
            ReLU-215           [-1, 512, 16, 8]               0
          Conv2d-216          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-217          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-218           [-1, 1024, 1, 1]               0
          Linear-219                   [-1, 64]          65,536
            ReLU-220                   [-1, 64]               0
          Linear-221                 [-1, 1024]          65,536
         Sigmoid-222                 [-1, 1024]               0
         SELayer-223          [-1, 1024, 16, 8]               0
            ReLU-224          [-1, 1024, 16, 8]               0
      Bottleneck-225          [-1, 1024, 16, 8]               0
          Conv2d-226           [-1, 512, 16, 8]         524,288
     BatchNorm2d-227           [-1, 512, 16, 8]           1,024
            ReLU-228           [-1, 512, 16, 8]               0
          Conv2d-229           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-230           [-1, 512, 16, 8]           1,024
            ReLU-231           [-1, 512, 16, 8]               0
          Conv2d-232          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-233          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-234           [-1, 1024, 1, 1]               0
          Linear-235                   [-1, 64]          65,536
            ReLU-236                   [-1, 64]               0
          Linear-237                 [-1, 1024]          65,536
         Sigmoid-238                 [-1, 1024]               0
         SELayer-239          [-1, 1024, 16, 8]               0
            ReLU-240          [-1, 1024, 16, 8]               0
      Bottleneck-241          [-1, 1024, 16, 8]               0
          Conv2d-242           [-1, 512, 16, 8]         524,288
     BatchNorm2d-243           [-1, 512, 16, 8]           1,024
            ReLU-244           [-1, 512, 16, 8]               0
          Conv2d-245           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-246           [-1, 512, 16, 8]           1,024
            ReLU-247           [-1, 512, 16, 8]               0
          Conv2d-248          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-249          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-250           [-1, 1024, 1, 1]               0
          Linear-251                   [-1, 64]          65,536
            ReLU-252                   [-1, 64]               0
          Linear-253                 [-1, 1024]          65,536
         Sigmoid-254                 [-1, 1024]               0
         SELayer-255          [-1, 1024, 16, 8]               0
            ReLU-256          [-1, 1024, 16, 8]               0
      Bottleneck-257          [-1, 1024, 16, 8]               0
          Conv2d-258           [-1, 512, 16, 8]         524,288
     BatchNorm2d-259           [-1, 512, 16, 8]           1,024
            ReLU-260           [-1, 512, 16, 8]               0
          Conv2d-261           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-262           [-1, 512, 16, 8]           1,024
            ReLU-263           [-1, 512, 16, 8]               0
          Conv2d-264          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-265          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-266           [-1, 1024, 1, 1]               0
          Linear-267                   [-1, 64]          65,536
            ReLU-268                   [-1, 64]               0
          Linear-269                 [-1, 1024]          65,536
         Sigmoid-270                 [-1, 1024]               0
         SELayer-271          [-1, 1024, 16, 8]               0
            ReLU-272          [-1, 1024, 16, 8]               0
      Bottleneck-273          [-1, 1024, 16, 8]               0
          Conv2d-274           [-1, 512, 16, 8]         524,288
     BatchNorm2d-275           [-1, 512, 16, 8]           1,024
            ReLU-276           [-1, 512, 16, 8]               0
          Conv2d-277           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-278           [-1, 512, 16, 8]           1,024
            ReLU-279           [-1, 512, 16, 8]               0
          Conv2d-280          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-281          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-282           [-1, 1024, 1, 1]               0
          Linear-283                   [-1, 64]          65,536
            ReLU-284                   [-1, 64]               0
          Linear-285                 [-1, 1024]          65,536
         Sigmoid-286                 [-1, 1024]               0
         SELayer-287          [-1, 1024, 16, 8]               0
            ReLU-288          [-1, 1024, 16, 8]               0
      Bottleneck-289          [-1, 1024, 16, 8]               0
          Conv2d-290           [-1, 512, 16, 8]         524,288
     BatchNorm2d-291           [-1, 512, 16, 8]           1,024
            ReLU-292           [-1, 512, 16, 8]               0
          Conv2d-293           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-294           [-1, 512, 16, 8]           1,024
            ReLU-295           [-1, 512, 16, 8]               0
          Conv2d-296          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-297          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-298           [-1, 1024, 1, 1]               0
          Linear-299                   [-1, 64]          65,536
            ReLU-300                   [-1, 64]               0
          Linear-301                 [-1, 1024]          65,536
         Sigmoid-302                 [-1, 1024]               0
         SELayer-303          [-1, 1024, 16, 8]               0
            ReLU-304          [-1, 1024, 16, 8]               0
      Bottleneck-305          [-1, 1024, 16, 8]               0
          Conv2d-306           [-1, 512, 16, 8]         524,288
     BatchNorm2d-307           [-1, 512, 16, 8]           1,024
            ReLU-308           [-1, 512, 16, 8]               0
          Conv2d-309           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-310           [-1, 512, 16, 8]           1,024
            ReLU-311           [-1, 512, 16, 8]               0
          Conv2d-312          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-313          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-314           [-1, 1024, 1, 1]               0
          Linear-315                   [-1, 64]          65,536
            ReLU-316                   [-1, 64]               0
          Linear-317                 [-1, 1024]          65,536
         Sigmoid-318                 [-1, 1024]               0
         SELayer-319          [-1, 1024, 16, 8]               0
            ReLU-320          [-1, 1024, 16, 8]               0
      Bottleneck-321          [-1, 1024, 16, 8]               0
          Conv2d-322           [-1, 512, 16, 8]         524,288
     BatchNorm2d-323           [-1, 512, 16, 8]           1,024
            ReLU-324           [-1, 512, 16, 8]               0
          Conv2d-325           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-326           [-1, 512, 16, 8]           1,024
            ReLU-327           [-1, 512, 16, 8]               0
          Conv2d-328          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-329          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-330           [-1, 1024, 1, 1]               0
          Linear-331                   [-1, 64]          65,536
            ReLU-332                   [-1, 64]               0
          Linear-333                 [-1, 1024]          65,536
         Sigmoid-334                 [-1, 1024]               0
         SELayer-335          [-1, 1024, 16, 8]               0
            ReLU-336          [-1, 1024, 16, 8]               0
      Bottleneck-337          [-1, 1024, 16, 8]               0
          Conv2d-338           [-1, 512, 16, 8]         524,288
     BatchNorm2d-339           [-1, 512, 16, 8]           1,024
            ReLU-340           [-1, 512, 16, 8]               0
          Conv2d-341           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-342           [-1, 512, 16, 8]           1,024
            ReLU-343           [-1, 512, 16, 8]               0
          Conv2d-344          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-345          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-346           [-1, 1024, 1, 1]               0
          Linear-347                   [-1, 64]          65,536
            ReLU-348                   [-1, 64]               0
          Linear-349                 [-1, 1024]          65,536
         Sigmoid-350                 [-1, 1024]               0
         SELayer-351          [-1, 1024, 16, 8]               0
            ReLU-352          [-1, 1024, 16, 8]               0
      Bottleneck-353          [-1, 1024, 16, 8]               0
          Conv2d-354           [-1, 512, 16, 8]         524,288
     BatchNorm2d-355           [-1, 512, 16, 8]           1,024
            ReLU-356           [-1, 512, 16, 8]               0
          Conv2d-357           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-358           [-1, 512, 16, 8]           1,024
            ReLU-359           [-1, 512, 16, 8]               0
          Conv2d-360          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-361          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-362           [-1, 1024, 1, 1]               0
          Linear-363                   [-1, 64]          65,536
            ReLU-364                   [-1, 64]               0
          Linear-365                 [-1, 1024]          65,536
         Sigmoid-366                 [-1, 1024]               0
         SELayer-367          [-1, 1024, 16, 8]               0
            ReLU-368          [-1, 1024, 16, 8]               0
      Bottleneck-369          [-1, 1024, 16, 8]               0
          Conv2d-370           [-1, 512, 16, 8]         524,288
     BatchNorm2d-371           [-1, 512, 16, 8]           1,024
            ReLU-372           [-1, 512, 16, 8]               0
          Conv2d-373           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-374           [-1, 512, 16, 8]           1,024
            ReLU-375           [-1, 512, 16, 8]               0
          Conv2d-376          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-377          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-378           [-1, 1024, 1, 1]               0
          Linear-379                   [-1, 64]          65,536
            ReLU-380                   [-1, 64]               0
          Linear-381                 [-1, 1024]          65,536
         Sigmoid-382                 [-1, 1024]               0
         SELayer-383          [-1, 1024, 16, 8]               0
            ReLU-384          [-1, 1024, 16, 8]               0
      Bottleneck-385          [-1, 1024, 16, 8]               0
          Conv2d-386           [-1, 512, 16, 8]         524,288
     BatchNorm2d-387           [-1, 512, 16, 8]           1,024
            ReLU-388           [-1, 512, 16, 8]               0
          Conv2d-389           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-390           [-1, 512, 16, 8]           1,024
            ReLU-391           [-1, 512, 16, 8]               0
          Conv2d-392          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-393          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-394           [-1, 1024, 1, 1]               0
          Linear-395                   [-1, 64]          65,536
            ReLU-396                   [-1, 64]               0
          Linear-397                 [-1, 1024]          65,536
         Sigmoid-398                 [-1, 1024]               0
         SELayer-399          [-1, 1024, 16, 8]               0
            ReLU-400          [-1, 1024, 16, 8]               0
      Bottleneck-401          [-1, 1024, 16, 8]               0
          Conv2d-402           [-1, 512, 16, 8]         524,288
     BatchNorm2d-403           [-1, 512, 16, 8]           1,024
            ReLU-404           [-1, 512, 16, 8]               0
          Conv2d-405           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-406           [-1, 512, 16, 8]           1,024
            ReLU-407           [-1, 512, 16, 8]               0
          Conv2d-408          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-409          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-410           [-1, 1024, 1, 1]               0
          Linear-411                   [-1, 64]          65,536
            ReLU-412                   [-1, 64]               0
          Linear-413                 [-1, 1024]          65,536
         Sigmoid-414                 [-1, 1024]               0
         SELayer-415          [-1, 1024, 16, 8]               0
            ReLU-416          [-1, 1024, 16, 8]               0
      Bottleneck-417          [-1, 1024, 16, 8]               0
          Conv2d-418           [-1, 512, 16, 8]         524,288
     BatchNorm2d-419           [-1, 512, 16, 8]           1,024
            ReLU-420           [-1, 512, 16, 8]               0
          Conv2d-421           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-422           [-1, 512, 16, 8]           1,024
            ReLU-423           [-1, 512, 16, 8]               0
          Conv2d-424          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-425          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-426           [-1, 1024, 1, 1]               0
          Linear-427                   [-1, 64]          65,536
            ReLU-428                   [-1, 64]               0
          Linear-429                 [-1, 1024]          65,536
         Sigmoid-430                 [-1, 1024]               0
         SELayer-431          [-1, 1024, 16, 8]               0
            ReLU-432          [-1, 1024, 16, 8]               0
      Bottleneck-433          [-1, 1024, 16, 8]               0
          Conv2d-434           [-1, 512, 16, 8]         524,288
     BatchNorm2d-435           [-1, 512, 16, 8]           1,024
            ReLU-436           [-1, 512, 16, 8]               0
          Conv2d-437           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-438           [-1, 512, 16, 8]           1,024
            ReLU-439           [-1, 512, 16, 8]               0
          Conv2d-440          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-441          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-442           [-1, 1024, 1, 1]               0
          Linear-443                   [-1, 64]          65,536
            ReLU-444                   [-1, 64]               0
          Linear-445                 [-1, 1024]          65,536
         Sigmoid-446                 [-1, 1024]               0
         SELayer-447          [-1, 1024, 16, 8]               0
            ReLU-448          [-1, 1024, 16, 8]               0
      Bottleneck-449          [-1, 1024, 16, 8]               0
          Conv2d-450           [-1, 512, 16, 8]         524,288
     BatchNorm2d-451           [-1, 512, 16, 8]           1,024
            ReLU-452           [-1, 512, 16, 8]               0
          Conv2d-453           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-454           [-1, 512, 16, 8]           1,024
            ReLU-455           [-1, 512, 16, 8]               0
          Conv2d-456          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-457          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-458           [-1, 1024, 1, 1]               0
          Linear-459                   [-1, 64]          65,536
            ReLU-460                   [-1, 64]               0
          Linear-461                 [-1, 1024]          65,536
         Sigmoid-462                 [-1, 1024]               0
         SELayer-463          [-1, 1024, 16, 8]               0
            ReLU-464          [-1, 1024, 16, 8]               0
      Bottleneck-465          [-1, 1024, 16, 8]               0
          Conv2d-466           [-1, 512, 16, 8]         524,288
     BatchNorm2d-467           [-1, 512, 16, 8]           1,024
            ReLU-468           [-1, 512, 16, 8]               0
          Conv2d-469           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-470           [-1, 512, 16, 8]           1,024
            ReLU-471           [-1, 512, 16, 8]               0
          Conv2d-472          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-473          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-474           [-1, 1024, 1, 1]               0
          Linear-475                   [-1, 64]          65,536
            ReLU-476                   [-1, 64]               0
          Linear-477                 [-1, 1024]          65,536
         Sigmoid-478                 [-1, 1024]               0
         SELayer-479          [-1, 1024, 16, 8]               0
            ReLU-480          [-1, 1024, 16, 8]               0
      Bottleneck-481          [-1, 1024, 16, 8]               0
          Conv2d-482           [-1, 512, 16, 8]         524,288
     BatchNorm2d-483           [-1, 512, 16, 8]           1,024
            ReLU-484           [-1, 512, 16, 8]               0
          Conv2d-485           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-486           [-1, 512, 16, 8]           1,024
            ReLU-487           [-1, 512, 16, 8]               0
          Conv2d-488          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-489          [-1, 1024, 16, 8]           2,048
AdaptiveAvgPool2d-490           [-1, 1024, 1, 1]               0
          Linear-491                   [-1, 64]          65,536
            ReLU-492                   [-1, 64]               0
          Linear-493                 [-1, 1024]          65,536
         Sigmoid-494                 [-1, 1024]               0
         SELayer-495          [-1, 1024, 16, 8]               0
            ReLU-496          [-1, 1024, 16, 8]               0
      Bottleneck-497          [-1, 1024, 16, 8]               0
          Conv2d-498          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-499          [-1, 1024, 16, 8]           2,048
            ReLU-500          [-1, 1024, 16, 8]               0
          Conv2d-501          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-502          [-1, 1024, 16, 8]           2,048
            ReLU-503          [-1, 1024, 16, 8]               0
          Conv2d-504          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-505          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-506           [-1, 2048, 1, 1]               0
          Linear-507                  [-1, 128]         262,144
            ReLU-508                  [-1, 128]               0
          Linear-509                 [-1, 2048]         262,144
         Sigmoid-510                 [-1, 2048]               0
         SELayer-511          [-1, 2048, 16, 8]               0
          Conv2d-512          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-513          [-1, 2048, 16, 8]           4,096
            ReLU-514          [-1, 2048, 16, 8]               0
      Bottleneck-515          [-1, 2048, 16, 8]               0
          Conv2d-516          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-517          [-1, 1024, 16, 8]           2,048
            ReLU-518          [-1, 1024, 16, 8]               0
          Conv2d-519          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-520          [-1, 1024, 16, 8]           2,048
            ReLU-521          [-1, 1024, 16, 8]               0
          Conv2d-522          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-523          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-524           [-1, 2048, 1, 1]               0
          Linear-525                  [-1, 128]         262,144
            ReLU-526                  [-1, 128]               0
          Linear-527                 [-1, 2048]         262,144
         Sigmoid-528                 [-1, 2048]               0
         SELayer-529          [-1, 2048, 16, 8]               0
            ReLU-530          [-1, 2048, 16, 8]               0
      Bottleneck-531          [-1, 2048, 16, 8]               0
          Conv2d-532          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-533          [-1, 1024, 16, 8]           2,048
            ReLU-534          [-1, 1024, 16, 8]               0
          Conv2d-535          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-536          [-1, 1024, 16, 8]           2,048
            ReLU-537          [-1, 1024, 16, 8]               0
          Conv2d-538          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-539          [-1, 2048, 16, 8]           4,096
AdaptiveAvgPool2d-540           [-1, 2048, 1, 1]               0
          Linear-541                  [-1, 128]         262,144
            ReLU-542                  [-1, 128]               0
          Linear-543                 [-1, 2048]         262,144
         Sigmoid-544                 [-1, 2048]               0
         SELayer-545          [-1, 2048, 16, 8]               0
            ReLU-546          [-1, 2048, 16, 8]               0
      Bottleneck-547          [-1, 2048, 16, 8]               0
================================================================
Total params: 129,586,496
Trainable params: 129,586,496
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 457.28
Params size (MB): 494.33
Estimated Total Size (MB): 951.98
----------------------------------------------------------------
**********************************************************************
**********************************************************************
wide_resnet101_2_ibn_a
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
       BatchNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
    InstanceNorm2d-6           [-1, 64, 64, 32]             128
       BatchNorm2d-7           [-1, 64, 64, 32]             128
               IBN-8          [-1, 128, 64, 32]               0
              ReLU-9          [-1, 128, 64, 32]               0
           Conv2d-10          [-1, 128, 64, 32]         147,456
      BatchNorm2d-11          [-1, 128, 64, 32]             256
             ReLU-12          [-1, 128, 64, 32]               0
           Conv2d-13          [-1, 256, 64, 32]          32,768
      BatchNorm2d-14          [-1, 256, 64, 32]             512
           Conv2d-15          [-1, 256, 64, 32]          16,384
      BatchNorm2d-16          [-1, 256, 64, 32]             512
             ReLU-17          [-1, 256, 64, 32]               0
       Bottleneck-18          [-1, 256, 64, 32]               0
           Conv2d-19          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-20           [-1, 64, 64, 32]             128
      BatchNorm2d-21           [-1, 64, 64, 32]             128
              IBN-22          [-1, 128, 64, 32]               0
             ReLU-23          [-1, 128, 64, 32]               0
           Conv2d-24          [-1, 128, 64, 32]         147,456
      BatchNorm2d-25          [-1, 128, 64, 32]             256
             ReLU-26          [-1, 128, 64, 32]               0
           Conv2d-27          [-1, 256, 64, 32]          32,768
      BatchNorm2d-28          [-1, 256, 64, 32]             512
             ReLU-29          [-1, 256, 64, 32]               0
       Bottleneck-30          [-1, 256, 64, 32]               0
           Conv2d-31          [-1, 128, 64, 32]          32,768
   InstanceNorm2d-32           [-1, 64, 64, 32]             128
      BatchNorm2d-33           [-1, 64, 64, 32]             128
              IBN-34          [-1, 128, 64, 32]               0
             ReLU-35          [-1, 128, 64, 32]               0
           Conv2d-36          [-1, 128, 64, 32]         147,456
      BatchNorm2d-37          [-1, 128, 64, 32]             256
             ReLU-38          [-1, 128, 64, 32]               0
           Conv2d-39          [-1, 256, 64, 32]          32,768
      BatchNorm2d-40          [-1, 256, 64, 32]             512
             ReLU-41          [-1, 256, 64, 32]               0
       Bottleneck-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 256, 64, 32]          65,536
   InstanceNorm2d-44          [-1, 128, 64, 32]             256
      BatchNorm2d-45          [-1, 128, 64, 32]             256
              IBN-46          [-1, 256, 64, 32]               0
             ReLU-47          [-1, 256, 64, 32]               0
           Conv2d-48          [-1, 256, 32, 16]         589,824
      BatchNorm2d-49          [-1, 256, 32, 16]             512
             ReLU-50          [-1, 256, 32, 16]               0
           Conv2d-51          [-1, 512, 32, 16]         131,072
      BatchNorm2d-52          [-1, 512, 32, 16]           1,024
           Conv2d-53          [-1, 512, 32, 16]         131,072
      BatchNorm2d-54          [-1, 512, 32, 16]           1,024
             ReLU-55          [-1, 512, 32, 16]               0
       Bottleneck-56          [-1, 512, 32, 16]               0
           Conv2d-57          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-58          [-1, 128, 32, 16]             256
      BatchNorm2d-59          [-1, 128, 32, 16]             256
              IBN-60          [-1, 256, 32, 16]               0
             ReLU-61          [-1, 256, 32, 16]               0
           Conv2d-62          [-1, 256, 32, 16]         589,824
      BatchNorm2d-63          [-1, 256, 32, 16]             512
             ReLU-64          [-1, 256, 32, 16]               0
           Conv2d-65          [-1, 512, 32, 16]         131,072
      BatchNorm2d-66          [-1, 512, 32, 16]           1,024
             ReLU-67          [-1, 512, 32, 16]               0
       Bottleneck-68          [-1, 512, 32, 16]               0
           Conv2d-69          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-70          [-1, 128, 32, 16]             256
      BatchNorm2d-71          [-1, 128, 32, 16]             256
              IBN-72          [-1, 256, 32, 16]               0
             ReLU-73          [-1, 256, 32, 16]               0
           Conv2d-74          [-1, 256, 32, 16]         589,824
      BatchNorm2d-75          [-1, 256, 32, 16]             512
             ReLU-76          [-1, 256, 32, 16]               0
           Conv2d-77          [-1, 512, 32, 16]         131,072
      BatchNorm2d-78          [-1, 512, 32, 16]           1,024
             ReLU-79          [-1, 512, 32, 16]               0
       Bottleneck-80          [-1, 512, 32, 16]               0
           Conv2d-81          [-1, 256, 32, 16]         131,072
   InstanceNorm2d-82          [-1, 128, 32, 16]             256
      BatchNorm2d-83          [-1, 128, 32, 16]             256
              IBN-84          [-1, 256, 32, 16]               0
             ReLU-85          [-1, 256, 32, 16]               0
           Conv2d-86          [-1, 256, 32, 16]         589,824
      BatchNorm2d-87          [-1, 256, 32, 16]             512
             ReLU-88          [-1, 256, 32, 16]               0
           Conv2d-89          [-1, 512, 32, 16]         131,072
      BatchNorm2d-90          [-1, 512, 32, 16]           1,024
             ReLU-91          [-1, 512, 32, 16]               0
       Bottleneck-92          [-1, 512, 32, 16]               0
           Conv2d-93          [-1, 512, 32, 16]         262,144
   InstanceNorm2d-94          [-1, 256, 32, 16]             512
      BatchNorm2d-95          [-1, 256, 32, 16]             512
              IBN-96          [-1, 512, 32, 16]               0
             ReLU-97          [-1, 512, 32, 16]               0
           Conv2d-98           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-99           [-1, 512, 16, 8]           1,024
            ReLU-100           [-1, 512, 16, 8]               0
          Conv2d-101          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-102          [-1, 1024, 16, 8]           2,048
          Conv2d-103          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-104          [-1, 1024, 16, 8]           2,048
            ReLU-105          [-1, 1024, 16, 8]               0
      Bottleneck-106          [-1, 1024, 16, 8]               0
          Conv2d-107           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-108           [-1, 256, 16, 8]             512
     BatchNorm2d-109           [-1, 256, 16, 8]             512
             IBN-110           [-1, 512, 16, 8]               0
            ReLU-111           [-1, 512, 16, 8]               0
          Conv2d-112           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-113           [-1, 512, 16, 8]           1,024
            ReLU-114           [-1, 512, 16, 8]               0
          Conv2d-115          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-116          [-1, 1024, 16, 8]           2,048
            ReLU-117          [-1, 1024, 16, 8]               0
      Bottleneck-118          [-1, 1024, 16, 8]               0
          Conv2d-119           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-120           [-1, 256, 16, 8]             512
     BatchNorm2d-121           [-1, 256, 16, 8]             512
             IBN-122           [-1, 512, 16, 8]               0
            ReLU-123           [-1, 512, 16, 8]               0
          Conv2d-124           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-125           [-1, 512, 16, 8]           1,024
            ReLU-126           [-1, 512, 16, 8]               0
          Conv2d-127          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-128          [-1, 1024, 16, 8]           2,048
            ReLU-129          [-1, 1024, 16, 8]               0
      Bottleneck-130          [-1, 1024, 16, 8]               0
          Conv2d-131           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-132           [-1, 256, 16, 8]             512
     BatchNorm2d-133           [-1, 256, 16, 8]             512
             IBN-134           [-1, 512, 16, 8]               0
            ReLU-135           [-1, 512, 16, 8]               0
          Conv2d-136           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-137           [-1, 512, 16, 8]           1,024
            ReLU-138           [-1, 512, 16, 8]               0
          Conv2d-139          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-140          [-1, 1024, 16, 8]           2,048
            ReLU-141          [-1, 1024, 16, 8]               0
      Bottleneck-142          [-1, 1024, 16, 8]               0
          Conv2d-143           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-144           [-1, 256, 16, 8]             512
     BatchNorm2d-145           [-1, 256, 16, 8]             512
             IBN-146           [-1, 512, 16, 8]               0
            ReLU-147           [-1, 512, 16, 8]               0
          Conv2d-148           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-149           [-1, 512, 16, 8]           1,024
            ReLU-150           [-1, 512, 16, 8]               0
          Conv2d-151          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-152          [-1, 1024, 16, 8]           2,048
            ReLU-153          [-1, 1024, 16, 8]               0
      Bottleneck-154          [-1, 1024, 16, 8]               0
          Conv2d-155           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-156           [-1, 256, 16, 8]             512
     BatchNorm2d-157           [-1, 256, 16, 8]             512
             IBN-158           [-1, 512, 16, 8]               0
            ReLU-159           [-1, 512, 16, 8]               0
          Conv2d-160           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-161           [-1, 512, 16, 8]           1,024
            ReLU-162           [-1, 512, 16, 8]               0
          Conv2d-163          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-164          [-1, 1024, 16, 8]           2,048
            ReLU-165          [-1, 1024, 16, 8]               0
      Bottleneck-166          [-1, 1024, 16, 8]               0
          Conv2d-167           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-168           [-1, 256, 16, 8]             512
     BatchNorm2d-169           [-1, 256, 16, 8]             512
             IBN-170           [-1, 512, 16, 8]               0
            ReLU-171           [-1, 512, 16, 8]               0
          Conv2d-172           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-173           [-1, 512, 16, 8]           1,024
            ReLU-174           [-1, 512, 16, 8]               0
          Conv2d-175          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-176          [-1, 1024, 16, 8]           2,048
            ReLU-177          [-1, 1024, 16, 8]               0
      Bottleneck-178          [-1, 1024, 16, 8]               0
          Conv2d-179           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-180           [-1, 256, 16, 8]             512
     BatchNorm2d-181           [-1, 256, 16, 8]             512
             IBN-182           [-1, 512, 16, 8]               0
            ReLU-183           [-1, 512, 16, 8]               0
          Conv2d-184           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-185           [-1, 512, 16, 8]           1,024
            ReLU-186           [-1, 512, 16, 8]               0
          Conv2d-187          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-188          [-1, 1024, 16, 8]           2,048
            ReLU-189          [-1, 1024, 16, 8]               0
      Bottleneck-190          [-1, 1024, 16, 8]               0
          Conv2d-191           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-192           [-1, 256, 16, 8]             512
     BatchNorm2d-193           [-1, 256, 16, 8]             512
             IBN-194           [-1, 512, 16, 8]               0
            ReLU-195           [-1, 512, 16, 8]               0
          Conv2d-196           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-197           [-1, 512, 16, 8]           1,024
            ReLU-198           [-1, 512, 16, 8]               0
          Conv2d-199          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-200          [-1, 1024, 16, 8]           2,048
            ReLU-201          [-1, 1024, 16, 8]               0
      Bottleneck-202          [-1, 1024, 16, 8]               0
          Conv2d-203           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-204           [-1, 256, 16, 8]             512
     BatchNorm2d-205           [-1, 256, 16, 8]             512
             IBN-206           [-1, 512, 16, 8]               0
            ReLU-207           [-1, 512, 16, 8]               0
          Conv2d-208           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-209           [-1, 512, 16, 8]           1,024
            ReLU-210           [-1, 512, 16, 8]               0
          Conv2d-211          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-212          [-1, 1024, 16, 8]           2,048
            ReLU-213          [-1, 1024, 16, 8]               0
      Bottleneck-214          [-1, 1024, 16, 8]               0
          Conv2d-215           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-216           [-1, 256, 16, 8]             512
     BatchNorm2d-217           [-1, 256, 16, 8]             512
             IBN-218           [-1, 512, 16, 8]               0
            ReLU-219           [-1, 512, 16, 8]               0
          Conv2d-220           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-221           [-1, 512, 16, 8]           1,024
            ReLU-222           [-1, 512, 16, 8]               0
          Conv2d-223          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-224          [-1, 1024, 16, 8]           2,048
            ReLU-225          [-1, 1024, 16, 8]               0
      Bottleneck-226          [-1, 1024, 16, 8]               0
          Conv2d-227           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-228           [-1, 256, 16, 8]             512
     BatchNorm2d-229           [-1, 256, 16, 8]             512
             IBN-230           [-1, 512, 16, 8]               0
            ReLU-231           [-1, 512, 16, 8]               0
          Conv2d-232           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-233           [-1, 512, 16, 8]           1,024
            ReLU-234           [-1, 512, 16, 8]               0
          Conv2d-235          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-236          [-1, 1024, 16, 8]           2,048
            ReLU-237          [-1, 1024, 16, 8]               0
      Bottleneck-238          [-1, 1024, 16, 8]               0
          Conv2d-239           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-240           [-1, 256, 16, 8]             512
     BatchNorm2d-241           [-1, 256, 16, 8]             512
             IBN-242           [-1, 512, 16, 8]               0
            ReLU-243           [-1, 512, 16, 8]               0
          Conv2d-244           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-245           [-1, 512, 16, 8]           1,024
            ReLU-246           [-1, 512, 16, 8]               0
          Conv2d-247          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-248          [-1, 1024, 16, 8]           2,048
            ReLU-249          [-1, 1024, 16, 8]               0
      Bottleneck-250          [-1, 1024, 16, 8]               0
          Conv2d-251           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-252           [-1, 256, 16, 8]             512
     BatchNorm2d-253           [-1, 256, 16, 8]             512
             IBN-254           [-1, 512, 16, 8]               0
            ReLU-255           [-1, 512, 16, 8]               0
          Conv2d-256           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-257           [-1, 512, 16, 8]           1,024
            ReLU-258           [-1, 512, 16, 8]               0
          Conv2d-259          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-260          [-1, 1024, 16, 8]           2,048
            ReLU-261          [-1, 1024, 16, 8]               0
      Bottleneck-262          [-1, 1024, 16, 8]               0
          Conv2d-263           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-264           [-1, 256, 16, 8]             512
     BatchNorm2d-265           [-1, 256, 16, 8]             512
             IBN-266           [-1, 512, 16, 8]               0
            ReLU-267           [-1, 512, 16, 8]               0
          Conv2d-268           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-269           [-1, 512, 16, 8]           1,024
            ReLU-270           [-1, 512, 16, 8]               0
          Conv2d-271          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-272          [-1, 1024, 16, 8]           2,048
            ReLU-273          [-1, 1024, 16, 8]               0
      Bottleneck-274          [-1, 1024, 16, 8]               0
          Conv2d-275           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-276           [-1, 256, 16, 8]             512
     BatchNorm2d-277           [-1, 256, 16, 8]             512
             IBN-278           [-1, 512, 16, 8]               0
            ReLU-279           [-1, 512, 16, 8]               0
          Conv2d-280           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-281           [-1, 512, 16, 8]           1,024
            ReLU-282           [-1, 512, 16, 8]               0
          Conv2d-283          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-284          [-1, 1024, 16, 8]           2,048
            ReLU-285          [-1, 1024, 16, 8]               0
      Bottleneck-286          [-1, 1024, 16, 8]               0
          Conv2d-287           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-288           [-1, 256, 16, 8]             512
     BatchNorm2d-289           [-1, 256, 16, 8]             512
             IBN-290           [-1, 512, 16, 8]               0
            ReLU-291           [-1, 512, 16, 8]               0
          Conv2d-292           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-293           [-1, 512, 16, 8]           1,024
            ReLU-294           [-1, 512, 16, 8]               0
          Conv2d-295          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-296          [-1, 1024, 16, 8]           2,048
            ReLU-297          [-1, 1024, 16, 8]               0
      Bottleneck-298          [-1, 1024, 16, 8]               0
          Conv2d-299           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-300           [-1, 256, 16, 8]             512
     BatchNorm2d-301           [-1, 256, 16, 8]             512
             IBN-302           [-1, 512, 16, 8]               0
            ReLU-303           [-1, 512, 16, 8]               0
          Conv2d-304           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-305           [-1, 512, 16, 8]           1,024
            ReLU-306           [-1, 512, 16, 8]               0
          Conv2d-307          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-308          [-1, 1024, 16, 8]           2,048
            ReLU-309          [-1, 1024, 16, 8]               0
      Bottleneck-310          [-1, 1024, 16, 8]               0
          Conv2d-311           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-312           [-1, 256, 16, 8]             512
     BatchNorm2d-313           [-1, 256, 16, 8]             512
             IBN-314           [-1, 512, 16, 8]               0
            ReLU-315           [-1, 512, 16, 8]               0
          Conv2d-316           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-317           [-1, 512, 16, 8]           1,024
            ReLU-318           [-1, 512, 16, 8]               0
          Conv2d-319          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-320          [-1, 1024, 16, 8]           2,048
            ReLU-321          [-1, 1024, 16, 8]               0
      Bottleneck-322          [-1, 1024, 16, 8]               0
          Conv2d-323           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-324           [-1, 256, 16, 8]             512
     BatchNorm2d-325           [-1, 256, 16, 8]             512
             IBN-326           [-1, 512, 16, 8]               0
            ReLU-327           [-1, 512, 16, 8]               0
          Conv2d-328           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-329           [-1, 512, 16, 8]           1,024
            ReLU-330           [-1, 512, 16, 8]               0
          Conv2d-331          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-332          [-1, 1024, 16, 8]           2,048
            ReLU-333          [-1, 1024, 16, 8]               0
      Bottleneck-334          [-1, 1024, 16, 8]               0
          Conv2d-335           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-336           [-1, 256, 16, 8]             512
     BatchNorm2d-337           [-1, 256, 16, 8]             512
             IBN-338           [-1, 512, 16, 8]               0
            ReLU-339           [-1, 512, 16, 8]               0
          Conv2d-340           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-341           [-1, 512, 16, 8]           1,024
            ReLU-342           [-1, 512, 16, 8]               0
          Conv2d-343          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-344          [-1, 1024, 16, 8]           2,048
            ReLU-345          [-1, 1024, 16, 8]               0
      Bottleneck-346          [-1, 1024, 16, 8]               0
          Conv2d-347           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-348           [-1, 256, 16, 8]             512
     BatchNorm2d-349           [-1, 256, 16, 8]             512
             IBN-350           [-1, 512, 16, 8]               0
            ReLU-351           [-1, 512, 16, 8]               0
          Conv2d-352           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-353           [-1, 512, 16, 8]           1,024
            ReLU-354           [-1, 512, 16, 8]               0
          Conv2d-355          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-356          [-1, 1024, 16, 8]           2,048
            ReLU-357          [-1, 1024, 16, 8]               0
      Bottleneck-358          [-1, 1024, 16, 8]               0
          Conv2d-359           [-1, 512, 16, 8]         524,288
  InstanceNorm2d-360           [-1, 256, 16, 8]             512
     BatchNorm2d-361           [-1, 256, 16, 8]             512
             IBN-362           [-1, 512, 16, 8]               0
            ReLU-363           [-1, 512, 16, 8]               0
          Conv2d-364           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-365           [-1, 512, 16, 8]           1,024
            ReLU-366           [-1, 512, 16, 8]               0
          Conv2d-367          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-368          [-1, 1024, 16, 8]           2,048
            ReLU-369          [-1, 1024, 16, 8]               0
      Bottleneck-370          [-1, 1024, 16, 8]               0
          Conv2d-371          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-372          [-1, 1024, 16, 8]           2,048
            ReLU-373          [-1, 1024, 16, 8]               0
          Conv2d-374          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-375          [-1, 1024, 16, 8]           2,048
            ReLU-376          [-1, 1024, 16, 8]               0
          Conv2d-377          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-378          [-1, 2048, 16, 8]           4,096
          Conv2d-379          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-380          [-1, 2048, 16, 8]           4,096
            ReLU-381          [-1, 2048, 16, 8]               0
      Bottleneck-382          [-1, 2048, 16, 8]               0
          Conv2d-383          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-384          [-1, 1024, 16, 8]           2,048
            ReLU-385          [-1, 1024, 16, 8]               0
          Conv2d-386          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-387          [-1, 1024, 16, 8]           2,048
            ReLU-388          [-1, 1024, 16, 8]               0
          Conv2d-389          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-390          [-1, 2048, 16, 8]           4,096
            ReLU-391          [-1, 2048, 16, 8]               0
      Bottleneck-392          [-1, 2048, 16, 8]               0
          Conv2d-393          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-394          [-1, 1024, 16, 8]           2,048
            ReLU-395          [-1, 1024, 16, 8]               0
          Conv2d-396          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-397          [-1, 1024, 16, 8]           2,048
            ReLU-398          [-1, 1024, 16, 8]               0
          Conv2d-399          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-400          [-1, 2048, 16, 8]           4,096
            ReLU-401          [-1, 2048, 16, 8]               0
      Bottleneck-402          [-1, 2048, 16, 8]               0
================================================================
Total params: 124,837,696
Trainable params: 124,837,696
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 413.50
Params size (MB): 476.22
Estimated Total Size (MB): 890.09
----------------------------------------------------------------
**********************************************************************
**********************************************************************
wide_resnet101_2_ibn_b
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 64, 128, 64]           9,408
    InstanceNorm2d-2          [-1, 64, 128, 64]             128
              ReLU-3          [-1, 64, 128, 64]               0
         MaxPool2d-4           [-1, 64, 64, 32]               0
            Conv2d-5          [-1, 128, 64, 32]           8,192
       BatchNorm2d-6          [-1, 128, 64, 32]             256
              ReLU-7          [-1, 128, 64, 32]               0
            Conv2d-8          [-1, 128, 64, 32]         147,456
       BatchNorm2d-9          [-1, 128, 64, 32]             256
             ReLU-10          [-1, 128, 64, 32]               0
           Conv2d-11          [-1, 256, 64, 32]          32,768
      BatchNorm2d-12          [-1, 256, 64, 32]             512
           Conv2d-13          [-1, 256, 64, 32]          16,384
      BatchNorm2d-14          [-1, 256, 64, 32]             512
   InstanceNorm2d-15          [-1, 256, 64, 32]             512
             ReLU-16          [-1, 256, 64, 32]               0
       Bottleneck-17          [-1, 256, 64, 32]               0
           Conv2d-18          [-1, 128, 64, 32]          32,768
      BatchNorm2d-19          [-1, 128, 64, 32]             256
             ReLU-20          [-1, 128, 64, 32]               0
           Conv2d-21          [-1, 128, 64, 32]         147,456
      BatchNorm2d-22          [-1, 128, 64, 32]             256
             ReLU-23          [-1, 128, 64, 32]               0
           Conv2d-24          [-1, 256, 64, 32]          32,768
      BatchNorm2d-25          [-1, 256, 64, 32]             512
   InstanceNorm2d-26          [-1, 256, 64, 32]             512
             ReLU-27          [-1, 256, 64, 32]               0
       Bottleneck-28          [-1, 256, 64, 32]               0
           Conv2d-29          [-1, 128, 64, 32]          32,768
      BatchNorm2d-30          [-1, 128, 64, 32]             256
             ReLU-31          [-1, 128, 64, 32]               0
           Conv2d-32          [-1, 128, 64, 32]         147,456
      BatchNorm2d-33          [-1, 128, 64, 32]             256
             ReLU-34          [-1, 128, 64, 32]               0
           Conv2d-35          [-1, 256, 64, 32]          32,768
      BatchNorm2d-36          [-1, 256, 64, 32]             512
   InstanceNorm2d-37          [-1, 256, 64, 32]             512
             ReLU-38          [-1, 256, 64, 32]               0
       Bottleneck-39          [-1, 256, 64, 32]               0
           Conv2d-40          [-1, 256, 64, 32]          65,536
      BatchNorm2d-41          [-1, 256, 64, 32]             512
             ReLU-42          [-1, 256, 64, 32]               0
           Conv2d-43          [-1, 256, 32, 16]         589,824
      BatchNorm2d-44          [-1, 256, 32, 16]             512
             ReLU-45          [-1, 256, 32, 16]               0
           Conv2d-46          [-1, 512, 32, 16]         131,072
      BatchNorm2d-47          [-1, 512, 32, 16]           1,024
           Conv2d-48          [-1, 512, 32, 16]         131,072
      BatchNorm2d-49          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-50          [-1, 512, 32, 16]           1,024
             ReLU-51          [-1, 512, 32, 16]               0
       Bottleneck-52          [-1, 512, 32, 16]               0
           Conv2d-53          [-1, 256, 32, 16]         131,072
      BatchNorm2d-54          [-1, 256, 32, 16]             512
             ReLU-55          [-1, 256, 32, 16]               0
           Conv2d-56          [-1, 256, 32, 16]         589,824
      BatchNorm2d-57          [-1, 256, 32, 16]             512
             ReLU-58          [-1, 256, 32, 16]               0
           Conv2d-59          [-1, 512, 32, 16]         131,072
      BatchNorm2d-60          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-61          [-1, 512, 32, 16]           1,024
             ReLU-62          [-1, 512, 32, 16]               0
       Bottleneck-63          [-1, 512, 32, 16]               0
           Conv2d-64          [-1, 256, 32, 16]         131,072
      BatchNorm2d-65          [-1, 256, 32, 16]             512
             ReLU-66          [-1, 256, 32, 16]               0
           Conv2d-67          [-1, 256, 32, 16]         589,824
      BatchNorm2d-68          [-1, 256, 32, 16]             512
             ReLU-69          [-1, 256, 32, 16]               0
           Conv2d-70          [-1, 512, 32, 16]         131,072
      BatchNorm2d-71          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-72          [-1, 512, 32, 16]           1,024
             ReLU-73          [-1, 512, 32, 16]               0
       Bottleneck-74          [-1, 512, 32, 16]               0
           Conv2d-75          [-1, 256, 32, 16]         131,072
      BatchNorm2d-76          [-1, 256, 32, 16]             512
             ReLU-77          [-1, 256, 32, 16]               0
           Conv2d-78          [-1, 256, 32, 16]         589,824
      BatchNorm2d-79          [-1, 256, 32, 16]             512
             ReLU-80          [-1, 256, 32, 16]               0
           Conv2d-81          [-1, 512, 32, 16]         131,072
      BatchNorm2d-82          [-1, 512, 32, 16]           1,024
   InstanceNorm2d-83          [-1, 512, 32, 16]           1,024
             ReLU-84          [-1, 512, 32, 16]               0
       Bottleneck-85          [-1, 512, 32, 16]               0
           Conv2d-86          [-1, 512, 32, 16]         262,144
      BatchNorm2d-87          [-1, 512, 32, 16]           1,024
             ReLU-88          [-1, 512, 32, 16]               0
           Conv2d-89           [-1, 512, 16, 8]       2,359,296
      BatchNorm2d-90           [-1, 512, 16, 8]           1,024
             ReLU-91           [-1, 512, 16, 8]               0
           Conv2d-92          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-93          [-1, 1024, 16, 8]           2,048
           Conv2d-94          [-1, 1024, 16, 8]         524,288
      BatchNorm2d-95          [-1, 1024, 16, 8]           2,048
             ReLU-96          [-1, 1024, 16, 8]               0
       Bottleneck-97          [-1, 1024, 16, 8]               0
           Conv2d-98           [-1, 512, 16, 8]         524,288
      BatchNorm2d-99           [-1, 512, 16, 8]           1,024
            ReLU-100           [-1, 512, 16, 8]               0
          Conv2d-101           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-102           [-1, 512, 16, 8]           1,024
            ReLU-103           [-1, 512, 16, 8]               0
          Conv2d-104          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-105          [-1, 1024, 16, 8]           2,048
            ReLU-106          [-1, 1024, 16, 8]               0
      Bottleneck-107          [-1, 1024, 16, 8]               0
          Conv2d-108           [-1, 512, 16, 8]         524,288
     BatchNorm2d-109           [-1, 512, 16, 8]           1,024
            ReLU-110           [-1, 512, 16, 8]               0
          Conv2d-111           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-112           [-1, 512, 16, 8]           1,024
            ReLU-113           [-1, 512, 16, 8]               0
          Conv2d-114          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-115          [-1, 1024, 16, 8]           2,048
            ReLU-116          [-1, 1024, 16, 8]               0
      Bottleneck-117          [-1, 1024, 16, 8]               0
          Conv2d-118           [-1, 512, 16, 8]         524,288
     BatchNorm2d-119           [-1, 512, 16, 8]           1,024
            ReLU-120           [-1, 512, 16, 8]               0
          Conv2d-121           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-122           [-1, 512, 16, 8]           1,024
            ReLU-123           [-1, 512, 16, 8]               0
          Conv2d-124          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-125          [-1, 1024, 16, 8]           2,048
            ReLU-126          [-1, 1024, 16, 8]               0
      Bottleneck-127          [-1, 1024, 16, 8]               0
          Conv2d-128           [-1, 512, 16, 8]         524,288
     BatchNorm2d-129           [-1, 512, 16, 8]           1,024
            ReLU-130           [-1, 512, 16, 8]               0
          Conv2d-131           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-132           [-1, 512, 16, 8]           1,024
            ReLU-133           [-1, 512, 16, 8]               0
          Conv2d-134          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-135          [-1, 1024, 16, 8]           2,048
            ReLU-136          [-1, 1024, 16, 8]               0
      Bottleneck-137          [-1, 1024, 16, 8]               0
          Conv2d-138           [-1, 512, 16, 8]         524,288
     BatchNorm2d-139           [-1, 512, 16, 8]           1,024
            ReLU-140           [-1, 512, 16, 8]               0
          Conv2d-141           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-142           [-1, 512, 16, 8]           1,024
            ReLU-143           [-1, 512, 16, 8]               0
          Conv2d-144          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-145          [-1, 1024, 16, 8]           2,048
            ReLU-146          [-1, 1024, 16, 8]               0
      Bottleneck-147          [-1, 1024, 16, 8]               0
          Conv2d-148           [-1, 512, 16, 8]         524,288
     BatchNorm2d-149           [-1, 512, 16, 8]           1,024
            ReLU-150           [-1, 512, 16, 8]               0
          Conv2d-151           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-152           [-1, 512, 16, 8]           1,024
            ReLU-153           [-1, 512, 16, 8]               0
          Conv2d-154          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-155          [-1, 1024, 16, 8]           2,048
            ReLU-156          [-1, 1024, 16, 8]               0
      Bottleneck-157          [-1, 1024, 16, 8]               0
          Conv2d-158           [-1, 512, 16, 8]         524,288
     BatchNorm2d-159           [-1, 512, 16, 8]           1,024
            ReLU-160           [-1, 512, 16, 8]               0
          Conv2d-161           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-162           [-1, 512, 16, 8]           1,024
            ReLU-163           [-1, 512, 16, 8]               0
          Conv2d-164          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-165          [-1, 1024, 16, 8]           2,048
            ReLU-166          [-1, 1024, 16, 8]               0
      Bottleneck-167          [-1, 1024, 16, 8]               0
          Conv2d-168           [-1, 512, 16, 8]         524,288
     BatchNorm2d-169           [-1, 512, 16, 8]           1,024
            ReLU-170           [-1, 512, 16, 8]               0
          Conv2d-171           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-172           [-1, 512, 16, 8]           1,024
            ReLU-173           [-1, 512, 16, 8]               0
          Conv2d-174          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-175          [-1, 1024, 16, 8]           2,048
            ReLU-176          [-1, 1024, 16, 8]               0
      Bottleneck-177          [-1, 1024, 16, 8]               0
          Conv2d-178           [-1, 512, 16, 8]         524,288
     BatchNorm2d-179           [-1, 512, 16, 8]           1,024
            ReLU-180           [-1, 512, 16, 8]               0
          Conv2d-181           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-182           [-1, 512, 16, 8]           1,024
            ReLU-183           [-1, 512, 16, 8]               0
          Conv2d-184          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-185          [-1, 1024, 16, 8]           2,048
            ReLU-186          [-1, 1024, 16, 8]               0
      Bottleneck-187          [-1, 1024, 16, 8]               0
          Conv2d-188           [-1, 512, 16, 8]         524,288
     BatchNorm2d-189           [-1, 512, 16, 8]           1,024
            ReLU-190           [-1, 512, 16, 8]               0
          Conv2d-191           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-192           [-1, 512, 16, 8]           1,024
            ReLU-193           [-1, 512, 16, 8]               0
          Conv2d-194          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-195          [-1, 1024, 16, 8]           2,048
            ReLU-196          [-1, 1024, 16, 8]               0
      Bottleneck-197          [-1, 1024, 16, 8]               0
          Conv2d-198           [-1, 512, 16, 8]         524,288
     BatchNorm2d-199           [-1, 512, 16, 8]           1,024
            ReLU-200           [-1, 512, 16, 8]               0
          Conv2d-201           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-202           [-1, 512, 16, 8]           1,024
            ReLU-203           [-1, 512, 16, 8]               0
          Conv2d-204          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-205          [-1, 1024, 16, 8]           2,048
            ReLU-206          [-1, 1024, 16, 8]               0
      Bottleneck-207          [-1, 1024, 16, 8]               0
          Conv2d-208           [-1, 512, 16, 8]         524,288
     BatchNorm2d-209           [-1, 512, 16, 8]           1,024
            ReLU-210           [-1, 512, 16, 8]               0
          Conv2d-211           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-212           [-1, 512, 16, 8]           1,024
            ReLU-213           [-1, 512, 16, 8]               0
          Conv2d-214          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-215          [-1, 1024, 16, 8]           2,048
            ReLU-216          [-1, 1024, 16, 8]               0
      Bottleneck-217          [-1, 1024, 16, 8]               0
          Conv2d-218           [-1, 512, 16, 8]         524,288
     BatchNorm2d-219           [-1, 512, 16, 8]           1,024
            ReLU-220           [-1, 512, 16, 8]               0
          Conv2d-221           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-222           [-1, 512, 16, 8]           1,024
            ReLU-223           [-1, 512, 16, 8]               0
          Conv2d-224          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-225          [-1, 1024, 16, 8]           2,048
            ReLU-226          [-1, 1024, 16, 8]               0
      Bottleneck-227          [-1, 1024, 16, 8]               0
          Conv2d-228           [-1, 512, 16, 8]         524,288
     BatchNorm2d-229           [-1, 512, 16, 8]           1,024
            ReLU-230           [-1, 512, 16, 8]               0
          Conv2d-231           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-232           [-1, 512, 16, 8]           1,024
            ReLU-233           [-1, 512, 16, 8]               0
          Conv2d-234          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-235          [-1, 1024, 16, 8]           2,048
            ReLU-236          [-1, 1024, 16, 8]               0
      Bottleneck-237          [-1, 1024, 16, 8]               0
          Conv2d-238           [-1, 512, 16, 8]         524,288
     BatchNorm2d-239           [-1, 512, 16, 8]           1,024
            ReLU-240           [-1, 512, 16, 8]               0
          Conv2d-241           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-242           [-1, 512, 16, 8]           1,024
            ReLU-243           [-1, 512, 16, 8]               0
          Conv2d-244          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-245          [-1, 1024, 16, 8]           2,048
            ReLU-246          [-1, 1024, 16, 8]               0
      Bottleneck-247          [-1, 1024, 16, 8]               0
          Conv2d-248           [-1, 512, 16, 8]         524,288
     BatchNorm2d-249           [-1, 512, 16, 8]           1,024
            ReLU-250           [-1, 512, 16, 8]               0
          Conv2d-251           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-252           [-1, 512, 16, 8]           1,024
            ReLU-253           [-1, 512, 16, 8]               0
          Conv2d-254          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-255          [-1, 1024, 16, 8]           2,048
            ReLU-256          [-1, 1024, 16, 8]               0
      Bottleneck-257          [-1, 1024, 16, 8]               0
          Conv2d-258           [-1, 512, 16, 8]         524,288
     BatchNorm2d-259           [-1, 512, 16, 8]           1,024
            ReLU-260           [-1, 512, 16, 8]               0
          Conv2d-261           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-262           [-1, 512, 16, 8]           1,024
            ReLU-263           [-1, 512, 16, 8]               0
          Conv2d-264          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-265          [-1, 1024, 16, 8]           2,048
            ReLU-266          [-1, 1024, 16, 8]               0
      Bottleneck-267          [-1, 1024, 16, 8]               0
          Conv2d-268           [-1, 512, 16, 8]         524,288
     BatchNorm2d-269           [-1, 512, 16, 8]           1,024
            ReLU-270           [-1, 512, 16, 8]               0
          Conv2d-271           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-272           [-1, 512, 16, 8]           1,024
            ReLU-273           [-1, 512, 16, 8]               0
          Conv2d-274          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-275          [-1, 1024, 16, 8]           2,048
            ReLU-276          [-1, 1024, 16, 8]               0
      Bottleneck-277          [-1, 1024, 16, 8]               0
          Conv2d-278           [-1, 512, 16, 8]         524,288
     BatchNorm2d-279           [-1, 512, 16, 8]           1,024
            ReLU-280           [-1, 512, 16, 8]               0
          Conv2d-281           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-282           [-1, 512, 16, 8]           1,024
            ReLU-283           [-1, 512, 16, 8]               0
          Conv2d-284          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-285          [-1, 1024, 16, 8]           2,048
            ReLU-286          [-1, 1024, 16, 8]               0
      Bottleneck-287          [-1, 1024, 16, 8]               0
          Conv2d-288           [-1, 512, 16, 8]         524,288
     BatchNorm2d-289           [-1, 512, 16, 8]           1,024
            ReLU-290           [-1, 512, 16, 8]               0
          Conv2d-291           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-292           [-1, 512, 16, 8]           1,024
            ReLU-293           [-1, 512, 16, 8]               0
          Conv2d-294          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-295          [-1, 1024, 16, 8]           2,048
            ReLU-296          [-1, 1024, 16, 8]               0
      Bottleneck-297          [-1, 1024, 16, 8]               0
          Conv2d-298           [-1, 512, 16, 8]         524,288
     BatchNorm2d-299           [-1, 512, 16, 8]           1,024
            ReLU-300           [-1, 512, 16, 8]               0
          Conv2d-301           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-302           [-1, 512, 16, 8]           1,024
            ReLU-303           [-1, 512, 16, 8]               0
          Conv2d-304          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-305          [-1, 1024, 16, 8]           2,048
            ReLU-306          [-1, 1024, 16, 8]               0
      Bottleneck-307          [-1, 1024, 16, 8]               0
          Conv2d-308           [-1, 512, 16, 8]         524,288
     BatchNorm2d-309           [-1, 512, 16, 8]           1,024
            ReLU-310           [-1, 512, 16, 8]               0
          Conv2d-311           [-1, 512, 16, 8]       2,359,296
     BatchNorm2d-312           [-1, 512, 16, 8]           1,024
            ReLU-313           [-1, 512, 16, 8]               0
          Conv2d-314          [-1, 1024, 16, 8]         524,288
     BatchNorm2d-315          [-1, 1024, 16, 8]           2,048
            ReLU-316          [-1, 1024, 16, 8]               0
      Bottleneck-317          [-1, 1024, 16, 8]               0
          Conv2d-318          [-1, 1024, 16, 8]       1,048,576
     BatchNorm2d-319          [-1, 1024, 16, 8]           2,048
            ReLU-320          [-1, 1024, 16, 8]               0
          Conv2d-321          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-322          [-1, 1024, 16, 8]           2,048
            ReLU-323          [-1, 1024, 16, 8]               0
          Conv2d-324          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-325          [-1, 2048, 16, 8]           4,096
          Conv2d-326          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-327          [-1, 2048, 16, 8]           4,096
            ReLU-328          [-1, 2048, 16, 8]               0
      Bottleneck-329          [-1, 2048, 16, 8]               0
          Conv2d-330          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-331          [-1, 1024, 16, 8]           2,048
            ReLU-332          [-1, 1024, 16, 8]               0
          Conv2d-333          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-334          [-1, 1024, 16, 8]           2,048
            ReLU-335          [-1, 1024, 16, 8]               0
          Conv2d-336          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-337          [-1, 2048, 16, 8]           4,096
            ReLU-338          [-1, 2048, 16, 8]               0
      Bottleneck-339          [-1, 2048, 16, 8]               0
          Conv2d-340          [-1, 1024, 16, 8]       2,097,152
     BatchNorm2d-341          [-1, 1024, 16, 8]           2,048
            ReLU-342          [-1, 1024, 16, 8]               0
          Conv2d-343          [-1, 1024, 16, 8]       9,437,184
     BatchNorm2d-344          [-1, 1024, 16, 8]           2,048
            ReLU-345          [-1, 1024, 16, 8]               0
          Conv2d-346          [-1, 2048, 16, 8]       2,097,152
     BatchNorm2d-347          [-1, 2048, 16, 8]           4,096
            ReLU-348          [-1, 2048, 16, 8]               0
      Bottleneck-349          [-1, 2048, 16, 8]               0
================================================================
Total params: 124,843,328
Trainable params: 124,843,328
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 407.50
Params size (MB): 476.24
Estimated Total Size (MB): 884.11
----------------------------------------------------------------
